---
title: ML概述
mathjax: true
date: 2021-06-03 10:16:47
tags: AI
---

&nbsp;

<!-- more -->

<!-- toc -->

&nbsp;

[浙大2021-机器学习 胡浩基](https://www.bilibili.com/video/BV1qf4y1x7kB)

&nbsp;

# 1.定义

1. 非显著式编程：如规定行为和收益函数，让计算机自行寻找最大收益，这种通过经验和数据自动学习。
2. 定义：对任务T，随着经验E增加，性能P提高。

&nbsp;

# 2.分类

按照任务性质区分：

1. 监督学习：使用数据和标签（人工提供）
	1. 传统监督学习：每个数据都有标签（SVM、NN、DNN）
	2. 非监督学习：数据都无标签（聚类、EM算法、PCA）
	3. 半监督学习：部分数据有标签
	4. 另一种区分监督学习的方法是基于标签的固有属性：分类（标签值离散）和回归（标签值连续）；但因离散与连续颇有联系，故本区分并不严格
2. 强化学习：经验是计算机与环境互动得来；计算机产生行为，我们只需定义收益函数

&nbsp;

# 3.过程

1. 特征提取：对数据感性观察得出可能的影响因素，并将其数量化；提取特征十分重要，但因媒质、任务不同，提取方法各不相同，故ML更注重后续算法的研究
2. 特征选择：选出以上结果中区分度高的特征
3. 特征整理：如选出两种特征，就将其处理后（如归一化）放入二维空间，一个dimension表示一种特征，这个二维空间就是特征空间
4. 算法选择与训练：训练结果会分割特征空间，结果一旦确定，训练结束，就可以用来预测新的样例了（不同算法自然划分结果不同）
5. 测试：多个算法结果测试后选择最优算法

注：ML的意义：解决高维空间的划分