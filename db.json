{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"themes/Chic/source/favicon.ico","path":"favicon.ico","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/base.styl","path":"css/base.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/custom.styl","path":"css/custom.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/font.styl","path":"css/font.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/media.styl","path":"css/media.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/layout.styl","path":"css/layout.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/normalize.styl","path":"css/normalize.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/css/variable.styl","path":"css/variable.styl","modified":0,"renderable":1},{"_id":"themes/Chic/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/Chic/source/js/tocbot.min.js","path":"js/tocbot.min.js","modified":0,"renderable":1},{"_id":"themes/Chic/source/js/mathjax2.7.5.js","path":"js/mathjax2.7.5.js","modified":0,"renderable":1},{"_id":"themes/Chic/source/image/avatar.jpg","path":"image/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/Chic/source/image/QQ.jpg","path":"image/QQ.jpg","modified":0,"renderable":1},{"_id":"source/static/images/avatar.jpg","path":"static/images/avatar.jpg","modified":0,"renderable":0},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.css","path":"fonts/iconfont/iconfont.css","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/demo.css","path":"fonts/iconfont/demo.css","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.json","path":"fonts/iconfont/iconfont.json","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.eot","path":"fonts/iconfont/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/demo_index.html","path":"fonts/iconfont/demo_index.html","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.svg","path":"fonts/iconfont/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.ttf","path":"fonts/iconfont/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.js","path":"fonts/iconfont/iconfont.js","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.woff","path":"fonts/iconfont/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.woff2","path":"fonts/iconfont/iconfont.woff2","modified":0,"renderable":1},{"_id":"source/static/images/background.jpg","path":"static/images/background.jpg","modified":0,"renderable":0},{"_id":"themes/Chic/source/fonts/lanting/lanting.woff2","path":"fonts/lanting/lanting.woff2","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/lanting/lanting.woff","path":"fonts/lanting/lanting.woff","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/lanting/lanting.eot","path":"fonts/lanting/lanting.eot","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/lanting/lanting.TTF","path":"fonts/lanting/lanting.TTF","modified":0,"renderable":1},{"_id":"themes/Chic/source/fonts/lanting/lanting.otf","path":"fonts/lanting/lanting.otf","modified":0,"renderable":1}],"Cache":[{"_id":"themes/Chic/LICENSE.md","hash":"632b916dd7e4f5c11790ab808388cda6610210ed","modified":1591448572239},{"_id":"themes/Chic/_config.yml","hash":"6f44132973b894ac6632766cbdc436ba8c246df7","modified":1594738534299},{"_id":"themes/Chic/package.json","hash":"55d477f0e6c76fa767b782ca0f5e0fede8d2ea28","modified":1591448572253},{"_id":"themes/Chic/README.md","hash":"b33e7d4a20dde46667050db2fb14c783fcd1a6c7","modified":1591448572240},{"_id":"themes/Chic/ChangeLogs.md","hash":"fab83fcf3eda5cc5b4a6092554e4c57b3a36630e","modified":1591448572238},{"_id":"themes/Chic/README-CN.md","hash":"e0b616b7546d05a50bd7bf046858af8e221fd0fc","modified":1591448572239},{"_id":"themes/Chic/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1591448572243},{"_id":"themes/Chic/languages/de.yml","hash":"d45cea36c5c83d7d09afcd1c26fff4a4c513c25b","modified":1591448572242},{"_id":"themes/Chic/languages/es.yml","hash":"e3b4937da4cd2d0393b8a0ba310e70fc605cc431","modified":1591448572243},{"_id":"themes/Chic/languages/fr.yml","hash":"8cb0fe4b6913b4d5b662cdd0108a923c90025f85","modified":1591448572243},{"_id":"themes/Chic/languages/ja.yml","hash":"3e2fedca096678c0c234ebffa4637828979296fa","modified":1591448572244},{"_id":"themes/Chic/languages/ko.yml","hash":"11330316e3c1262474a2b496e40dbc29f93fe01b","modified":1591448572244},{"_id":"themes/Chic/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1591448572244},{"_id":"themes/Chic/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1591448572245},{"_id":"themes/Chic/languages/pt.yml","hash":"ae2c61b30e638f74f1a42c9ce39ac08d063b30f5","modified":1591448572245},{"_id":"themes/Chic/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1591448572245},{"_id":"themes/Chic/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1591448572245},{"_id":"themes/Chic/languages/zh-TW.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1591448572246},{"_id":"themes/Chic/layout/archive.ejs","hash":"48cdf67b628eb6a1c24d484ed252f5b0e3f06ddf","modified":1591448572250},{"_id":"themes/Chic/layout/category.ejs","hash":"78c93c3a13f9678fa0f27061fa3a91a82edbcc17","modified":1591448572250},{"_id":"themes/Chic/layout/index.ejs","hash":"b44f40dd5b866e1d6a840654aa8323054f061dac","modified":1591448572250},{"_id":"themes/Chic/layout/layout.ejs","hash":"c2ab5ebca1c0f7ac2fa7e5999f95788861dcefd7","modified":1591448572251},{"_id":"themes/Chic/layout/page.ejs","hash":"92c2d419faea7ec7d984a3d960f5668608d36842","modified":1591448572251},{"_id":"themes/Chic/layout/tag.ejs","hash":"f6a48442749c2a743e47fde26bddabaaa2d7d95b","modified":1591448572252},{"_id":"themes/Chic/layout/post.ejs","hash":"a23f83d6c559ce88588472267468a54488d50e8e","modified":1591448572252},{"_id":"themes/Chic/scripts/imageTag.js","hash":"21c67e132584333eaa7b0c015fdd37d2e56ea934","modified":1591448572253},{"_id":"themes/Chic/source/favicon.ico","hash":"4f249bf78e4236db9e235e94bcab89bb5aeb0786","modified":1582778266450},{"_id":"source/_posts/DES和分组密码工作模式.md","hash":"8270d40eb38966119800db408491bf883b67966c","modified":1592790119449},{"_id":"source/_posts/MD5.md","hash":"16155b6bd70edf4b3dc7bc454c9a0504a2811cd3","modified":1594738038229},{"_id":"source/_posts/AdaBound.md","hash":"51ba964f8af61bb7ec87d01c2a6b1f3d85738e4e","modified":1592482633551},{"_id":"source/_posts/MDNet.md","hash":"ed05e452b877b64ead5e78b8f2277f49c55e05e9","modified":1592482685249},{"_id":"source/_posts/CS231n笔记.md","hash":"6f075f5dc3aa64ba4257f643e611cfd3044983f7","modified":1592483228737},{"_id":"source/_posts/Android总结1.md","hash":"e1c6db7342efa510f7c0d50c4534442ea14aca31","modified":1594738055775},{"_id":"source/_posts/RSA.md","hash":"beadcc0b144c8f074c296dabe5b7768a3ec3147b","modified":1594738024633},{"_id":"source/_posts/SiamDW.md","hash":"6a8d48e72cdee9aa078b5593e71ad3f0c3c28485","modified":1594738010373},{"_id":"source/_posts/RT-MDNet.md","hash":"509c3f922a445621b4e719fdb24aa3566d181e36","modified":1592482004436},{"_id":"source/_posts/Siamese系列.md","hash":"899b32ef1c377b824c33ffaadabaad956e49a105","modified":1592482238468},{"_id":"source/_posts/英语3：名词从句.md","hash":"451e91473e51f904310bbcf31e4985c92f170462","modified":1592313164256},{"_id":"source/_posts/英语4：定语和定语从句.md","hash":"2fcb560ddfa0532a013dabafbf598dad9ffc2c31","modified":1593702376037},{"_id":"source/_posts/线性代数空间角度理解.md","hash":"a2602cc2360d1112d0efeff8df76b7a015d1db39","modified":1594737979801},{"_id":"source/_posts/英语1：简单句.md","hash":"f796cf075050eed2cf3665cc2963d655b88d6175","modified":1592313191229},{"_id":"source/_posts/英语2：并列句.md","hash":"1b7810ff5242637d197797c3819157794027da13","modified":1592313178441},{"_id":"source/_posts/重置博客.md","hash":"05e1f5ea7c11efb784e88ad577f0be7b4e806ca5","modified":1590841362439},{"_id":"source/about/index.md","hash":"50c30d7d6c054d67af59a41e5853df97edd7fa79","modified":1591522809870},{"_id":"source/tag/index.md","hash":"d9b07bf16872a08b1dbd48c37c853604b1990884","modified":1591455226188},{"_id":"source/category/index.md","hash":"01a8f9ce02529b4cb7cb6c59a0079f86c1f22882","modified":1591455298262},{"_id":"themes/Chic/layout/_page/about.md","hash":"e0b616b7546d05a50bd7bf046858af8e221fd0fc","modified":1591448572239},{"_id":"themes/Chic/layout/_page/archive.ejs","hash":"074ef6ede857a3404a454684b2a3bf6121d53bf3","modified":1591448572246},{"_id":"themes/Chic/layout/_page/page.ejs","hash":"90559c37712ec3d7cdd58ad15d14d5662816bce1","modified":1591523392534},{"_id":"themes/Chic/layout/_page/category.ejs","hash":"607bbfd724c47649a5b4c54d0509194ec1f6bbbd","modified":1591448572247},{"_id":"themes/Chic/layout/_page/post.ejs","hash":"354e4a74681c10b3e6481c1a2ced03b606a0dd9f","modified":1591448572247},{"_id":"themes/Chic/layout/_page/profile.ejs","hash":"0f8584965cdb9c2fabb4f81dae7973022b9ff422","modified":1591448572247},{"_id":"themes/Chic/layout/_page/tag.ejs","hash":"271bbaf9549a62cffbe7b5aab7afdabb4eea5ebc","modified":1591448572248},{"_id":"themes/Chic/layout/_partial/head.ejs","hash":"ff8fd108858018e92e632ec9db43a413079984f6","modified":1591448572248},{"_id":"themes/Chic/layout/_partial/footer.ejs","hash":"5ae3880e3badf8f413e503a7a2662c41219b3b82","modified":1591448572248},{"_id":"themes/Chic/layout/_partial/header.ejs","hash":"2d4be1a3899d4512892fb951e11c9cd47d38ed56","modified":1591448572249},{"_id":"themes/Chic/layout/_partial/paginator.ejs","hash":"8ad8d7752378f71708ce9d25e19f06f316eacce0","modified":1591448572249},{"_id":"themes/Chic/layout/_partial/toc.ejs","hash":"ced91b79bfa99e4141b3e37e3ac22648729474d2","modified":1591448572249},{"_id":"themes/Chic/layout/_plugins/mathjax.ejs","hash":"56722622edf8cb6e7bb138ad1d0329e2125d9c38","modified":1591448572250},{"_id":"themes/Chic/source/css/base.styl","hash":"b4fe58e7b149e5ee54bedf234d3c32d037749b65","modified":1591448572282},{"_id":"themes/Chic/source/css/custom.styl","hash":"730200ab0f2a18cb51633c707252d42d03a17fa1","modified":1591448572282},{"_id":"themes/Chic/source/css/font.styl","hash":"2b993f2d28650b2ec7b4d14972530c79e9b0fb66","modified":1591523328231},{"_id":"themes/Chic/source/css/media.styl","hash":"512311f047b94f886163f664e1236f58798e5677","modified":1591448572284},{"_id":"themes/Chic/source/css/layout.styl","hash":"5e43163d7da6e535d211522ed5ac93356d6447ee","modified":1591448572283},{"_id":"themes/Chic/source/css/normalize.styl","hash":"df9ca719f651c45a88ab4d6afa6d29edf51aeba9","modified":1591448572284},{"_id":"themes/Chic/source/css/style.styl","hash":"9fd5774b422999424856fa583aac12cf16648e50","modified":1591522347431},{"_id":"themes/Chic/source/css/variable.styl","hash":"4fbb2ffdc00cad2f5cd6ff0dd689836d6f20d227","modified":1591448572285},{"_id":"themes/Chic/source/js/script.js","hash":"b69c0facab01049908ad936d63ea705d33dea731","modified":1591448572398},{"_id":"themes/Chic/source/js/tocbot.min.js","hash":"bae97e8a24a05a99335f8e725641c8ca9c50502a","modified":1591448572398},{"_id":"source/_posts/AdaBound/AdaBound_figure1.png","hash":"6f7c98a0c568ad2ca0a3d93a0cc06628f58ad6a4","modified":1582643166691},{"_id":"source/_posts/AdaBound/AdaBound_clip.png","hash":"627fa7bd207e4c8d05556bc1b8ce3bb0ba67ec2d","modified":1582643166689},{"_id":"source/_posts/AdaBound/AdaBound_corollary4.1.png","hash":"7d09dbd52ddb15143eb8811007584933ce8c8632","modified":1582643166690},{"_id":"source/_posts/AdaBound/AdaBound_figure4.2.png","hash":"aefcf6c021c7ec7dda0f16995950867700f86db3","modified":1582643166699},{"_id":"source/_posts/AdaBound/AdaBound_table1.png","hash":"78d04a419bbd480d892f9aba8f5ac2929ce716dd","modified":1582643166707},{"_id":"source/_posts/AdaBound/AdaBound_theorem4.png","hash":"4b799edbca0c064b58910bc5f2c3c6dc294de673","modified":1582643166709},{"_id":"source/_posts/CS231n笔记/AdaBound_clip.png","hash":"627fa7bd207e4c8d05556bc1b8ce3bb0ba67ec2d","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/AdaBound_figure1.png","hash":"6f7c98a0c568ad2ca0a3d93a0cc06628f58ad6a4","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/bn_forward.png","hash":"b62b7984ac0f4391ab9a078c3c44c8c194703c21","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/elu.png","hash":"fb3022e5c7789235eaa4fba08d71e36ceed55bc0","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/leaky relu.png","hash":"dae5d5df131aa32f71ac43bf9d9de3efbeda33a4","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/SGDM.jpg","hash":"f8e86dcb9585e68a8f8df99ac67cf92cc22e4304","modified":1592483147053},{"_id":"source/_posts/CS231n笔记/relu.png","hash":"1c2075be25a1820db3c48be414ebabbe48d58b33","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/sgd_problem2.png","hash":"9800ad0a55dfdb14eea60a2bd28fd08a35d79ef8","modified":1592483147053},{"_id":"source/_posts/CS231n笔记/sigmoid.png","hash":"7b00654e99b9898633ff050006768cff5f314da2","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/tanh.png","hash":"dca8ebe17a629124143fd3a9b2f5200697eb5756","modified":1592483147054},{"_id":"source/_posts/CS231n笔记/sgd_problem1.png","hash":"75bb4ac3c468e2b6ac13fe164b95468bbd752df2","modified":1592483147053},{"_id":"source/_posts/DES和分组密码工作模式/CBC.jpg","hash":"ef0738b2e4a071b176f35f3fddf6b32f2bcda6d4","modified":1589797106723},{"_id":"source/_posts/DES和分组密码工作模式/DES.png","hash":"ba381fde13518bec33aa92a9f2358ccb381f09e4","modified":1589804539926},{"_id":"source/_posts/DES和分组密码工作模式/CFB.jpg","hash":"23d8382f847c722e9d826fbe8a5040e8170d6a1d","modified":1589797538292},{"_id":"source/_posts/DES和分组密码工作模式/S.png","hash":"6d16a6237c05fa49ef66cb7f26279665566476e5","modified":1589290592766},{"_id":"source/_posts/DES和分组密码工作模式/P.png","hash":"6d4a52734a9435660bed6b2669ff924dc9e2cb26","modified":1589290825233},{"_id":"source/_posts/DES和分组密码工作模式/ECB.jpg","hash":"1ec35e5bda633d10605b4886dff9c9c96f619548","modified":1589797069685},{"_id":"source/_posts/DES和分组密码工作模式/e_bit-selection.png","hash":"11f4e5c757c16619494753e629335461590f0fa2","modified":1589289947991},{"_id":"source/_posts/DES和分组密码工作模式/f(R,K).png","hash":"a0d28b676dc700b8fb469c5b8d8b625481582b12","modified":1589290214944},{"_id":"source/_posts/DES和分组密码工作模式/pc_1.png","hash":"4c087409247b236fae622268688ba09a0f6ee834","modified":1589286846325},{"_id":"source/_posts/DES和分组密码工作模式/pc_2.png","hash":"787d7f337e5b3d427ad4e4aef287970ab51be858","modified":1589287981753},{"_id":"source/_posts/MD5/FFGGHHII.png","hash":"f72ea1a9861ca1c3d84aa14d186f1185738346e9","modified":1591015284723},{"_id":"source/_posts/MD5/FGHI.png","hash":"627f0c8fb45796a7f79a8ca365000c0fcee91a8d","modified":1591015284723},{"_id":"source/_posts/MD5/MD5.png","hash":"eea41fb561bb7b52fbaf067c8d3cc34d0f5dc4c6","modified":1591015284722},{"_id":"source/_posts/RT-MDNet/ROIAlign.png","hash":"451ec2ff4a5e191c3bb132360340e57a225a6c23","modified":1582643166647},{"_id":"themes/Chic/source/js/mathjax2.7.5.js","hash":"fd54df22584629c604511acf67c9e992d362a5e3","modified":1591448572397},{"_id":"source/_posts/SiamDW/SiamFC_1.png","hash":"423b023d347c17156fb2fb2d1f292dd961f2d6b9","modified":1583158574376},{"_id":"source/_posts/SiamDW/SiamFC_1-1583335627710.png","hash":"423b023d347c17156fb2fb2d1f292dd961f2d6b9","modified":1583335627777},{"_id":"source/_posts/SiamDW/motivation.png","hash":"9da37821d3f5a0fabc24c0b86eeb77dabf059261","modified":1583159289160},{"_id":"source/_posts/SiamDW/motivation-1583335627710.png","hash":"9da37821d3f5a0fabc24c0b86eeb77dabf059261","modified":1583335627778},{"_id":"source/_posts/Siamese系列/Bicubic interpolation1.PNG","hash":"b167138376b6973945b565b3b1c006ebb69c7190","modified":1582643165887},{"_id":"source/_posts/Siamese系列/Bicubic interpolation2.png","hash":"4c146538f63338bd8a00559ff89d51866a4bb18c","modified":1582643165887},{"_id":"source/_posts/Siamese系列/SiamFC_1.png","hash":"423b023d347c17156fb2fb2d1f292dd961f2d6b9","modified":1582643165903},{"_id":"source/_posts/Siamese系列/SiamFC_3.jpg","hash":"69571371223697f1dfe8168a7a175e0dddb051d7","modified":1582643165904},{"_id":"source/_posts/Siamese系列/SiamFC_loss.png","hash":"88591a98ddb3c3d5deee2b0206ef8ab64b71a2cc","modified":1582643165904},{"_id":"source/_posts/Siamese系列/SiamFC_2.jpg","hash":"182ea6a1e613978ec7bf7216c8b847333f248e5a","modified":1582643165903},{"_id":"source/_posts/Siamese系列/RPN.jpg","hash":"03cd9ec411375f08d0aaa17ba6848cc659171eae","modified":1582643165902},{"_id":"source/_posts/Siamese系列/Siamese Net.png","hash":"d12b60357769e92c7e739d5f3a7a9a42040cbeb4","modified":1582643165943},{"_id":"source/_posts/Siamese系列/Siamese Net_loss.png","hash":"aca927f79767fc731f300f5b6a6a7d091d6fad63","modified":1582643165944},{"_id":"source/_posts/Siamese系列/anchors.jpg","hash":"f5ba8713a246f721776b48fc82b9b63a3a8706f4","modified":1582643165946},{"_id":"source/_posts/Siamese系列/Siamese Net_loss1.png","hash":"5b04979b521efd9328890b0be12ba9b643167672","modified":1582643165944},{"_id":"source/_posts/Siamese系列/nonlocal_eq1.png","hash":"ec0edcdfb9d9b45a6ba28f9229759d92c0160ede","modified":1582643165948},{"_id":"source/_posts/Siamese系列/nonlocal_eq2.png","hash":"688cac5b7ad8a10ea25098a4b97a2619245bfc6e","modified":1582643165949},{"_id":"source/_posts/Siamese系列/nonlocal_eq3.png","hash":"ba34e5e3591a6667979427481ee1f30a26c4df4f","modified":1582643165950},{"_id":"source/_posts/Siamese系列/rpn_regression1.png","hash":"487b9f29598f094fc512afd03eee4fd13c1c2de5","modified":1582643165952},{"_id":"source/_posts/Siamese系列/差值3.png","hash":"2f39cacb8f8e6a1a8992eab610d1692746ab5dfd","modified":1582643165954},{"_id":"source/_posts/Siamese系列/smooth loss.png","hash":"32cf78b67141d86a48f0b91cf0d81a4ac624c9cc","modified":1582643165953},{"_id":"source/_posts/Siamese系列/smoothL1.jpg","hash":"94cc0b697e6186fbc0713dc6a06ce954efea658f","modified":1582643165954},{"_id":"themes/Chic/source/image/avatar.jpg","hash":"b6abbc09bc522d042206341be6a7029511ef59c9","modified":1591456249693},{"_id":"source/_posts/AdaBound/AdaBound_algorithm1.png","hash":"0bc029d87295a2bc291ac12e6db4d9e6dc70af33","modified":1582643166687},{"_id":"themes/Chic/source/image/QQ.jpg","hash":"eeb8273511430456b0f159a74cb99f57cddb3d67","modified":1591456123503},{"_id":"source/_posts/AdaBound/AdaBound_figure4.1.png","hash":"dd609d1abf28e2b2a7318096e6a2ca1b7caa868e","modified":1582643166698},{"_id":"source/_posts/AdaBound/AdaBound_figure7.2.png","hash":"e73bd627c8a93b2a2e3b7dbd22fa7e2016032cd5","modified":1582643166706},{"_id":"source/_posts/AdaBound/AdaBound_table2.png","hash":"1826d838163352dc916a1ec8d917b49a739f0e71","modified":1582643166708},{"_id":"source/_posts/CS231n笔记/loss-learing rate.png","hash":"496d231347075a58a0e30b7cd5bfe76fe19195cf","modified":1592483147066},{"_id":"source/static/images/avatar.jpg","hash":"31a06079aa533dc955a96181e6c391a314748bec","modified":1560935824000},{"_id":"source/_posts/CS231n笔记/bn_backward.jpg","hash":"32c1ee6f8b70b28fe472c1a55aff20ad4a2d5c9d","modified":1592483147066},{"_id":"source/_posts/DES和分组密码工作模式/OFB.jpg","hash":"c7d41970cebc18185c461583fe25bc92493c9c39","modified":1589798408567},{"_id":"source/_posts/DES和分组密码工作模式/image-20200512205728831.png","hash":"334dfa1db8912bc53fb9bf2282cf2f3ad0b27bd3","modified":1589288248866},{"_id":"source/_posts/RT-MDNet/ROIPooling.png","hash":"8f20b6bd13177177d30630116ffc183ea98f70b2","modified":1582643166648},{"_id":"source/_posts/SiamDW/CIR-1583335627710.png","hash":"cb5eb13d8bc0c523bb2c3b7b12a4d3876865fdaa","modified":1583335627791},{"_id":"source/_posts/SiamDW/CIR-D-1583335627710.png","hash":"f3d55c5d2a34f249e12c962ff0b8185943b238a4","modified":1583335627791},{"_id":"source/_posts/SiamDW/CIR-D.png","hash":"f3d55c5d2a34f249e12c962ff0b8185943b238a4","modified":1582897888991},{"_id":"source/_posts/SiamDW/CIR.png","hash":"cb5eb13d8bc0c523bb2c3b7b12a4d3876865fdaa","modified":1582897878835},{"_id":"source/_posts/SiamDW/simple_siam-1583335627709.png","hash":"df968173ed649cc6071e8ad88de262c82386aecd","modified":1583335627786},{"_id":"source/_posts/SiamDW/simple_siam.png","hash":"df968173ed649cc6071e8ad88de262c82386aecd","modified":1583158513411},{"_id":"source/_posts/Siamese系列/SiamRPN++_RPN.png","hash":"dc05e56c8ef2da068c477d26c1cbf24c16004cfe","modified":1582643165913},{"_id":"source/_posts/Siamese系列/SiamRPN++_correlation.png","hash":"fd80616eab508b26f95acad0834c99093c2c1021","modified":1582643165921},{"_id":"source/_posts/Siamese系列/SiamRPN++_translation.png","hash":"784c53d6f6543613931cdf2a37ef7d2d79795522","modified":1582643165928},{"_id":"source/_posts/Siamese系列/SiamRPN_prosal_select.png","hash":"729db7ad5abb8ae261560ae3d17bd7d2ec521f71","modified":1582643165930},{"_id":"source/_posts/Siamese系列/SiamRPN_tracking.png","hash":"5943e9f7a94600df285149a48bcd913bdc6948cc","modified":1582643165943},{"_id":"source/_posts/Siamese系列/nonlocal_block_struct.jpg","hash":"7f98b268cc001bad88027f1530fa6bf93eabf0b1","modified":1582643165948},{"_id":"source/_posts/Siamese系列/rpn1.png","hash":"f0eb97c1d44f24289ccebd66b66368b750150c05","modified":1582643165951},{"_id":"source/_posts/Siamese系列/rpn_regression.png","hash":"84b4a064d851999f06aa01c51eb0bae48cac4a7f","modified":1582643165952},{"_id":"source/_posts/线性代数空间角度理解/2.png","hash":"a282c4192172af67ce2b8791bbdb62256cb5d013","modified":1582509558000},{"_id":"source/_posts/Siamese系列/Siamese twins.jpg","hash":"76c05c83a3bd03262488c9340c88f0abc02e5e83","modified":1582643165945},{"_id":"source/_posts/线性代数空间角度理解/1.png","hash":"66a18fa757a36b1bcad7a3f35a2c272394542cb2","modified":1582509524000},{"_id":"source/_posts/线性代数空间角度理解/3.png","hash":"0a373fe980cf13fda7de10d6154206f70a9a042a","modified":1582509616000},{"_id":"source/_posts/线性代数空间角度理解/5.png","hash":"4728f5dc19563ef99ded4d774f2d2aa1abdfda9b","modified":1582509680000},{"_id":"source/_posts/线性代数空间角度理解/7.png","hash":"baff3a8ea6a40708300ddeda5e90444c519d9a30","modified":1582524062000},{"_id":"themes/Chic/source/css/_highlight/agate.styl","hash":"fc289ba8f47ead6331ec3a51533cfa93251c5634","modified":1591448572255},{"_id":"themes/Chic/source/css/_highlight/androidstudio.styl","hash":"4d67bdab6cc9c614486ca42f98199a04d053e7f0","modified":1591448572255},{"_id":"themes/Chic/source/css/_highlight/arduino-light.styl","hash":"591962bfc758a521b4cb907750c19a1a2423b4d5","modified":1591448572255},{"_id":"themes/Chic/source/css/_highlight/arta.styl","hash":"262167aaebcf28de7f85af7ac77a76fa1fa284f7","modified":1591448572256},{"_id":"themes/Chic/source/css/_highlight/ascetic.styl","hash":"ca087a3c70998c7ac6b0b42d5cf7a653b8707591","modified":1591448572256},{"_id":"themes/Chic/source/css/_highlight/atelier-cave-dark.styl","hash":"7e83c7f2acaaaa98864660afe2794745c36c8e51","modified":1591448572256},{"_id":"themes/Chic/source/css/_highlight/atelier-cave-light.styl","hash":"f47de0b9d66617728f68096ed48371dd6bb9e67a","modified":1591448572257},{"_id":"themes/Chic/source/css/_highlight/atelier-dune-dark.styl","hash":"68584ed0e99c7d0e49ef8a2e67cd4dcdad359de4","modified":1591448572257},{"_id":"themes/Chic/source/css/_highlight/atelier-dune-light.styl","hash":"657fe215931fd06e21b56374df699a94890f7ab4","modified":1591448572258},{"_id":"themes/Chic/source/css/_highlight/atelier-estuary-dark.styl","hash":"1cecd13e0d6b24042ff86372f0596c1441bb834a","modified":1591448572258},{"_id":"themes/Chic/source/css/_highlight/atelier-forest-dark.styl","hash":"a741eba35cdfe2cfd67dfbf109655f253d6b4795","modified":1591448572258},{"_id":"themes/Chic/source/css/_highlight/atelier-estuary-light.styl","hash":"2b416a0567a53aa0fa8898b196ddd44315c1a5f3","modified":1591448572258},{"_id":"themes/Chic/source/css/_highlight/atelier-forest-light.styl","hash":"8d7c7242974aa2454fa792c5d7a47c5f9632355a","modified":1591448572259},{"_id":"themes/Chic/source/css/_highlight/atelier-heath-light.styl","hash":"c1db353e8613607580d40b12ddc162d029560576","modified":1591448572259},{"_id":"themes/Chic/source/css/_highlight/atelier-heath-dark.styl","hash":"f186b357dcebded89b7bcc77389b2cff76533d72","modified":1591448572259},{"_id":"themes/Chic/source/css/_highlight/atelier-lakeside-light.styl","hash":"8659eaae6a0c2e00b4b9199803e50adf4ff0128d","modified":1591448572260},{"_id":"themes/Chic/source/css/_highlight/atelier-lakeside-dark.styl","hash":"802979cea895a0a384645cb30a43de9572cb0e3f","modified":1591448572260},{"_id":"themes/Chic/source/css/_highlight/atelier-plateau-light.styl","hash":"96181544eeadc5b0749229f11607e7c01f81e078","modified":1591448572260},{"_id":"themes/Chic/source/css/_highlight/atelier-plateau-dark.styl","hash":"0d51ddc580ccb0a291271fa9632bc91dab632df6","modified":1591448572260},{"_id":"themes/Chic/source/css/_highlight/atelier-savanna-dark.styl","hash":"bbad7a9512b4873294e73ce806e36e43973e6ed8","modified":1591448572261},{"_id":"themes/Chic/source/css/_highlight/atelier-seaside-light.styl","hash":"08e2df313c272d5c70c93e713639663c168180d0","modified":1591448572262},{"_id":"themes/Chic/source/css/_highlight/atelier-savanna-light.styl","hash":"8a5207a0c30262a0bf5e1a41411a306f7a89a7e7","modified":1591448572261},{"_id":"themes/Chic/source/css/_highlight/atelier-seaside-dark.styl","hash":"2f008271299042f2443bca98c9bcadbc8c45e837","modified":1591448572261},{"_id":"themes/Chic/source/css/_highlight/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1591448572264},{"_id":"themes/Chic/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"18dcb00ab9c62eb810d492047214331c51bb654f","modified":1591448572262},{"_id":"themes/Chic/source/css/_highlight/atelier-sulphurpool-light.styl","hash":"add3d88c9d12567dcfae7a8e49984d119fc72227","modified":1591448572263},{"_id":"themes/Chic/source/css/_highlight/brown-paper.styl","hash":"e45a5e2ae53c90334e9bc8be1e45f3c3aa3d785d","modified":1591448572263},{"_id":"themes/Chic/source/css/_highlight/dark.styl","hash":"98d7884806838a0b46132d759d60ac27c0c4bd9c","modified":1591448572264},{"_id":"themes/Chic/source/css/_highlight/color-brewer.styl","hash":"9c4905eab730d0b389e6972e907057577f7e25f1","modified":1591448572264},{"_id":"themes/Chic/source/css/_highlight/docco.styl","hash":"7bd3389ce16d20488ab336d557056cc703c921c7","modified":1591448572265},{"_id":"themes/Chic/source/css/_highlight/codepen-embed.styl","hash":"1de45e603e2c71c7f6b0c1372a3ba00b1bc153a8","modified":1591448572264},{"_id":"themes/Chic/source/css/_highlight/darkula.styl","hash":"8965ad6920601c275ca97e617beff5536925a266","modified":1591448572265},{"_id":"themes/Chic/source/css/_highlight/far.styl","hash":"8da83d66724f2ce508a40f21b4f6dc0d704be562","modified":1591448572265},{"_id":"themes/Chic/source/css/_highlight/foundation.styl","hash":"28c59a31467c33bd51cbf3b6085782c2a724ff6c","modified":1591448572266},{"_id":"themes/Chic/source/css/_highlight/github.styl","hash":"a84eb710b302006120c3e7f8ca18f9e6fbc231c3","modified":1591448572266},{"_id":"themes/Chic/source/css/_highlight/hopscotch.styl","hash":"dd3c78c42d4a865f11623235e5e5f6829d789706","modified":1591448572267},{"_id":"themes/Chic/source/css/_highlight/github-gist.styl","hash":"71f4b0fca91a587e6eba15a5306dca963bb8f441","modified":1591448572266},{"_id":"themes/Chic/source/css/_highlight/googlecode.styl","hash":"7f5082ae008925a23eb713f160773fe647eb3ff7","modified":1591448572266},{"_id":"themes/Chic/source/css/_highlight/gruvbox-dark.styl","hash":"f66403ce77dcb16b1f98a5061b72f7581630d69f","modified":1591448572267},{"_id":"themes/Chic/source/css/_highlight/highlightjs.styl","hash":"192611c56d6fe4da343718548de21c31a75919db","modified":1591448572267},{"_id":"themes/Chic/source/css/_highlight/hybrid.styl","hash":"4906456025787de04b48a87c42bb704c5ff67065","modified":1591448572268},{"_id":"themes/Chic/source/css/_highlight/idea.styl","hash":"e284c1760e8da0848f56cd5601d867ceeb0192d7","modified":1591448572268},{"_id":"themes/Chic/source/css/_highlight/index.styl","hash":"36c44375229613a5bb9ee84a8e90214978070439","modified":1591448572268},{"_id":"themes/Chic/source/css/_highlight/grayscale.styl","hash":"c83804abe39faebd80f8f4ff64fbd7137674cb1c","modified":1591448572267},{"_id":"themes/Chic/source/css/_highlight/ir-black.styl","hash":"aa31b30069ebee39e2c3ebb75e2c96ba8678eb14","modified":1591448572268},{"_id":"themes/Chic/source/css/_highlight/kimbie.dark.styl","hash":"3b998c640eeb2c6192fee24bc78b4137de475dd7","modified":1591448572269},{"_id":"themes/Chic/source/css/_highlight/kimbie.light.styl","hash":"e901738455ec9a1bddde7b62bbd8595de6033e1e","modified":1591448572269},{"_id":"themes/Chic/source/css/_highlight/kimbie.styl","hash":"13113af220dfed09cb49d85102babb352c3eff97","modified":1591448572269},{"_id":"themes/Chic/source/css/_highlight/mono-blue.styl","hash":"14fb8678739b77f35771b6d63101ddbf1e7a9fbc","modified":1591448572270},{"_id":"themes/Chic/source/css/_highlight/monokai-sublime.styl","hash":"84a27bd29d939105d65f4164c219d6cc2e09ae60","modified":1591448572270},{"_id":"themes/Chic/source/css/_highlight/magula.styl","hash":"ab179306c12a1cf2949482beaca328e379ef034a","modified":1591448572269},{"_id":"themes/Chic/source/css/_highlight/monokai.styl","hash":"c3a3bfae1eb864505fbc8748db734600057af1af","modified":1591448572270},{"_id":"themes/Chic/source/css/_highlight/obsidian.styl","hash":"efba069860181d2b709e1548dd16cf102ca267fa","modified":1591448572271},{"_id":"themes/Chic/source/css/_highlight/paraiso-dark.styl","hash":"50f1cee8a5b3b165b4184ead0a99dc564b62ef4f","modified":1591448572271},{"_id":"themes/Chic/source/css/_highlight/paraiso-light.styl","hash":"e428e8202b01e83b0f018a96058d806e7f4c76bf","modified":1591448572271},{"_id":"themes/Chic/source/css/_highlight/paraiso.styl","hash":"846a06a57fa0b3db7f83ec7ac2bf34911f32cf66","modified":1591448572271},{"_id":"themes/Chic/source/css/_highlight/pojoaque.jpg","hash":"c5fe6533b88b21f8d90d3d03954c6b29baa67791","modified":1591448572272},{"_id":"themes/Chic/source/css/_highlight/pojoaque.styl","hash":"37436c1018394f799a1f3dfd326309da8df89742","modified":1591448572272},{"_id":"themes/Chic/source/css/_highlight/railscasts.styl","hash":"5dc9ce33cecee87fe9ca8f2ed9342602194484ec","modified":1591448572272},{"_id":"themes/Chic/source/css/_highlight/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1591448572273},{"_id":"themes/Chic/source/css/_highlight/rainbow.styl","hash":"95246afef181bd96f9adb1a2e84fb3ef302d4598","modified":1591448572272},{"_id":"themes/Chic/source/css/_highlight/school-book.styl","hash":"6d685307f4362d3b2b0868f7b0a94b930db66e6a","modified":1591448572273},{"_id":"themes/Chic/source/css/_highlight/solarized-dark.styl","hash":"9fc9400d3a8cae97eb5761c284140acb0f847538","modified":1591448572273},{"_id":"themes/Chic/source/css/_highlight/solarized-light.styl","hash":"bb04944fc06c12ecd7b56ad933dbedde60c2259a","modified":1591448572274},{"_id":"themes/Chic/source/css/_highlight/tomorrow-night-blue.styl","hash":"92f4423d4964fcfe34ff7ca6cb21012b5738c697","modified":1591448572274},{"_id":"themes/Chic/source/css/_highlight/tomorrow-night-bright.styl","hash":"e6b025b247e4027fb3c1b7833588f5a5b04a549c","modified":1591448572275},{"_id":"themes/Chic/source/css/_highlight/sunburst.styl","hash":"e6e4c009b10b9805f0c593446bf013edec47d146","modified":1591448572274},{"_id":"themes/Chic/source/css/_highlight/tomorrow-night-eighties.styl","hash":"8b16876cf205111d5d5454100de712bc3ea8f477","modified":1591448572275},{"_id":"themes/Chic/source/css/_highlight/tomorrow.styl","hash":"502335f0fac07ed74ca78207bcf3ef8dd2252cf6","modified":1591448572276},{"_id":"themes/Chic/source/css/_highlight/vs.styl","hash":"14fbb0c43af440a290280b26968c8a5c0786b27f","modified":1591448572276},{"_id":"themes/Chic/source/css/_highlight/tomorrow-night.styl","hash":"eb8441364bb1664ecebde77b965dc36c91133aa0","modified":1591448572275},{"_id":"themes/Chic/source/css/_lib/looper.css","hash":"f4ee39f122059c1e7793b8dc1d72fcbc5fa5ea15","modified":1591448572277},{"_id":"themes/Chic/source/css/_page/archive.styl","hash":"edc8ee7f34629c59fd4d31f2889d5c069e9d63ac","modified":1591448572280},{"_id":"themes/Chic/source/css/_lib/tocbot.css","hash":"f646f2bb75bcd1eb65b2788ac7bf15d4fd243ce9","modified":1591448572277},{"_id":"themes/Chic/source/css/_page/category.styl","hash":"9b0c89a525b2b4f0163f6ff1bf1d208277c8bb1f","modified":1591448572280},{"_id":"themes/Chic/source/css/_page/page.styl","hash":"b2cf99b15965f6851129d52d23f26ed91dc2ede7","modified":1591448572280},{"_id":"themes/Chic/source/css/_page/profile.styl","hash":"da31d90eb4529499f9e43eed612967a81f8244c1","modified":1591448572280},{"_id":"themes/Chic/source/css/_page/tag.styl","hash":"715f3fb46c9ccd7c1b701bcf5aac87051ecb3d17","modified":1591448572281},{"_id":"themes/Chic/source/css/_partial/footer.styl","hash":"578a744914f05bab4eae73838076b1cdb8130929","modified":1591448572281},{"_id":"themes/Chic/source/css/_partial/header.styl","hash":"9e4d9b67cc2dbbb92b190be3f9ebcd77e093f057","modified":1591448572281},{"_id":"themes/Chic/source/css/_partial/paginator.styl","hash":"fbe7e3ce8234e5e1a18764113f997b98d777ee5f","modified":1591448572282},{"_id":"themes/Chic/source/css/_highlight/xcode.styl","hash":"5fa8999c7f807c1aae29c7a1cdf681678576fb69","modified":1591448572276},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.css","hash":"496a69ed5e5232feecfd8e1390877b77003e405c","modified":1591448572286},{"_id":"themes/Chic/source/css/_highlight/zenburn.styl","hash":"f63534764dd6598e81177d64714a184f98153b11","modified":1591448572276},{"_id":"themes/Chic/source/fonts/iconfont/demo.css","hash":"53456972a11d52af67187fc17999e6665f9f06fe","modified":1591448572286},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.json","hash":"cb99651b9be2f87afcd5989480dd7360b4bf4643","modified":1591448572287},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.eot","hash":"d18736f7885569e497698d17f49b9167add67dc6","modified":1591448572287},{"_id":"themes/Chic/source/fonts/iconfont/demo_index.html","hash":"55c47c8924542a89da4741fcce7eca7e5f881e77","modified":1591448572286},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.svg","hash":"8f1d735e4fae3757dac1866dc3e30147140811e2","modified":1591448572288},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.ttf","hash":"41c4f4dc82e42452dcfd19caed6c7dc333ee769e","modified":1591448572289},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.js","hash":"87bfdaae31251f4d605646c5ae9c67196f6cc4e2","modified":1591448572287},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.woff","hash":"a57593c49b56c16ac1def0e1f3dbca3f658b3579","modified":1591448572289},{"_id":"themes/Chic/source/fonts/iconfont/iconfont.woff2","hash":"39d97a0f72417487f5c1e0a0abf8e27dd6ebda31","modified":1591448572289},{"_id":"source/_posts/AdaBound/AdaBound_algorithm2.png","hash":"11ce9a8d79b45afb2f6c4505235dd277cf326372","modified":1582643166689},{"_id":"source/_posts/AdaBound/AdaBound_figure2.png","hash":"4b95f0c7250e175a5e717159cefe78f5b3c646fc","modified":1582643166693},{"_id":"source/_posts/AdaBound/AdaBound_figure7.1.png","hash":"f5afca527c607095e22325a94754bce11168cdc7","modified":1582643166705},{"_id":"source/_posts/CS231n笔记/主流.png","hash":"bbed2bc32b587b4ba7a12f33a89d9760c9a1e10e","modified":1592483147076},{"_id":"source/_posts/DES和分组密码工作模式/IP&IP-1.png","hash":"fbde8065d915e1b878ba9b136a1f97b248623bdc","modified":1589289196442},{"_id":"source/_posts/SiamDW/SiamRPN_net-1583335627710.png","hash":"0085ca3f08cc4d1ed73fda37ad7ec8da510d3f19","modified":1583335627884},{"_id":"source/_posts/SiamDW/SiamRPN_net.png","hash":"0085ca3f08cc4d1ed73fda37ad7ec8da510d3f19","modified":1583158609845},{"_id":"source/_posts/Siamese系列/SiamFC_net_layer.png","hash":"ffc9a10e6fb6c575af233037f125a1e55c5917ce","modified":1582643165906},{"_id":"source/_posts/Siamese系列/SiamRPN++_net.png","hash":"0873c2bfc2cd787c48142eb5a29c7fa944fa2d28","modified":1582643165924},{"_id":"source/_posts/Siamese系列/SiamRPN++_heatmap.png","hash":"d9cac41ec101aaeb67bf11dc1b70cf146b944fe4","modified":1582643165923},{"_id":"source/_posts/Siamese系列/SiamRPN_net.png","hash":"0085ca3f08cc4d1ed73fda37ad7ec8da510d3f19","modified":1582643165929},{"_id":"source/_posts/AdaBound/AdaBound_figure5.png","hash":"5f4fc769c44f22f3f54c23eea59675428f176c42","modified":1582643166701},{"_id":"source/_posts/CS231n笔记/SGD+Nesterov.png","hash":"23ecf6cc69d51cd0aa38fe8dec38786ecf537ab2","modified":1592483147083},{"_id":"source/_posts/MDNet/MDNet_struct.png","hash":"d506e2d1e2171aed32c01d3c69c7cc333698c975","modified":1582643166726},{"_id":"source/_posts/MDNet/MDnet_algorithm.png","hash":"acb38b23e6be39dc946494976df3c952d76fb2a5","modified":1582643166727},{"_id":"themes/Chic/source/css/_page/_post/post_code.styl","hash":"7b57bafe7e8e375372055f4a775bb42a3c190c95","modified":1591448572278},{"_id":"themes/Chic/source/css/_page/_post/post_content.styl","hash":"8fa506bf4dd38c7cb6d5f48445ab170de4cd6868","modified":1591448572278},{"_id":"themes/Chic/source/css/_page/_post/post_copyright.styl","hash":"e1851fabb110414a624a1be634129dc6b0ce8d03","modified":1591448572278},{"_id":"themes/Chic/source/css/_page/_post/post_nav.styl","hash":"9c73772ad0d2b1e67007aa2816ee9b97d5152ffa","modified":1591448572279},{"_id":"themes/Chic/source/css/_page/_post/post_header.styl","hash":"6ea0ede34416dfaddda04a903f658325572f91a4","modified":1591448572279},{"_id":"themes/Chic/source/css/_page/_post/post_tags.styl","hash":"bd16f8c0e5ee2e302b61b861470ab993b6af709b","modified":1591448572279},{"_id":"themes/Chic/source/css/_page/_post/post_toc.styl","hash":"6c64f313146416a17b087d0a2fc90362cd977776","modified":1591448572279},{"_id":"source/_posts/AdaBound/AdaBound_figure3.1.png","hash":"ef29f326b64298373fa21077369fd424887a9588","modified":1582643166694},{"_id":"source/_posts/AdaBound/AdaBound_figure6.png","hash":"88acd06546d1681aa14438f526c49c41ccb31575","modified":1582643166703},{"_id":"source/_posts/SiamDW/1times1conv.png","hash":"439a8d133928a688d015bbd8a59141d6ef780476","modified":1582814622049},{"_id":"source/_posts/Siamese系列/NMS_multi1.png","hash":"5cc14d760b4eea79e45494568f13869053c9df6d","modified":1582643165894},{"_id":"source/_posts/Siamese系列/NMS_multi3.png","hash":"73b77e7645d81a6099d94e5a1ea8e21a6f089da3","modified":1582643165897},{"_id":"source/_posts/Siamese系列/NMS_multi4.png","hash":"c298a55af3effb71a21dec8ec9b340cfb3318de1","modified":1582643165899},{"_id":"source/_posts/Siamese系列/SiamRPN++_net_left.png","hash":"12cc86b39975b6d2a6f50c998eb898cf5c9d9f99","modified":1582643165927},{"_id":"source/_posts/线性代数空间角度理解/4.png","hash":"b3c79d0f730f4294c269544e873950acce8cf18b","modified":1582509672000},{"_id":"source/_posts/AdaBound/AdaBound_figure3.2.png","hash":"f2888d3432f73471678d54083f44b5053c906128","modified":1582643166697},{"_id":"source/_posts/CS231n笔记/1062917-20161117212457248-1468090428.png","hash":"47b986560de89d833552a546c2165809243cda0e","modified":1592483147367},{"_id":"source/static/images/background.jpg","hash":"3d711c925fb0419a8265502f5146f33c29f58060","modified":1582777556474},{"_id":"source/_posts/CS231n笔记/optimizations on saddle point.gif","hash":"f41e1bc9f4c1df2c53d0522c29725b36820809d6","modified":1592483147367},{"_id":"source/_posts/CS231n笔记/sgd_problem.png","hash":"ac08775056cba0bb7b608c1a99076fd2d4451d68","modified":1592483147435},{"_id":"source/_posts/RT-MDNet/inst_loss.png","hash":"2f2adc47242cb10d7213f2f6576d70e3dd39d941","modified":1582643166651},{"_id":"source/_posts/RT-MDNet/Adaptive RoIAlign.png","hash":"e7e5212cd381b83f7dd7d6082f6b12086d3a4fe7","modified":1582643166647},{"_id":"source/_posts/SiamDW/1times1conv-1583335627710.png","hash":"439a8d133928a688d015bbd8a59141d6ef780476","modified":1583335627884},{"_id":"source/_posts/SiamDW/other_test-1583335627710.png","hash":"7ecaa0d2e4646bb0fe300a3de711949d24486c8a","modified":1583335627921},{"_id":"source/_posts/SiamDW/other_test.png","hash":"7ecaa0d2e4646bb0fe300a3de711949d24486c8a","modified":1583245434493},{"_id":"source/_posts/SiamDW/padding_test.png","hash":"a36139656138e145ecc8edc50fb1217e98de3d20","modified":1583244893956},{"_id":"source/_posts/Siamese系列/NMS_multi2.png","hash":"ee4b72973285c1de9775594389e1579ead113581","modified":1582643165895},{"_id":"source/_posts/Siamese系列/NMS_single.png","hash":"6f8bcdaad7538aea52e32262592946dfd36277eb","modified":1582643165901},{"_id":"source/_posts/CS231n笔记/optimizations on loss surface contours.gif","hash":"6e1e4c2b76d05bf34f3df3a9a967819a679de317","modified":1592483147435},{"_id":"source/_posts/SiamDW/loss_feature_with_str.png","hash":"bddff0cfcc64ebe379015c655aaddd4e83a337f5","modified":1582897948084},{"_id":"source/_posts/SiamDW/padding_test-1583335627710.png","hash":"a36139656138e145ecc8edc50fb1217e98de3d20","modified":1583335627920},{"_id":"source/_posts/SiamDW/CIR-D_2.png","hash":"51f52911f320c7ba285214947c8c4bf74ea2bb3f","modified":1583334715978},{"_id":"source/_posts/SiamDW/CIR-D_2-1583335627710.png","hash":"51f52911f320c7ba285214947c8c4bf74ea2bb3f","modified":1583335627942},{"_id":"source/_posts/SiamDW/analysis.png","hash":"e3a390c93ff30f3334a8c4f4526775cc6c12ecc9","modified":1583245729603},{"_id":"source/_posts/SiamDW/loss_feature_with_str-1583335627710.png","hash":"bddff0cfcc64ebe379015c655aaddd4e83a337f5","modified":1583335627943},{"_id":"source/_posts/SiamDW/with_padding-1583335627710.png","hash":"79f9f218fc8e4188ed870cd97e287c14dd7c50a2","modified":1583335627952},{"_id":"source/_posts/SiamDW/without_padding.png","hash":"9a8c727062ed3ade8f61af2aaf65f4351b96e6bc","modified":1582897486303},{"_id":"source/_posts/SiamDW/analysis-1583335627710.png","hash":"e3a390c93ff30f3334a8c4f4526775cc6c12ecc9","modified":1583335627952},{"_id":"source/_posts/SiamDW/without_padding-1583335627710.png","hash":"9a8c727062ed3ade8f61af2aaf65f4351b96e6bc","modified":1583335627948},{"_id":"source/_posts/英语1：简单句/搜狗截图20200316222055.png","hash":"d40103d68074a93625e1c830dcec9a8e1326aa0c","modified":1590074553301},{"_id":"source/_posts/SiamDW/with_padding.png","hash":"79f9f218fc8e4188ed870cd97e287c14dd7c50a2","modified":1582897499891},{"_id":"source/_posts/SiamDW/SINT-1583335627709.png","hash":"83984a88a43dd8fcab9e313d0a31b3704daf8d7e","modified":1583335627994},{"_id":"source/_posts/SiamDW/SINT.png","hash":"83984a88a43dd8fcab9e313d0a31b3704daf8d7e","modified":1583158931287},{"_id":"source/_posts/Siamese系列/SiamRPN_shortcoming2.png","hash":"416f77ed6aff42e38d92cb86dce88a42b323514f","modified":1582643165941},{"_id":"source/_posts/MDNet/MDNet_neg_mining.png","hash":"53ec4c5b2b7479fa854cc9f50b361030d49dff76","modified":1582643166724},{"_id":"source/_posts/Siamese系列/DaSiamRPN_data.png","hash":"ccc4163b44de9883a5f14937c3db88fa39b8008b","modified":1582643165893},{"_id":"source/_posts/Siamese系列/SiamFC_training_pairs.png","hash":"3a991a8f07f961354503bf6aaaeedce28e222fb2","modified":1582643165912},{"_id":"source/_posts/Siamese系列/SiamRPN++_correlate_heatmap.png","hash":"32d76180e7962c5beba4d876a9f28874af2a3e41","modified":1582643165920},{"_id":"source/_posts/Siamese系列/SiamRPN_shortcoming1.png","hash":"1c61a93d44e7d35fe61f5e8942b6ed087bf71bf2","modified":1582643165937},{"_id":"themes/Chic/source/fonts/lanting/lanting.woff2","hash":"5f325fcd2726a5b44e08b7004a5219e14847cbfa","modified":1591448572394},{"_id":"themes/Chic/source/fonts/lanting/lanting.woff","hash":"642ad1f17d27d4b1010d1a0571d1b44cbc823d9d","modified":1591448572389},{"_id":"themes/Chic/source/fonts/lanting/lanting.eot","hash":"3e184614f037939a6f98d607da3ed7dffb350e65","modified":1591448572346},{"_id":"themes/Chic/source/fonts/lanting/lanting.TTF","hash":"97e9a4538cceef4b17d54c7dc589524905d1b685","modified":1591448572319},{"_id":"source/_posts/RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png","hash":"923cc634dfdfe7d5800bf57871783a91ee9c1089","modified":1590840963953},{"_id":"source/_posts/Android总结1/zelda.png","hash":"3c0f45e7753a93777509faaf5b46583731276753","modified":1589546499461},{"_id":"themes/Chic/source/fonts/lanting/lanting.otf","hash":"4e184da596772d3ef6e5763cdee3e46a1ce2f2dd","modified":1591448572382},{"_id":"public/about/index.html","hash":"ec4ec3fbd6b82760ea299457d641b4f1b6e73c1b","modified":1594738555904},{"_id":"public/category/index.html","hash":"b1dce07d4b5c54847a0fb61530a5aecb1dd76118","modified":1594738555904},{"_id":"public/tag/index.html","hash":"8fc89d796683f35f32fd13b21b6bbe59f72e68cc","modified":1594738555904},{"_id":"public/2020/06/18/MDNet/index.html","hash":"5b50e5a47e504e287ed037e76a688ad6613e51f7","modified":1594738555904},{"_id":"public/2020/06/16/英语3：名词从句/index.html","hash":"96cb5b12e7f868241e31df9235af785ce677c5e6","modified":1594738555904},{"_id":"public/2020/06/09/英语2：并列句/index.html","hash":"73eb3404a9e7cf0bfc79542c22caaaff8e39d754","modified":1594738555904},{"_id":"public/2020/06/01/MD5/index.html","hash":"9127f3a338471ff50b0e97fe1d18df7e11ca71e9","modified":1594738555904},{"_id":"public/2020/02/27/重置博客/index.html","hash":"660fdb16867c09e86240036a51490abed1b86d34","modified":1594738555904},{"_id":"public/index.html","hash":"fa76c8966e94af3e386ece2639918b5952054859","modified":1594738555904},{"_id":"public/page/2/index.html","hash":"fa76c8966e94af3e386ece2639918b5952054859","modified":1594738555904},{"_id":"public/tags/信息安全/index.html","hash":"edfcde831ea84ee8246e9b170ebc67d48c81ed85","modified":1594738555904},{"_id":"public/tags/AI/index.html","hash":"6b4b0df5e617510954de08ba76effe4d10bd7c87","modified":1594738555904},{"_id":"public/tags/Android/index.html","hash":"69715ccfc78777eae370d6b17104a7f70efbf09c","modified":1594738555904},{"_id":"public/tags/英语/index.html","hash":"d8493118026200d4af516bd3072a741cc5a0c367","modified":1594738555904},{"_id":"public/tags/数学/index.html","hash":"85ba3983c614badfbc55632cdf24f66f99642417","modified":1594738555904},{"_id":"public/tags/杂项/index.html","hash":"438e1e1b62f44dc05865d32baee43c3d6e1a720e","modified":1594738555904},{"_id":"public/archives/index.html","hash":"685ff23d0e0da83e460a5b34bfcce0926bc8de2a","modified":1594738555904},{"_id":"public/archives/page/2/index.html","hash":"4dc4888edd879f2e95a910b1ddf9c718c8699020","modified":1594738555904},{"_id":"public/archives/2020/index.html","hash":"b3c6cdc467cbd49dd9e8b449823ec6aad5b4cecb","modified":1594738555904},{"_id":"public/archives/2020/page/2/index.html","hash":"d62be42d3579381cbf0ede63936381938f06fc90","modified":1594738555904},{"_id":"public/archives/2020/02/index.html","hash":"2c36213670acddd196d691799120977cb2df8137","modified":1594738555904},{"_id":"public/archives/2020/03/index.html","hash":"eb7eacfa3d4ee2a8b926b1231fcf1b8f058feeae","modified":1594738555904},{"_id":"public/archives/2020/05/index.html","hash":"14c40933bebb0cc88973f7d5cc48210a6027da7d","modified":1594738555904},{"_id":"public/archives/2020/06/index.html","hash":"e5dacfef8454b1d80ea5f5bad49b4cac98caf9b6","modified":1594738555904},{"_id":"public/archives/2020/07/index.html","hash":"02670dbaa09ae587047d0ae1487217d4d0bc5368","modified":1594738555904},{"_id":"public/2020/07/02/英语4：定语和定语从句/index.html","hash":"3ea83277b73aa5f28b32923f33460b0a310f93c1","modified":1594738555904},{"_id":"public/2020/06/18/CS231n笔记/index.html","hash":"b369299bbfe338de768205704815ce94f3aaa37a","modified":1594738555904},{"_id":"public/2020/06/18/AdaBound/index.html","hash":"ed9539307b453d304096f94e5e4cf56ad689991b","modified":1594738555904},{"_id":"public/2020/06/18/Siamese系列/index.html","hash":"76f8c0fd3238e143c1a0a301f718dd06c5b88f98","modified":1594738555904},{"_id":"public/2020/06/18/RT-MDNet/index.html","hash":"1d35fe1ee42a32ff68c8a120b190e3a0527c9012","modified":1594738555904},{"_id":"public/2020/06/06/线性代数空间角度理解/index.html","hash":"ae1859b2dcfdfc92486aacf4ad799d357b2e567a","modified":1594738555904},{"_id":"public/2020/05/30/RSA/index.html","hash":"609e10ba9361244a6bc5dc0522582782d6846f00","modified":1594738555904},{"_id":"public/2020/05/21/英语1：简单句/index.html","hash":"963bf3a07ba83cde34171c53e8e1c0bb9ffa4aff","modified":1594738555904},{"_id":"public/2020/05/18/DES和分组密码工作模式/index.html","hash":"747a1f16dd338a6f7daccaa8737aae3e34feefa7","modified":1594738555904},{"_id":"public/2020/05/15/Android总结1/index.html","hash":"a6f5829270fcbdbc189eb94543d769babe92e97c","modified":1594738555904},{"_id":"public/2020/03/04/SiamDW/index.html","hash":"6b0329a58b2e83fbf30e7638cae82701ccc4c0e1","modified":1594738555904},{"_id":"public/favicon.ico","hash":"4f249bf78e4236db9e235e94bcab89bb5aeb0786","modified":1593702493195},{"_id":"public/image/avatar.jpg","hash":"b6abbc09bc522d042206341be6a7029511ef59c9","modified":1593702493195},{"_id":"public/static/images/avatar.jpg","hash":"31a06079aa533dc955a96181e6c391a314748bec","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.eot","hash":"d18736f7885569e497698d17f49b9167add67dc6","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.svg","hash":"8f1d735e4fae3757dac1866dc3e30147140811e2","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.ttf","hash":"41c4f4dc82e42452dcfd19caed6c7dc333ee769e","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.woff","hash":"a57593c49b56c16ac1def0e1f3dbca3f658b3579","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.woff2","hash":"39d97a0f72417487f5c1e0a0abf8e27dd6ebda31","modified":1593702493195},{"_id":"public/2020/06/01/MD5/FFGGHHII.png","hash":"f72ea1a9861ca1c3d84aa14d186f1185738346e9","modified":1593702493195},{"_id":"public/2020/06/01/MD5/FGHI.png","hash":"627f0c8fb45796a7f79a8ca365000c0fcee91a8d","modified":1593702493195},{"_id":"public/2020/06/01/MD5/MD5.png","hash":"eea41fb561bb7b52fbaf067c8d3cc34d0f5dc4c6","modified":1593702493195},{"_id":"public/2020/06/18/RT-MDNet/ROIAlign.png","hash":"451ec2ff4a5e191c3bb132360340e57a225a6c23","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/CBC.jpg","hash":"ef0738b2e4a071b176f35f3fddf6b32f2bcda6d4","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/DES.png","hash":"ba381fde13518bec33aa92a9f2358ccb381f09e4","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/CFB.jpg","hash":"23d8382f847c722e9d826fbe8a5040e8170d6a1d","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/ECB.jpg","hash":"1ec35e5bda633d10605b4886dff9c9c96f619548","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/P.png","hash":"6d4a52734a9435660bed6b2669ff924dc9e2cb26","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/S.png","hash":"6d16a6237c05fa49ef66cb7f26279665566476e5","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/e_bit-selection.png","hash":"11f4e5c757c16619494753e629335461590f0fa2","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/f(R,K).png","hash":"a0d28b676dc700b8fb469c5b8d8b625481582b12","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/pc_1.png","hash":"4c087409247b236fae622268688ba09a0f6ee834","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/pc_2.png","hash":"787d7f337e5b3d427ad4e4aef287970ab51be858","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_clip.png","hash":"627fa7bd207e4c8d05556bc1b8ce3bb0ba67ec2d","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure1.png","hash":"6f7c98a0c568ad2ca0a3d93a0cc06628f58ad6a4","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_corollary4.1.png","hash":"7d09dbd52ddb15143eb8811007584933ce8c8632","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure4.2.png","hash":"aefcf6c021c7ec7dda0f16995950867700f86db3","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_table1.png","hash":"78d04a419bbd480d892f9aba8f5ac2929ce716dd","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_theorem4.png","hash":"4b799edbca0c064b58910bc5f2c3c6dc294de673","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/AdaBound_figure1.png","hash":"6f7c98a0c568ad2ca0a3d93a0cc06628f58ad6a4","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/AdaBound_clip.png","hash":"627fa7bd207e4c8d05556bc1b8ce3bb0ba67ec2d","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/SGDM.jpg","hash":"f8e86dcb9585e68a8f8df99ac67cf92cc22e4304","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/bn_forward.png","hash":"b62b7984ac0f4391ab9a078c3c44c8c194703c21","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/elu.png","hash":"fb3022e5c7789235eaa4fba08d71e36ceed55bc0","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/leaky relu.png","hash":"dae5d5df131aa32f71ac43bf9d9de3efbeda33a4","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/relu.png","hash":"1c2075be25a1820db3c48be414ebabbe48d58b33","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/sgd_problem1.png","hash":"75bb4ac3c468e2b6ac13fe164b95468bbd752df2","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/sgd_problem2.png","hash":"9800ad0a55dfdb14eea60a2bd28fd08a35d79ef8","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/sigmoid.png","hash":"7b00654e99b9898633ff050006768cff5f314da2","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/tanh.png","hash":"dca8ebe17a629124143fd3a9b2f5200697eb5756","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/SiamFC_1.png","hash":"423b023d347c17156fb2fb2d1f292dd961f2d6b9","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/SiamFC_1-1583335627710.png","hash":"423b023d347c17156fb2fb2d1f292dd961f2d6b9","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/motivation-1583335627710.png","hash":"9da37821d3f5a0fabc24c0b86eeb77dabf059261","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/motivation.png","hash":"9da37821d3f5a0fabc24c0b86eeb77dabf059261","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/Bicubic interpolation2.png","hash":"4c146538f63338bd8a00559ff89d51866a4bb18c","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/Bicubic interpolation1.PNG","hash":"b167138376b6973945b565b3b1c006ebb69c7190","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/RPN.jpg","hash":"03cd9ec411375f08d0aaa17ba6848cc659171eae","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamFC_1.png","hash":"423b023d347c17156fb2fb2d1f292dd961f2d6b9","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamFC_2.jpg","hash":"182ea6a1e613978ec7bf7216c8b847333f248e5a","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamFC_loss.png","hash":"88591a98ddb3c3d5deee2b0206ef8ab64b71a2cc","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamFC_3.jpg","hash":"69571371223697f1dfe8168a7a175e0dddb051d7","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/Siamese Net_loss.png","hash":"aca927f79767fc731f300f5b6a6a7d091d6fad63","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/Siamese Net.png","hash":"d12b60357769e92c7e739d5f3a7a9a42040cbeb4","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/Siamese Net_loss1.png","hash":"5b04979b521efd9328890b0be12ba9b643167672","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/anchors.jpg","hash":"f5ba8713a246f721776b48fc82b9b63a3a8706f4","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/nonlocal_eq1.png","hash":"ec0edcdfb9d9b45a6ba28f9229759d92c0160ede","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/nonlocal_eq3.png","hash":"ba34e5e3591a6667979427481ee1f30a26c4df4f","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/nonlocal_eq2.png","hash":"688cac5b7ad8a10ea25098a4b97a2619245bfc6e","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/rpn_regression1.png","hash":"487b9f29598f094fc512afd03eee4fd13c1c2de5","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/smooth loss.png","hash":"32cf78b67141d86a48f0b91cf0d81a4ac624c9cc","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/smoothL1.jpg","hash":"94cc0b697e6186fbc0713dc6a06ce954efea658f","modified":1593702493195},{"_id":"public/live2dw/assets/hijiki.model.json","hash":"feff43bf7498d213982c3736c2c029664e4bcbd2","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/差值3.png","hash":"2f39cacb8f8e6a1a8992eab610d1692746ab5dfd","modified":1593702493195},{"_id":"public/live2dw/assets/hijiki.pose.json","hash":"81438bf69b32c7c11e311b4fe043730cdc7b7ec2","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/00_idle.mtn","hash":"b224c60e463b9f71ddbfc0c720e430496c175f4f","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/02.mtn","hash":"7eafc52edc73b7cb80ae70d34b43c6ac778fa47b","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/01.mtn","hash":"fb550833ae22c9954c3e01df37ed29b2d61700f2","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/03.mtn","hash":"f900737c7a98441cbb2e05255427e6260e19ae68","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/04.mtn","hash":"c7a25d3c5d783639bae18db2f3cd284b819c3c85","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/05.mtn","hash":"dd20ad24b5d1830a5d44b9bccb28f922eea5e0e5","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/06.mtn","hash":"ad404bd852d276cdd3d054c953e23f90e4e45ae1","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/07.mtn","hash":"b7f2e3a9fa4f3ffbb6e64a08f8d9f45ca1868ffb","modified":1593702493195},{"_id":"public/live2dw/assets/mtn/08.mtn","hash":"4411c7651ff65195b113d95e7d5ebef8a59a37d9","modified":1593702493195},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1593702493195},{"_id":"public/image/QQ.jpg","hash":"eeb8273511430456b0f159a74cb99f57cddb3d67","modified":1593702493195},{"_id":"public/2020/06/18/RT-MDNet/ROIPooling.png","hash":"8f20b6bd13177177d30630116ffc183ea98f70b2","modified":1593702493195},{"_id":"public/2020/06/06/线性代数空间角度理解/1.png","hash":"66a18fa757a36b1bcad7a3f35a2c272394542cb2","modified":1593702493195},{"_id":"public/2020/06/06/线性代数空间角度理解/3.png","hash":"0a373fe980cf13fda7de10d6154206f70a9a042a","modified":1593702493195},{"_id":"public/2020/06/06/线性代数空间角度理解/2.png","hash":"a282c4192172af67ce2b8791bbdb62256cb5d013","modified":1593702493195},{"_id":"public/2020/06/06/线性代数空间角度理解/5.png","hash":"4728f5dc19563ef99ded4d774f2d2aa1abdfda9b","modified":1593702493195},{"_id":"public/2020/06/06/线性代数空间角度理解/7.png","hash":"baff3a8ea6a40708300ddeda5e90444c519d9a30","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/OFB.jpg","hash":"c7d41970cebc18185c461583fe25bc92493c9c39","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/image-20200512205728831.png","hash":"334dfa1db8912bc53fb9bf2282cf2f3ad0b27bd3","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_algorithm1.png","hash":"0bc029d87295a2bc291ac12e6db4d9e6dc70af33","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure2.png","hash":"4b95f0c7250e175a5e717159cefe78f5b3c646fc","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure4.1.png","hash":"dd609d1abf28e2b2a7318096e6a2ca1b7caa868e","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure7.2.png","hash":"e73bd627c8a93b2a2e3b7dbd22fa7e2016032cd5","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_table2.png","hash":"1826d838163352dc916a1ec8d917b49a739f0e71","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/bn_backward.jpg","hash":"32c1ee6f8b70b28fe472c1a55aff20ad4a2d5c9d","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/loss-learing rate.png","hash":"496d231347075a58a0e30b7cd5bfe76fe19195cf","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/CIR-1583335627710.png","hash":"cb5eb13d8bc0c523bb2c3b7b12a4d3876865fdaa","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/CIR-D-1583335627710.png","hash":"f3d55c5d2a34f249e12c962ff0b8185943b238a4","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/CIR-D.png","hash":"f3d55c5d2a34f249e12c962ff0b8185943b238a4","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/CIR.png","hash":"cb5eb13d8bc0c523bb2c3b7b12a4d3876865fdaa","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/simple_siam-1583335627709.png","hash":"df968173ed649cc6071e8ad88de262c82386aecd","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/simple_siam.png","hash":"df968173ed649cc6071e8ad88de262c82386aecd","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_RPN.png","hash":"dc05e56c8ef2da068c477d26c1cbf24c16004cfe","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_correlation.png","hash":"fd80616eab508b26f95acad0834c99093c2c1021","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_translation.png","hash":"784c53d6f6543613931cdf2a37ef7d2d79795522","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN_prosal_select.png","hash":"729db7ad5abb8ae261560ae3d17bd7d2ec521f71","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN_tracking.png","hash":"5943e9f7a94600df285149a48bcd913bdc6948cc","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/Siamese twins.jpg","hash":"76c05c83a3bd03262488c9340c88f0abc02e5e83","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/nonlocal_block_struct.jpg","hash":"7f98b268cc001bad88027f1530fa6bf93eabf0b1","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/rpn1.png","hash":"f0eb97c1d44f24289ccebd66b66368b750150c05","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/rpn_regression.png","hash":"84b4a064d851999f06aa01c51eb0bae48cac4a7f","modified":1593702493195},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1593702493195},{"_id":"public/css/font.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1593702493195},{"_id":"public/css/base.css","hash":"ea2d491ce6242c6b7087a2652a1135694c292137","modified":1593702493195},{"_id":"public/css/normalize.css","hash":"2d4b663b6a4c68295b6ba240fa2dd9fb3863093c","modified":1593702493195},{"_id":"public/css/layout.css","hash":"c81e2e01ff5e95a3e613064b8490045ff936c305","modified":1593702493195},{"_id":"public/css/custom.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1593702493195},{"_id":"public/css/media.css","hash":"5023ee404900a47d61ca0591b2d4e9eace0fe88e","modified":1593702493195},{"_id":"public/js/script.js","hash":"93694e4e16893f83611daa5ba3723b14ecc80abb","modified":1593702493195},{"_id":"public/css/variable.css","hash":"cb4180b3bbad471e30cf52ebb40e998d58a30d7d","modified":1593702493195},{"_id":"public/js/tocbot.min.js","hash":"bae97e8a24a05a99335f8e725641c8ca9c50502a","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.css","hash":"1e5540dca41dc53879226750f936e72daf616662","modified":1593702493195},{"_id":"public/fonts/iconfont/demo.css","hash":"65c50db528a5abe06426b1a20735feaf1f2a0d9b","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.json","hash":"3123aa840109e385d58a75d34e88a2d621e1ada8","modified":1593702493195},{"_id":"public/css/style.css","hash":"12517e9e60010207b536c224c6fc70c43caf4499","modified":1593702493195},{"_id":"public/js/mathjax2.7.5.js","hash":"7ba18c783d543cfb4b45a0118ccb73d3f68cd46e","modified":1593702493195},{"_id":"public/fonts/iconfont/iconfont.js","hash":"87bfdaae31251f4d605646c5ae9c67196f6cc4e2","modified":1593702493195},{"_id":"public/fonts/iconfont/demo_index.html","hash":"3a677d6437a198ff3ab830f61431f6f1726d15ae","modified":1593702493195},{"_id":"public/2020/06/18/MDNet/MDNet_struct.png","hash":"d506e2d1e2171aed32c01d3c69c7cc333698c975","modified":1593702493195},{"_id":"public/2020/06/18/MDNet/MDnet_algorithm.png","hash":"acb38b23e6be39dc946494976df3c952d76fb2a5","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure3.1.png","hash":"ef29f326b64298373fa21077369fd424887a9588","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure3.2.png","hash":"f2888d3432f73471678d54083f44b5053c906128","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_algorithm2.png","hash":"11ce9a8d79b45afb2f6c4505235dd277cf326372","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure7.1.png","hash":"f5afca527c607095e22325a94754bce11168cdc7","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/主流.png","hash":"bbed2bc32b587b4ba7a12f33a89d9760c9a1e10e","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/SiamRPN_net.png","hash":"0085ca3f08cc4d1ed73fda37ad7ec8da510d3f19","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamFC_net_layer.png","hash":"ffc9a10e6fb6c575af233037f125a1e55c5917ce","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_heatmap.png","hash":"d9cac41ec101aaeb67bf11dc1b70cf146b944fe4","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN_net.png","hash":"0085ca3f08cc4d1ed73fda37ad7ec8da510d3f19","modified":1593702493195},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/SGD+Nesterov.png","hash":"23ecf6cc69d51cd0aa38fe8dec38786ecf537ab2","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/1times1conv.png","hash":"439a8d133928a688d015bbd8a59141d6ef780476","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure6.png","hash":"88acd06546d1681aa14438f526c49c41ccb31575","modified":1593702493195},{"_id":"public/2020/06/06/线性代数空间角度理解/4.png","hash":"b3c79d0f730f4294c269544e873950acce8cf18b","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/1times1conv-1583335627710.png","hash":"439a8d133928a688d015bbd8a59141d6ef780476","modified":1593702493195},{"_id":"public/2020/05/18/DES和分组密码工作模式/IP&IP-1.png","hash":"fbde8065d915e1b878ba9b136a1f97b248623bdc","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/SiamRPN_net-1583335627710.png","hash":"0085ca3f08cc4d1ed73fda37ad7ec8da510d3f19","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_net.png","hash":"0873c2bfc2cd787c48142eb5a29c7fa944fa2d28","modified":1593702493195},{"_id":"public/live2dw/assets/moc/hijiki.moc","hash":"44289e62545a7046e0f5231103a851750b78524e","modified":1593702493195},{"_id":"public/2020/06/18/AdaBound/AdaBound_figure5.png","hash":"5f4fc769c44f22f3f54c23eea59675428f176c42","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/NMS_multi3.png","hash":"73b77e7645d81a6099d94e5a1ea8e21a6f089da3","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/NMS_multi4.png","hash":"c298a55af3effb71a21dec8ec9b340cfb3318de1","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/1062917-20161117212457248-1468090428.png","hash":"47b986560de89d833552a546c2165809243cda0e","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/optimizations on saddle point.gif","hash":"f41e1bc9f4c1df2c53d0522c29725b36820809d6","modified":1593702493195},{"_id":"public/2020/06/18/RT-MDNet/inst_loss.png","hash":"2f2adc47242cb10d7213f2f6576d70e3dd39d941","modified":1593702493195},{"_id":"public/live2dw/assets/moc/hijiki.2048/texture_00.png","hash":"66464e0d96439695b5542c5e2f5be60739c29999","modified":1593702493195},{"_id":"public/static/images/background.jpg","hash":"3d711c925fb0419a8265502f5146f33c29f58060","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_net_left.png","hash":"12cc86b39975b6d2a6f50c998eb898cf5c9d9f99","modified":1593702493195},{"_id":"public/2020/06/18/RT-MDNet/Adaptive RoIAlign.png","hash":"e7e5212cd381b83f7dd7d6082f6b12086d3a4fe7","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/optimizations on loss surface contours.gif","hash":"6e1e4c2b76d05bf34f3df3a9a967819a679de317","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/padding_test-1583335627710.png","hash":"a36139656138e145ecc8edc50fb1217e98de3d20","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/other_test.png","hash":"7ecaa0d2e4646bb0fe300a3de711949d24486c8a","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/NMS_multi2.png","hash":"ee4b72973285c1de9775594389e1579ead113581","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/NMS_single.png","hash":"6f8bcdaad7538aea52e32262592946dfd36277eb","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/CIR-D_2.png","hash":"51f52911f320c7ba285214947c8c4bf74ea2bb3f","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/NMS_multi1.png","hash":"5cc14d760b4eea79e45494568f13869053c9df6d","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/padding_test.png","hash":"a36139656138e145ecc8edc50fb1217e98de3d20","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/CIR-D_2-1583335627710.png","hash":"51f52911f320c7ba285214947c8c4bf74ea2bb3f","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/loss_feature_with_str-1583335627710.png","hash":"bddff0cfcc64ebe379015c655aaddd4e83a337f5","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/loss_feature_with_str.png","hash":"bddff0cfcc64ebe379015c655aaddd4e83a337f5","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/without_padding.png","hash":"9a8c727062ed3ade8f61af2aaf65f4351b96e6bc","modified":1593702493195},{"_id":"public/2020/06/18/CS231n笔记/sgd_problem.png","hash":"ac08775056cba0bb7b608c1a99076fd2d4451d68","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/other_test-1583335627710.png","hash":"7ecaa0d2e4646bb0fe300a3de711949d24486c8a","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/without_padding-1583335627710.png","hash":"9a8c727062ed3ade8f61af2aaf65f4351b96e6bc","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/with_padding.png","hash":"79f9f218fc8e4188ed870cd97e287c14dd7c50a2","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/with_padding-1583335627710.png","hash":"79f9f218fc8e4188ed870cd97e287c14dd7c50a2","modified":1593702493195},{"_id":"public/2020/05/21/英语1：简单句/搜狗截图20200316222055.png","hash":"d40103d68074a93625e1c830dcec9a8e1326aa0c","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/analysis-1583335627710.png","hash":"e3a390c93ff30f3334a8c4f4526775cc6c12ecc9","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/SINT.png","hash":"83984a88a43dd8fcab9e313d0a31b3704daf8d7e","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/analysis.png","hash":"e3a390c93ff30f3334a8c4f4526775cc6c12ecc9","modified":1593702493195},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1593702493195},{"_id":"public/2020/03/04/SiamDW/SINT-1583335627709.png","hash":"83984a88a43dd8fcab9e313d0a31b3704daf8d7e","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN_shortcoming2.png","hash":"416f77ed6aff42e38d92cb86dce88a42b323514f","modified":1593702493195},{"_id":"public/2020/06/18/MDNet/MDNet_neg_mining.png","hash":"53ec4c5b2b7479fa854cc9f50b361030d49dff76","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamFC_training_pairs.png","hash":"3a991a8f07f961354503bf6aaaeedce28e222fb2","modified":1593702493195},{"_id":"public/fonts/lanting/lanting.woff2","hash":"5f325fcd2726a5b44e08b7004a5219e14847cbfa","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN++_correlate_heatmap.png","hash":"32d76180e7962c5beba4d876a9f28874af2a3e41","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/SiamRPN_shortcoming1.png","hash":"1c61a93d44e7d35fe61f5e8942b6ed087bf71bf2","modified":1593702493195},{"_id":"public/2020/06/18/Siamese系列/DaSiamRPN_data.png","hash":"ccc4163b44de9883a5f14937c3db88fa39b8008b","modified":1593702493195},{"_id":"public/fonts/lanting/lanting.woff","hash":"642ad1f17d27d4b1010d1a0571d1b44cbc823d9d","modified":1593702493195},{"_id":"public/fonts/lanting/lanting.eot","hash":"3e184614f037939a6f98d607da3ed7dffb350e65","modified":1593702493195},{"_id":"public/fonts/lanting/lanting.TTF","hash":"97e9a4538cceef4b17d54c7dc589524905d1b685","modified":1593702493195},{"_id":"public/2020/05/30/RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png","hash":"923cc634dfdfe7d5800bf57871783a91ee9c1089","modified":1593702493195},{"_id":"public/2020/05/15/Android总结1/zelda.png","hash":"3c0f45e7753a93777509faaf5b46583731276753","modified":1593702493195},{"_id":"public/fonts/lanting/lanting.otf","hash":"4e184da596772d3ef6e5763cdee3e46a1ce2f2dd","modified":1593702493195},{"_id":"source/_posts/英语5：状语和状语从句.md","hash":"1294acdbbbdd178151d165cf8e09bd7b8ae65561","modified":1595947187081},{"_id":"public/2020/07/11/英语5：状语和状语从句/index.html","hash":"2de5c730e4f12319c2389dcf2d1ee45885cde08b","modified":1596642193397}],"Category":[],"Data":[],"Page":[{"title":"About","date":"2020-06-07T09:38:34.000Z","_content":"\n\n\n靳世阳\n\nHDU\n\n划水，摸鱼，偷鸡，三项全能。","source":"about/index.md","raw":"---\ntitle: About\ndate: 2020-06-07 17:38:34\n---\n\n\n\n靳世阳\n\nHDU\n\n划水，摸鱼，偷鸡，三项全能。","updated":"2020-06-07T09:40:09.870Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckc4xbev80001i0qv95fwecgd","content":"<p>靳世阳</p>\n<p>HDU</p>\n<p>划水，摸鱼，偷鸡，三项全能。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>靳世阳</p>\n<p>HDU</p>\n<p>划水，摸鱼，偷鸡，三项全能。</p>\n"},{"title":"category","layout":"category","date":"2020-06-06T14:52:54.000Z","_content":"","source":"category/index.md","raw":"---\ntitle: category\nlayout: category\ndate: 2020-06-06 22:52:54\n---\n","updated":"2020-06-06T14:54:58.262Z","path":"category/index.html","comments":1,"_id":"ckc4xbewy0015i0qv05yj5gjw","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tag","layout":"tag","date":"2020-06-06T14:52:45.000Z","_content":"","source":"tag/index.md","raw":"---\ntitle: tag\nlayout: tag\ndate: 2020-06-06 22:52:45\n---\n","updated":"2020-06-06T14:53:46.188Z","path":"tag/index.html","comments":1,"_id":"ckc4xbewz0016i0qvdf4f4pct","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"DES和分组密码工作模式","date":"2020-05-18T12:17:27.000Z","mathjax":true,"_content":"\n\n\n信息安全试验所需。\n\n<!--more-->\n\n<!-- toc -->\n\n[toc]\n\n<br/>\n\n# DES\n\n![DES](DES和分组密码工作模式/DES.png)\n\n<br/>\n\n## 按表变换\n\nDES涉及多次依据表格进行位置变换。\n\n![pc_1](DES和分组密码工作模式/pc_1.png)\n\n如此表，第1位的57，表示把原数据的第57位的数字移至第1位。\n\n<br/>\n\n---\n\n<br/>\n\n## 秘钥部分\n\n1. 全长64位，但8的倍数位是奇偶校验，不参与实际加密。\n\n2. PC-1变换：64分8组，按照PC-1表进行变换，此步表中没有8*k位置（此步消去奇偶校验位），得到56位秘钥。\n\n\t![pc_1](DES和分组密码工作模式/pc_1.png)\n\n3. 拆分：56位秘钥左右均分为$C_0$和$D_0$（各28位）\n\n4. 循环左移：将上述两部分，各自逐次循环左移16次，得到$C_i,D_i \\ (i\\in[1,16])$\n\n\t* i=1,2,9,16时是左移1位**得到**\n\t* 其余左移2位**得到**\n\n\t> $ C_0 = 1111000011001100101010101111\n\t> \\\\ C_1 = 1110000110011001010101011111 $\n\n5. 合并：$ C_iD_i $ \n\n6. PC-2变换：得到子秘钥$ K_i $，此步表中仅48位，即子秘钥仅48位（删除C的第9,18,22,25位以及D的第7,9,15,26比特位）\n\n\t![pc_2](DES和分组密码工作模式/pc_2.png)\n\n\t\n\n总过程：原秘钥（64） -> PC-1（56↓） -> 两侧循环左移（28×2） -> PC-2（48↓） -> 子秘钥$K_i $（48）\n\n![image-20200512205728831](DES和分组密码工作模式/image-20200512205728831.png)\n\n<br/>\n\n---\n\n<br/>\n\n## 信息部分\n\nDES基于组块，每块64位。\n\n1. 初始变换IP（Initial permutation）：右上是IP表，右下是IP逆的表。两表互为逆操作。\n\n\t![IP&IP-1](DES和分组密码工作模式/IP&IP-1.png)\n\n2. 分块：64位均分为左右$L_0、 \\ R_0$，各32位\n\n3. 16次迭代：\n\t$$\n\tL_i = R_{i-1}\n\t\\\\ R_i = L_{i-1} \\ XOR \\ f(R_{i-1}, \\ K_i)\n\t$$\n\n4. $f(R_{i-1}, \\ K_{i})$：输入两个32位，输出一个32位\n\n\t![f(R,K)](DES和分组密码工作模式/f(R,K).png)\n\n\t1. 扩展置换E：$R_{i-1}$ 经下表扩展至48位\n\n\t\t![e_bit-selection](DES和分组密码工作模式/e_bit-selection.png)\n\n\t2. XOR：扩展所得与子秘钥异或 $E(R_{i-1}) \\ XOR \\ K_i$ \n\n\t3. S盒替换：将异或得到的48位结果分成八个6位的块，每一块通过对应的一个S盒产生一个4位的输出。\n\n\t\t每个S盒都是4×16的矩阵。例如块1：$x_1x_2x_3x_4x_5x_6$，将$x_1x_6$转为10进制作为S盒1的行号，将$x_2x_3x_4x_5$转为10进制作为S盒1的列号，则确定一个数字，转为4位二进制。\n\n\t\t最终实现每块的6位->4位，整体的32位。\n\n\t\t![S](DES和分组密码工作模式/S.png)\n\n\t4. P置换：将上述所得进行移位变换，得32位\n\n\t\t![P](DES和分组密码工作模式/P.png)\n\n5. 16次后，得到$L_{16}, \\ R_{16}$，将其倒置得$R_{16}L_{16}(64)$，进行IP逆置换，得到最终密文。\n\n<br/>\n\n---\n\n<br/>\n\n## 解密\n\n仅将秘钥调换使用顺序（$K_{16},K_{15},...,K_1$），其余与加密相同。\n\n<br/>\n\n<br/>\n\n# 分组密码工作模式\n\n## ECB\n\n电子密码本ECB (electronic codebookmode)\n\n![ECB](DES和分组密码工作模式/ECB.jpg)\n\n* 最简单的方法：原数据分组后按顺序加密，之后将所得密文按顺序连接即可\n* 特点\n\t* 简单可并行\n\t* 不能隐藏明文的模式信息\n\t* 加密消息块相互独立成为被攻击的弱点（可能主动攻击明文）\n\n## CBC\n\n密码分组链接CBC (cipher blockchaining)\n\n![CBC](DES和分组密码工作模式/CBC.jpg)\n\n* 使加密的各段数据之间有了联系\n* 解密时先解密再与初始向量/**密文**异或\n* 解密后补位数据要删除\n* 特点：\n\t* 加密无法并行\n\t* 隐藏明文的模式信息（相同明文块，生成密文不同）\n\t* 不易对明文主动攻击\n\t* 密文块损坏导致两明文块损坏\n\t* 安全性更好，更适合长报文传输\n\n## CFB\n\n密码反馈CFB (cipher feedback)\n\n![CFB](DES和分组密码工作模式/CFB.jpg)\n\n使用一个与块大小相同的移位寄存器（用IV初始化）。将其加密后，取高n位（K块作用）与明文的n位异或。随后寄存器左移n位，将得到的n位密文补至尾部。解密过程与加密过程相似，以IV开始，对寄存器加密，将结果的高x与密文异或，产生x位平文，再将密文的下面x位移入寄存器。\n\n特点：\n\n* 流密码\n* 隐藏明文模式\n* 误差传递：一个单元损坏影响多个单元\n\n## OFB\n\n输出反馈OFB (output feedback)\n\n![OFB](DES和分组密码工作模式/OFB.jpg)\n\n特点：\n\n* 流密码\n* 隐藏了明文模式\n* 误差传递：一个单元损坏只影响对应单元\n* 对明文的主动攻击是可能的,信息块可被替换、重放\n* 安全性较CFB差","source":"_posts/DES和分组密码工作模式.md","raw":"---\ntitle: DES和分组密码工作模式\ndate: 2020-05-18 20:17:27\ntags: 信息安全\nmathjax: true\n---\n\n\n\n信息安全试验所需。\n\n<!--more-->\n\n<!-- toc -->\n\n[toc]\n\n<br/>\n\n# DES\n\n![DES](DES和分组密码工作模式/DES.png)\n\n<br/>\n\n## 按表变换\n\nDES涉及多次依据表格进行位置变换。\n\n![pc_1](DES和分组密码工作模式/pc_1.png)\n\n如此表，第1位的57，表示把原数据的第57位的数字移至第1位。\n\n<br/>\n\n---\n\n<br/>\n\n## 秘钥部分\n\n1. 全长64位，但8的倍数位是奇偶校验，不参与实际加密。\n\n2. PC-1变换：64分8组，按照PC-1表进行变换，此步表中没有8*k位置（此步消去奇偶校验位），得到56位秘钥。\n\n\t![pc_1](DES和分组密码工作模式/pc_1.png)\n\n3. 拆分：56位秘钥左右均分为$C_0$和$D_0$（各28位）\n\n4. 循环左移：将上述两部分，各自逐次循环左移16次，得到$C_i,D_i \\ (i\\in[1,16])$\n\n\t* i=1,2,9,16时是左移1位**得到**\n\t* 其余左移2位**得到**\n\n\t> $ C_0 = 1111000011001100101010101111\n\t> \\\\ C_1 = 1110000110011001010101011111 $\n\n5. 合并：$ C_iD_i $ \n\n6. PC-2变换：得到子秘钥$ K_i $，此步表中仅48位，即子秘钥仅48位（删除C的第9,18,22,25位以及D的第7,9,15,26比特位）\n\n\t![pc_2](DES和分组密码工作模式/pc_2.png)\n\n\t\n\n总过程：原秘钥（64） -> PC-1（56↓） -> 两侧循环左移（28×2） -> PC-2（48↓） -> 子秘钥$K_i $（48）\n\n![image-20200512205728831](DES和分组密码工作模式/image-20200512205728831.png)\n\n<br/>\n\n---\n\n<br/>\n\n## 信息部分\n\nDES基于组块，每块64位。\n\n1. 初始变换IP（Initial permutation）：右上是IP表，右下是IP逆的表。两表互为逆操作。\n\n\t![IP&IP-1](DES和分组密码工作模式/IP&IP-1.png)\n\n2. 分块：64位均分为左右$L_0、 \\ R_0$，各32位\n\n3. 16次迭代：\n\t$$\n\tL_i = R_{i-1}\n\t\\\\ R_i = L_{i-1} \\ XOR \\ f(R_{i-1}, \\ K_i)\n\t$$\n\n4. $f(R_{i-1}, \\ K_{i})$：输入两个32位，输出一个32位\n\n\t![f(R,K)](DES和分组密码工作模式/f(R,K).png)\n\n\t1. 扩展置换E：$R_{i-1}$ 经下表扩展至48位\n\n\t\t![e_bit-selection](DES和分组密码工作模式/e_bit-selection.png)\n\n\t2. XOR：扩展所得与子秘钥异或 $E(R_{i-1}) \\ XOR \\ K_i$ \n\n\t3. S盒替换：将异或得到的48位结果分成八个6位的块，每一块通过对应的一个S盒产生一个4位的输出。\n\n\t\t每个S盒都是4×16的矩阵。例如块1：$x_1x_2x_3x_4x_5x_6$，将$x_1x_6$转为10进制作为S盒1的行号，将$x_2x_3x_4x_5$转为10进制作为S盒1的列号，则确定一个数字，转为4位二进制。\n\n\t\t最终实现每块的6位->4位，整体的32位。\n\n\t\t![S](DES和分组密码工作模式/S.png)\n\n\t4. P置换：将上述所得进行移位变换，得32位\n\n\t\t![P](DES和分组密码工作模式/P.png)\n\n5. 16次后，得到$L_{16}, \\ R_{16}$，将其倒置得$R_{16}L_{16}(64)$，进行IP逆置换，得到最终密文。\n\n<br/>\n\n---\n\n<br/>\n\n## 解密\n\n仅将秘钥调换使用顺序（$K_{16},K_{15},...,K_1$），其余与加密相同。\n\n<br/>\n\n<br/>\n\n# 分组密码工作模式\n\n## ECB\n\n电子密码本ECB (electronic codebookmode)\n\n![ECB](DES和分组密码工作模式/ECB.jpg)\n\n* 最简单的方法：原数据分组后按顺序加密，之后将所得密文按顺序连接即可\n* 特点\n\t* 简单可并行\n\t* 不能隐藏明文的模式信息\n\t* 加密消息块相互独立成为被攻击的弱点（可能主动攻击明文）\n\n## CBC\n\n密码分组链接CBC (cipher blockchaining)\n\n![CBC](DES和分组密码工作模式/CBC.jpg)\n\n* 使加密的各段数据之间有了联系\n* 解密时先解密再与初始向量/**密文**异或\n* 解密后补位数据要删除\n* 特点：\n\t* 加密无法并行\n\t* 隐藏明文的模式信息（相同明文块，生成密文不同）\n\t* 不易对明文主动攻击\n\t* 密文块损坏导致两明文块损坏\n\t* 安全性更好，更适合长报文传输\n\n## CFB\n\n密码反馈CFB (cipher feedback)\n\n![CFB](DES和分组密码工作模式/CFB.jpg)\n\n使用一个与块大小相同的移位寄存器（用IV初始化）。将其加密后，取高n位（K块作用）与明文的n位异或。随后寄存器左移n位，将得到的n位密文补至尾部。解密过程与加密过程相似，以IV开始，对寄存器加密，将结果的高x与密文异或，产生x位平文，再将密文的下面x位移入寄存器。\n\n特点：\n\n* 流密码\n* 隐藏明文模式\n* 误差传递：一个单元损坏影响多个单元\n\n## OFB\n\n输出反馈OFB (output feedback)\n\n![OFB](DES和分组密码工作模式/OFB.jpg)\n\n特点：\n\n* 流密码\n* 隐藏了明文模式\n* 误差传递：一个单元损坏只影响对应单元\n* 对明文的主动攻击是可能的,信息块可被替换、重放\n* 安全性较CFB差","slug":"DES和分组密码工作模式","published":1,"updated":"2020-06-22T01:41:59.449Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbev30000i0qvh8et3qd0","content":"<p>信息安全试验所需。</p>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#des\">DES</a>\n<ul>\n<li><a href=\"#%E6%8C%89%E8%A1%A8%E5%8F%98%E6%8D%A2\">按表变换</a></li>\n<li><a href=\"#%E7%A7%98%E9%92%A5%E9%83%A8%E5%88%86\">秘钥部分</a></li>\n<li><a href=\"#%E4%BF%A1%E6%81%AF%E9%83%A8%E5%88%86\">信息部分</a></li>\n<li><a href=\"#%E8%A7%A3%E5%AF%86\">解密</a></li>\n</ul>\n</li>\n<li><a href=\"#%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F\">分组密码工作模式</a>\n<ul>\n<li><a href=\"#ecb\">ECB</a></li>\n<li><a href=\"#cbc\">CBC</a></li>\n<li><a href=\"#cfb\">CFB</a></li>\n<li><a href=\"#ofb\">OFB</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<p>[toc]</p>\n<br>\n<h1><span id=\"des\"> DES</span></h1>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/DES.png\" alt=\"DES\"></p>\n<br>\n<h2><span id=\"按表变换\"> 按表变换</span></h2>\n<p>DES涉及多次依据表格进行位置变换。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/pc_1.png\" alt=\"pc_1\"></p>\n<p>如此表，第1位的57，表示把原数据的第57位的数字移至第1位。</p>\n<br>\n<hr>\n<br>\n<h2><span id=\"秘钥部分\"> 秘钥部分</span></h2>\n<ol>\n<li>\n<p>全长64位，但8的倍数位是奇偶校验，不参与实际加密。</p>\n</li>\n<li>\n<p>PC-1变换：64分8组，按照PC-1表进行变换，此步表中没有8*k位置（此步消去奇偶校验位），得到56位秘钥。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/pc_1.png\" alt=\"pc_1\"></p>\n</li>\n<li>\n<p>拆分：56位秘钥左右均分为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>C</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">C_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">D_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>（各28位）</p>\n</li>\n<li>\n<p>循环左移：将上述两部分，各自逐次循环左移16次，得到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>D</mi><mi>i</mi></msub><mtext> </mtext><mo stretchy=\"false\">(</mo><mi>i</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>16</mn><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">C_i,D_i \\ (i\\in[1,16])</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">i</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mord\">6</span><span class=\"mclose\">]</span><span class=\"mclose\">)</span></span></span></span></p>\n<ul>\n<li>i=1,2,9,16时是左移1位<strong>得到</strong></li>\n<li>其余左移2位<strong>得到</strong></li>\n</ul>\n<blockquote>\n<p>$ C_0 = 1111000011001100101010101111<br>\n\\ C_1 = 1110000110011001010101011111 $</p>\n</blockquote>\n</li>\n<li>\n<p>合并：$ C_iD_i $</p>\n</li>\n<li>\n<p>PC-2变换：得到子秘钥$ K_i $，此步表中仅48位，即子秘钥仅48位（删除C的第9,18,22,25位以及D的第7,9,15,26比特位）</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/pc_2.png\" alt=\"pc_2\"></p>\n</li>\n</ol>\n<p>总过程：原秘钥（64） -&gt; PC-1（56↓） -&gt; 两侧循环左移（28×2） -&gt; PC-2（48↓） -&gt; 子秘钥$K_i $（48）</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/image-20200512205728831.png\" alt=\"image-20200512205728831\"></p>\n<br>\n<hr>\n<br>\n<h2><span id=\"信息部分\"> 信息部分</span></h2>\n<p>DES基于组块，每块64位。</p>\n<ol>\n<li>\n<p>初始变换IP（Initial permutation）：右上是IP表，右下是IP逆的表。两表互为逆操作。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/IP&amp;IP-1.png\" alt=\"IP&amp;IP-1\"></p>\n</li>\n<li>\n<p>分块：64位均分为左右<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mn>0</mn></msub><mi mathvariant=\"normal\">、</mi><mtext> </mtext><msub><mi>R</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">L_0、 \\ R_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">、</span><span class=\"mspace\"> </span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，各32位</p>\n</li>\n<li>\n<p>16次迭代：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\ R_i = L_{i-1} \\ XOR \\ f(R_{i-1}, \\ K_i)</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/f(R,K).png\" alt=\"f(R,K)\"></p>\n<ol>\n<li>\n<p>扩展置换E：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">R_{i-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.891661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> 经下表扩展至48位</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/e_bit-selection.png\" alt=\"e_bit-selection\"></p>\n</li>\n<li>\n<p>XOR：扩展所得与子秘钥异或 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>E</mi><mo stretchy=\"false\">(</mo><msub><mi>R</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mtext> </mtext><mi>X</mi><mi>O</mi><mi>R</mi><mtext> </mtext><msub><mi>K</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">E(R_{i-1}) \\ XOR \\ K_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\"> </span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mspace\"> </span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>S盒替换：将异或得到的48位结果分成八个6位的块，每一块通过对应的一个S盒产生一个4位的输出。</p>\n<p>每个S盒都是4×16的矩阵。例如块1：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>x</mi><mn>2</mn></msub><msub><mi>x</mi><mn>3</mn></msub><msub><mi>x</mi><mn>4</mn></msub><msub><mi>x</mi><mn>5</mn></msub><msub><mi>x</mi><mn>6</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1x_2x_3x_4x_5x_6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">6</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>x</mi><mn>6</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1x_6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">6</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>转为10进制作为S盒1的行号，将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><msub><mi>x</mi><mn>3</mn></msub><msub><mi>x</mi><mn>4</mn></msub><msub><mi>x</mi><mn>5</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_2x_3x_4x_5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>转为10进制作为S盒1的列号，则确定一个数字，转为4位二进制。</p>\n<p>最终实现每块的6位-&gt;4位，整体的32位。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/S.png\" alt=\"S\"></p>\n</li>\n<li>\n<p>P置换：将上述所得进行移位变换，得32位</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/P.png\" alt=\"P\"></p>\n</li>\n</ol>\n</li>\n<li>\n<p>16次后，得到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mn>16</mn></msub><mo separator=\"true\">,</mo><mtext> </mtext><msub><mi>R</mi><mn>16</mn></msub></mrow><annotation encoding=\"application/x-tex\">L_{16}, \\ R_{16}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\"> </span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，将其倒置得<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mn>16</mn></msub><msub><mi>L</mi><mn>16</mn></msub><mo stretchy=\"false\">(</mo><mn>64</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R_{16}L_{16}(64)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">6</span><span class=\"mord\">4</span><span class=\"mclose\">)</span></span></span></span>，进行IP逆置换，得到最终密文。</p>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h2><span id=\"解密\"> 解密</span></h2>\n<p>仅将秘钥调换使用顺序（<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>K</mi><mn>16</mn></msub><mo separator=\"true\">,</mo><msub><mi>K</mi><mn>15</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">K_{16},K_{15},...,K_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">5</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>），其余与加密相同。</p>\n<br>\n<br>\n<h1><span id=\"分组密码工作模式\"> 分组密码工作模式</span></h1>\n<h2><span id=\"ecb\"> ECB</span></h2>\n<p>电子密码本ECB (electronic codebookmode)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/ECB.jpg\" alt=\"ECB\"></p>\n<ul>\n<li>最简单的方法：原数据分组后按顺序加密，之后将所得密文按顺序连接即可</li>\n<li>特点\n<ul>\n<li>简单可并行</li>\n<li>不能隐藏明文的模式信息</li>\n<li>加密消息块相互独立成为被攻击的弱点（可能主动攻击明文）</li>\n</ul>\n</li>\n</ul>\n<h2><span id=\"cbc\"> CBC</span></h2>\n<p>密码分组链接CBC (cipher blockchaining)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/CBC.jpg\" alt=\"CBC\"></p>\n<ul>\n<li>使加密的各段数据之间有了联系</li>\n<li>解密时先解密再与初始向量/<strong>密文</strong>异或</li>\n<li>解密后补位数据要删除</li>\n<li>特点：\n<ul>\n<li>加密无法并行</li>\n<li>隐藏明文的模式信息（相同明文块，生成密文不同）</li>\n<li>不易对明文主动攻击</li>\n<li>密文块损坏导致两明文块损坏</li>\n<li>安全性更好，更适合长报文传输</li>\n</ul>\n</li>\n</ul>\n<h2><span id=\"cfb\"> CFB</span></h2>\n<p>密码反馈CFB (cipher feedback)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/CFB.jpg\" alt=\"CFB\"></p>\n<p>使用一个与块大小相同的移位寄存器（用IV初始化）。将其加密后，取高n位（K块作用）与明文的n位异或。随后寄存器左移n位，将得到的n位密文补至尾部。解密过程与加密过程相似，以IV开始，对寄存器加密，将结果的高x与密文异或，产生x位平文，再将密文的下面x位移入寄存器。</p>\n<p>特点：</p>\n<ul>\n<li>流密码</li>\n<li>隐藏明文模式</li>\n<li>误差传递：一个单元损坏影响多个单元</li>\n</ul>\n<h2><span id=\"ofb\"> OFB</span></h2>\n<p>输出反馈OFB (output feedback)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/OFB.jpg\" alt=\"OFB\"></p>\n<p>特点：</p>\n<ul>\n<li>流密码</li>\n<li>隐藏了明文模式</li>\n<li>误差传递：一个单元损坏只影响对应单元</li>\n<li>对明文的主动攻击是可能的,信息块可被替换、重放</li>\n<li>安全性较CFB差</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>信息安全试验所需。</p>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#des\">DES</a>\n<ul>\n<li><a href=\"#%E6%8C%89%E8%A1%A8%E5%8F%98%E6%8D%A2\">按表变换</a></li>\n<li><a href=\"#%E7%A7%98%E9%92%A5%E9%83%A8%E5%88%86\">秘钥部分</a></li>\n<li><a href=\"#%E4%BF%A1%E6%81%AF%E9%83%A8%E5%88%86\">信息部分</a></li>\n<li><a href=\"#%E8%A7%A3%E5%AF%86\">解密</a></li>\n</ul>\n</li>\n<li><a href=\"#%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F\">分组密码工作模式</a>\n<ul>\n<li><a href=\"#ecb\">ECB</a></li>\n<li><a href=\"#cbc\">CBC</a></li>\n<li><a href=\"#cfb\">CFB</a></li>\n<li><a href=\"#ofb\">OFB</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<p>[toc]</p>\n<br>\n<h1 id=\"des\"><a class=\"markdownIt-Anchor\" href=\"#des\"></a> DES</h1>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/DES.png\" alt=\"DES\"></p>\n<br>\n<h2 id=\"按表变换\"><a class=\"markdownIt-Anchor\" href=\"#按表变换\"></a> 按表变换</h2>\n<p>DES涉及多次依据表格进行位置变换。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/pc_1.png\" alt=\"pc_1\"></p>\n<p>如此表，第1位的57，表示把原数据的第57位的数字移至第1位。</p>\n<br>\n<hr>\n<br>\n<h2 id=\"秘钥部分\"><a class=\"markdownIt-Anchor\" href=\"#秘钥部分\"></a> 秘钥部分</h2>\n<ol>\n<li>\n<p>全长64位，但8的倍数位是奇偶校验，不参与实际加密。</p>\n</li>\n<li>\n<p>PC-1变换：64分8组，按照PC-1表进行变换，此步表中没有8*k位置（此步消去奇偶校验位），得到56位秘钥。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/pc_1.png\" alt=\"pc_1\"></p>\n</li>\n<li>\n<p>拆分：56位秘钥左右均分为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>C</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">C_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">D_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>（各28位）</p>\n</li>\n<li>\n<p>循环左移：将上述两部分，各自逐次循环左移16次，得到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>C</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><msub><mi>D</mi><mi>i</mi></msub><mtext> </mtext><mo stretchy=\"false\">(</mo><mi>i</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>16</mn><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">C_i,D_i \\ (i\\in[1,16])</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">i</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mord\">6</span><span class=\"mclose\">]</span><span class=\"mclose\">)</span></span></span></span></p>\n<ul>\n<li>i=1,2,9,16时是左移1位<strong>得到</strong></li>\n<li>其余左移2位<strong>得到</strong></li>\n</ul>\n<blockquote>\n<p>$ C_0 = 1111000011001100101010101111<br>\n\\ C_1 = 1110000110011001010101011111 $</p>\n</blockquote>\n</li>\n<li>\n<p>合并：$ C_iD_i $</p>\n</li>\n<li>\n<p>PC-2变换：得到子秘钥$ K_i $，此步表中仅48位，即子秘钥仅48位（删除C的第9,18,22,25位以及D的第7,9,15,26比特位）</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/pc_2.png\" alt=\"pc_2\"></p>\n</li>\n</ol>\n<p>总过程：原秘钥（64） -&gt; PC-1（56↓） -&gt; 两侧循环左移（28×2） -&gt; PC-2（48↓） -&gt; 子秘钥$K_i $（48）</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/image-20200512205728831.png\" alt=\"image-20200512205728831\"></p>\n<br>\n<hr>\n<br>\n<h2 id=\"信息部分\"><a class=\"markdownIt-Anchor\" href=\"#信息部分\"></a> 信息部分</h2>\n<p>DES基于组块，每块64位。</p>\n<ol>\n<li>\n<p>初始变换IP（Initial permutation）：右上是IP表，右下是IP逆的表。两表互为逆操作。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/IP&amp;IP-1.png\" alt=\"IP&amp;IP-1\"></p>\n</li>\n<li>\n<p>分块：64位均分为左右<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mn>0</mn></msub><mi mathvariant=\"normal\">、</mi><mtext> </mtext><msub><mi>R</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">L_0、 \\ R_0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">、</span><span class=\"mspace\"> </span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，各32位</p>\n</li>\n<li>\n<p>16次迭代：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\ R_i = L_{i-1} \\ XOR \\ f(R_{i-1}, \\ K_i)</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/f(R,K).png\" alt=\"f(R,K)\"></p>\n<ol>\n<li>\n<p>扩展置换E：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">R_{i-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.891661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span> 经下表扩展至48位</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/e_bit-selection.png\" alt=\"e_bit-selection\"></p>\n</li>\n<li>\n<p>XOR：扩展所得与子秘钥异或 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>E</mi><mo stretchy=\"false\">(</mo><msub><mi>R</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy=\"false\">)</mo><mtext> </mtext><mi>X</mi><mi>O</mi><mi>R</mi><mtext> </mtext><msub><mi>K</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">E(R_{i-1}) \\ XOR \\ K_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\"> </span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mspace\"> </span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>S盒替换：将异或得到的48位结果分成八个6位的块，每一块通过对应的一个S盒产生一个4位的输出。</p>\n<p>每个S盒都是4×16的矩阵。例如块1：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>x</mi><mn>2</mn></msub><msub><mi>x</mi><mn>3</mn></msub><msub><mi>x</mi><mn>4</mn></msub><msub><mi>x</mi><mn>5</mn></msub><msub><mi>x</mi><mn>6</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1x_2x_3x_4x_5x_6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">6</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><msub><mi>x</mi><mn>6</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1x_6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">6</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>转为10进制作为S盒1的行号，将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub><msub><mi>x</mi><mn>3</mn></msub><msub><mi>x</mi><mn>4</mn></msub><msub><mi>x</mi><mn>5</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_2x_3x_4x_5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>转为10进制作为S盒1的列号，则确定一个数字，转为4位二进制。</p>\n<p>最终实现每块的6位-&gt;4位，整体的32位。</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/S.png\" alt=\"S\"></p>\n</li>\n<li>\n<p>P置换：将上述所得进行移位变换，得32位</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/P.png\" alt=\"P\"></p>\n</li>\n</ol>\n</li>\n<li>\n<p>16次后，得到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mn>16</mn></msub><mo separator=\"true\">,</mo><mtext> </mtext><msub><mi>R</mi><mn>16</mn></msub></mrow><annotation encoding=\"application/x-tex\">L_{16}, \\ R_{16}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\"> </span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，将其倒置得<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mn>16</mn></msub><msub><mi>L</mi><mn>16</mn></msub><mo stretchy=\"false\">(</mo><mn>64</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R_{16}L_{16}(64)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">6</span><span class=\"mord\">4</span><span class=\"mclose\">)</span></span></span></span>，进行IP逆置换，得到最终密文。</p>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h2 id=\"解密\"><a class=\"markdownIt-Anchor\" href=\"#解密\"></a> 解密</h2>\n<p>仅将秘钥调换使用顺序（<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>K</mi><mn>16</mn></msub><mo separator=\"true\">,</mo><msub><mi>K</mi><mn>15</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><msub><mi>K</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">K_{16},K_{15},...,K_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8777699999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">6</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">5</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>），其余与加密相同。</p>\n<br>\n<br>\n<h1 id=\"分组密码工作模式\"><a class=\"markdownIt-Anchor\" href=\"#分组密码工作模式\"></a> 分组密码工作模式</h1>\n<h2 id=\"ecb\"><a class=\"markdownIt-Anchor\" href=\"#ecb\"></a> ECB</h2>\n<p>电子密码本ECB (electronic codebookmode)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/ECB.jpg\" alt=\"ECB\"></p>\n<ul>\n<li>最简单的方法：原数据分组后按顺序加密，之后将所得密文按顺序连接即可</li>\n<li>特点\n<ul>\n<li>简单可并行</li>\n<li>不能隐藏明文的模式信息</li>\n<li>加密消息块相互独立成为被攻击的弱点（可能主动攻击明文）</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"cbc\"><a class=\"markdownIt-Anchor\" href=\"#cbc\"></a> CBC</h2>\n<p>密码分组链接CBC (cipher blockchaining)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/CBC.jpg\" alt=\"CBC\"></p>\n<ul>\n<li>使加密的各段数据之间有了联系</li>\n<li>解密时先解密再与初始向量/<strong>密文</strong>异或</li>\n<li>解密后补位数据要删除</li>\n<li>特点：\n<ul>\n<li>加密无法并行</li>\n<li>隐藏明文的模式信息（相同明文块，生成密文不同）</li>\n<li>不易对明文主动攻击</li>\n<li>密文块损坏导致两明文块损坏</li>\n<li>安全性更好，更适合长报文传输</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"cfb\"><a class=\"markdownIt-Anchor\" href=\"#cfb\"></a> CFB</h2>\n<p>密码反馈CFB (cipher feedback)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/CFB.jpg\" alt=\"CFB\"></p>\n<p>使用一个与块大小相同的移位寄存器（用IV初始化）。将其加密后，取高n位（K块作用）与明文的n位异或。随后寄存器左移n位，将得到的n位密文补至尾部。解密过程与加密过程相似，以IV开始，对寄存器加密，将结果的高x与密文异或，产生x位平文，再将密文的下面x位移入寄存器。</p>\n<p>特点：</p>\n<ul>\n<li>流密码</li>\n<li>隐藏明文模式</li>\n<li>误差传递：一个单元损坏影响多个单元</li>\n</ul>\n<h2 id=\"ofb\"><a class=\"markdownIt-Anchor\" href=\"#ofb\"></a> OFB</h2>\n<p>输出反馈OFB (output feedback)</p>\n<p><img src=\"/2020/05/18/DES%E5%92%8C%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F/OFB.jpg\" alt=\"OFB\"></p>\n<p>特点：</p>\n<ul>\n<li>流密码</li>\n<li>隐藏了明文模式</li>\n<li>误差传递：一个单元损坏只影响对应单元</li>\n<li>对明文的主动攻击是可能的,信息块可被替换、重放</li>\n<li>安全性较CFB差</li>\n</ul>"},{"title":"AdaBound","mathjax":true,"date":"2020-06-18T12:14:20.000Z","_content":"\n\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n# AdaBound\n\nAdaptive Gradient Methods with Dynamic Bound of Learning Rate 动态限制学习率的自适应梯度下降方法\n\n[Github](https://github.com/Luolc/AdaBound)\n\n[论文](https://openreview.net/pdf?id=Bkg3g2R9FX)\n\n[slides](https://www.luolc.com/assets/research/adabound/slides-AdaptiveGradientMethodsAndBeyond.pdf)\n\n<br/>\n\n## 背景\n\n**引自[作者知乎专栏](https://zhuanlan.zhihu.com/p/37269222)**\n\n- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning). 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。**推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。**\n- [On the Convergence of Adam and Beyond](http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ). ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。主要攻击的是Adam有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但AdaBound作者认为这篇 paper 的**意义十分有限，同时有很大误导性**。\n\t1. 作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为**这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值**，极端构造下的收敛性，并不意味着什么。\n\t2. 作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，**training loss 的意义对于一个模型是十分有限的**。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，**Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差**。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 [Experiments with AMSGrad](http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/) 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。\n\t3. 最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。\n\t4. 相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的performance对模型而言才是更加重要的性质。\n- [Improving Generalization Performance by Switching from Adam to SGD](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628). 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。**实验表明训练后期更新步长过小也是原因之一。**\n- 综上而言，**在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向**。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。\n\n---\n\n<br/>\n\n## ABSTRACT 摘要\n\n  已经提出了很多自适应优化方法，例如ADAGRAD，RMSPROP和ADAM，以实现具有对学习率逐元缩放的快速训练过程。尽管盛行，但人们观察到它们有时难以与SGD相比，甚至由于不稳定和极端学习率而未能收敛。最近有人提出了一些算法，如AMSGRAD(2018)，但他们未能比现有方法取得相当大的进步。在我们的论文中，我们证明极端学习率确实可能导致表现不佳。我们提供ADAM和AMSGRAD的新变种，称为分别使用ADABOUND和AMSBOUND，它们采用动态限制学习率实现从自适应方法逐步平稳过渡到SGD，并给出了收敛的理论证明。实验结果表明，新变种可以消除在自适应方法和SGD之间的泛化差距，并在早期保持较高的学习速度同时训练。而且，它们可以显着地改善各自原型，尤其是复杂的深度网络。\n\n----\n\n<br/>\n\n## 1.介绍\n\n  在用于训练深度神经网络的一阶优化算法方面取得了巨大进步。最主要的算法之一是随机梯度下降（SGD），尽管简单，但在许多应用程序中表现良好。然而，SGD的一个缺点是它在所有方向上均匀地调整梯度。这可能会导致当训练数据稀疏时，表现不佳以及训练速度有限。为解决这个问题，最近提出了各种自适应方法来缩放梯度，包括ADAM，ADAGRAD和RMSPROP。特别是ADAM，由于其快速的训练速度，已经成为默认算法。\n\n  然而，这些自适应方法的泛化能力可能比非适应性方法更差。自适应方法通常在训练的初始部分显得更快，但在测试集不佳。实际上，最近在自然语言处理和计算机视觉方面的一些最先进的作品中，优化器大多被选为SGD。其中这些实例SGD确实表现得比自适应方法更好。Reddi（2018）提出了一种名为AMSGRAD的ADAM变体，希望能解决这个问题。作者提供了收敛的理论保证，但仅限于说明其在训练数据方面的更好表现。然而，发现AMSGRAD对测试集数据的泛化能力与ADAM相似，和SGD仍存在相当大的性能差距。\n\n  在本文中，首先对ADAM进行了实证研究，说明两者在训练结束时存在极端（极大和极小）的学习率。结果与2017年Wilson的paper中的“自适应方法泛化性能差可能是源于不稳定和极端的学习率”一致。实际上，2018年AMSGrad的paper中，关键点就是引入非增长学习率，这可能有助于减轻巨大学习率的影响，忽略小的可能影响。我们进一步提供了一个简单凸优化问题的例子，以阐明自适应方法的微小学习率如何导致不收敛。在这样的设置中，RMSPROP和ADAM可证明不会收敛到最优\n解。此外，无论初始步长α是多大，ADAM都无法改变规格下降的情况。\n\n  基于以上分析，我们提出了ADAM和AMSGRAD的新变种，命名为ADABOUND和AMSBOUND，它们不会受到极端学习的负面影响。我们采用学习率的动态界限，其中最低和最高界限分别初始化为零和无穷大，它们都平滑地收敛到一个恒定的最终步长。新变种在开始时可被视为自适应方法训练，随着时间增加，逐渐平稳地转变为SGD。在这个框架中，我们可以享受快速的初始训练过程以及良好的泛化能力。我们为凸面设置中的新变体提供收敛分析。\n\n  最后，转向对计算机视觉和自然语言处理中的流行任务和模型进行实证研究，结果证明训练早期有较高学习速度，同时与几种自适应和非自适应方法相比，保证了强大的泛化性能。而且，他们可以在原型上带来了相当大的改进，特别是在复杂的深层网络上。\n\n---\n\n<br/>\n\n## 2.符号和前提设定\n\n### 符号\n\n* $\\theta\\in R^d$：向量\n* $\\theta_i$：向量第$i$位\n* $\\theta ^k$：逐元素指数运算\n* $||\\theta||$：L2范数\n* $\\theta_t$：迭代后向量 \n* $\\theta_{t,i}$：迭代后向量的第$i$位\n* $\\langle v,w\\rangle$：向量内积\n* $v \\bigodot w$：逐元素相乘\n* $v/w$：逐元素相除\n* $max(v,w)$：逐元素取最大\n* $S^d_+$：所有$d\\times d$的正定矩阵\n* 向量$a\\in R^d$，正定矩阵$M\\in R^{d\\times d}$，$a/M$：$M^{-1}a$\n* 投影操作$\\prod_{F,M}(y)$，$M\\in S^d_+$：$argmin_{x\\in F}||\\sqrt M(x-y)||$，$y\\in R^d$，意为将不在$F$中的向量$y$投影为一个与$y$最近且在$F$中的向量\n* $||a||_\\infty=max(|a_1|,|a_2|,\\cdots ,|a_n|)$：向量无穷范数\n* $D_\\infty=max_{1\\leq i\\leq n}\\sum^n_{j=1}|a_{ij}|$，矩阵无穷范数，行模，行绝对值和的最大值\n* $F\\subset R^d$：凸可行集\n* F凸集：$\\lambda\\in [0,1]，a,b\\in F$，有$\\lambda a+(1-\\lambda)b\\in F$\n* 满足约束条件的点称为可行点，全体可行点组成的集合称为可行集\n* $x,y\\in F$,如果$||x-y||_\\infty\\leq D_\\infty$ ，则称$F$限制了直径$D_\\infty$ \n* diag(A)是提取出矩阵A的主对角线元素，得到的是一维的向量，diag（diag（A））是一个对角矩阵\n* 设A是n阶方阵，如果对任何非零向量X，都有X'A*X≥0*，其中*X‘'*表示X的转置，就称A为**半正定矩阵**/＞0，正定\n\n<br/>\n\n### 在线凸优化\n\n#### 在线学习\n\n* 机器学习中的一种模型训练方法\n* 比喻：有一老师和一学生，每天老师让学生回答一个问题，然后老师告诉学生正确答案，学生则比较正确答案来更新自己的知识。就这样学生终成大师（博弈论里的重复游戏）\n* 认为数据的分布是可以任意的；而寻常算法中，认为数据独立同分布；目的是正确预测数据的类别，并且在每次预测后，该结果用来更新修正预测模型，用于对以后数据进行更好的预测\n* 主要限制是当前只能看到当前的和过去的数据，因此，对在线学习而言，它追求的是知道所有数据时所能设计的最优策略。同这个最优策略的差异称之为遗憾（regret）：遗憾没能一开始就选对最优策略。我们的希望是，时间一久，数据一多，这个差异就会变得很小。我们追求的是，没有后悔（no-regret）\n* 如果与统计学习一样对数据做独立同分布假设，那么在线学习里的最优策略就是在得知所有数据的离线学习所能得到最优解。因此在线学习可以看成是一种优化方法：随着对数据的不断访问来逐步逼近这个离线最优解\n* 过程：$t$时刻，模型收到样本$x_t$；然后从策略集中选出一个策略$w_t$，并对样本做出判断$w_t(x_t)$；收到正确答案$y_t$。用损失函数$l(w_t(x_t),y_t)$衡量在$t$时刻做出不正确判断所受损失，简记为$l_t(w_t)$，故$T$轮总损失为$\\sum^T_{t=1}l_t(w_t)$。遗憾值记为$R_T=\\sum^T_{t=1}l_t（w_t）-min_{w\\in F}\\sum^T_{t=1}l_t(w)$，即总损失减去使用最佳策略的损失和。但是存在小概率事件：每次选择的策略恰能很好适应当前样本，最终使遗憾值小于零。故我们关心平均遗憾是不是随着步骤增加而减小，即$lim_{T\\rarr\\infty}\\frac{R(T)}{T}\\rarr0$\n\n<br/>\n\n#### 在线凸优化\n\n* 挑选$w_t$的策略集$F$是凸的，且损失函数$l_t(w_t)$关于$w_t$是凸的，则称此问题为在线凸优化\n\n<br/>\n\n#### 在线梯度下降\n\n* $t$时做两步：\n\n1. 利用当前得到数据对$w_t$进行一次梯度下降得到$w_{t+1}$\n2. 若新$w_{t+1}$不在策略集中，使用投影公式投影进来\n\n* 优势：N个数据，每次一个，N步找到最优策略，即总共只计算N个数据\n\n\t在本文中，我们假设可行集$F$具有有界直径并且$||\\nabla f_t(x)||_\\infty$是对于所有$t\\in [T]，x\\in F$都有界限。我们希望算法的遗憾值很小。我们的目标是设计一种确保$R_T=o(T)$的算法，这意味着平均来说，模型的性能收敛到最佳。已经指出，具有平均后悔为0的在线优化算法产生相应的随机优化算法（Cesa-Bianchi等，2002）。因此，跟随Reddi等人（2018），我们同样使用在线梯度下降和随机梯度下降。\n\n<br/>\n\n### 优化方法概述\n\n  我们遵循Reddi等人的观点（2018），提供算法1中的通用优化方法框架，封装了许多流行的自适应和非自适应方法。 这对于理解不同优化的属性很有用。\n\n![](AdaBound/AdaBound_algorithm1.png)\n\n  注意，因为函数$\\phi_t:F^t\\rarr R^d,\\psi:F^d\\rarr S^d_+$还未确定，所以算法仍是抽象的。本文中，我们将$a$称为初始步长，将$a_t/\\sqrt {V_t}$称为算法的学习率。注意，我们采用$a_t=a/\\sqrt t$减小步长。然而这种鲁莽的的衰退步骤通常表现较差，而简单的恒定步长$α_t =\nα$通常在实践中很有效。本文其余部分的理论分析和常量方案的实证研究中，我们将使用递减方案。\n\n![](AdaBound/AdaBound_table1.png)\n\nAdaGrad和RMSProp可看作Adam特例，着重研究Adam。\n\n---\n\n<br/>\n\n## 3.极端学习率导致的非收敛性\n\n  在本节中，初步实验和严格的证明，详细阐述了当前已有自适应方法的主要缺陷。如上所述，观察到诸如ADAM的自适应方法表现比SGD差。 Reddi等（2018）提出AMSGRAD来解决这个问题，但最近的工作指出AMSGRAD并没有显示出对ADAM的明显改善（Keskar＆Socher，2017年; Chen等，2018）。作者声称AMSGRAD与ADAM相比具有较小的学习率，作者仅将大的极端学习率视为ADAM性能不佳的原因。然而，小的也可能是个陷阱。因此，我们推测两个极端值都是ADAM的学习率是其泛化能力不足的原因。\n\n  为了证实我们的推测，我们对在CIFAR-10上使用ADAM的ResNet-34网络的几个权重Weight和偏差bias的学习率进行了抽样。具体来说，我们随机选择来自不同层的9个3×3卷积核和最后一个线性层中的偏差bias。通常作为同一层的参数具有相似6的属性，这里我们只展示在训练结束时九个卷积核中的九个权重的学习率和最后一层的bias，内核分别和最后一层的偏差，如图1所示。我们可以发现当模型接近收敛时，学习率有小于0.01的的以及大于1000的大小的。\n\n![](AdaBound/AdaBound_figure1.png)\n\n图1 采样参数的学习率。每个单元都是学习率的对数。\n\n  上述分析和观察表明在训练过程的最后阶段确实存在过大或过大的学习率太小。 AMSGRAD可能有助于减轻巨大的学习率的影响，但它忽略了过小的学习率。就此而言，我们仍然有以下两个疑惑。首先，微小的学习率真的会损害ADAM的效果吗？第二，学习率高度依赖于初始步长，我们可以使用相对较大的初始步长α来摆脱后期太小的学习率？\n\n  我们表明ADAM和RMSPROP的不良收敛行为可能是由极小的学习率引起的，此外，在某些情况下无论如何初始步长α，ADAM仍然无法找到正确的路径并收敛。\n\n  考虑以下线性函数序列，$F=[-2,2]，C\\in N$，满足$5\\beta^{C-2}_2\\leq(1-\\beta_2)/(4-\\beta_2)$。\n$$\nf_t(x) =\n\\begin{cases}\n-100,  & \\text{$x$ < 0} \\\\\n0,     & \\text{$x$ > 0} \\\\\n-x,    & \\text{0 $\\leq$ $x$ $\\leq$ 1 && $t$ mod $C$ = 1} \\\\\n2x,    & \\text{0 $\\leq$ $x$ $\\leq$ 1 && $t$ mod $C$ = 2} \\\\\n0,     & \\text{else} \n\\end{cases}\n$$\n很容易看出任何x<0的点都有最小的遗憾。 假设$\\beta_1=0$，我们表明ADAM收敛于此设置的x≥0的极端非优解。该算法在每C步梯度-1，这使算法向错误的方向移动。然后，在下一步，它观察到梯度2。但是较大的梯度2不能抵消错误方向，因为本步中，学习率将缩小到远小于前一个值。因此随着时间的增加，x变得越来越大。\n我们在下面的结果中形式化这种直觉。\n\n**定理1.**总会有一个在线凸优化问题，对任何初始步长$a$，Adam都有非0平均遗憾值。$R_T/T\\nrightarrow0$ 当 $T \\rarr \\infty$。\n\n  我们将所有证明都归入附录中。注意，上述示例也适用于恒定步长。另，SGD不会遇到这个问题。初始步长有多种有效选择，其中SGD的平均遗憾为0，换句话说，收敛到最优解。这个问题在后期会更加明显。当算法陷入某些非优点时。在这种情况下，大多数步骤的梯度接近0并且二阶动量的平均值会各种各样，由于指数移动平均的特性。因此，如果出现频率相对较低的“正确”信号（即上例中每C步骤的梯度2）在一些“错误”信号（即示例中的梯度1）之后到来，即使正确的具有更大的梯度绝对值，也可能无法将算法引导到正确的路径。\n\n  人们可能想知道使用大的$\\beta_1$是否有帮助，因为我们通常在实践中使其接近1。然而，以下结果表明，对于具有$β1<\\sqrt{\\beta_2}$的任何恒定$β_1$和$β_2$，存在ADAM具有非零平均遗憾的示例，而与初始步长α无关。\n\n**定理2.**对任意$\\beta_1,\\beta_2\\in [0,1), \\beta1<\\sqrt{\\beta_2}$，都存在一个在线凸优化问题，无论初始步长如何，ADAM都有非0平均遗憾值。$R_T/T\\nrightarrow0$ as $T \\rarr \\infty$。\n\n**定理3.**对任意$\\beta_1,\\beta_2\\in [0,1), \\beta1<\\sqrt{\\beta_2}$，都有一个随机凸优化问题，无论初始步长如何，ADAM都无法收敛至最优解。\n\n  Kingma＆Lei Ba（2015）中ADAM的分析依赖于随着时间的推移降低β1，而在这里我们使用常数β1。实际上，由于我们的分析中关键参数是β2而不是β1，因此使用β1的递减方案将我们的示例扩展到案例非常容易。\n\n  如Reddi等人所述（2018），条件$\\beta1<\\sqrt{\\beta_2}$是良性的并且通常在实践中使用的参数设置中得到满足。在Kingma＆Lei Ba（2015）的收敛证明中也假设了这种情况。 上述结果说明了极端学习率的潜在不良影响，并且算法在不解决该问题的情况下不可能实现良好的泛化能力。\n\n<br/>\n\n## 4.动态限制的ADAM\n\n  在本节中，我们开发了优化方法的新变体并提供了它们的收敛性分析。我们的目标是制定一种方法，结合自适应方法的好处，即快速的初步进展，以及SGD良好的最终泛化特性。最后，我们想构建一种算法，其在训练早期就像自适应方法一样，最后像SGD一样。\n\n![](AdaBound/AdaBound_algorithm2.png)\n\n受梯度剪辑的启发，这是一种在实践中用于剪切大于阈值的梯度以避免渐变爆炸的流行技术，我们在ADAM中使用剪切学习速率来在算法2中提出ADABOUND。考虑在ADAM中应用以下操作$Clip(\\alpha/\\sqrt{V_t},\\eta_l,\\eta_u)$，对学习率逐元素剪切，使输出约束在$[\\eta_l,\\eta_u]$内。由此得出，具有$a=a^*$的SGD（M）可以被看作是$η_l=η_u=α^*$的情况。至于ADAM，$η_l= 0$和$η_u= \\infty$。现在我们可以通过以下步骤提供新策略：我们使用$η_l$和$η_u$作为t的函数,而不是常数下限和上限，其中$η_l(t)$是一个非递减函数，$t = 0$时值为0，并逐渐收敛到$a^*$；并且$η_u(t)$是非增加函数，$t = 0$时值为$\\infty$，并且也渐近地收敛到$a^*$。在此设置中，ADABOUND在开始时表现得像ADAM一样，因为边界对学习速率的影响非常小，并且随着边界收缩而逐渐转换为SGD（M）。我们证明了ADABOUND的以下关键结果。\n\n**定理4.**\n$$\n\\{x_t\\},\\{v_t\\}是由算法2得出。对所有t\\in[T]且\\beta_1/\\sqrt{\\beta_2}<1,都有        \\beta_1=\\beta_{11},\\beta_{1t}\\leq\\beta1。\\\\\n假设当t\\rarr \\infty 时，\\eta_l(t+1)\\geq\\eta_l(t)\\geq0，\\eta_u(t+1)\\leq\\eta_y(t)，\\\\ \\eta_l(t)\\rarr a^*，\\eta_u(t)\\rarr a^*，L_{\\infty}=\\eta _l(1)且R_\\infty=\\eta_u(1)。\\\\\n假定对所有x,y\\in F，有||x-y||_\\infty \\leq D_\\infty；对所有t\\in [T]和x\\in F，有||\\nabla f_t(x)||\\leq G_2。\\\\\n对经AdaBound产生的x_t，在其遗憾值上都有以下界限：\n$$\n![](AdaBound/AdaBound_theorem4.png)\n\n**推论4.1**\n\n假设$\\beta_{1t}=\\beta_1\\lambda^{t-1}$是由定理4得出，则\n\n![](AdaBound/AdaBound_corollary4.1.png)\n\n很容易看出，ADABOUND的遗憾值上限是$O(\\sqrt T)$。与Reddi等人类似（2018），人们可以使用更适度的动量衰减$\\beta_{1t}=\\beta_1/t$，并且仍然确保遗憾值上限是$O(\\sqrt T)$。\n\n  最后进行比较。对于将ADAM转换为SGD的想法，Keskar＆Socher（2017）也有类似的工作。作者提出了一种首先使用ADAM的措施，并在某个特定步骤将算法切换到SGD。与他们的方法相比，我们的方法有两个优点。首先，是否存在区分ADAM和SGD的固定转折点是不确定的。因此，我们使用连续转换过程而不是“硬”开关来解决此问题。其次，他们引入了额外的超参数来决定切换时间，这不是很容易微调。至于我们的方法，引入的灵活部分是两个绑定函数。我们对不同类型的约束函数的影响进行了实证研究。结果放在附录G中，我们发现收敛目标$a^*$和收敛速度对最终结果不是很重要。为了清楚起见，我们将在其余部分使用$\\eta_l(t)=0.1-\\frac{0.1}{(1-\\beta_2)t+1}，\\eta_u(t)=0.1+\\frac{0.1}{(1-\\beta_2)t}$。\n\n---\n\n<br/>\n\n## 5.实验结果\n\n  在这一节中，我们将对不同的模型进行实证研究，将新方法与常用的优化方法(包括SGD(M)、ADAGRAD、ADAM和AMSGRAD))进行比较。我们主要关注三个任务：MNIST图像分类任务)、CIFAR-10图像分类任务和Penn Treebank上的语言建模任务。我们之所以选择它们，是因为它们的架构具有广泛的重要性和可再现性。表2详细列出了每个任务的设置。我们使用指定的初始化方法从随机的起点运行每个实验三次。为训练指定了固定的时域数预算，下面将介绍衰减策略。我们选择的设置，实现最低的训练损失在最后。\n\n![](AdaBound/AdaBound_table2.png)\n\n<br/>\n\n### 5.1 参数设置\n\n<br/>\n\n### 5.2 前馈神经网络\n\n   针对MNIST数据集上的多类分类问题，我们训练了一个具有隐层的简单全连通神经网络。我们运行了100个epochs，省略了这个实验的衰变方案。图2显示了训练和测试集上每种优化方法的学习曲线。我们发现在训练中，所有算法都能达到接近100%的准确率。在测试部分，SGD的性能略优于ADAM和AMSGRAD的自适应方法。我们提出的ADABOUND和AMSBOUND两种方法显示出轻微的改进，但与它们的原型相比，测试精度仍然有明显的提高。\n\n![](AdaBound/AdaBound_figure2.png)\n\n<br/>\n\n### 5.3 卷积神经网络\n\n  利用DenseNet-121和ResNet-34对CIFAR-10标准数据集进行图像分类。在这个实验中，我们使用200个epoch，在150个epoch后将学习率降低10个。\n\n  DenseNet：我们首先在CIFAR-10上运行DenseNet-121模型，结果如图3所示。我们可以看到，ADAGRAD、ADAM和AMSGRAD等自适应方法在早期训练中表现得比非自适应方法更好。但是到了150轮，当学习速率衰减时，SGDM开始优于那些自适应方法。对于我们的方法ADABOUND和AMSBOUND，它们收敛速度和自适应方法一样快，并且在训练结束时的测试集上达到比SGDM稍高的精度。此外，与原型机相比，其性能得到了显著提高，测试精度提高了约2%。\n\n  ResNet：实验结果如图3所示。正如预期的那样，ResNet-34上的每个算法的总体性能与DenseNet-121上的相似。ADABOUND和AMSBOUND甚至超过SGDM 1%。尽管自适应方法的泛化能力相对较差，但我们提出的方法克服了这一缺点，为其学习速率分配了界限，在CIFAR-10上对DenseNet和ResNet的测试集都获得了几乎最佳的准确率。\n\n![](AdaBound/AdaBound_figure3.1.png)\n\n![](AdaBound/AdaBound_figure3.2.png)\n\n<br/>\n\n### 5.4 递归神经网络\n\n  我们发现，在所有模型中，ADAM的初始进展最快，但在性能上停滞不前，不如SGD和我们的方法。与以往在图像分类任务实验中出现的现象不同，ADABOUND和AMSBOUND在训练初期的速度并不快，但曲线比SGD平滑。\n\n![](AdaBound/AdaBound_figure4.1.png)\n\n![](AdaBound/AdaBound_figure4.2.png)\n\n对比L1、L2和L3，我们可以很容易地发现改善程度的显著差异。在最简单的模型L1中，我们的方法比ADAM的方法略好1.1%，而在最复杂的模型L3中，我们的方法在复杂的方面明显优于2.8%。为模型的复杂性与改进程度之间的关系提供了依据。\n\n<br/>\n\n### 5.5 结果分析\n\n  为了研究我们提出的算法的有效性，我们从计算机视觉和自然语言处理中选择流行的任务。根据上面显示的结果，不难发现ADAM和AMSGRAD的表现通常是相似的，而AMSGRAD在大多数情况下并没有太大的改善。另一方面，它们的变体ADABOUND和AMSBOUND与SGD相比具有较快的收敛速度，同时在训练结束时的测试精度也大大超过了两种原始方法。这一现象正好印证了我们在第3节中提到的观点，学习速率的大小都会影响收敛。\n  此外，我们还对不同复杂度的模型进行了实验，包括一个per- ceptron模型、两个深度卷积神经网络模型和一个递归神经网络模型。MNIST上使用的感知器是最简单的，我们的方法比其他方法稍好一些。DenseNet和ResNet的测试精度明显提高。我们把这种不同归因于模型的复杂性。具体来说，对于深度CNN模型，卷积层和全连通层在任务中扮演不同的角色。此外，不同的卷积层可能负责不同的角色(Lee et al.2009)，这可能导致参数梯度的明显变化。换句话说，极端的学习速率(巨大或微小)可能在ResNet等复杂模型中出现得更频繁。由于我们的算法是为了避免这些问题而提出的，因此可以直观地解释在复杂体系结构中性能的提高。LSTM在语言建模任务上的层次越多，改进程度越高，也与上述分析一致。\n\n<br/>\n\n## 6. 限制函数\n\n$\\eta_l (t)=(1-\\frac{1}{(1-\\beta)t+1})\\alpha^*$\n\n$\\eta_u(t)=(1+\\frac{1}{(1-\\beta)t})\\alpha^*$\n\n* $\\beta$：影响算法从自适应变为SGD的转换速度\n* $\\alpha^*$：转换目标，反映最终SGD的步长\n\n![](AdaBound/AdaBound_figure5.png)\n\n* 图5，定$\\alpha^*$变化$\\beta$，反映出对于特定的$\\alpha^*$，不同的$\\beta$的性能几乎相同。表明限制函数的收敛速度在一定程度上不影响最终结果。并且在$[\\beta_1,\\beta_2]$内的$\\beta$通常效果更佳。\n\n![](AdaBound/AdaBound_figure6.png)\n\n* 图6，不同$\\alpha^*$对SGD和AdaBound的影响。结果表明SGDM对超参数非常敏感。SGDM步长的最佳值为0.1，且与其他设置相比性能差距很大。相比之下，ADABOUND针对不同的最终步长具有稳定的性能，说明它对收敛目标不敏感。\n\n![](AdaBound/AdaBound_figure7.1.png)\n\n![AdaBound_figure7.2](AdaBound/AdaBound_figure7.2.png)\n\n* 图7，进一步直接比较SGDM和ADABOUND与每个α（或α*）之间的性能。\n\t结果如图7所示。我们可以看到，ADABOUND在所有步骤中都优于SGDM\n\t大小。 由于绑定函数的形式对ADABOUND的性能影响很小，因此它是\n\t即使没有仔细调整超参数，也可能击败SGDM。\n* ADABOUND对其超参数不敏感。而且，它即使没有仔细微调，也能获得与SGDM更高或相似的性能。","source":"_posts/AdaBound.md","raw":"---\ntitle: AdaBound\nmathjax: true\ndate: 2020-06-18 20:14:20\ntags: AI\n---\n\n\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n# AdaBound\n\nAdaptive Gradient Methods with Dynamic Bound of Learning Rate 动态限制学习率的自适应梯度下降方法\n\n[Github](https://github.com/Luolc/AdaBound)\n\n[论文](https://openreview.net/pdf?id=Bkg3g2R9FX)\n\n[slides](https://www.luolc.com/assets/research/adabound/slides-AdaptiveGradientMethodsAndBeyond.pdf)\n\n<br/>\n\n## 背景\n\n**引自[作者知乎专栏](https://zhuanlan.zhihu.com/p/37269222)**\n\n- [The Marginal Value of Adaptive Gradient Methods in Machine Learning](http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning). 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。**推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。**\n- [On the Convergence of Adam and Beyond](http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ). ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。主要攻击的是Adam有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但AdaBound作者认为这篇 paper 的**意义十分有限，同时有很大误导性**。\n\t1. 作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为**这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值**，极端构造下的收敛性，并不意味着什么。\n\t2. 作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，**training loss 的意义对于一个模型是十分有限的**。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，**Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差**。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 [Experiments with AMSGrad](http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/) 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。\n\t3. 最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。\n\t4. 相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的performance对模型而言才是更加重要的性质。\n- [Improving Generalization Performance by Switching from Adam to SGD](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628). 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。**实验表明训练后期更新步长过小也是原因之一。**\n- 综上而言，**在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向**。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。\n\n---\n\n<br/>\n\n## ABSTRACT 摘要\n\n  已经提出了很多自适应优化方法，例如ADAGRAD，RMSPROP和ADAM，以实现具有对学习率逐元缩放的快速训练过程。尽管盛行，但人们观察到它们有时难以与SGD相比，甚至由于不稳定和极端学习率而未能收敛。最近有人提出了一些算法，如AMSGRAD(2018)，但他们未能比现有方法取得相当大的进步。在我们的论文中，我们证明极端学习率确实可能导致表现不佳。我们提供ADAM和AMSGRAD的新变种，称为分别使用ADABOUND和AMSBOUND，它们采用动态限制学习率实现从自适应方法逐步平稳过渡到SGD，并给出了收敛的理论证明。实验结果表明，新变种可以消除在自适应方法和SGD之间的泛化差距，并在早期保持较高的学习速度同时训练。而且，它们可以显着地改善各自原型，尤其是复杂的深度网络。\n\n----\n\n<br/>\n\n## 1.介绍\n\n  在用于训练深度神经网络的一阶优化算法方面取得了巨大进步。最主要的算法之一是随机梯度下降（SGD），尽管简单，但在许多应用程序中表现良好。然而，SGD的一个缺点是它在所有方向上均匀地调整梯度。这可能会导致当训练数据稀疏时，表现不佳以及训练速度有限。为解决这个问题，最近提出了各种自适应方法来缩放梯度，包括ADAM，ADAGRAD和RMSPROP。特别是ADAM，由于其快速的训练速度，已经成为默认算法。\n\n  然而，这些自适应方法的泛化能力可能比非适应性方法更差。自适应方法通常在训练的初始部分显得更快，但在测试集不佳。实际上，最近在自然语言处理和计算机视觉方面的一些最先进的作品中，优化器大多被选为SGD。其中这些实例SGD确实表现得比自适应方法更好。Reddi（2018）提出了一种名为AMSGRAD的ADAM变体，希望能解决这个问题。作者提供了收敛的理论保证，但仅限于说明其在训练数据方面的更好表现。然而，发现AMSGRAD对测试集数据的泛化能力与ADAM相似，和SGD仍存在相当大的性能差距。\n\n  在本文中，首先对ADAM进行了实证研究，说明两者在训练结束时存在极端（极大和极小）的学习率。结果与2017年Wilson的paper中的“自适应方法泛化性能差可能是源于不稳定和极端的学习率”一致。实际上，2018年AMSGrad的paper中，关键点就是引入非增长学习率，这可能有助于减轻巨大学习率的影响，忽略小的可能影响。我们进一步提供了一个简单凸优化问题的例子，以阐明自适应方法的微小学习率如何导致不收敛。在这样的设置中，RMSPROP和ADAM可证明不会收敛到最优\n解。此外，无论初始步长α是多大，ADAM都无法改变规格下降的情况。\n\n  基于以上分析，我们提出了ADAM和AMSGRAD的新变种，命名为ADABOUND和AMSBOUND，它们不会受到极端学习的负面影响。我们采用学习率的动态界限，其中最低和最高界限分别初始化为零和无穷大，它们都平滑地收敛到一个恒定的最终步长。新变种在开始时可被视为自适应方法训练，随着时间增加，逐渐平稳地转变为SGD。在这个框架中，我们可以享受快速的初始训练过程以及良好的泛化能力。我们为凸面设置中的新变体提供收敛分析。\n\n  最后，转向对计算机视觉和自然语言处理中的流行任务和模型进行实证研究，结果证明训练早期有较高学习速度，同时与几种自适应和非自适应方法相比，保证了强大的泛化性能。而且，他们可以在原型上带来了相当大的改进，特别是在复杂的深层网络上。\n\n---\n\n<br/>\n\n## 2.符号和前提设定\n\n### 符号\n\n* $\\theta\\in R^d$：向量\n* $\\theta_i$：向量第$i$位\n* $\\theta ^k$：逐元素指数运算\n* $||\\theta||$：L2范数\n* $\\theta_t$：迭代后向量 \n* $\\theta_{t,i}$：迭代后向量的第$i$位\n* $\\langle v,w\\rangle$：向量内积\n* $v \\bigodot w$：逐元素相乘\n* $v/w$：逐元素相除\n* $max(v,w)$：逐元素取最大\n* $S^d_+$：所有$d\\times d$的正定矩阵\n* 向量$a\\in R^d$，正定矩阵$M\\in R^{d\\times d}$，$a/M$：$M^{-1}a$\n* 投影操作$\\prod_{F,M}(y)$，$M\\in S^d_+$：$argmin_{x\\in F}||\\sqrt M(x-y)||$，$y\\in R^d$，意为将不在$F$中的向量$y$投影为一个与$y$最近且在$F$中的向量\n* $||a||_\\infty=max(|a_1|,|a_2|,\\cdots ,|a_n|)$：向量无穷范数\n* $D_\\infty=max_{1\\leq i\\leq n}\\sum^n_{j=1}|a_{ij}|$，矩阵无穷范数，行模，行绝对值和的最大值\n* $F\\subset R^d$：凸可行集\n* F凸集：$\\lambda\\in [0,1]，a,b\\in F$，有$\\lambda a+(1-\\lambda)b\\in F$\n* 满足约束条件的点称为可行点，全体可行点组成的集合称为可行集\n* $x,y\\in F$,如果$||x-y||_\\infty\\leq D_\\infty$ ，则称$F$限制了直径$D_\\infty$ \n* diag(A)是提取出矩阵A的主对角线元素，得到的是一维的向量，diag（diag（A））是一个对角矩阵\n* 设A是n阶方阵，如果对任何非零向量X，都有X'A*X≥0*，其中*X‘'*表示X的转置，就称A为**半正定矩阵**/＞0，正定\n\n<br/>\n\n### 在线凸优化\n\n#### 在线学习\n\n* 机器学习中的一种模型训练方法\n* 比喻：有一老师和一学生，每天老师让学生回答一个问题，然后老师告诉学生正确答案，学生则比较正确答案来更新自己的知识。就这样学生终成大师（博弈论里的重复游戏）\n* 认为数据的分布是可以任意的；而寻常算法中，认为数据独立同分布；目的是正确预测数据的类别，并且在每次预测后，该结果用来更新修正预测模型，用于对以后数据进行更好的预测\n* 主要限制是当前只能看到当前的和过去的数据，因此，对在线学习而言，它追求的是知道所有数据时所能设计的最优策略。同这个最优策略的差异称之为遗憾（regret）：遗憾没能一开始就选对最优策略。我们的希望是，时间一久，数据一多，这个差异就会变得很小。我们追求的是，没有后悔（no-regret）\n* 如果与统计学习一样对数据做独立同分布假设，那么在线学习里的最优策略就是在得知所有数据的离线学习所能得到最优解。因此在线学习可以看成是一种优化方法：随着对数据的不断访问来逐步逼近这个离线最优解\n* 过程：$t$时刻，模型收到样本$x_t$；然后从策略集中选出一个策略$w_t$，并对样本做出判断$w_t(x_t)$；收到正确答案$y_t$。用损失函数$l(w_t(x_t),y_t)$衡量在$t$时刻做出不正确判断所受损失，简记为$l_t(w_t)$，故$T$轮总损失为$\\sum^T_{t=1}l_t(w_t)$。遗憾值记为$R_T=\\sum^T_{t=1}l_t（w_t）-min_{w\\in F}\\sum^T_{t=1}l_t(w)$，即总损失减去使用最佳策略的损失和。但是存在小概率事件：每次选择的策略恰能很好适应当前样本，最终使遗憾值小于零。故我们关心平均遗憾是不是随着步骤增加而减小，即$lim_{T\\rarr\\infty}\\frac{R(T)}{T}\\rarr0$\n\n<br/>\n\n#### 在线凸优化\n\n* 挑选$w_t$的策略集$F$是凸的，且损失函数$l_t(w_t)$关于$w_t$是凸的，则称此问题为在线凸优化\n\n<br/>\n\n#### 在线梯度下降\n\n* $t$时做两步：\n\n1. 利用当前得到数据对$w_t$进行一次梯度下降得到$w_{t+1}$\n2. 若新$w_{t+1}$不在策略集中，使用投影公式投影进来\n\n* 优势：N个数据，每次一个，N步找到最优策略，即总共只计算N个数据\n\n\t在本文中，我们假设可行集$F$具有有界直径并且$||\\nabla f_t(x)||_\\infty$是对于所有$t\\in [T]，x\\in F$都有界限。我们希望算法的遗憾值很小。我们的目标是设计一种确保$R_T=o(T)$的算法，这意味着平均来说，模型的性能收敛到最佳。已经指出，具有平均后悔为0的在线优化算法产生相应的随机优化算法（Cesa-Bianchi等，2002）。因此，跟随Reddi等人（2018），我们同样使用在线梯度下降和随机梯度下降。\n\n<br/>\n\n### 优化方法概述\n\n  我们遵循Reddi等人的观点（2018），提供算法1中的通用优化方法框架，封装了许多流行的自适应和非自适应方法。 这对于理解不同优化的属性很有用。\n\n![](AdaBound/AdaBound_algorithm1.png)\n\n  注意，因为函数$\\phi_t:F^t\\rarr R^d,\\psi:F^d\\rarr S^d_+$还未确定，所以算法仍是抽象的。本文中，我们将$a$称为初始步长，将$a_t/\\sqrt {V_t}$称为算法的学习率。注意，我们采用$a_t=a/\\sqrt t$减小步长。然而这种鲁莽的的衰退步骤通常表现较差，而简单的恒定步长$α_t =\nα$通常在实践中很有效。本文其余部分的理论分析和常量方案的实证研究中，我们将使用递减方案。\n\n![](AdaBound/AdaBound_table1.png)\n\nAdaGrad和RMSProp可看作Adam特例，着重研究Adam。\n\n---\n\n<br/>\n\n## 3.极端学习率导致的非收敛性\n\n  在本节中，初步实验和严格的证明，详细阐述了当前已有自适应方法的主要缺陷。如上所述，观察到诸如ADAM的自适应方法表现比SGD差。 Reddi等（2018）提出AMSGRAD来解决这个问题，但最近的工作指出AMSGRAD并没有显示出对ADAM的明显改善（Keskar＆Socher，2017年; Chen等，2018）。作者声称AMSGRAD与ADAM相比具有较小的学习率，作者仅将大的极端学习率视为ADAM性能不佳的原因。然而，小的也可能是个陷阱。因此，我们推测两个极端值都是ADAM的学习率是其泛化能力不足的原因。\n\n  为了证实我们的推测，我们对在CIFAR-10上使用ADAM的ResNet-34网络的几个权重Weight和偏差bias的学习率进行了抽样。具体来说，我们随机选择来自不同层的9个3×3卷积核和最后一个线性层中的偏差bias。通常作为同一层的参数具有相似6的属性，这里我们只展示在训练结束时九个卷积核中的九个权重的学习率和最后一层的bias，内核分别和最后一层的偏差，如图1所示。我们可以发现当模型接近收敛时，学习率有小于0.01的的以及大于1000的大小的。\n\n![](AdaBound/AdaBound_figure1.png)\n\n图1 采样参数的学习率。每个单元都是学习率的对数。\n\n  上述分析和观察表明在训练过程的最后阶段确实存在过大或过大的学习率太小。 AMSGRAD可能有助于减轻巨大的学习率的影响，但它忽略了过小的学习率。就此而言，我们仍然有以下两个疑惑。首先，微小的学习率真的会损害ADAM的效果吗？第二，学习率高度依赖于初始步长，我们可以使用相对较大的初始步长α来摆脱后期太小的学习率？\n\n  我们表明ADAM和RMSPROP的不良收敛行为可能是由极小的学习率引起的，此外，在某些情况下无论如何初始步长α，ADAM仍然无法找到正确的路径并收敛。\n\n  考虑以下线性函数序列，$F=[-2,2]，C\\in N$，满足$5\\beta^{C-2}_2\\leq(1-\\beta_2)/(4-\\beta_2)$。\n$$\nf_t(x) =\n\\begin{cases}\n-100,  & \\text{$x$ < 0} \\\\\n0,     & \\text{$x$ > 0} \\\\\n-x,    & \\text{0 $\\leq$ $x$ $\\leq$ 1 && $t$ mod $C$ = 1} \\\\\n2x,    & \\text{0 $\\leq$ $x$ $\\leq$ 1 && $t$ mod $C$ = 2} \\\\\n0,     & \\text{else} \n\\end{cases}\n$$\n很容易看出任何x<0的点都有最小的遗憾。 假设$\\beta_1=0$，我们表明ADAM收敛于此设置的x≥0的极端非优解。该算法在每C步梯度-1，这使算法向错误的方向移动。然后，在下一步，它观察到梯度2。但是较大的梯度2不能抵消错误方向，因为本步中，学习率将缩小到远小于前一个值。因此随着时间的增加，x变得越来越大。\n我们在下面的结果中形式化这种直觉。\n\n**定理1.**总会有一个在线凸优化问题，对任何初始步长$a$，Adam都有非0平均遗憾值。$R_T/T\\nrightarrow0$ 当 $T \\rarr \\infty$。\n\n  我们将所有证明都归入附录中。注意，上述示例也适用于恒定步长。另，SGD不会遇到这个问题。初始步长有多种有效选择，其中SGD的平均遗憾为0，换句话说，收敛到最优解。这个问题在后期会更加明显。当算法陷入某些非优点时。在这种情况下，大多数步骤的梯度接近0并且二阶动量的平均值会各种各样，由于指数移动平均的特性。因此，如果出现频率相对较低的“正确”信号（即上例中每C步骤的梯度2）在一些“错误”信号（即示例中的梯度1）之后到来，即使正确的具有更大的梯度绝对值，也可能无法将算法引导到正确的路径。\n\n  人们可能想知道使用大的$\\beta_1$是否有帮助，因为我们通常在实践中使其接近1。然而，以下结果表明，对于具有$β1<\\sqrt{\\beta_2}$的任何恒定$β_1$和$β_2$，存在ADAM具有非零平均遗憾的示例，而与初始步长α无关。\n\n**定理2.**对任意$\\beta_1,\\beta_2\\in [0,1), \\beta1<\\sqrt{\\beta_2}$，都存在一个在线凸优化问题，无论初始步长如何，ADAM都有非0平均遗憾值。$R_T/T\\nrightarrow0$ as $T \\rarr \\infty$。\n\n**定理3.**对任意$\\beta_1,\\beta_2\\in [0,1), \\beta1<\\sqrt{\\beta_2}$，都有一个随机凸优化问题，无论初始步长如何，ADAM都无法收敛至最优解。\n\n  Kingma＆Lei Ba（2015）中ADAM的分析依赖于随着时间的推移降低β1，而在这里我们使用常数β1。实际上，由于我们的分析中关键参数是β2而不是β1，因此使用β1的递减方案将我们的示例扩展到案例非常容易。\n\n  如Reddi等人所述（2018），条件$\\beta1<\\sqrt{\\beta_2}$是良性的并且通常在实践中使用的参数设置中得到满足。在Kingma＆Lei Ba（2015）的收敛证明中也假设了这种情况。 上述结果说明了极端学习率的潜在不良影响，并且算法在不解决该问题的情况下不可能实现良好的泛化能力。\n\n<br/>\n\n## 4.动态限制的ADAM\n\n  在本节中，我们开发了优化方法的新变体并提供了它们的收敛性分析。我们的目标是制定一种方法，结合自适应方法的好处，即快速的初步进展，以及SGD良好的最终泛化特性。最后，我们想构建一种算法，其在训练早期就像自适应方法一样，最后像SGD一样。\n\n![](AdaBound/AdaBound_algorithm2.png)\n\n受梯度剪辑的启发，这是一种在实践中用于剪切大于阈值的梯度以避免渐变爆炸的流行技术，我们在ADAM中使用剪切学习速率来在算法2中提出ADABOUND。考虑在ADAM中应用以下操作$Clip(\\alpha/\\sqrt{V_t},\\eta_l,\\eta_u)$，对学习率逐元素剪切，使输出约束在$[\\eta_l,\\eta_u]$内。由此得出，具有$a=a^*$的SGD（M）可以被看作是$η_l=η_u=α^*$的情况。至于ADAM，$η_l= 0$和$η_u= \\infty$。现在我们可以通过以下步骤提供新策略：我们使用$η_l$和$η_u$作为t的函数,而不是常数下限和上限，其中$η_l(t)$是一个非递减函数，$t = 0$时值为0，并逐渐收敛到$a^*$；并且$η_u(t)$是非增加函数，$t = 0$时值为$\\infty$，并且也渐近地收敛到$a^*$。在此设置中，ADABOUND在开始时表现得像ADAM一样，因为边界对学习速率的影响非常小，并且随着边界收缩而逐渐转换为SGD（M）。我们证明了ADABOUND的以下关键结果。\n\n**定理4.**\n$$\n\\{x_t\\},\\{v_t\\}是由算法2得出。对所有t\\in[T]且\\beta_1/\\sqrt{\\beta_2}<1,都有        \\beta_1=\\beta_{11},\\beta_{1t}\\leq\\beta1。\\\\\n假设当t\\rarr \\infty 时，\\eta_l(t+1)\\geq\\eta_l(t)\\geq0，\\eta_u(t+1)\\leq\\eta_y(t)，\\\\ \\eta_l(t)\\rarr a^*，\\eta_u(t)\\rarr a^*，L_{\\infty}=\\eta _l(1)且R_\\infty=\\eta_u(1)。\\\\\n假定对所有x,y\\in F，有||x-y||_\\infty \\leq D_\\infty；对所有t\\in [T]和x\\in F，有||\\nabla f_t(x)||\\leq G_2。\\\\\n对经AdaBound产生的x_t，在其遗憾值上都有以下界限：\n$$\n![](AdaBound/AdaBound_theorem4.png)\n\n**推论4.1**\n\n假设$\\beta_{1t}=\\beta_1\\lambda^{t-1}$是由定理4得出，则\n\n![](AdaBound/AdaBound_corollary4.1.png)\n\n很容易看出，ADABOUND的遗憾值上限是$O(\\sqrt T)$。与Reddi等人类似（2018），人们可以使用更适度的动量衰减$\\beta_{1t}=\\beta_1/t$，并且仍然确保遗憾值上限是$O(\\sqrt T)$。\n\n  最后进行比较。对于将ADAM转换为SGD的想法，Keskar＆Socher（2017）也有类似的工作。作者提出了一种首先使用ADAM的措施，并在某个特定步骤将算法切换到SGD。与他们的方法相比，我们的方法有两个优点。首先，是否存在区分ADAM和SGD的固定转折点是不确定的。因此，我们使用连续转换过程而不是“硬”开关来解决此问题。其次，他们引入了额外的超参数来决定切换时间，这不是很容易微调。至于我们的方法，引入的灵活部分是两个绑定函数。我们对不同类型的约束函数的影响进行了实证研究。结果放在附录G中，我们发现收敛目标$a^*$和收敛速度对最终结果不是很重要。为了清楚起见，我们将在其余部分使用$\\eta_l(t)=0.1-\\frac{0.1}{(1-\\beta_2)t+1}，\\eta_u(t)=0.1+\\frac{0.1}{(1-\\beta_2)t}$。\n\n---\n\n<br/>\n\n## 5.实验结果\n\n  在这一节中，我们将对不同的模型进行实证研究，将新方法与常用的优化方法(包括SGD(M)、ADAGRAD、ADAM和AMSGRAD))进行比较。我们主要关注三个任务：MNIST图像分类任务)、CIFAR-10图像分类任务和Penn Treebank上的语言建模任务。我们之所以选择它们，是因为它们的架构具有广泛的重要性和可再现性。表2详细列出了每个任务的设置。我们使用指定的初始化方法从随机的起点运行每个实验三次。为训练指定了固定的时域数预算，下面将介绍衰减策略。我们选择的设置，实现最低的训练损失在最后。\n\n![](AdaBound/AdaBound_table2.png)\n\n<br/>\n\n### 5.1 参数设置\n\n<br/>\n\n### 5.2 前馈神经网络\n\n   针对MNIST数据集上的多类分类问题，我们训练了一个具有隐层的简单全连通神经网络。我们运行了100个epochs，省略了这个实验的衰变方案。图2显示了训练和测试集上每种优化方法的学习曲线。我们发现在训练中，所有算法都能达到接近100%的准确率。在测试部分，SGD的性能略优于ADAM和AMSGRAD的自适应方法。我们提出的ADABOUND和AMSBOUND两种方法显示出轻微的改进，但与它们的原型相比，测试精度仍然有明显的提高。\n\n![](AdaBound/AdaBound_figure2.png)\n\n<br/>\n\n### 5.3 卷积神经网络\n\n  利用DenseNet-121和ResNet-34对CIFAR-10标准数据集进行图像分类。在这个实验中，我们使用200个epoch，在150个epoch后将学习率降低10个。\n\n  DenseNet：我们首先在CIFAR-10上运行DenseNet-121模型，结果如图3所示。我们可以看到，ADAGRAD、ADAM和AMSGRAD等自适应方法在早期训练中表现得比非自适应方法更好。但是到了150轮，当学习速率衰减时，SGDM开始优于那些自适应方法。对于我们的方法ADABOUND和AMSBOUND，它们收敛速度和自适应方法一样快，并且在训练结束时的测试集上达到比SGDM稍高的精度。此外，与原型机相比，其性能得到了显著提高，测试精度提高了约2%。\n\n  ResNet：实验结果如图3所示。正如预期的那样，ResNet-34上的每个算法的总体性能与DenseNet-121上的相似。ADABOUND和AMSBOUND甚至超过SGDM 1%。尽管自适应方法的泛化能力相对较差，但我们提出的方法克服了这一缺点，为其学习速率分配了界限，在CIFAR-10上对DenseNet和ResNet的测试集都获得了几乎最佳的准确率。\n\n![](AdaBound/AdaBound_figure3.1.png)\n\n![](AdaBound/AdaBound_figure3.2.png)\n\n<br/>\n\n### 5.4 递归神经网络\n\n  我们发现，在所有模型中，ADAM的初始进展最快，但在性能上停滞不前，不如SGD和我们的方法。与以往在图像分类任务实验中出现的现象不同，ADABOUND和AMSBOUND在训练初期的速度并不快，但曲线比SGD平滑。\n\n![](AdaBound/AdaBound_figure4.1.png)\n\n![](AdaBound/AdaBound_figure4.2.png)\n\n对比L1、L2和L3，我们可以很容易地发现改善程度的显著差异。在最简单的模型L1中，我们的方法比ADAM的方法略好1.1%，而在最复杂的模型L3中，我们的方法在复杂的方面明显优于2.8%。为模型的复杂性与改进程度之间的关系提供了依据。\n\n<br/>\n\n### 5.5 结果分析\n\n  为了研究我们提出的算法的有效性，我们从计算机视觉和自然语言处理中选择流行的任务。根据上面显示的结果，不难发现ADAM和AMSGRAD的表现通常是相似的，而AMSGRAD在大多数情况下并没有太大的改善。另一方面，它们的变体ADABOUND和AMSBOUND与SGD相比具有较快的收敛速度，同时在训练结束时的测试精度也大大超过了两种原始方法。这一现象正好印证了我们在第3节中提到的观点，学习速率的大小都会影响收敛。\n  此外，我们还对不同复杂度的模型进行了实验，包括一个per- ceptron模型、两个深度卷积神经网络模型和一个递归神经网络模型。MNIST上使用的感知器是最简单的，我们的方法比其他方法稍好一些。DenseNet和ResNet的测试精度明显提高。我们把这种不同归因于模型的复杂性。具体来说，对于深度CNN模型，卷积层和全连通层在任务中扮演不同的角色。此外，不同的卷积层可能负责不同的角色(Lee et al.2009)，这可能导致参数梯度的明显变化。换句话说，极端的学习速率(巨大或微小)可能在ResNet等复杂模型中出现得更频繁。由于我们的算法是为了避免这些问题而提出的，因此可以直观地解释在复杂体系结构中性能的提高。LSTM在语言建模任务上的层次越多，改进程度越高，也与上述分析一致。\n\n<br/>\n\n## 6. 限制函数\n\n$\\eta_l (t)=(1-\\frac{1}{(1-\\beta)t+1})\\alpha^*$\n\n$\\eta_u(t)=(1+\\frac{1}{(1-\\beta)t})\\alpha^*$\n\n* $\\beta$：影响算法从自适应变为SGD的转换速度\n* $\\alpha^*$：转换目标，反映最终SGD的步长\n\n![](AdaBound/AdaBound_figure5.png)\n\n* 图5，定$\\alpha^*$变化$\\beta$，反映出对于特定的$\\alpha^*$，不同的$\\beta$的性能几乎相同。表明限制函数的收敛速度在一定程度上不影响最终结果。并且在$[\\beta_1,\\beta_2]$内的$\\beta$通常效果更佳。\n\n![](AdaBound/AdaBound_figure6.png)\n\n* 图6，不同$\\alpha^*$对SGD和AdaBound的影响。结果表明SGDM对超参数非常敏感。SGDM步长的最佳值为0.1，且与其他设置相比性能差距很大。相比之下，ADABOUND针对不同的最终步长具有稳定的性能，说明它对收敛目标不敏感。\n\n![](AdaBound/AdaBound_figure7.1.png)\n\n![AdaBound_figure7.2](AdaBound/AdaBound_figure7.2.png)\n\n* 图7，进一步直接比较SGDM和ADABOUND与每个α（或α*）之间的性能。\n\t结果如图7所示。我们可以看到，ADABOUND在所有步骤中都优于SGDM\n\t大小。 由于绑定函数的形式对ADABOUND的性能影响很小，因此它是\n\t即使没有仔细调整超参数，也可能击败SGDM。\n* ADABOUND对其超参数不敏感。而且，它即使没有仔细微调，也能获得与SGDM更高或相似的性能。","slug":"AdaBound","published":1,"updated":"2020-06-18T12:17:13.551Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbevb0002i0qvfygubo7z","content":"<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#adabound\">AdaBound</a>\n<ul>\n<li><a href=\"#%E8%83%8C%E6%99%AF\">背景</a></li>\n<li><a href=\"#abstract-%E6%91%98%E8%A6%81\">ABSTRACT 摘要</a></li>\n<li><a href=\"#1%E4%BB%8B%E7%BB%8D\">1.介绍</a></li>\n<li><a href=\"#2%E7%AC%A6%E5%8F%B7%E5%92%8C%E5%89%8D%E6%8F%90%E8%AE%BE%E5%AE%9A\">2.符号和前提设定</a>\n<ul>\n<li><a href=\"#%E7%AC%A6%E5%8F%B7\">符号</a></li>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E5%87%B8%E4%BC%98%E5%8C%96\">在线凸优化</a>\n<ul>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0\">在线学习</a></li>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E5%87%B8%E4%BC%98%E5%8C%96-1\">在线凸优化</a></li>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">在线梯度下降</a></li>\n</ul>\n</li>\n<li><a href=\"#%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0\">优化方法概述</a></li>\n</ul>\n</li>\n<li><a href=\"#3%E6%9E%81%E7%AB%AF%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%BC%E8%87%B4%E7%9A%84%E9%9D%9E%E6%94%B6%E6%95%9B%E6%80%A7\">3.极端学习率导致的非收敛性</a></li>\n<li><a href=\"#4%E5%8A%A8%E6%80%81%E9%99%90%E5%88%B6%E7%9A%84adam\">4.动态限制的ADAM</a></li>\n<li><a href=\"#5%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C\">5.实验结果</a>\n<ul>\n<li><a href=\"#51-%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE\">5.1 参数设置</a></li>\n<li><a href=\"#52-%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">5.2 前馈神经网络</a></li>\n<li><a href=\"#53-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">5.3 卷积神经网络</a></li>\n<li><a href=\"#54-%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">5.4 递归神经网络</a></li>\n<li><a href=\"#55-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90\">5.5 结果分析</a></li>\n</ul>\n</li>\n<li><a href=\"#6-%E9%99%90%E5%88%B6%E5%87%BD%E6%95%B0\">6. 限制函数</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"adabound\"> AdaBound</span></h1>\n<p>Adaptive Gradient Methods with Dynamic Bound of Learning Rate 动态限制学习率的自适应梯度下降方法</p>\n<p><a href=\"https://github.com/Luolc/AdaBound\" target=\"_blank\" rel=\"noopener\">Github</a></p>\n<p><a href=\"https://openreview.net/pdf?id=Bkg3g2R9FX\" target=\"_blank\" rel=\"noopener\">论文</a></p>\n<p><a href=\"https://www.luolc.com/assets/research/adabound/slides-AdaptiveGradientMethodsAndBeyond.pdf\" target=\"_blank\" rel=\"noopener\">slides</a></p>\n<br>\n<h2><span id=\"背景\"> 背景</span></h2>\n<p><strong>引自<a href=\"https://zhuanlan.zhihu.com/p/37269222\" target=\"_blank\" rel=\"noopener\">作者知乎专栏</a></strong></p>\n<ul>\n<li><a href=\"http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning\">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a>. 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。<strong>推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。</strong></li>\n<li><a href=\"http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ\">On the Convergence of Adam and Beyond</a>. ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。主要攻击的是Adam有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但AdaBound作者认为这篇 paper 的<strong>意义十分有限，同时有很大误导性</strong>。\n<ol>\n<li>作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为<strong>这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值</strong>，极端构造下的收敛性，并不意味着什么。</li>\n<li>作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，<strong>training loss 的意义对于一个模型是十分有限的</strong>。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，<strong>Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差</strong>。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 <a href=\"http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/\">Experiments with AMSGrad</a> 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。</li>\n<li>最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。</li>\n<li>相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的performance对模型而言才是更加重要的性质。</li>\n</ol>\n</li>\n<li><a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628\">Improving Generalization Performance by Switching from Adam to SGD</a>. 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。<strong>实验表明训练后期更新步长过小也是原因之一。</strong></li>\n<li>综上而言，<strong>在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向</strong>。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。</li>\n</ul>\n<hr>\n<br>\n<h2><span id=\"abstract-摘要\"> ABSTRACT 摘要</span></h2>\n<p>已经提出了很多自适应优化方法，例如ADAGRAD，RMSPROP和ADAM，以实现具有对学习率逐元缩放的快速训练过程。尽管盛行，但人们观察到它们有时难以与SGD相比，甚至由于不稳定和极端学习率而未能收敛。最近有人提出了一些算法，如AMSGRAD(2018)，但他们未能比现有方法取得相当大的进步。在我们的论文中，我们证明极端学习率确实可能导致表现不佳。我们提供ADAM和AMSGRAD的新变种，称为分别使用ADABOUND和AMSBOUND，它们采用动态限制学习率实现从自适应方法逐步平稳过渡到SGD，并给出了收敛的理论证明。实验结果表明，新变种可以消除在自适应方法和SGD之间的泛化差距，并在早期保持较高的学习速度同时训练。而且，它们可以显着地改善各自原型，尤其是复杂的深度网络。</p>\n<hr>\n<br>\n<h2><span id=\"1介绍\"> 1.介绍</span></h2>\n<p>在用于训练深度神经网络的一阶优化算法方面取得了巨大进步。最主要的算法之一是随机梯度下降（SGD），尽管简单，但在许多应用程序中表现良好。然而，SGD的一个缺点是它在所有方向上均匀地调整梯度。这可能会导致当训练数据稀疏时，表现不佳以及训练速度有限。为解决这个问题，最近提出了各种自适应方法来缩放梯度，包括ADAM，ADAGRAD和RMSPROP。特别是ADAM，由于其快速的训练速度，已经成为默认算法。</p>\n<p>然而，这些自适应方法的泛化能力可能比非适应性方法更差。自适应方法通常在训练的初始部分显得更快，但在测试集不佳。实际上，最近在自然语言处理和计算机视觉方面的一些最先进的作品中，优化器大多被选为SGD。其中这些实例SGD确实表现得比自适应方法更好。Reddi（2018）提出了一种名为AMSGRAD的ADAM变体，希望能解决这个问题。作者提供了收敛的理论保证，但仅限于说明其在训练数据方面的更好表现。然而，发现AMSGRAD对测试集数据的泛化能力与ADAM相似，和SGD仍存在相当大的性能差距。</p>\n<p>在本文中，首先对ADAM进行了实证研究，说明两者在训练结束时存在极端（极大和极小）的学习率。结果与2017年Wilson的paper中的“自适应方法泛化性能差可能是源于不稳定和极端的学习率”一致。实际上，2018年AMSGrad的paper中，关键点就是引入非增长学习率，这可能有助于减轻巨大学习率的影响，忽略小的可能影响。我们进一步提供了一个简单凸优化问题的例子，以阐明自适应方法的微小学习率如何导致不收敛。在这样的设置中，RMSPROP和ADAM可证明不会收敛到最优<br>\n解。此外，无论初始步长α是多大，ADAM都无法改变规格下降的情况。</p>\n<p>基于以上分析，我们提出了ADAM和AMSGRAD的新变种，命名为ADABOUND和AMSBOUND，它们不会受到极端学习的负面影响。我们采用学习率的动态界限，其中最低和最高界限分别初始化为零和无穷大，它们都平滑地收敛到一个恒定的最终步长。新变种在开始时可被视为自适应方法训练，随着时间增加，逐渐平稳地转变为SGD。在这个框架中，我们可以享受快速的初始训练过程以及良好的泛化能力。我们为凸面设置中的新变体提供收敛分析。</p>\n<p>最后，转向对计算机视觉和自然语言处理中的流行任务和模型进行实证研究，结果证明训练早期有较高学习速度，同时与几种自适应和非自适应方法相比，保证了强大的泛化性能。而且，他们可以在原型上带来了相当大的改进，特别是在复杂的深层网络上。</p>\n<hr>\n<br>\n<h2><span id=\"2符号和前提设定\"> 2.符号和前提设定</span></h2>\n<h3><span id=\"符号\"> 符号</span></h3>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\theta\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>：向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：向量第<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">i</span></span></span></span>位</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>θ</mi><mi>k</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\theta ^k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span></span></span></span>：逐元素指数运算</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>θ</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">||\\theta||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span>：L2范数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：迭代后向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{t,i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>：迭代后向量的第<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">i</span></span></span></span>位</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">⟨</mo><mi>v</mi><mo separator=\"true\">,</mo><mi>w</mi><mo stretchy=\"false\">⟩</mo></mrow><annotation encoding=\"application/x-tex\">\\langle v,w\\rangle</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">⟨</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">⟩</span></span></span></span>：向量内积</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>v</mi><mo>⨀</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">v \\bigodot w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">⨀</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>：逐元素相乘</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>v</mi><mi mathvariant=\"normal\">/</mi><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">v/w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>：逐元素相除</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi>v</mi><mo separator=\"true\">,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">max(v,w)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span></span></span></span>：逐元素取最大</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msubsup><mi>S</mi><mo>+</mo><mi>d</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">S^d_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.154439em;vertical-align:-0.305331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.305331em;\"><span></span></span></span></span></span></span></span></span></span>：所有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d\\times d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>的正定矩阵</li>\n<li>向量<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">a\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>，正定矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">M\\in R^{d\\times d}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mi mathvariant=\"normal\">/</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">a/M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span></span></span></span>：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>M</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">M^{-1}a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\">a</span></span></span></span></li>\n<li>投影操作<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mo>∏</mo><mrow><mi>F</mi><mo separator=\"true\">,</mo><mi>M</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\prod_{F,M}(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.185818em;vertical-align:-0.43581800000000004em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">F</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>∈</mo><msubsup><mi>S</mi><mo>+</mo><mi>d</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">M\\in S^d_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.154439em;vertical-align:-0.305331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.305331em;\"><span></span></span></span></span></span></span></span></span></span>：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>x</mi><mo>∈</mo><mi>F</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msqrt><mi>M</mi></msqrt><mo stretchy=\"false\">(</mo><mi>x</mi><mo>−</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">argmin_{x\\in F}||\\sqrt M(x-y)||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.176665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">i</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"mrel mtight\">∈</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">F</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9266650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;padding-left:0.833em;\">M</span></span><span style=\"top:-2.886665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.11333499999999996em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">y\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>，意为将不在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>中的向量<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>投影为一个与<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>最近且在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>中的向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>a</mi><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mn>1</mn></msub><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mn>2</mn></msub><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mi>n</mi></msub><mi mathvariant=\"normal\">∣</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">||a||_\\infty=max(|a_1|,|a_2|,\\cdots ,|a_n|)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">a</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mclose\">)</span></span></span></span>：向量无穷范数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><mi>m</mi><mi>a</mi><msub><mi>x</mi><mrow><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>n</mi></mrow></msub><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">D_\\infty=max_{1\\leq i\\leq n}\\sum^n_{j=1}|a_{ij}|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24011em;vertical-align:-0.43581800000000004em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">≤</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">≤</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24517899999999998em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span></span>，矩阵无穷范数，行模，行绝对值和的最大值</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi><mo>⊂</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">F\\subset R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⊂</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>：凸可行集</li>\n<li>F凸集：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">，</mi><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda\\in [0,1]，a,b\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord mathdefault\">a</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>，有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mi>a</mi><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy=\"false\">)</mo><mi>b</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda a+(1-\\lambda)b\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mclose\">)</span><span class=\"mord mathdefault\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span></li>\n<li>满足约束条件的点称为可行点，全体可行点组成的集合称为可行集</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">x,y\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>,如果<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>≤</mo><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub></mrow><annotation encoding=\"application/x-tex\">||x-y||_\\infty\\leq D_\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ，则称<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>限制了直径<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub></mrow><annotation encoding=\"application/x-tex\">D_\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>diag(A)是提取出矩阵A的主对角线元素，得到的是一维的向量，diag（diag（A））是一个对角矩阵</li>\n<li>设A是n阶方阵，如果对任何非零向量X，都有X’A<em>X≥0</em>，其中*X‘’*表示X的转置，就称A为<strong>半正定矩阵</strong>/＞0，正定</li>\n</ul>\n<br>\n<h3><span id=\"在线凸优化\"> 在线凸优化</span></h3>\n<h4><span id=\"在线学习\"> 在线学习</span></h4>\n<ul>\n<li>机器学习中的一种模型训练方法</li>\n<li>比喻：有一老师和一学生，每天老师让学生回答一个问题，然后老师告诉学生正确答案，学生则比较正确答案来更新自己的知识。就这样学生终成大师（博弈论里的重复游戏）</li>\n<li>认为数据的分布是可以任意的；而寻常算法中，认为数据独立同分布；目的是正确预测数据的类别，并且在每次预测后，该结果用来更新修正预测模型，用于对以后数据进行更好的预测</li>\n<li>主要限制是当前只能看到当前的和过去的数据，因此，对在线学习而言，它追求的是知道所有数据时所能设计的最优策略。同这个最优策略的差异称之为遗憾（regret）：遗憾没能一开始就选对最优策略。我们的希望是，时间一久，数据一多，这个差异就会变得很小。我们追求的是，没有后悔（no-regret）</li>\n<li>如果与统计学习一样对数据做独立同分布假设，那么在线学习里的最优策略就是在得知所有数据的离线学习所能得到最优解。因此在线学习可以看成是一种优化方法：随着对数据的不断访问来逐步逼近这个离线最优解</li>\n<li>过程：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时刻，模型收到样本<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>；然后从策略集中选出一个策略<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，并对样本做出判断<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">w_t(x_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>；收到正确答案<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。用损失函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>l</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">l(w_t(x_t),y_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>衡量在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时刻做出不正确判断所受损失，简记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">l_t(w_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，故<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span></span></span></span>轮总损失为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\sum^T_{t=1}l_t(w_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。遗憾值记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>l</mi><mi>t</mi></msub><mi mathvariant=\"normal\">（</mi><msub><mi>w</mi><mi>t</mi></msub><mi mathvariant=\"normal\">）</mi><mo>−</mo><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>w</mi><mo>∈</mo><mi>F</mi></mrow></msub><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R_T=\\sum^T_{t=1}l_t（w_t）-min_{w\\in F}\\sum^T_{t=1}l_t(w)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">（</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">）</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">i</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mrel mtight\">∈</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">F</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span></span></span></span>，即总损失减去使用最佳策略的损失和。但是存在小概率事件：每次选择的策略恰能很好适应当前样本，最终使遗憾值小于零。故我们关心平均遗憾是不是随着步骤增加而减小，即<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>l</mi><mi>i</mi><msub><mi>m</mi><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></msub><mfrac><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></mfrac><mo>→</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">lim_{T\\rarr\\infty}\\frac{R(T)}{T}\\rarr0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.355em;vertical-align:-0.345em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">i</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></li>\n</ul>\n<br>\n<h4><span id=\"在线凸优化\"> 在线凸优化</span></h4>\n<ul>\n<li>挑选<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>的策略集<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>是凸的，且损失函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">l_t(w_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>关于<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>是凸的，则称此问题为在线凸优化</li>\n</ul>\n<br>\n<h4><span id=\"在线梯度下降\"> 在线梯度下降</span></h4>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时做两步：</li>\n</ul>\n<ol>\n<li>利用当前得到数据对<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>进行一次梯度下降得到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{t+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>若新<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{t+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span>不在策略集中，使用投影公式投影进来</li>\n</ol>\n<ul>\n<li>\n<p>优势：N个数据，每次一个，N步找到最优策略，即总共只计算N个数据</p>\n<p>在本文中，我们假设可行集<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>具有有界直径并且<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∇</mi><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub></mrow><annotation encoding=\"application/x-tex\">||\\nabla f_t(x)||_\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\">∇</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>是对于所有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>T</mi><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">，</mi><mi>x</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">t\\in [T]，x\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65418em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>都有界限。我们希望算法的遗憾值很小。我们的目标是设计一种确保<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mo>=</mo><mi>o</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R_T=o(T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">o</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span></span></span></span>的算法，这意味着平均来说，模型的性能收敛到最佳。已经指出，具有平均后悔为0的在线优化算法产生相应的随机优化算法（Cesa-Bianchi等，2002）。因此，跟随Reddi等人（2018），我们同样使用在线梯度下降和随机梯度下降。</p>\n</li>\n</ul>\n<br>\n<h3><span id=\"优化方法概述\"> 优化方法概述</span></h3>\n<p>我们遵循Reddi等人的观点（2018），提供算法1中的通用优化方法框架，封装了许多流行的自适应和非自适应方法。 这对于理解不同优化的属性很有用。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_algorithm1.png\" alt></p>\n<p>注意，因为函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>ϕ</mi><mi>t</mi></msub><mo>:</mo><msup><mi>F</mi><mi>t</mi></msup><mo>→</mo><msup><mi>R</mi><mi>d</mi></msup><mo separator=\"true\">,</mo><mi>ψ</mi><mo>:</mo><msup><mi>F</mi><mi>d</mi></msup><mo>→</mo><msubsup><mi>S</mi><mo>+</mo><mi>d</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\phi_t:F^t\\rarr R^d,\\psi:F^d\\rarr S^d_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϕ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7935559999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.043548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ψ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.154439em;vertical-align:-0.305331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.305331em;\"><span></span></span></span></span></span></span></span></span></span>还未确定，所以算法仍是抽象的。本文中，我们将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span></span></span></span>称为初始步长，将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant=\"normal\">/</mi><msqrt><msub><mi>V</mi><mi>t</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">a_t/\\sqrt {V_t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1016650000000001em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.851665em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.811665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18833500000000003em;\"><span></span></span></span></span></span></span></span></span>称为算法的学习率。注意，我们采用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mi mathvariant=\"normal\">/</mi><msqrt><mi>t</mi></msqrt></mrow><annotation encoding=\"application/x-tex\">a_t=a/\\sqrt t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.14254em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.89254em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"padding-left:0.833em;\">t</span></span><span style=\"top:-2.85254em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14746000000000004em;\"><span></span></span></span></span></span></span></span></span>减小步长。然而这种鲁莽的的衰退步骤通常表现较差，而简单的恒定步长<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>α</mi><mi>t</mi></msub><mo>=</mo><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">α_t =\nα</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span></span></span></span>通常在实践中很有效。本文其余部分的理论分析和常量方案的实证研究中，我们将使用递减方案。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_table1.png\" alt></p>\n<p>AdaGrad和RMSProp可看作Adam特例，着重研究Adam。</p>\n<hr>\n<br>\n<h2><span id=\"3极端学习率导致的非收敛性\"> 3.极端学习率导致的非收敛性</span></h2>\n<p>在本节中，初步实验和严格的证明，详细阐述了当前已有自适应方法的主要缺陷。如上所述，观察到诸如ADAM的自适应方法表现比SGD差。 Reddi等（2018）提出AMSGRAD来解决这个问题，但最近的工作指出AMSGRAD并没有显示出对ADAM的明显改善（Keskar＆Socher，2017年; Chen等，2018）。作者声称AMSGRAD与ADAM相比具有较小的学习率，作者仅将大的极端学习率视为ADAM性能不佳的原因。然而，小的也可能是个陷阱。因此，我们推测两个极端值都是ADAM的学习率是其泛化能力不足的原因。</p>\n<p>为了证实我们的推测，我们对在CIFAR-10上使用ADAM的ResNet-34网络的几个权重Weight和偏差bias的学习率进行了抽样。具体来说，我们随机选择来自不同层的9个3×3卷积核和最后一个线性层中的偏差bias。通常作为同一层的参数具有相似6的属性，这里我们只展示在训练结束时九个卷积核中的九个权重的学习率和最后一层的bias，内核分别和最后一层的偏差，如图1所示。我们可以发现当模型接近收敛时，学习率有小于0.01的的以及大于1000的大小的。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure1.png\" alt></p>\n<p>图1 采样参数的学习率。每个单元都是学习率的对数。</p>\n<p>上述分析和观察表明在训练过程的最后阶段确实存在过大或过大的学习率太小。 AMSGRAD可能有助于减轻巨大的学习率的影响，但它忽略了过小的学习率。就此而言，我们仍然有以下两个疑惑。首先，微小的学习率真的会损害ADAM的效果吗？第二，学习率高度依赖于初始步长，我们可以使用相对较大的初始步长α来摆脱后期太小的学习率？</p>\n<p>我们表明ADAM和RMSPROP的不良收敛行为可能是由极小的学习率引起的，此外，在某些情况下无论如何初始步长α，ADAM仍然无法找到正确的路径并收敛。</p>\n<p>考虑以下线性函数序列，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi><mo>=</mo><mo stretchy=\"false\">[</mo><mo>−</mo><mn>2</mn><mo separator=\"true\">,</mo><mn>2</mn><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">，</mi><mi>C</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">F=[-2,2]，C\\in N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">−</span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span></span></span></span>，满足<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>5</mn><msubsup><mi>β</mi><mn>2</mn><mrow><mi>C</mi><mo>−</mo><mn>2</mn></mrow></msubsup><mo>≤</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mn>4</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">5\\beta^{C-2}_2\\leq(1-\\beta_2)/(4-\\beta_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.14777em;vertical-align:-0.266308em;\"></span><span class=\"mord\">5</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.881462em;\"><span style=\"top:-2.433692em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.1031310000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.266308em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mopen\">(</span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。</p>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;&amp;&#039; at position 115: …$ $x$ $\\leq$ 1 &amp;̲&amp; $t$ mod $C$ =…\">f_t(x) =\n\\begin{cases}\n-100,  &amp; \\text{$x$ &lt; 0} \\\\\n0,     &amp; \\text{$x$ &gt; 0} \\\\\n-x,    &amp; \\text{0 $\\leq$ $x$ $\\leq$ 1 &amp;&amp; $t$ mod $C$ = 1} \\\\\n2x,    &amp; \\text{0 $\\leq$ $x$ $\\leq$ 1 &amp;&amp; $t$ mod $C$ = 2} \\\\\n0,     &amp; \\text{else} \n\\end{cases}\n</p>\n<p>很容易看出任何x&lt;0的点都有最小的遗憾。 假设<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_1=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>，我们表明ADAM收敛于此设置的x≥0的极端非优解。该算法在每C步梯度-1，这使算法向错误的方向移动。然后，在下一步，它观察到梯度2。但是较大的梯度2不能抵消错误方向，因为本步中，学习率将缩小到远小于前一个值。因此随着时间的增加，x变得越来越大。<br>\n我们在下面的结果中形式化这种直觉。</p>\n<p>**定理1.**总会有一个在线凸优化问题，对任何初始步长<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span></span></span></span>，Adam都有非0平均遗憾值。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mi mathvariant=\"normal\">/</mi><mi>T</mi><mo>↛</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">R_T/T\\nrightarrow0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel amsrm\">↛</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> 当 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">T \\rarr \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。</p>\n<p>我们将所有证明都归入附录中。注意，上述示例也适用于恒定步长。另，SGD不会遇到这个问题。初始步长有多种有效选择，其中SGD的平均遗憾为0，换句话说，收敛到最优解。这个问题在后期会更加明显。当算法陷入某些非优点时。在这种情况下，大多数步骤的梯度接近0并且二阶动量的平均值会各种各样，由于指数移动平均的特性。因此，如果出现频率相对较低的“正确”信号（即上例中每C步骤的梯度2）在一些“错误”信号（即示例中的梯度1）之后到来，即使正确的具有更大的梯度绝对值，也可能无法将算法引导到正确的路径。</p>\n<p>人们可能想知道使用大的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>是否有帮助，因为我们通常在实践中使其接近1。然而，以下结果表明，对于具有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">β1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>的任何恒定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">β_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">β_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，存在ADAM具有非零平均遗憾的示例，而与初始步长α无关。</p>\n<p>**定理2.**对任意<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\beta_1,\\beta_2\\in [0,1), \\beta1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>，都存在一个在线凸优化问题，无论初始步长如何，ADAM都有非0平均遗憾值。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mi mathvariant=\"normal\">/</mi><mi>T</mi><mo>↛</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">R_T/T\\nrightarrow0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel amsrm\">↛</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> as <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">T \\rarr \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。</p>\n<p>**定理3.**对任意<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\beta_1,\\beta_2\\in [0,1), \\beta1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>，都有一个随机凸优化问题，无论初始步长如何，ADAM都无法收敛至最优解。</p>\n<p>Kingma＆Lei Ba（2015）中ADAM的分析依赖于随着时间的推移降低β1，而在这里我们使用常数β1。实际上，由于我们的分析中关键参数是β2而不是β1，因此使用β1的递减方案将我们的示例扩展到案例非常容易。</p>\n<p>如Reddi等人所述（2018），条件<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\beta1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>是良性的并且通常在实践中使用的参数设置中得到满足。在Kingma＆Lei Ba（2015）的收敛证明中也假设了这种情况。 上述结果说明了极端学习率的潜在不良影响，并且算法在不解决该问题的情况下不可能实现良好的泛化能力。</p>\n<br>\n<h2><span id=\"4动态限制的adam\"> 4.动态限制的ADAM</span></h2>\n<p>在本节中，我们开发了优化方法的新变体并提供了它们的收敛性分析。我们的目标是制定一种方法，结合自适应方法的好处，即快速的初步进展，以及SGD良好的最终泛化特性。最后，我们想构建一种算法，其在训练早期就像自适应方法一样，最后像SGD一样。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_algorithm2.png\" alt></p>\n<p>受梯度剪辑的启发，这是一种在实践中用于剪切大于阈值的梯度以避免渐变爆炸的流行技术，我们在ADAM中使用剪切学习速率来在算法2中提出ADABOUND。考虑在ADAM中应用以下操作<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>C</mi><mi>l</mi><mi>i</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mi mathvariant=\"normal\">/</mi><msqrt><msub><mi>V</mi><mi>t</mi></msub></msqrt><mo separator=\"true\">,</mo><msub><mi>η</mi><mi>l</mi></msub><mo separator=\"true\">,</mo><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Clip(\\alpha/\\sqrt{V_t},\\eta_l,\\eta_u)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1016650000000001em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.851665em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.811665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18833500000000003em;\"><span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，对学习率逐元素剪切，使输出约束在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>η</mi><mi>l</mi></msub><mo separator=\"true\">,</mo><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[\\eta_l,\\eta_u]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>内。由此得出，具有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>=</mo><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a=a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>的SGD（M）可以被看作是<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo>=</mo><msub><mi>η</mi><mi>u</mi></msub><mo>=</mo><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">η_l=η_u=α^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>的情况。至于ADAM，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">η_l= 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo>=</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">η_u= \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。现在我们可以通过以下步骤提供新策略：我们使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub></mrow><annotation encoding=\"application/x-tex\">η_l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">η_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>作为t的函数,而不是常数下限和上限，其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">η_l(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>是一个非递减函数，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">t = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>时值为0，并逐渐收敛到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>；并且<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">η_u(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>是非增加函数，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">t = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>时值为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>，并且也渐近地收敛到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>。在此设置中，ADABOUND在开始时表现得像ADAM一样，因为边界对学习速率的影响非常小，并且随着边界收缩而逐渐转换为SGD（M）。我们证明了ADABOUND的以下关键结果。</p>\n<p><strong>定理4.</strong></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">{</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">}</mo><mo separator=\"true\">,</mo><mo stretchy=\"false\">{</mo><msub><mi>v</mi><mi>t</mi></msub><mo stretchy=\"false\">}</mo><mi mathvariant=\"normal\">是</mi><mi mathvariant=\"normal\">由</mi><mi mathvariant=\"normal\">算</mi><mi mathvariant=\"normal\">法</mi><mn>2</mn><mi mathvariant=\"normal\">得</mi><mi mathvariant=\"normal\">出</mi><mi mathvariant=\"normal\">。</mi><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">所</mi><mi mathvariant=\"normal\">有</mi><mi>t</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>T</mi><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">且</mi><msub><mi>β</mi><mn>1</mn></msub><mi mathvariant=\"normal\">/</mi><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt><mo>&lt;</mo><mn>1</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">都</mi><mi mathvariant=\"normal\">有</mi><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><msub><mi>β</mi><mn>11</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mrow><mn>1</mn><mi>t</mi></mrow></msub><mo>≤</mo><mi>β</mi><mn>1</mn><mi mathvariant=\"normal\">。</mi><mspace linebreak=\"newline\"></mspace><mi mathvariant=\"normal\">假</mi><mi mathvariant=\"normal\">设</mi><mi mathvariant=\"normal\">当</mi><mi>t</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi><mi mathvariant=\"normal\">时</mi><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>≥</mo><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>≥</mo><mn>0</mn><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>≤</mo><msub><mi>η</mi><mi>y</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">，</mi><mspace linebreak=\"newline\"></mspace><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>→</mo><msup><mi>a</mi><mo>∗</mo></msup><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>→</mo><msup><mi>a</mi><mo>∗</mo></msup><mi mathvariant=\"normal\">，</mi><msub><mi>L</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">且</mi><msub><mi>R</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">。</mi><mspace linebreak=\"newline\"></mspace><mi mathvariant=\"normal\">假</mi><mi mathvariant=\"normal\">定</mi><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">所</mi><mi mathvariant=\"normal\">有</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo>∈</mo><mi>F</mi><mi mathvariant=\"normal\">，</mi><mi mathvariant=\"normal\">有</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>≤</mo><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub><mi mathvariant=\"normal\">；</mi><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">所</mi><mi mathvariant=\"normal\">有</mi><mi>t</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>T</mi><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">和</mi><mi>x</mi><mo>∈</mo><mi>F</mi><mi mathvariant=\"normal\">，</mi><mi mathvariant=\"normal\">有</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∇</mi><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo>≤</mo><msub><mi>G</mi><mn>2</mn></msub><mi mathvariant=\"normal\">。</mi><mspace linebreak=\"newline\"></mspace><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">经</mi><mi>A</mi><mi>d</mi><mi>a</mi><mi>B</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>d</mi><mi mathvariant=\"normal\">产</mi><mi mathvariant=\"normal\">生</mi><mi mathvariant=\"normal\">的</mi><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">，</mi><mi mathvariant=\"normal\">在</mi><mi mathvariant=\"normal\">其</mi><mi mathvariant=\"normal\">遗</mi><mi mathvariant=\"normal\">憾</mi><mi mathvariant=\"normal\">值</mi><mi mathvariant=\"normal\">上</mi><mi mathvariant=\"normal\">都</mi><mi mathvariant=\"normal\">有</mi><mi mathvariant=\"normal\">以</mi><mi mathvariant=\"normal\">下</mi><mi mathvariant=\"normal\">界</mi><mi mathvariant=\"normal\">限</mi><mi mathvariant=\"normal\">：</mi></mrow><annotation encoding=\"application/x-tex\">\\{x_t\\},\\{v_t\\}是由算法2得出。对所有t\\in[T]且\\beta_1/\\sqrt{\\beta_2}&lt;1,都有        \\beta_1=\\beta_{11},\\beta_{1t}\\leq\\beta1。\\\\\n假设当t\\rarr \\infty 时，\\eta_l(t+1)\\geq\\eta_l(t)\\geq0，\\eta_u(t+1)\\leq\\eta_y(t)，\\\\ \\eta_l(t)\\rarr a^*，\\eta_u(t)\\rarr a^*，L_{\\infty}=\\eta _l(1)且R_\\infty=\\eta_u(1)。\\\\\n假定对所有x,y\\in F，有||x-y||_\\infty \\leq D_\\infty；对所有t\\in [T]和x\\in F，有||\\nabla f_t(x)||\\leq G_2。\\\\\n对经AdaBound产生的x_t，在其遗憾值上都有以下界限：\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">}</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">}</span><span class=\"mord cjk_fallback\">是</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">算</span><span class=\"mord cjk_fallback\">法</span><span class=\"mord\">2</span><span class=\"mord cjk_fallback\">得</span><span class=\"mord cjk_fallback\">出</span><span class=\"mord cjk_fallback\">。</span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.25612499999999994em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">且</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.983875em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.9438750000000002em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.25612499999999994em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord cjk_fallback\">都</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mord cjk_fallback\">。</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">假</span><span class=\"mord cjk_fallback\">设</span><span class=\"mord cjk_fallback\">当</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∞</span><span class=\"mord cjk_fallback\">时</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">，</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.888696em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">且</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">。</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord cjk_fallback\">假</span><span class=\"mord cjk_fallback\">定</span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">；</span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">和</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\">∇</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">G</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">。</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">经</span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">d</span><span class=\"mord cjk_fallback\">产</span><span class=\"mord cjk_fallback\">生</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">其</span><span class=\"mord cjk_fallback\">遗</span><span class=\"mord cjk_fallback\">憾</span><span class=\"mord cjk_fallback\">值</span><span class=\"mord cjk_fallback\">上</span><span class=\"mord cjk_fallback\">都</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord cjk_fallback\">以</span><span class=\"mord cjk_fallback\">下</span><span class=\"mord cjk_fallback\">界</span><span class=\"mord cjk_fallback\">限</span><span class=\"mord cjk_fallback\">：</span></span></span></span></span></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_theorem4.png\" alt></p>\n<p><strong>推论4.1</strong></p>\n<p>假设<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mrow><mn>1</mn><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><msup><mi>λ</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\beta_{1t}=\\beta_1\\lambda^{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.008548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">λ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span>是由定理4得出，则</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_corollary4.1.png\" alt></p>\n<p>很容易看出，ADABOUND的遗憾值上限是<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(\\sqrt T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.176665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9266650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;padding-left:0.833em;\">T</span></span><span style=\"top:-2.886665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.11333499999999996em;\"><span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。与Reddi等人类似（2018），人们可以使用更适度的动量衰减<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mrow><mn>1</mn><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><mi mathvariant=\"normal\">/</mi><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">\\beta_{1t}=\\beta_1/t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathdefault\">t</span></span></span></span>，并且仍然确保遗憾值上限是<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(\\sqrt T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.176665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9266650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;padding-left:0.833em;\">T</span></span><span style=\"top:-2.886665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.11333499999999996em;\"><span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。</p>\n<p>最后进行比较。对于将ADAM转换为SGD的想法，Keskar＆Socher（2017）也有类似的工作。作者提出了一种首先使用ADAM的措施，并在某个特定步骤将算法切换到SGD。与他们的方法相比，我们的方法有两个优点。首先，是否存在区分ADAM和SGD的固定转折点是不确定的。因此，我们使用连续转换过程而不是“硬”开关来解决此问题。其次，他们引入了额外的超参数来决定切换时间，这不是很容易微调。至于我们的方法，引入的灵活部分是两个绑定函数。我们对不同类型的约束函数的影响进行了实证研究。结果放在附录G中，我们发现收敛目标<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>和收敛速度对最终结果不是很重要。为了清楚起见，我们将在其余部分使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.1</mn><mo>−</mo><mfrac><mn>0.1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.1</mn><mo>+</mo><mfrac><mn>0.1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mi>t</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\eta_l(t)=0.1-\\frac{0.1}{(1-\\beta_2)t+1}，\\eta_u(t)=0.1+\\frac{0.1}{(1-\\beta_2)t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>。</p>\n<hr>\n<br>\n<h2><span id=\"5实验结果\"> 5.实验结果</span></h2>\n<p>在这一节中，我们将对不同的模型进行实证研究，将新方法与常用的优化方法(包括SGD(M)、ADAGRAD、ADAM和AMSGRAD))进行比较。我们主要关注三个任务：MNIST图像分类任务)、CIFAR-10图像分类任务和Penn Treebank上的语言建模任务。我们之所以选择它们，是因为它们的架构具有广泛的重要性和可再现性。表2详细列出了每个任务的设置。我们使用指定的初始化方法从随机的起点运行每个实验三次。为训练指定了固定的时域数预算，下面将介绍衰减策略。我们选择的设置，实现最低的训练损失在最后。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_table2.png\" alt></p>\n<br>\n<h3><span id=\"51-参数设置\"> 5.1 参数设置</span></h3>\n<br>\n<h3><span id=\"52-前馈神经网络\"> 5.2 前馈神经网络</span></h3>\n<p>针对MNIST数据集上的多类分类问题，我们训练了一个具有隐层的简单全连通神经网络。我们运行了100个epochs，省略了这个实验的衰变方案。图2显示了训练和测试集上每种优化方法的学习曲线。我们发现在训练中，所有算法都能达到接近100%的准确率。在测试部分，SGD的性能略优于ADAM和AMSGRAD的自适应方法。我们提出的ADABOUND和AMSBOUND两种方法显示出轻微的改进，但与它们的原型相比，测试精度仍然有明显的提高。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure2.png\" alt></p>\n<br>\n<h3><span id=\"53-卷积神经网络\"> 5.3 卷积神经网络</span></h3>\n<p>利用DenseNet-121和ResNet-34对CIFAR-10标准数据集进行图像分类。在这个实验中，我们使用200个epoch，在150个epoch后将学习率降低10个。</p>\n<p>DenseNet：我们首先在CIFAR-10上运行DenseNet-121模型，结果如图3所示。我们可以看到，ADAGRAD、ADAM和AMSGRAD等自适应方法在早期训练中表现得比非自适应方法更好。但是到了150轮，当学习速率衰减时，SGDM开始优于那些自适应方法。对于我们的方法ADABOUND和AMSBOUND，它们收敛速度和自适应方法一样快，并且在训练结束时的测试集上达到比SGDM稍高的精度。此外，与原型机相比，其性能得到了显著提高，测试精度提高了约2%。</p>\n<p>ResNet：实验结果如图3所示。正如预期的那样，ResNet-34上的每个算法的总体性能与DenseNet-121上的相似。ADABOUND和AMSBOUND甚至超过SGDM 1%。尽管自适应方法的泛化能力相对较差，但我们提出的方法克服了这一缺点，为其学习速率分配了界限，在CIFAR-10上对DenseNet和ResNet的测试集都获得了几乎最佳的准确率。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure3.1.png\" alt></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure3.2.png\" alt></p>\n<br>\n<h3><span id=\"54-递归神经网络\"> 5.4 递归神经网络</span></h3>\n<p>我们发现，在所有模型中，ADAM的初始进展最快，但在性能上停滞不前，不如SGD和我们的方法。与以往在图像分类任务实验中出现的现象不同，ADABOUND和AMSBOUND在训练初期的速度并不快，但曲线比SGD平滑。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure4.1.png\" alt></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure4.2.png\" alt></p>\n<p>对比L1、L2和L3，我们可以很容易地发现改善程度的显著差异。在最简单的模型L1中，我们的方法比ADAM的方法略好1.1%，而在最复杂的模型L3中，我们的方法在复杂的方面明显优于2.8%。为模型的复杂性与改进程度之间的关系提供了依据。</p>\n<br>\n<h3><span id=\"55-结果分析\"> 5.5 结果分析</span></h3>\n<p>为了研究我们提出的算法的有效性，我们从计算机视觉和自然语言处理中选择流行的任务。根据上面显示的结果，不难发现ADAM和AMSGRAD的表现通常是相似的，而AMSGRAD在大多数情况下并没有太大的改善。另一方面，它们的变体ADABOUND和AMSBOUND与SGD相比具有较快的收敛速度，同时在训练结束时的测试精度也大大超过了两种原始方法。这一现象正好印证了我们在第3节中提到的观点，学习速率的大小都会影响收敛。<br>\n此外，我们还对不同复杂度的模型进行了实验，包括一个per- ceptron模型、两个深度卷积神经网络模型和一个递归神经网络模型。MNIST上使用的感知器是最简单的，我们的方法比其他方法稍好一些。DenseNet和ResNet的测试精度明显提高。我们把这种不同归因于模型的复杂性。具体来说，对于深度CNN模型，卷积层和全连通层在任务中扮演不同的角色。此外，不同的卷积层可能负责不同的角色(Lee et al.2009)，这可能导致参数梯度的明显变化。换句话说，极端的学习速率(巨大或微小)可能在ResNet等复杂模型中出现得更频繁。由于我们的算法是为了避免这些问题而提出的，因此可以直观地解释在复杂体系结构中性能的提高。LSTM在语言建模任务上的层次越多，改进程度越高，也与上述分析一致。</p>\n<br>\n<h2><span id=\"6-限制函数\"> 6. 限制函数</span></h2>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy=\"false\">)</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mo stretchy=\"false\">)</mo><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\eta_l (t)=(1-\\frac{1}{(1-\\beta)t+1})\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy=\"false\">)</mo><mi>t</mi></mrow></mfrac><mo stretchy=\"false\">)</mo><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\eta_u(t)=(1+\\frac{1}{(1-\\beta)t})\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>：影响算法从自适应变为SGD的转换速度</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>：转换目标，反映最终SGD的步长</li>\n</ul>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure5.png\" alt></p>\n<ul>\n<li>图5，定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>变化<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>，反映出对于特定的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>，不同的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>的性能几乎相同。表明限制函数的收敛速度在一定程度上不影响最终结果。并且在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>β</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[\\beta_1,\\beta_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>内的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>通常效果更佳。</li>\n</ul>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure6.png\" alt></p>\n<ul>\n<li>图6，不同<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>对SGD和AdaBound的影响。结果表明SGDM对超参数非常敏感。SGDM步长的最佳值为0.1，且与其他设置相比性能差距很大。相比之下，ADABOUND针对不同的最终步长具有稳定的性能，说明它对收敛目标不敏感。</li>\n</ul>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure7.1.png\" alt></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure7.2.png\" alt=\"AdaBound_figure7.2\"></p>\n<ul>\n<li>图7，进一步直接比较SGDM和ADABOUND与每个α（或α*）之间的性能。<br>\n结果如图7所示。我们可以看到，ADABOUND在所有步骤中都优于SGDM<br>\n大小。 由于绑定函数的形式对ADABOUND的性能影响很小，因此它是<br>\n即使没有仔细调整超参数，也可能击败SGDM。</li>\n<li>ADABOUND对其超参数不敏感。而且，它即使没有仔细微调，也能获得与SGDM更高或相似的性能。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<!-- toc -->\n<ul>\n<li><a href=\"#adabound\">AdaBound</a>\n<ul>\n<li><a href=\"#%E8%83%8C%E6%99%AF\">背景</a></li>\n<li><a href=\"#abstract-%E6%91%98%E8%A6%81\">ABSTRACT 摘要</a></li>\n<li><a href=\"#1%E4%BB%8B%E7%BB%8D\">1.介绍</a></li>\n<li><a href=\"#2%E7%AC%A6%E5%8F%B7%E5%92%8C%E5%89%8D%E6%8F%90%E8%AE%BE%E5%AE%9A\">2.符号和前提设定</a>\n<ul>\n<li><a href=\"#%E7%AC%A6%E5%8F%B7\">符号</a></li>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E5%87%B8%E4%BC%98%E5%8C%96\">在线凸优化</a>\n<ul>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0\">在线学习</a></li>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E5%87%B8%E4%BC%98%E5%8C%96-1\">在线凸优化</a></li>\n<li><a href=\"#%E5%9C%A8%E7%BA%BF%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">在线梯度下降</a></li>\n</ul>\n</li>\n<li><a href=\"#%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E6%A6%82%E8%BF%B0\">优化方法概述</a></li>\n</ul>\n</li>\n<li><a href=\"#3%E6%9E%81%E7%AB%AF%E5%AD%A6%E4%B9%A0%E7%8E%87%E5%AF%BC%E8%87%B4%E7%9A%84%E9%9D%9E%E6%94%B6%E6%95%9B%E6%80%A7\">3.极端学习率导致的非收敛性</a></li>\n<li><a href=\"#4%E5%8A%A8%E6%80%81%E9%99%90%E5%88%B6%E7%9A%84adam\">4.动态限制的ADAM</a></li>\n<li><a href=\"#5%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C\">5.实验结果</a>\n<ul>\n<li><a href=\"#51-%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE\">5.1 参数设置</a></li>\n<li><a href=\"#52-%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">5.2 前馈神经网络</a></li>\n<li><a href=\"#53-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">5.3 卷积神经网络</a></li>\n<li><a href=\"#54-%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">5.4 递归神经网络</a></li>\n<li><a href=\"#55-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90\">5.5 结果分析</a></li>\n</ul>\n</li>\n<li><a href=\"#6-%E9%99%90%E5%88%B6%E5%87%BD%E6%95%B0\">6. 限制函数</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"adabound\"><a class=\"markdownIt-Anchor\" href=\"#adabound\"></a> AdaBound</h1>\n<p>Adaptive Gradient Methods with Dynamic Bound of Learning Rate 动态限制学习率的自适应梯度下降方法</p>\n<p><a href=\"https://github.com/Luolc/AdaBound\" target=\"_blank\" rel=\"noopener\">Github</a></p>\n<p><a href=\"https://openreview.net/pdf?id=Bkg3g2R9FX\" target=\"_blank\" rel=\"noopener\">论文</a></p>\n<p><a href=\"https://www.luolc.com/assets/research/adabound/slides-AdaptiveGradientMethodsAndBeyond.pdf\" target=\"_blank\" rel=\"noopener\">slides</a></p>\n<br>\n<h2 id=\"背景\"><a class=\"markdownIt-Anchor\" href=\"#背景\"></a> 背景</h2>\n<p><strong>引自<a href=\"https://zhuanlan.zhihu.com/p/37269222\" target=\"_blank\" rel=\"noopener\">作者知乎专栏</a></strong></p>\n<ul>\n<li><a href=\"http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning\">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a>. 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。<strong>推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。</strong></li>\n<li><a href=\"http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ\">On the Convergence of Adam and Beyond</a>. ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。主要攻击的是Adam有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但AdaBound作者认为这篇 paper 的<strong>意义十分有限，同时有很大误导性</strong>。\n<ol>\n<li>作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为<strong>这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值</strong>，极端构造下的收敛性，并不意味着什么。</li>\n<li>作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，<strong>training loss 的意义对于一个模型是十分有限的</strong>。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，<strong>Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差</strong>。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 <a href=\"http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/\">Experiments with AMSGrad</a> 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。</li>\n<li>最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。</li>\n<li>相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的performance对模型而言才是更加重要的性质。</li>\n</ol>\n</li>\n<li><a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628\">Improving Generalization Performance by Switching from Adam to SGD</a>. 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。<strong>实验表明训练后期更新步长过小也是原因之一。</strong></li>\n<li>综上而言，<strong>在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向</strong>。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。</li>\n</ul>\n<hr>\n<br>\n<h2 id=\"abstract-摘要\"><a class=\"markdownIt-Anchor\" href=\"#abstract-摘要\"></a> ABSTRACT 摘要</h2>\n<p>已经提出了很多自适应优化方法，例如ADAGRAD，RMSPROP和ADAM，以实现具有对学习率逐元缩放的快速训练过程。尽管盛行，但人们观察到它们有时难以与SGD相比，甚至由于不稳定和极端学习率而未能收敛。最近有人提出了一些算法，如AMSGRAD(2018)，但他们未能比现有方法取得相当大的进步。在我们的论文中，我们证明极端学习率确实可能导致表现不佳。我们提供ADAM和AMSGRAD的新变种，称为分别使用ADABOUND和AMSBOUND，它们采用动态限制学习率实现从自适应方法逐步平稳过渡到SGD，并给出了收敛的理论证明。实验结果表明，新变种可以消除在自适应方法和SGD之间的泛化差距，并在早期保持较高的学习速度同时训练。而且，它们可以显着地改善各自原型，尤其是复杂的深度网络。</p>\n<hr>\n<br>\n<h2 id=\"1介绍\"><a class=\"markdownIt-Anchor\" href=\"#1介绍\"></a> 1.介绍</h2>\n<p>在用于训练深度神经网络的一阶优化算法方面取得了巨大进步。最主要的算法之一是随机梯度下降（SGD），尽管简单，但在许多应用程序中表现良好。然而，SGD的一个缺点是它在所有方向上均匀地调整梯度。这可能会导致当训练数据稀疏时，表现不佳以及训练速度有限。为解决这个问题，最近提出了各种自适应方法来缩放梯度，包括ADAM，ADAGRAD和RMSPROP。特别是ADAM，由于其快速的训练速度，已经成为默认算法。</p>\n<p>然而，这些自适应方法的泛化能力可能比非适应性方法更差。自适应方法通常在训练的初始部分显得更快，但在测试集不佳。实际上，最近在自然语言处理和计算机视觉方面的一些最先进的作品中，优化器大多被选为SGD。其中这些实例SGD确实表现得比自适应方法更好。Reddi（2018）提出了一种名为AMSGRAD的ADAM变体，希望能解决这个问题。作者提供了收敛的理论保证，但仅限于说明其在训练数据方面的更好表现。然而，发现AMSGRAD对测试集数据的泛化能力与ADAM相似，和SGD仍存在相当大的性能差距。</p>\n<p>在本文中，首先对ADAM进行了实证研究，说明两者在训练结束时存在极端（极大和极小）的学习率。结果与2017年Wilson的paper中的“自适应方法泛化性能差可能是源于不稳定和极端的学习率”一致。实际上，2018年AMSGrad的paper中，关键点就是引入非增长学习率，这可能有助于减轻巨大学习率的影响，忽略小的可能影响。我们进一步提供了一个简单凸优化问题的例子，以阐明自适应方法的微小学习率如何导致不收敛。在这样的设置中，RMSPROP和ADAM可证明不会收敛到最优<br>\n解。此外，无论初始步长α是多大，ADAM都无法改变规格下降的情况。</p>\n<p>基于以上分析，我们提出了ADAM和AMSGRAD的新变种，命名为ADABOUND和AMSBOUND，它们不会受到极端学习的负面影响。我们采用学习率的动态界限，其中最低和最高界限分别初始化为零和无穷大，它们都平滑地收敛到一个恒定的最终步长。新变种在开始时可被视为自适应方法训练，随着时间增加，逐渐平稳地转变为SGD。在这个框架中，我们可以享受快速的初始训练过程以及良好的泛化能力。我们为凸面设置中的新变体提供收敛分析。</p>\n<p>最后，转向对计算机视觉和自然语言处理中的流行任务和模型进行实证研究，结果证明训练早期有较高学习速度，同时与几种自适应和非自适应方法相比，保证了强大的泛化性能。而且，他们可以在原型上带来了相当大的改进，特别是在复杂的深层网络上。</p>\n<hr>\n<br>\n<h2 id=\"2符号和前提设定\"><a class=\"markdownIt-Anchor\" href=\"#2符号和前提设定\"></a> 2.符号和前提设定</h2>\n<h3 id=\"符号\"><a class=\"markdownIt-Anchor\" href=\"#符号\"></a> 符号</h3>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\theta\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>：向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：向量第<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">i</span></span></span></span>位</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>θ</mi><mi>k</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\theta ^k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span></span></span></span>：逐元素指数运算</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>θ</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">||\\theta||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span>：L2范数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：迭代后向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{t,i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>：迭代后向量的第<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">i</span></span></span></span>位</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">⟨</mo><mi>v</mi><mo separator=\"true\">,</mo><mi>w</mi><mo stretchy=\"false\">⟩</mo></mrow><annotation encoding=\"application/x-tex\">\\langle v,w\\rangle</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">⟨</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">⟩</span></span></span></span>：向量内积</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>v</mi><mo>⨀</mo><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">v \\bigodot w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">⨀</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>：逐元素相乘</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>v</mi><mi mathvariant=\"normal\">/</mi><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">v/w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>：逐元素相除</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi>v</mi><mo separator=\"true\">,</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">max(v,w)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span></span></span></span>：逐元素取最大</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msubsup><mi>S</mi><mo>+</mo><mi>d</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">S^d_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.154439em;vertical-align:-0.305331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.305331em;\"><span></span></span></span></span></span></span></span></span></span>：所有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d\\times d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>的正定矩阵</li>\n<li>向量<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">a\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>，正定矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">M\\in R^{d\\times d}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mi mathvariant=\"normal\">/</mi><mi>M</mi></mrow><annotation encoding=\"application/x-tex\">a/M</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span></span></span></span>：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>M</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">M^{-1}a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\">a</span></span></span></span></li>\n<li>投影操作<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mo>∏</mo><mrow><mi>F</mi><mo separator=\"true\">,</mo><mi>M</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\prod_{F,M}(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.185818em;vertical-align:-0.43581800000000004em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∏</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17862099999999992em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">F</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">M</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>M</mi><mo>∈</mo><msubsup><mi>S</mi><mo>+</mo><mi>d</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">M\\in S^d_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.154439em;vertical-align:-0.305331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.305331em;\"><span></span></span></span></span></span></span></span></span></span>：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>x</mi><mo>∈</mo><mi>F</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msqrt><mi>M</mi></msqrt><mo stretchy=\"false\">(</mo><mi>x</mi><mo>−</mo><mi>y</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">argmin_{x\\in F}||\\sqrt M(x-y)||</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.176665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">i</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"mrel mtight\">∈</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">F</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9266650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;padding-left:0.833em;\">M</span></span><span style=\"top:-2.886665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.11333499999999996em;\"><span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">y\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>，意为将不在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>中的向量<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>投影为一个与<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>最近且在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>中的向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>a</mi><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mn>1</mn></msub><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mn>2</mn></msub><mi mathvariant=\"normal\">∣</mi><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mi>n</mi></msub><mi mathvariant=\"normal\">∣</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">||a||_\\infty=max(|a_1|,|a_2|,\\cdots ,|a_n|)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">a</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mclose\">)</span></span></span></span>：向量无穷范数</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><mi>m</mi><mi>a</mi><msub><mi>x</mi><mrow><mn>1</mn><mo>≤</mo><mi>i</mi><mo>≤</mo><mi>n</mi></mrow></msub><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi mathvariant=\"normal\">∣</mi></mrow><annotation encoding=\"application/x-tex\">D_\\infty=max_{1\\leq i\\leq n}\\sum^n_{j=1}|a_{ij}|</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24011em;vertical-align:-0.43581800000000004em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">≤</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">≤</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24517899999999998em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.804292em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span></span></span></span>，矩阵无穷范数，行模，行绝对值和的最大值</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi><mo>⊂</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">F\\subset R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">⊂</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>：凸可行集</li>\n<li>F凸集：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">，</mi><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda\\in [0,1]，a,b\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord mathdefault\">a</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>，有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mi>a</mi><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mo stretchy=\"false\">)</mo><mi>b</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda a+(1-\\lambda)b\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mclose\">)</span><span class=\"mord mathdefault\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span></li>\n<li>满足约束条件的点称为可行点，全体可行点组成的集合称为可行集</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">x,y\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>,如果<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>≤</mo><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub></mrow><annotation encoding=\"application/x-tex\">||x-y||_\\infty\\leq D_\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> ，则称<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>限制了直径<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub></mrow><annotation encoding=\"application/x-tex\">D_\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>diag(A)是提取出矩阵A的主对角线元素，得到的是一维的向量，diag（diag（A））是一个对角矩阵</li>\n<li>设A是n阶方阵，如果对任何非零向量X，都有X’A<em>X≥0</em>，其中*X‘’*表示X的转置，就称A为<strong>半正定矩阵</strong>/＞0，正定</li>\n</ul>\n<br>\n<h3 id=\"在线凸优化\"><a class=\"markdownIt-Anchor\" href=\"#在线凸优化\"></a> 在线凸优化</h3>\n<h4 id=\"在线学习\"><a class=\"markdownIt-Anchor\" href=\"#在线学习\"></a> 在线学习</h4>\n<ul>\n<li>机器学习中的一种模型训练方法</li>\n<li>比喻：有一老师和一学生，每天老师让学生回答一个问题，然后老师告诉学生正确答案，学生则比较正确答案来更新自己的知识。就这样学生终成大师（博弈论里的重复游戏）</li>\n<li>认为数据的分布是可以任意的；而寻常算法中，认为数据独立同分布；目的是正确预测数据的类别，并且在每次预测后，该结果用来更新修正预测模型，用于对以后数据进行更好的预测</li>\n<li>主要限制是当前只能看到当前的和过去的数据，因此，对在线学习而言，它追求的是知道所有数据时所能设计的最优策略。同这个最优策略的差异称之为遗憾（regret）：遗憾没能一开始就选对最优策略。我们的希望是，时间一久，数据一多，这个差异就会变得很小。我们追求的是，没有后悔（no-regret）</li>\n<li>如果与统计学习一样对数据做独立同分布假设，那么在线学习里的最优策略就是在得知所有数据的离线学习所能得到最优解。因此在线学习可以看成是一种优化方法：随着对数据的不断访问来逐步逼近这个离线最优解</li>\n<li>过程：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时刻，模型收到样本<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>；然后从策略集中选出一个策略<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，并对样本做出判断<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">w_t(x_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>；收到正确答案<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>。用损失函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>l</mi><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">l(w_t(x_t),y_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>衡量在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时刻做出不正确判断所受损失，简记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">l_t(w_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，故<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi></mrow><annotation encoding=\"application/x-tex\">T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span></span></span></span>轮总损失为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\sum^T_{t=1}l_t(w_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。遗憾值记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>l</mi><mi>t</mi></msub><mi mathvariant=\"normal\">（</mi><msub><mi>w</mi><mi>t</mi></msub><mi mathvariant=\"normal\">）</mi><mo>−</mo><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>w</mi><mo>∈</mo><mi>F</mi></mrow></msub><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></msubsup><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>w</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R_T=\\sum^T_{t=1}l_t（w_t）-min_{w\\in F}\\sum^T_{t=1}l_t(w)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">（</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">）</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2809409999999999em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">i</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mrel mtight\">∈</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">F</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.981231em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mclose\">)</span></span></span></span>，即总损失减去使用最佳策略的损失和。但是存在小概率事件：每次选择的策略恰能很好适应当前样本，最终使遗憾值小于零。故我们关心平均遗憾是不是随着步骤增加而减小，即<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>l</mi><mi>i</mi><msub><mi>m</mi><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow></msub><mfrac><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow><mi>T</mi></mfrac><mo>→</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">lim_{T\\rarr\\infty}\\frac{R(T)}{T}\\rarr0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.355em;vertical-align:-0.345em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">i</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></li>\n</ul>\n<br>\n<h4 id=\"在线凸优化-2\"><a class=\"markdownIt-Anchor\" href=\"#在线凸优化-2\"></a> 在线凸优化</h4>\n<ul>\n<li>挑选<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>的策略集<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>是凸的，且损失函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>l</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">l_t(w_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.01968em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>关于<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>是凸的，则称此问题为在线凸优化</li>\n</ul>\n<br>\n<h4 id=\"在线梯度下降\"><a class=\"markdownIt-Anchor\" href=\"#在线梯度下降\"></a> 在线梯度下降</h4>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时做两步：</li>\n</ul>\n<ol>\n<li>利用当前得到数据对<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">w_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>进行一次梯度下降得到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{t+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span></li>\n<li>若新<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">w_{t+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span>不在策略集中，使用投影公式投影进来</li>\n</ol>\n<ul>\n<li>\n<p>优势：N个数据，每次一个，N步找到最优策略，即总共只计算N个数据</p>\n<p>在本文中，我们假设可行集<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>具有有界直径并且<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∇</mi><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub></mrow><annotation encoding=\"application/x-tex\">||\\nabla f_t(x)||_\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\">∇</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>是对于所有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>T</mi><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">，</mi><mi>x</mi><mo>∈</mo><mi>F</mi></mrow><annotation encoding=\"application/x-tex\">t\\in [T]，x\\in F</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65418em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span></span></span></span>都有界限。我们希望算法的遗憾值很小。我们的目标是设计一种确保<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mo>=</mo><mi>o</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R_T=o(T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">o</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span></span></span></span>的算法，这意味着平均来说，模型的性能收敛到最佳。已经指出，具有平均后悔为0的在线优化算法产生相应的随机优化算法（Cesa-Bianchi等，2002）。因此，跟随Reddi等人（2018），我们同样使用在线梯度下降和随机梯度下降。</p>\n</li>\n</ul>\n<br>\n<h3 id=\"优化方法概述\"><a class=\"markdownIt-Anchor\" href=\"#优化方法概述\"></a> 优化方法概述</h3>\n<p>我们遵循Reddi等人的观点（2018），提供算法1中的通用优化方法框架，封装了许多流行的自适应和非自适应方法。 这对于理解不同优化的属性很有用。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_algorithm1.png\" alt></p>\n<p>注意，因为函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>ϕ</mi><mi>t</mi></msub><mo>:</mo><msup><mi>F</mi><mi>t</mi></msup><mo>→</mo><msup><mi>R</mi><mi>d</mi></msup><mo separator=\"true\">,</mo><mi>ψ</mi><mo>:</mo><msup><mi>F</mi><mi>d</mi></msup><mo>→</mo><msubsup><mi>S</mi><mo>+</mo><mi>d</mi></msubsup></mrow><annotation encoding=\"application/x-tex\">\\phi_t:F^t\\rarr R^d,\\psi:F^d\\rarr S^d_+</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϕ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7935559999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7935559999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.043548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ψ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.154439em;vertical-align:-0.305331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">+</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.305331em;\"><span></span></span></span></span></span></span></span></span></span>还未确定，所以算法仍是抽象的。本文中，我们将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span></span></span></span>称为初始步长，将<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mi mathvariant=\"normal\">/</mi><msqrt><msub><mi>V</mi><mi>t</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">a_t/\\sqrt {V_t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1016650000000001em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.851665em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.811665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18833500000000003em;\"><span></span></span></span></span></span></span></span></span>称为算法的学习率。注意，我们采用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mo>=</mo><mi>a</mi><mi mathvariant=\"normal\">/</mi><msqrt><mi>t</mi></msqrt></mrow><annotation encoding=\"application/x-tex\">a_t=a/\\sqrt t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.14254em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.89254em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"padding-left:0.833em;\">t</span></span><span style=\"top:-2.85254em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14746000000000004em;\"><span></span></span></span></span></span></span></span></span>减小步长。然而这种鲁莽的的衰退步骤通常表现较差，而简单的恒定步长<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>α</mi><mi>t</mi></msub><mo>=</mo><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">α_t =\nα</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.0037em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span></span></span></span>通常在实践中很有效。本文其余部分的理论分析和常量方案的实证研究中，我们将使用递减方案。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_table1.png\" alt></p>\n<p>AdaGrad和RMSProp可看作Adam特例，着重研究Adam。</p>\n<hr>\n<br>\n<h2 id=\"3极端学习率导致的非收敛性\"><a class=\"markdownIt-Anchor\" href=\"#3极端学习率导致的非收敛性\"></a> 3.极端学习率导致的非收敛性</h2>\n<p>在本节中，初步实验和严格的证明，详细阐述了当前已有自适应方法的主要缺陷。如上所述，观察到诸如ADAM的自适应方法表现比SGD差。 Reddi等（2018）提出AMSGRAD来解决这个问题，但最近的工作指出AMSGRAD并没有显示出对ADAM的明显改善（Keskar＆Socher，2017年; Chen等，2018）。作者声称AMSGRAD与ADAM相比具有较小的学习率，作者仅将大的极端学习率视为ADAM性能不佳的原因。然而，小的也可能是个陷阱。因此，我们推测两个极端值都是ADAM的学习率是其泛化能力不足的原因。</p>\n<p>为了证实我们的推测，我们对在CIFAR-10上使用ADAM的ResNet-34网络的几个权重Weight和偏差bias的学习率进行了抽样。具体来说，我们随机选择来自不同层的9个3×3卷积核和最后一个线性层中的偏差bias。通常作为同一层的参数具有相似6的属性，这里我们只展示在训练结束时九个卷积核中的九个权重的学习率和最后一层的bias，内核分别和最后一层的偏差，如图1所示。我们可以发现当模型接近收敛时，学习率有小于0.01的的以及大于1000的大小的。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure1.png\" alt></p>\n<p>图1 采样参数的学习率。每个单元都是学习率的对数。</p>\n<p>上述分析和观察表明在训练过程的最后阶段确实存在过大或过大的学习率太小。 AMSGRAD可能有助于减轻巨大的学习率的影响，但它忽略了过小的学习率。就此而言，我们仍然有以下两个疑惑。首先，微小的学习率真的会损害ADAM的效果吗？第二，学习率高度依赖于初始步长，我们可以使用相对较大的初始步长α来摆脱后期太小的学习率？</p>\n<p>我们表明ADAM和RMSPROP的不良收敛行为可能是由极小的学习率引起的，此外，在某些情况下无论如何初始步长α，ADAM仍然无法找到正确的路径并收敛。</p>\n<p>考虑以下线性函数序列，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>F</mi><mo>=</mo><mo stretchy=\"false\">[</mo><mo>−</mo><mn>2</mn><mo separator=\"true\">,</mo><mn>2</mn><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">，</mi><mi>C</mi><mo>∈</mo><mi>N</mi></mrow><annotation encoding=\"application/x-tex\">F=[-2,2]，C\\in N</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">−</span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span></span></span></span>，满足<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>5</mn><msubsup><mi>β</mi><mn>2</mn><mrow><mi>C</mi><mo>−</mo><mn>2</mn></mrow></msubsup><mo>≤</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mn>4</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">5\\beta^{C-2}_2\\leq(1-\\beta_2)/(4-\\beta_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.14777em;vertical-align:-0.266308em;\"></span><span class=\"mord\">5</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.881462em;\"><span style=\"top:-2.433692em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.1031310000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.266308em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mopen\">(</span><span class=\"mord\">4</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。</p>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;&amp;&#039; at position 115: …$ $x$ $\\leq$ 1 &amp;̲&amp; $t$ mod $C$ =…\">f_t(x) =\n\\begin{cases}\n-100,  &amp; \\text{$x$ &lt; 0} \\\\\n0,     &amp; \\text{$x$ &gt; 0} \\\\\n-x,    &amp; \\text{0 $\\leq$ $x$ $\\leq$ 1 &amp;&amp; $t$ mod $C$ = 1} \\\\\n2x,    &amp; \\text{0 $\\leq$ $x$ $\\leq$ 1 &amp;&amp; $t$ mod $C$ = 2} \\\\\n0,     &amp; \\text{else} \n\\end{cases}\n</p>\n<p>很容易看出任何x&lt;0的点都有最小的遗憾。 假设<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\beta_1=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>，我们表明ADAM收敛于此设置的x≥0的极端非优解。该算法在每C步梯度-1，这使算法向错误的方向移动。然后，在下一步，它观察到梯度2。但是较大的梯度2不能抵消错误方向，因为本步中，学习率将缩小到远小于前一个值。因此随着时间的增加，x变得越来越大。<br>\n我们在下面的结果中形式化这种直觉。</p>\n<p>**定理1.**总会有一个在线凸优化问题，对任何初始步长<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span></span></span></span>，Adam都有非0平均遗憾值。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mi mathvariant=\"normal\">/</mi><mi>T</mi><mo>↛</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">R_T/T\\nrightarrow0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel amsrm\">↛</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> 当 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">T \\rarr \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。</p>\n<p>我们将所有证明都归入附录中。注意，上述示例也适用于恒定步长。另，SGD不会遇到这个问题。初始步长有多种有效选择，其中SGD的平均遗憾为0，换句话说，收敛到最优解。这个问题在后期会更加明显。当算法陷入某些非优点时。在这种情况下，大多数步骤的梯度接近0并且二阶动量的平均值会各种各样，由于指数移动平均的特性。因此，如果出现频率相对较低的“正确”信号（即上例中每C步骤的梯度2）在一些“错误”信号（即示例中的梯度1）之后到来，即使正确的具有更大的梯度绝对值，也可能无法将算法引导到正确的路径。</p>\n<p>人们可能想知道使用大的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">\\beta_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>是否有帮助，因为我们通常在实践中使其接近1。然而，以下结果表明，对于具有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">β1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>的任何恒定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">β_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">β_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，存在ADAM具有非零平均遗憾的示例，而与初始步长α无关。</p>\n<p>**定理2.**对任意<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\beta_1,\\beta_2\\in [0,1), \\beta1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>，都存在一个在线凸优化问题，无论初始步长如何，ADAM都有非0平均遗憾值。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>R</mi><mi>T</mi></msub><mi mathvariant=\"normal\">/</mi><mi>T</mi><mo>↛</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">R_T/T\\nrightarrow0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel amsrm\">↛</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> as <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>T</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">T \\rarr \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。</p>\n<p>**定理3.**对任意<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\beta_1,\\beta_2\\in [0,1), \\beta1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>，都有一个随机凸优化问题，无论初始步长如何，ADAM都无法收敛至最优解。</p>\n<p>Kingma＆Lei Ba（2015）中ADAM的分析依赖于随着时间的推移降低β1，而在这里我们使用常数β1。实际上，由于我们的分析中关键参数是β2而不是β1，因此使用β1的递减方案将我们的示例扩展到案例非常容易。</p>\n<p>如Reddi等人所述（2018），条件<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi><mn>1</mn><mo>&lt;</mo><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\beta1&lt;\\sqrt{\\beta_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.20500000000000007em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.835em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.795em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.20500000000000007em;\"><span></span></span></span></span></span></span></span></span>是良性的并且通常在实践中使用的参数设置中得到满足。在Kingma＆Lei Ba（2015）的收敛证明中也假设了这种情况。 上述结果说明了极端学习率的潜在不良影响，并且算法在不解决该问题的情况下不可能实现良好的泛化能力。</p>\n<br>\n<h2 id=\"4动态限制的adam\"><a class=\"markdownIt-Anchor\" href=\"#4动态限制的adam\"></a> 4.动态限制的ADAM</h2>\n<p>在本节中，我们开发了优化方法的新变体并提供了它们的收敛性分析。我们的目标是制定一种方法，结合自适应方法的好处，即快速的初步进展，以及SGD良好的最终泛化特性。最后，我们想构建一种算法，其在训练早期就像自适应方法一样，最后像SGD一样。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_algorithm2.png\" alt></p>\n<p>受梯度剪辑的启发，这是一种在实践中用于剪切大于阈值的梯度以避免渐变爆炸的流行技术，我们在ADAM中使用剪切学习速率来在算法2中提出ADABOUND。考虑在ADAM中应用以下操作<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>C</mi><mi>l</mi><mi>i</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mi mathvariant=\"normal\">/</mi><msqrt><msub><mi>V</mi><mi>t</mi></msub></msqrt><mo separator=\"true\">,</mo><msub><mi>η</mi><mi>l</mi></msub><mo separator=\"true\">,</mo><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Clip(\\alpha/\\sqrt{V_t},\\eta_l,\\eta_u)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1016650000000001em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">p</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.851665em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.22222em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.811665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18833500000000003em;\"><span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，对学习率逐元素剪切，使输出约束在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>η</mi><mi>l</mi></msub><mo separator=\"true\">,</mo><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[\\eta_l,\\eta_u]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>内。由此得出，具有<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>=</mo><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a=a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>的SGD（M）可以被看作是<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo>=</mo><msub><mi>η</mi><mi>u</mi></msub><mo>=</mo><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">η_l=η_u=α^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>的情况。至于ADAM，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">η_l= 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo>=</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">η_u= \\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。现在我们可以通过以下步骤提供新策略：我们使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub></mrow><annotation encoding=\"application/x-tex\">η_l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">η_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>作为t的函数,而不是常数下限和上限，其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">η_l(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>是一个非递减函数，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">t = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>时值为0，并逐渐收敛到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>；并且<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">η_u(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>是非增加函数，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">t = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>时值为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>，并且也渐近地收敛到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>。在此设置中，ADABOUND在开始时表现得像ADAM一样，因为边界对学习速率的影响非常小，并且随着边界收缩而逐渐转换为SGD（M）。我们证明了ADABOUND的以下关键结果。</p>\n<p><strong>定理4.</strong></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">{</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=\"false\">}</mo><mo separator=\"true\">,</mo><mo stretchy=\"false\">{</mo><msub><mi>v</mi><mi>t</mi></msub><mo stretchy=\"false\">}</mo><mi mathvariant=\"normal\">是</mi><mi mathvariant=\"normal\">由</mi><mi mathvariant=\"normal\">算</mi><mi mathvariant=\"normal\">法</mi><mn>2</mn><mi mathvariant=\"normal\">得</mi><mi mathvariant=\"normal\">出</mi><mi mathvariant=\"normal\">。</mi><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">所</mi><mi mathvariant=\"normal\">有</mi><mi>t</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>T</mi><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">且</mi><msub><mi>β</mi><mn>1</mn></msub><mi mathvariant=\"normal\">/</mi><msqrt><msub><mi>β</mi><mn>2</mn></msub></msqrt><mo>&lt;</mo><mn>1</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">都</mi><mi mathvariant=\"normal\">有</mi><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><msub><mi>β</mi><mn>11</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mrow><mn>1</mn><mi>t</mi></mrow></msub><mo>≤</mo><mi>β</mi><mn>1</mn><mi mathvariant=\"normal\">。</mi><mspace linebreak=\"newline\"></mspace><mi mathvariant=\"normal\">假</mi><mi mathvariant=\"normal\">设</mi><mi mathvariant=\"normal\">当</mi><mi>t</mi><mo>→</mo><mi mathvariant=\"normal\">∞</mi><mi mathvariant=\"normal\">时</mi><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>≥</mo><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>≥</mo><mn>0</mn><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>≤</mo><msub><mi>η</mi><mi>y</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">，</mi><mspace linebreak=\"newline\"></mspace><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>→</mo><msup><mi>a</mi><mo>∗</mo></msup><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>→</mo><msup><mi>a</mi><mo>∗</mo></msup><mi mathvariant=\"normal\">，</mi><msub><mi>L</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">且</mi><msub><mi>R</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>=</mo><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">。</mi><mspace linebreak=\"newline\"></mspace><mi mathvariant=\"normal\">假</mi><mi mathvariant=\"normal\">定</mi><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">所</mi><mi mathvariant=\"normal\">有</mi><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo>∈</mo><mi>F</mi><mi mathvariant=\"normal\">，</mi><mi mathvariant=\"normal\">有</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>x</mi><mo>−</mo><mi>y</mi><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∞</mi></msub><mo>≤</mo><msub><mi>D</mi><mi mathvariant=\"normal\">∞</mi></msub><mi mathvariant=\"normal\">；</mi><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">所</mi><mi mathvariant=\"normal\">有</mi><mi>t</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mi>T</mi><mo stretchy=\"false\">]</mo><mi mathvariant=\"normal\">和</mi><mi>x</mi><mo>∈</mo><mi>F</mi><mi mathvariant=\"normal\">，</mi><mi mathvariant=\"normal\">有</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∇</mi><msub><mi>f</mi><mi>t</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mo>≤</mo><msub><mi>G</mi><mn>2</mn></msub><mi mathvariant=\"normal\">。</mi><mspace linebreak=\"newline\"></mspace><mi mathvariant=\"normal\">对</mi><mi mathvariant=\"normal\">经</mi><mi>A</mi><mi>d</mi><mi>a</mi><mi>B</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>d</mi><mi mathvariant=\"normal\">产</mi><mi mathvariant=\"normal\">生</mi><mi mathvariant=\"normal\">的</mi><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">，</mi><mi mathvariant=\"normal\">在</mi><mi mathvariant=\"normal\">其</mi><mi mathvariant=\"normal\">遗</mi><mi mathvariant=\"normal\">憾</mi><mi mathvariant=\"normal\">值</mi><mi mathvariant=\"normal\">上</mi><mi mathvariant=\"normal\">都</mi><mi mathvariant=\"normal\">有</mi><mi mathvariant=\"normal\">以</mi><mi mathvariant=\"normal\">下</mi><mi mathvariant=\"normal\">界</mi><mi mathvariant=\"normal\">限</mi><mi mathvariant=\"normal\">：</mi></mrow><annotation encoding=\"application/x-tex\">\\{x_t\\},\\{v_t\\}是由算法2得出。对所有t\\in[T]且\\beta_1/\\sqrt{\\beta_2}&lt;1,都有        \\beta_1=\\beta_{11},\\beta_{1t}\\leq\\beta1。\\\\\n假设当t\\rarr \\infty 时，\\eta_l(t+1)\\geq\\eta_l(t)\\geq0，\\eta_u(t+1)\\leq\\eta_y(t)，\\\\ \\eta_l(t)\\rarr a^*，\\eta_u(t)\\rarr a^*，L_{\\infty}=\\eta _l(1)且R_\\infty=\\eta_u(1)。\\\\\n假定对所有x,y\\in F，有||x-y||_\\infty \\leq D_\\infty；对所有t\\in [T]和x\\in F，有||\\nabla f_t(x)||\\leq G_2。\\\\\n对经AdaBound产生的x_t，在其遗憾值上都有以下界限：\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">}</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mopen\">{</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">}</span><span class=\"mord cjk_fallback\">是</span><span class=\"mord cjk_fallback\">由</span><span class=\"mord cjk_fallback\">算</span><span class=\"mord cjk_fallback\">法</span><span class=\"mord\">2</span><span class=\"mord cjk_fallback\">得</span><span class=\"mord cjk_fallback\">出</span><span class=\"mord cjk_fallback\">。</span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.25612499999999994em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">且</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.983875em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.9438750000000002em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.25612499999999994em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord cjk_fallback\">都</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mord cjk_fallback\">。</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">假</span><span class=\"mord cjk_fallback\">设</span><span class=\"mord cjk_fallback\">当</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∞</span><span class=\"mord cjk_fallback\">时</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">，</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">→</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.888696em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.738696em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∞</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">且</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mord cjk_fallback\">。</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7335400000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord cjk_fallback\">假</span><span class=\"mord cjk_fallback\">定</span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">∞</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">；</span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">所</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord mathdefault\">t</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">]</span><span class=\"mord cjk_fallback\">和</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\">∇</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">G</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">。</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord cjk_fallback\">对</span><span class=\"mord cjk_fallback\">经</span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">d</span><span class=\"mord cjk_fallback\">产</span><span class=\"mord cjk_fallback\">生</span><span class=\"mord cjk_fallback\">的</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">其</span><span class=\"mord cjk_fallback\">遗</span><span class=\"mord cjk_fallback\">憾</span><span class=\"mord cjk_fallback\">值</span><span class=\"mord cjk_fallback\">上</span><span class=\"mord cjk_fallback\">都</span><span class=\"mord cjk_fallback\">有</span><span class=\"mord cjk_fallback\">以</span><span class=\"mord cjk_fallback\">下</span><span class=\"mord cjk_fallback\">界</span><span class=\"mord cjk_fallback\">限</span><span class=\"mord cjk_fallback\">：</span></span></span></span></span></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_theorem4.png\" alt></p>\n<p><strong>推论4.1</strong></p>\n<p>假设<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mrow><mn>1</mn><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><msup><mi>λ</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\beta_{1t}=\\beta_1\\lambda^{t-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.008548em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">λ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span>是由定理4得出，则</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_corollary4.1.png\" alt></p>\n<p>很容易看出，ADABOUND的遗憾值上限是<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(\\sqrt T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.176665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9266650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;padding-left:0.833em;\">T</span></span><span style=\"top:-2.886665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.11333499999999996em;\"><span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。与Reddi等人类似（2018），人们可以使用更适度的动量衰减<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>β</mi><mrow><mn>1</mn><mi>t</mi></mrow></msub><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><mi mathvariant=\"normal\">/</mi><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">\\beta_{1t}=\\beta_1/t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathdefault\">t</span></span></span></span>，并且仍然确保遗憾值上限是<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msqrt><mi>T</mi></msqrt><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(\\sqrt T)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.176665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9266650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;padding-left:0.833em;\">T</span></span><span style=\"top:-2.886665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.11333499999999996em;\"><span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>。</p>\n<p>最后进行比较。对于将ADAM转换为SGD的想法，Keskar＆Socher（2017）也有类似的工作。作者提出了一种首先使用ADAM的措施，并在某个特定步骤将算法切换到SGD。与他们的方法相比，我们的方法有两个优点。首先，是否存在区分ADAM和SGD的固定转折点是不确定的。因此，我们使用连续转换过程而不是“硬”开关来解决此问题。其次，他们引入了额外的超参数来决定切换时间，这不是很容易微调。至于我们的方法，引入的灵活部分是两个绑定函数。我们对不同类型的约束函数的影响进行了实证研究。结果放在附录G中，我们发现收敛目标<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>a</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">a^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>和收敛速度对最终结果不是很重要。为了清楚起见，我们将在其余部分使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.1</mn><mo>−</mo><mfrac><mn>0.1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mi mathvariant=\"normal\">，</mi><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.1</mn><mo>+</mo><mfrac><mn>0.1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mi>t</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\eta_l(t)=0.1-\\frac{0.1}{(1-\\beta_2)t+1}，\\eta_u(t)=0.1+\\frac{0.1}{(1-\\beta_2)t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord cjk_fallback\">，</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31731428571428577em;\"><span style=\"top:-2.357em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mord mtight\">.</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>。</p>\n<hr>\n<br>\n<h2 id=\"5实验结果\"><a class=\"markdownIt-Anchor\" href=\"#5实验结果\"></a> 5.实验结果</h2>\n<p>在这一节中，我们将对不同的模型进行实证研究，将新方法与常用的优化方法(包括SGD(M)、ADAGRAD、ADAM和AMSGRAD))进行比较。我们主要关注三个任务：MNIST图像分类任务)、CIFAR-10图像分类任务和Penn Treebank上的语言建模任务。我们之所以选择它们，是因为它们的架构具有广泛的重要性和可再现性。表2详细列出了每个任务的设置。我们使用指定的初始化方法从随机的起点运行每个实验三次。为训练指定了固定的时域数预算，下面将介绍衰减策略。我们选择的设置，实现最低的训练损失在最后。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_table2.png\" alt></p>\n<br>\n<h3 id=\"51-参数设置\"><a class=\"markdownIt-Anchor\" href=\"#51-参数设置\"></a> 5.1 参数设置</h3>\n<br>\n<h3 id=\"52-前馈神经网络\"><a class=\"markdownIt-Anchor\" href=\"#52-前馈神经网络\"></a> 5.2 前馈神经网络</h3>\n<p>针对MNIST数据集上的多类分类问题，我们训练了一个具有隐层的简单全连通神经网络。我们运行了100个epochs，省略了这个实验的衰变方案。图2显示了训练和测试集上每种优化方法的学习曲线。我们发现在训练中，所有算法都能达到接近100%的准确率。在测试部分，SGD的性能略优于ADAM和AMSGRAD的自适应方法。我们提出的ADABOUND和AMSBOUND两种方法显示出轻微的改进，但与它们的原型相比，测试精度仍然有明显的提高。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure2.png\" alt></p>\n<br>\n<h3 id=\"53-卷积神经网络\"><a class=\"markdownIt-Anchor\" href=\"#53-卷积神经网络\"></a> 5.3 卷积神经网络</h3>\n<p>利用DenseNet-121和ResNet-34对CIFAR-10标准数据集进行图像分类。在这个实验中，我们使用200个epoch，在150个epoch后将学习率降低10个。</p>\n<p>DenseNet：我们首先在CIFAR-10上运行DenseNet-121模型，结果如图3所示。我们可以看到，ADAGRAD、ADAM和AMSGRAD等自适应方法在早期训练中表现得比非自适应方法更好。但是到了150轮，当学习速率衰减时，SGDM开始优于那些自适应方法。对于我们的方法ADABOUND和AMSBOUND，它们收敛速度和自适应方法一样快，并且在训练结束时的测试集上达到比SGDM稍高的精度。此外，与原型机相比，其性能得到了显著提高，测试精度提高了约2%。</p>\n<p>ResNet：实验结果如图3所示。正如预期的那样，ResNet-34上的每个算法的总体性能与DenseNet-121上的相似。ADABOUND和AMSBOUND甚至超过SGDM 1%。尽管自适应方法的泛化能力相对较差，但我们提出的方法克服了这一缺点，为其学习速率分配了界限，在CIFAR-10上对DenseNet和ResNet的测试集都获得了几乎最佳的准确率。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure3.1.png\" alt></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure3.2.png\" alt></p>\n<br>\n<h3 id=\"54-递归神经网络\"><a class=\"markdownIt-Anchor\" href=\"#54-递归神经网络\"></a> 5.4 递归神经网络</h3>\n<p>我们发现，在所有模型中，ADAM的初始进展最快，但在性能上停滞不前，不如SGD和我们的方法。与以往在图像分类任务实验中出现的现象不同，ADABOUND和AMSBOUND在训练初期的速度并不快，但曲线比SGD平滑。</p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure4.1.png\" alt></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure4.2.png\" alt></p>\n<p>对比L1、L2和L3，我们可以很容易地发现改善程度的显著差异。在最简单的模型L1中，我们的方法比ADAM的方法略好1.1%，而在最复杂的模型L3中，我们的方法在复杂的方面明显优于2.8%。为模型的复杂性与改进程度之间的关系提供了依据。</p>\n<br>\n<h3 id=\"55-结果分析\"><a class=\"markdownIt-Anchor\" href=\"#55-结果分析\"></a> 5.5 结果分析</h3>\n<p>为了研究我们提出的算法的有效性，我们从计算机视觉和自然语言处理中选择流行的任务。根据上面显示的结果，不难发现ADAM和AMSGRAD的表现通常是相似的，而AMSGRAD在大多数情况下并没有太大的改善。另一方面，它们的变体ADABOUND和AMSBOUND与SGD相比具有较快的收敛速度，同时在训练结束时的测试精度也大大超过了两种原始方法。这一现象正好印证了我们在第3节中提到的观点，学习速率的大小都会影响收敛。<br>\n此外，我们还对不同复杂度的模型进行了实验，包括一个per- ceptron模型、两个深度卷积神经网络模型和一个递归神经网络模型。MNIST上使用的感知器是最简单的，我们的方法比其他方法稍好一些。DenseNet和ResNet的测试精度明显提高。我们把这种不同归因于模型的复杂性。具体来说，对于深度CNN模型，卷积层和全连通层在任务中扮演不同的角色。此外，不同的卷积层可能负责不同的角色(Lee et al.2009)，这可能导致参数梯度的明显变化。换句话说，极端的学习速率(巨大或微小)可能在ResNet等复杂模型中出现得更频繁。由于我们的算法是为了避免这些问题而提出的，因此可以直观地解释在复杂体系结构中性能的提高。LSTM在语言建模任务上的层次越多，改进程度越高，也与上述分析一致。</p>\n<br>\n<h2 id=\"6-限制函数\"><a class=\"markdownIt-Anchor\" href=\"#6-限制函数\"></a> 6. 限制函数</h2>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy=\"false\">)</mo><mi>t</mi><mo>+</mo><mn>1</mn></mrow></mfrac><mo stretchy=\"false\">)</mo><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\eta_l (t)=(1-\\frac{1}{(1-\\beta)t+1})\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mfrac><mn>1</mn><mrow><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><mi>β</mi><mo stretchy=\"false\">)</mo><mi>t</mi></mrow></mfrac><mo stretchy=\"false\">)</mo><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\eta_u(t)=(1+\\frac{1}{(1-\\beta)t})\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.365108em;vertical-align:-0.52em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"mclose mtight\">)</span><span class=\"mord mathdefault mtight\">t</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.52em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>：影响算法从自适应变为SGD的转换速度</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>：转换目标，反映最终SGD的步长</li>\n</ul>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure5.png\" alt></p>\n<ul>\n<li>图5，定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>变化<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>，反映出对于特定的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>，不同的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>的性能几乎相同。表明限制函数的收敛速度在一定程度上不影响最终结果。并且在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>β</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[\\beta_1,\\beta_2]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>内的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding=\"application/x-tex\">\\beta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span></span></span>通常效果更佳。</li>\n</ul>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure6.png\" alt></p>\n<ul>\n<li>图6，不同<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>对SGD和AdaBound的影响。结果表明SGDM对超参数非常敏感。SGDM步长的最佳值为0.1，且与其他设置相比性能差距很大。相比之下，ADABOUND针对不同的最终步长具有稳定的性能，说明它对收敛目标不敏感。</li>\n</ul>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure7.1.png\" alt></p>\n<p><img src=\"/2020/06/18/AdaBound/AdaBound_figure7.2.png\" alt=\"AdaBound_figure7.2\"></p>\n<ul>\n<li>图7，进一步直接比较SGDM和ADABOUND与每个α（或α*）之间的性能。<br>\n结果如图7所示。我们可以看到，ADABOUND在所有步骤中都优于SGDM<br>\n大小。 由于绑定函数的形式对ADABOUND的性能影响很小，因此它是<br>\n即使没有仔细调整超参数，也可能击败SGDM。</li>\n<li>ADABOUND对其超参数不敏感。而且，它即使没有仔细微调，也能获得与SGDM更高或相似的性能。</li>\n</ul>"},{"title":"Android总结1","date":"2020-05-15T12:36:25.000Z","mathjax":true,"_content":"\n\n\nAndroid开发App踩坑记录\n\n<!--more-->\n\n<!-- toc -->\n\n[toc]\n\n<br/>\n\n## 音频\n\n### 录音\n\n```java\n// 录音部分，以tag的01标记是否正在录音\nif (audio.getTag().toString().equals(\"0\")) {\n    // 开始录音\n    audio.setImageResource(R.mipmap.stop);\n    audio.setTag(\"1\");\n    time = (String) DateFormat.format(\"yyyyMMdd_HHmmss\", Calendar.getInstance(Locale.CHINA));\n\n    String dir_path = Note.this.getFilesDir().getPath() + \"/recordings/\";\n    Log.d(TAG, \"onClick: dir: \" + dir_path);\n    File dir = new File(dir_path);\n    if(!dir.exists()){\n        dir.mkdirs();\n    }\n\n    String file_name = dir_path + \"/\" + time + \".aac\";\n    recordAudioFile = new File(file_name);\n    try {\n        if (!recordAudioFile.createNewFile()) {\n            Log.d(TAG, \"onClick: file create failed.\");\n        } else {\n            Log.d(TAG, \"onClick: file create done.\");\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n\n    // recordAudioFile = File.createTempFile(file_name,\".aac\");\n    // recordAudioFile = new File(file_name, \".aac\");\n    // 录音设置\n    mediaRecorder = new MediaRecorder();\n    mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);\n    mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT);\n    mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC_ELD);\n    mediaRecorder.setOutputFile(recordAudioFile.getAbsolutePath());\n    // /data/user/0/com.example.curriculum/cache/\n    try {\n        mediaRecorder.prepare();\n    } catch (IOException e) {\n        Log.d(TAG, \"onClick: prepare failed.\");\n    }\n    mediaRecorder.start();\n\n} else {\n    // 停止录音\n    audio.setImageResource(R.mipmap.audio);\n    audio.setTag(\"0\");\n\n    if (mediaRecorder != null){\n        Log.d(TAG, \"onClick: record stop: \" + recordAudioFile.getPath());\n        mediaRecorder.stop();\n        mediaRecorder.release();\n        mediaRecorder = null;\n        if (getCurrentFocus() != null) {\n            // 当前项下插入一个singlerecord\n            SingleNoteLayout child = (SingleNoteLayout) getCurrentFocus().getParent().getParent();\n            create_record(linearLayout.indexOfChild(child), recordAudioFile.getAbsolutePath());\n        } else {\n            // 若无焦点，添加至末尾\n            create_record(linearLayout.getChildCount()-1, recordAudioFile.getAbsolutePath());\n        }\n\n    }\n}\n```\n\n### 播音：资源文件\n\n```java\n// 播放器需设置为类成员，以保证不会回收，否则播放可能会中断\nprivate MediaPlayer mediaPlayer;\n\n// MediaPlayer.create方法会自动进行设置+prepare\nmediaPlayer = MediaPlayer.create(this, resid);\nmediaPlayer.start();\t\n```\n\n### 播音：本地文件\n\n```java\nprivate MediaPlayer mediaPlayer;\n\n// new MediaPlayer()的方法不会自动设置及prepare\nmediaPlayer = new MediaPlayer();\nmediaPlayer.setDataSource(path);\nmediaPlayer.prepare();\t\nmediaPlayer.setOnCompletionListener(new MediaPlayer.OnCompletionListener() {\n    @Override\n    public void onCompletion(MediaPlayer mp) {\n        mp.stop();\n        mp.release();\n        mp = null;\n        Log.d(TAG, \"play: complete\");\n    }\n});\nmediaPlayer.start();\n} catch (Exception e) {\n    e.printStackTrace();\n    Log.d(TAG, \"play: file_path is wrong.\");\n}\n// 最后勿加stop release等\n```\n\n<br/>\n\n## LinearLayout的动态增删控件\n\n增：addView时需要index参数，getChildCount、getChildAt、indexOfChild是很常用的方法。\n\n删：removeView、removeViewAt、removeViewAll\n\n<br/>\n\n## 控件嵌套的parent\n\n控件嵌套，同时只能点击到某个子控件，要通过子控件获取父级控件甚至更高级控件，可以使用onClick的参数view，一路getParent获取，同时使用getClass判断类型。多层嵌套时可能要使用多次getParent。\n\n<br/>\n\n## 权限框架\n\neasypermissions\n\n[参考博客](www.jianshu.com/p/41b093d213fb)\n\n<br/>\n\n## ImageView 上下空白区域\n\n图片像素大于屏幕像素时，显示有问题。尝试以下设置：android:adjustViewBounds=\"true\" 。\n\nGlide注入图片，与androidx/android10可能兼容性较差，出现了奇怪错误。\n\n<br/>\n\n## createNewFile()\n\n要在手动建立的文件夹下，才可create\n\n```java\n// 建立文件夹\nString dir_path = Note.this.getFilesDir().getPath() + \"/new_dir/\";\nLog.d(TAG, \"onClick: dir: \" + dir_path);\nFile dir = new File(dir_path);\nif(!dir.exists()){\n    dir.mkdirs();\n}\n// 在该文件夹下建文件\nString filename = dir_path + \"/hi.txt\";\nFile des = new File(filename);\ntry {\n    if (!des.createNewFile()) {\n        Log.d(TAG, \"onClick: file already exists\");\n    } else {\n        Log.d(TAG, \"onClick: test file create done.\");\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n```\n\n<br/>\n\n## 数据库升级\n\n```java\ndbHelper = new MyDBHelper(this, \"Course.db\", null, 2);\ndb = dbHelper.getWritableDatabase();\n```\n\n首行参数指定新的version_code，DBHelper.class的onUpgrade中，针对不同版本的升级做出判断与操作。\n\n<br/>\n\n## Uri.fromFile(new File(path))\n\n报错：java.io.FileNotFoundException: open failed: EACCES (Permission denied)\n\n解决：`android:requestLegacyExternalStorage=\"true\"` application\n\n<br/>\n\n## imageView.setImageURI(uri)\n\n从库中读取string，setImageURI(Uri.pairse(string))会报错：\n\njava.lang.SecurityException: Permission Denial: opening provider ... that is not exported from UID 10096\n\n无合适解决方法，改用setImageURI(Uri.fromFile(new File(path)))。\n\n但是该方法获得的Uri，调用图库查看图片时又会引起FileUriExposedException异常 :sweat:\n\n<br/>\n\n## intent向前传递的顺序问题\n\n子活动返回result，即setResult()是在被finish()之前。\n\n子活动setResult()之后，主活动的onActivityResult()就会启动。这就会导致**onActivityResult()先于子活动的onDestroy()**。\n\n同时，onPause()， onStop()， onDestroy()中调用setResult()也是不安全的，这些步骤可能会在finish()之后。\n\n<br/>\n\n## 录音设置\n\n编码器、输出文件、文件后缀之间的协调：最终采用文件指定后缀、输出文件Default、编码器与文件后缀匹配\n\n\n\n![](Android总结1/zelda.png)","source":"_posts/Android总结1.md","raw":"---\ntitle: Android总结1\ndate: 2020-05-15 20:36:25\nmathjax: true\ntags: Android\n---\n\n\n\nAndroid开发App踩坑记录\n\n<!--more-->\n\n<!-- toc -->\n\n[toc]\n\n<br/>\n\n## 音频\n\n### 录音\n\n```java\n// 录音部分，以tag的01标记是否正在录音\nif (audio.getTag().toString().equals(\"0\")) {\n    // 开始录音\n    audio.setImageResource(R.mipmap.stop);\n    audio.setTag(\"1\");\n    time = (String) DateFormat.format(\"yyyyMMdd_HHmmss\", Calendar.getInstance(Locale.CHINA));\n\n    String dir_path = Note.this.getFilesDir().getPath() + \"/recordings/\";\n    Log.d(TAG, \"onClick: dir: \" + dir_path);\n    File dir = new File(dir_path);\n    if(!dir.exists()){\n        dir.mkdirs();\n    }\n\n    String file_name = dir_path + \"/\" + time + \".aac\";\n    recordAudioFile = new File(file_name);\n    try {\n        if (!recordAudioFile.createNewFile()) {\n            Log.d(TAG, \"onClick: file create failed.\");\n        } else {\n            Log.d(TAG, \"onClick: file create done.\");\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n\n    // recordAudioFile = File.createTempFile(file_name,\".aac\");\n    // recordAudioFile = new File(file_name, \".aac\");\n    // 录音设置\n    mediaRecorder = new MediaRecorder();\n    mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);\n    mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT);\n    mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC_ELD);\n    mediaRecorder.setOutputFile(recordAudioFile.getAbsolutePath());\n    // /data/user/0/com.example.curriculum/cache/\n    try {\n        mediaRecorder.prepare();\n    } catch (IOException e) {\n        Log.d(TAG, \"onClick: prepare failed.\");\n    }\n    mediaRecorder.start();\n\n} else {\n    // 停止录音\n    audio.setImageResource(R.mipmap.audio);\n    audio.setTag(\"0\");\n\n    if (mediaRecorder != null){\n        Log.d(TAG, \"onClick: record stop: \" + recordAudioFile.getPath());\n        mediaRecorder.stop();\n        mediaRecorder.release();\n        mediaRecorder = null;\n        if (getCurrentFocus() != null) {\n            // 当前项下插入一个singlerecord\n            SingleNoteLayout child = (SingleNoteLayout) getCurrentFocus().getParent().getParent();\n            create_record(linearLayout.indexOfChild(child), recordAudioFile.getAbsolutePath());\n        } else {\n            // 若无焦点，添加至末尾\n            create_record(linearLayout.getChildCount()-1, recordAudioFile.getAbsolutePath());\n        }\n\n    }\n}\n```\n\n### 播音：资源文件\n\n```java\n// 播放器需设置为类成员，以保证不会回收，否则播放可能会中断\nprivate MediaPlayer mediaPlayer;\n\n// MediaPlayer.create方法会自动进行设置+prepare\nmediaPlayer = MediaPlayer.create(this, resid);\nmediaPlayer.start();\t\n```\n\n### 播音：本地文件\n\n```java\nprivate MediaPlayer mediaPlayer;\n\n// new MediaPlayer()的方法不会自动设置及prepare\nmediaPlayer = new MediaPlayer();\nmediaPlayer.setDataSource(path);\nmediaPlayer.prepare();\t\nmediaPlayer.setOnCompletionListener(new MediaPlayer.OnCompletionListener() {\n    @Override\n    public void onCompletion(MediaPlayer mp) {\n        mp.stop();\n        mp.release();\n        mp = null;\n        Log.d(TAG, \"play: complete\");\n    }\n});\nmediaPlayer.start();\n} catch (Exception e) {\n    e.printStackTrace();\n    Log.d(TAG, \"play: file_path is wrong.\");\n}\n// 最后勿加stop release等\n```\n\n<br/>\n\n## LinearLayout的动态增删控件\n\n增：addView时需要index参数，getChildCount、getChildAt、indexOfChild是很常用的方法。\n\n删：removeView、removeViewAt、removeViewAll\n\n<br/>\n\n## 控件嵌套的parent\n\n控件嵌套，同时只能点击到某个子控件，要通过子控件获取父级控件甚至更高级控件，可以使用onClick的参数view，一路getParent获取，同时使用getClass判断类型。多层嵌套时可能要使用多次getParent。\n\n<br/>\n\n## 权限框架\n\neasypermissions\n\n[参考博客](www.jianshu.com/p/41b093d213fb)\n\n<br/>\n\n## ImageView 上下空白区域\n\n图片像素大于屏幕像素时，显示有问题。尝试以下设置：android:adjustViewBounds=\"true\" 。\n\nGlide注入图片，与androidx/android10可能兼容性较差，出现了奇怪错误。\n\n<br/>\n\n## createNewFile()\n\n要在手动建立的文件夹下，才可create\n\n```java\n// 建立文件夹\nString dir_path = Note.this.getFilesDir().getPath() + \"/new_dir/\";\nLog.d(TAG, \"onClick: dir: \" + dir_path);\nFile dir = new File(dir_path);\nif(!dir.exists()){\n    dir.mkdirs();\n}\n// 在该文件夹下建文件\nString filename = dir_path + \"/hi.txt\";\nFile des = new File(filename);\ntry {\n    if (!des.createNewFile()) {\n        Log.d(TAG, \"onClick: file already exists\");\n    } else {\n        Log.d(TAG, \"onClick: test file create done.\");\n    }\n} catch (IOException e) {\n    e.printStackTrace();\n}\n```\n\n<br/>\n\n## 数据库升级\n\n```java\ndbHelper = new MyDBHelper(this, \"Course.db\", null, 2);\ndb = dbHelper.getWritableDatabase();\n```\n\n首行参数指定新的version_code，DBHelper.class的onUpgrade中，针对不同版本的升级做出判断与操作。\n\n<br/>\n\n## Uri.fromFile(new File(path))\n\n报错：java.io.FileNotFoundException: open failed: EACCES (Permission denied)\n\n解决：`android:requestLegacyExternalStorage=\"true\"` application\n\n<br/>\n\n## imageView.setImageURI(uri)\n\n从库中读取string，setImageURI(Uri.pairse(string))会报错：\n\njava.lang.SecurityException: Permission Denial: opening provider ... that is not exported from UID 10096\n\n无合适解决方法，改用setImageURI(Uri.fromFile(new File(path)))。\n\n但是该方法获得的Uri，调用图库查看图片时又会引起FileUriExposedException异常 :sweat:\n\n<br/>\n\n## intent向前传递的顺序问题\n\n子活动返回result，即setResult()是在被finish()之前。\n\n子活动setResult()之后，主活动的onActivityResult()就会启动。这就会导致**onActivityResult()先于子活动的onDestroy()**。\n\n同时，onPause()， onStop()， onDestroy()中调用setResult()也是不安全的，这些步骤可能会在finish()之后。\n\n<br/>\n\n## 录音设置\n\n编码器、输出文件、文件后缀之间的协调：最终采用文件指定后缀、输出文件Default、编码器与文件后缀匹配\n\n\n\n![](Android总结1/zelda.png)","slug":"Android总结1","published":1,"updated":"2020-07-14T14:47:35.775Z","_id":"ckc4xbevh0004i0qv1xegcufu","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Android开发App踩坑记录</p>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#%E9%9F%B3%E9%A2%91\">音频</a>\n<ul>\n<li><a href=\"#%E5%BD%95%E9%9F%B3\">录音</a></li>\n<li><a href=\"#%E6%92%AD%E9%9F%B3%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6\">播音：资源文件</a></li>\n<li><a href=\"#%E6%92%AD%E9%9F%B3%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6\">播音：本地文件</a></li>\n</ul>\n</li>\n<li><a href=\"#linearlayout%E7%9A%84%E5%8A%A8%E6%80%81%E5%A2%9E%E5%88%A0%E6%8E%A7%E4%BB%B6\">LinearLayout的动态增删控件</a></li>\n<li><a href=\"#%E6%8E%A7%E4%BB%B6%E5%B5%8C%E5%A5%97%E7%9A%84parent\">控件嵌套的parent</a></li>\n<li><a href=\"#%E6%9D%83%E9%99%90%E6%A1%86%E6%9E%B6\">权限框架</a></li>\n<li><a href=\"#imageview-%E4%B8%8A%E4%B8%8B%E7%A9%BA%E7%99%BD%E5%8C%BA%E5%9F%9F\">ImageView 上下空白区域</a></li>\n<li><a href=\"#createnewfile\">createNewFile()</a></li>\n<li><a href=\"#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%87%E7%BA%A7\">数据库升级</a></li>\n<li><a href=\"#urifromfilenew-filepath\">Uri.fromFile(new File(path))</a></li>\n<li><a href=\"#imageviewsetimageuriuri\">imageView.setImageURI(uri)</a></li>\n<li><a href=\"#intent%E5%90%91%E5%89%8D%E4%BC%A0%E9%80%92%E7%9A%84%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98\">intent向前传递的顺序问题</a></li>\n<li><a href=\"#%E5%BD%95%E9%9F%B3%E8%AE%BE%E7%BD%AE\">录音设置</a></li>\n</ul>\n<!-- tocstop -->\n<p>[toc]</p>\n<br>\n<h2><span id=\"音频\"> 音频</span></h2>\n<h3><span id=\"录音\"> 录音</span></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 录音部分，以tag的01标记是否正在录音</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (audio.getTag().toString().equals(<span class=\"string\">\"0\"</span>)) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 开始录音</span></span><br><span class=\"line\">    audio.setImageResource(R.mipmap.stop);</span><br><span class=\"line\">    audio.setTag(<span class=\"string\">\"1\"</span>);</span><br><span class=\"line\">    time = (String) DateFormat.format(<span class=\"string\">\"yyyyMMdd_HHmmss\"</span>, Calendar.getInstance(Locale.CHINA));</span><br><span class=\"line\"></span><br><span class=\"line\">    String dir_path = Note.<span class=\"keyword\">this</span>.getFilesDir().getPath() + <span class=\"string\">\"/recordings/\"</span>;</span><br><span class=\"line\">    Log.d(TAG, <span class=\"string\">\"onClick: dir: \"</span> + dir_path);</span><br><span class=\"line\">    File dir = <span class=\"keyword\">new</span> File(dir_path);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!dir.exists())&#123;</span><br><span class=\"line\">        dir.mkdirs();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    String file_name = dir_path + <span class=\"string\">\"/\"</span> + time + <span class=\"string\">\".aac\"</span>;</span><br><span class=\"line\">    recordAudioFile = <span class=\"keyword\">new</span> File(file_name);</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!recordAudioFile.createNewFile()) &#123;</span><br><span class=\"line\">            Log.d(TAG, <span class=\"string\">\"onClick: file create failed.\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            Log.d(TAG, <span class=\"string\">\"onClick: file create done.\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// recordAudioFile = File.createTempFile(file_name,\".aac\");</span></span><br><span class=\"line\">    <span class=\"comment\">// recordAudioFile = new File(file_name, \".aac\");</span></span><br><span class=\"line\">    <span class=\"comment\">// 录音设置</span></span><br><span class=\"line\">    mediaRecorder = <span class=\"keyword\">new</span> MediaRecorder();</span><br><span class=\"line\">    mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);</span><br><span class=\"line\">    mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT);</span><br><span class=\"line\">    mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC_ELD);</span><br><span class=\"line\">    mediaRecorder.setOutputFile(recordAudioFile.getAbsolutePath());</span><br><span class=\"line\">    <span class=\"comment\">// /data/user/0/com.example.curriculum/cache/</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        mediaRecorder.prepare();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: prepare failed.\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    mediaRecorder.start();</span><br><span class=\"line\"></span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 停止录音</span></span><br><span class=\"line\">    audio.setImageResource(R.mipmap.audio);</span><br><span class=\"line\">    audio.setTag(<span class=\"string\">\"0\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (mediaRecorder != <span class=\"keyword\">null</span>)&#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: record stop: \"</span> + recordAudioFile.getPath());</span><br><span class=\"line\">        mediaRecorder.stop();</span><br><span class=\"line\">        mediaRecorder.release();</span><br><span class=\"line\">        mediaRecorder = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (getCurrentFocus() != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 当前项下插入一个singlerecord</span></span><br><span class=\"line\">            SingleNoteLayout child = (SingleNoteLayout) getCurrentFocus().getParent().getParent();</span><br><span class=\"line\">            create_record(linearLayout.indexOfChild(child), recordAudioFile.getAbsolutePath());</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 若无焦点，添加至末尾</span></span><br><span class=\"line\">            create_record(linearLayout.getChildCount()-<span class=\"number\">1</span>, recordAudioFile.getAbsolutePath());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3><span id=\"播音资源文件\"> 播音：资源文件</span></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 播放器需设置为类成员，以保证不会回收，否则播放可能会中断</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> MediaPlayer mediaPlayer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// MediaPlayer.create方法会自动进行设置+prepare</span></span><br><span class=\"line\">mediaPlayer = MediaPlayer.create(<span class=\"keyword\">this</span>, resid);</span><br><span class=\"line\">mediaPlayer.start();</span><br></pre></td></tr></table></figure>\n<h3><span id=\"播音本地文件\"> 播音：本地文件</span></h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> MediaPlayer mediaPlayer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// new MediaPlayer()的方法不会自动设置及prepare</span></span><br><span class=\"line\">mediaPlayer = <span class=\"keyword\">new</span> MediaPlayer();</span><br><span class=\"line\">mediaPlayer.setDataSource(path);</span><br><span class=\"line\">mediaPlayer.prepare();\t</span><br><span class=\"line\">mediaPlayer.setOnCompletionListener(<span class=\"keyword\">new</span> MediaPlayer.OnCompletionListener() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onCompletion</span><span class=\"params\">(MediaPlayer mp)</span> </span>&#123;</span><br><span class=\"line\">        mp.stop();</span><br><span class=\"line\">        mp.release();</span><br><span class=\"line\">        mp = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"play: complete\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">mediaPlayer.start();</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">    Log.d(TAG, <span class=\"string\">\"play: file_path is wrong.\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 最后勿加stop release等</span></span><br></pre></td></tr></table></figure>\n<br>\n<h2><span id=\"linearlayout的动态增删控件\"> LinearLayout的动态增删控件</span></h2>\n<p>增：addView时需要index参数，getChildCount、getChildAt、indexOfChild是很常用的方法。</p>\n<p>删：removeView、removeViewAt、removeViewAll</p>\n<br>\n<h2><span id=\"控件嵌套的parent\"> 控件嵌套的parent</span></h2>\n<p>控件嵌套，同时只能点击到某个子控件，要通过子控件获取父级控件甚至更高级控件，可以使用onClick的参数view，一路getParent获取，同时使用getClass判断类型。多层嵌套时可能要使用多次getParent。</p>\n<br>\n<h2><span id=\"权限框架\"> 权限框架</span></h2>\n<p>easypermissions</p>\n<p><a href=\"www.jianshu.com/p/41b093d213fb\">参考博客</a></p>\n<br>\n<h2><span id=\"imageview-上下空白区域\"> ImageView 上下空白区域</span></h2>\n<p>图片像素大于屏幕像素时，显示有问题。尝试以下设置：android:adjustViewBounds=“true” 。</p>\n<p>Glide注入图片，与androidx/android10可能兼容性较差，出现了奇怪错误。</p>\n<br>\n<h2><span id=\"createnewfile\"> createNewFile()</span></h2>\n<p>要在手动建立的文件夹下，才可create</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 建立文件夹</span></span><br><span class=\"line\">String dir_path = Note.<span class=\"keyword\">this</span>.getFilesDir().getPath() + <span class=\"string\">\"/new_dir/\"</span>;</span><br><span class=\"line\">Log.d(TAG, <span class=\"string\">\"onClick: dir: \"</span> + dir_path);</span><br><span class=\"line\">File dir = <span class=\"keyword\">new</span> File(dir_path);</span><br><span class=\"line\"><span class=\"keyword\">if</span>(!dir.exists())&#123;</span><br><span class=\"line\">    dir.mkdirs();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 在该文件夹下建文件</span></span><br><span class=\"line\">String filename = dir_path + <span class=\"string\">\"/hi.txt\"</span>;</span><br><span class=\"line\">File des = <span class=\"keyword\">new</span> File(filename);</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!des.createNewFile()) &#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: file already exists\"</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: test file create done.\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<br>\n<h2><span id=\"数据库升级\"> 数据库升级</span></h2>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dbHelper = <span class=\"keyword\">new</span> MyDBHelper(<span class=\"keyword\">this</span>, <span class=\"string\">\"Course.db\"</span>, <span class=\"keyword\">null</span>, <span class=\"number\">2</span>);</span><br><span class=\"line\">db = dbHelper.getWritableDatabase();</span><br></pre></td></tr></table></figure>\n<p>首行参数指定新的version_code，DBHelper.class的onUpgrade中，针对不同版本的升级做出判断与操作。</p>\n<br>\n<h2><span id=\"urifromfilenew-filepath\"> Uri.fromFile(new File(path))</span></h2>\n<p>报错：java.io.FileNotFoundException: open failed: EACCES (Permission denied)</p>\n<p>解决：<code>android:requestLegacyExternalStorage=&quot;true&quot;</code> application</p>\n<br>\n<h2><span id=\"imageviewsetimageuriuri\"> imageView.setImageURI(uri)</span></h2>\n<p>从库中读取string，setImageURI(Uri.pairse(string))会报错：</p>\n<p>java.lang.SecurityException: Permission Denial: opening provider … that is not exported from UID 10096</p>\n<p>无合适解决方法，改用setImageURI(Uri.fromFile(new File(path)))。</p>\n<p>但是该方法获得的Uri，调用图库查看图片时又会引起FileUriExposedException异常 😓</p>\n<br>\n<h2><span id=\"intent向前传递的顺序问题\"> intent向前传递的顺序问题</span></h2>\n<p>子活动返回result，即setResult()是在被finish()之前。</p>\n<p>子活动setResult()之后，主活动的onActivityResult()就会启动。这就会导致<strong>onActivityResult()先于子活动的onDestroy()</strong>。</p>\n<p>同时，onPause()， onStop()， onDestroy()中调用setResult()也是不安全的，这些步骤可能会在finish()之后。</p>\n<br>\n<h2><span id=\"录音设置\"> 录音设置</span></h2>\n<p>编码器、输出文件、文件后缀之间的协调：最终采用文件指定后缀、输出文件Default、编码器与文件后缀匹配</p>\n<p><img src=\"/2020/05/15/Android%E6%80%BB%E7%BB%931/zelda.png\" alt></p>\n","site":{"data":{}},"excerpt":"<p>Android开发App踩坑记录</p>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#%E9%9F%B3%E9%A2%91\">音频</a>\n<ul>\n<li><a href=\"#%E5%BD%95%E9%9F%B3\">录音</a></li>\n<li><a href=\"#%E6%92%AD%E9%9F%B3%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6\">播音：资源文件</a></li>\n<li><a href=\"#%E6%92%AD%E9%9F%B3%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6\">播音：本地文件</a></li>\n</ul>\n</li>\n<li><a href=\"#linearlayout%E7%9A%84%E5%8A%A8%E6%80%81%E5%A2%9E%E5%88%A0%E6%8E%A7%E4%BB%B6\">LinearLayout的动态增删控件</a></li>\n<li><a href=\"#%E6%8E%A7%E4%BB%B6%E5%B5%8C%E5%A5%97%E7%9A%84parent\">控件嵌套的parent</a></li>\n<li><a href=\"#%E6%9D%83%E9%99%90%E6%A1%86%E6%9E%B6\">权限框架</a></li>\n<li><a href=\"#imageview-%E4%B8%8A%E4%B8%8B%E7%A9%BA%E7%99%BD%E5%8C%BA%E5%9F%9F\">ImageView 上下空白区域</a></li>\n<li><a href=\"#createnewfile\">createNewFile()</a></li>\n<li><a href=\"#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8D%87%E7%BA%A7\">数据库升级</a></li>\n<li><a href=\"#urifromfilenew-filepath\">Uri.fromFile(new File(path))</a></li>\n<li><a href=\"#imageviewsetimageuriuri\">imageView.setImageURI(uri)</a></li>\n<li><a href=\"#intent%E5%90%91%E5%89%8D%E4%BC%A0%E9%80%92%E7%9A%84%E9%A1%BA%E5%BA%8F%E9%97%AE%E9%A2%98\">intent向前传递的顺序问题</a></li>\n<li><a href=\"#%E5%BD%95%E9%9F%B3%E8%AE%BE%E7%BD%AE\">录音设置</a></li>\n</ul>\n<!-- tocstop -->\n<p>[toc]</p>\n<br>\n<h2 id=\"音频\"><a class=\"markdownIt-Anchor\" href=\"#音频\"></a> 音频</h2>\n<h3 id=\"录音\"><a class=\"markdownIt-Anchor\" href=\"#录音\"></a> 录音</h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 录音部分，以tag的01标记是否正在录音</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> (audio.getTag().toString().equals(<span class=\"string\">\"0\"</span>)) &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 开始录音</span></span><br><span class=\"line\">    audio.setImageResource(R.mipmap.stop);</span><br><span class=\"line\">    audio.setTag(<span class=\"string\">\"1\"</span>);</span><br><span class=\"line\">    time = (String) DateFormat.format(<span class=\"string\">\"yyyyMMdd_HHmmss\"</span>, Calendar.getInstance(Locale.CHINA));</span><br><span class=\"line\"></span><br><span class=\"line\">    String dir_path = Note.<span class=\"keyword\">this</span>.getFilesDir().getPath() + <span class=\"string\">\"/recordings/\"</span>;</span><br><span class=\"line\">    Log.d(TAG, <span class=\"string\">\"onClick: dir: \"</span> + dir_path);</span><br><span class=\"line\">    File dir = <span class=\"keyword\">new</span> File(dir_path);</span><br><span class=\"line\">    <span class=\"keyword\">if</span>(!dir.exists())&#123;</span><br><span class=\"line\">        dir.mkdirs();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    String file_name = dir_path + <span class=\"string\">\"/\"</span> + time + <span class=\"string\">\".aac\"</span>;</span><br><span class=\"line\">    recordAudioFile = <span class=\"keyword\">new</span> File(file_name);</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (!recordAudioFile.createNewFile()) &#123;</span><br><span class=\"line\">            Log.d(TAG, <span class=\"string\">\"onClick: file create failed.\"</span>);</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            Log.d(TAG, <span class=\"string\">\"onClick: file create done.\"</span>);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// recordAudioFile = File.createTempFile(file_name,\".aac\");</span></span><br><span class=\"line\">    <span class=\"comment\">// recordAudioFile = new File(file_name, \".aac\");</span></span><br><span class=\"line\">    <span class=\"comment\">// 录音设置</span></span><br><span class=\"line\">    mediaRecorder = <span class=\"keyword\">new</span> MediaRecorder();</span><br><span class=\"line\">    mediaRecorder.setAudioSource(MediaRecorder.AudioSource.MIC);</span><br><span class=\"line\">    mediaRecorder.setOutputFormat(MediaRecorder.OutputFormat.DEFAULT);</span><br><span class=\"line\">    mediaRecorder.setAudioEncoder(MediaRecorder.AudioEncoder.AAC_ELD);</span><br><span class=\"line\">    mediaRecorder.setOutputFile(recordAudioFile.getAbsolutePath());</span><br><span class=\"line\">    <span class=\"comment\">// /data/user/0/com.example.curriculum/cache/</span></span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        mediaRecorder.prepare();</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: prepare failed.\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    mediaRecorder.start();</span><br><span class=\"line\"></span><br><span class=\"line\">&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">// 停止录音</span></span><br><span class=\"line\">    audio.setImageResource(R.mipmap.audio);</span><br><span class=\"line\">    audio.setTag(<span class=\"string\">\"0\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> (mediaRecorder != <span class=\"keyword\">null</span>)&#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: record stop: \"</span> + recordAudioFile.getPath());</span><br><span class=\"line\">        mediaRecorder.stop();</span><br><span class=\"line\">        mediaRecorder.release();</span><br><span class=\"line\">        mediaRecorder = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (getCurrentFocus() != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 当前项下插入一个singlerecord</span></span><br><span class=\"line\">            SingleNoteLayout child = (SingleNoteLayout) getCurrentFocus().getParent().getParent();</span><br><span class=\"line\">            create_record(linearLayout.indexOfChild(child), recordAudioFile.getAbsolutePath());</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 若无焦点，添加至末尾</span></span><br><span class=\"line\">            create_record(linearLayout.getChildCount()-<span class=\"number\">1</span>, recordAudioFile.getAbsolutePath());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"播音资源文件\"><a class=\"markdownIt-Anchor\" href=\"#播音资源文件\"></a> 播音：资源文件</h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 播放器需设置为类成员，以保证不会回收，否则播放可能会中断</span></span><br><span class=\"line\"><span class=\"keyword\">private</span> MediaPlayer mediaPlayer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// MediaPlayer.create方法会自动进行设置+prepare</span></span><br><span class=\"line\">mediaPlayer = MediaPlayer.create(<span class=\"keyword\">this</span>, resid);</span><br><span class=\"line\">mediaPlayer.start();</span><br></pre></td></tr></table></figure>\n<h3 id=\"播音本地文件\"><a class=\"markdownIt-Anchor\" href=\"#播音本地文件\"></a> 播音：本地文件</h3>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">private</span> MediaPlayer mediaPlayer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// new MediaPlayer()的方法不会自动设置及prepare</span></span><br><span class=\"line\">mediaPlayer = <span class=\"keyword\">new</span> MediaPlayer();</span><br><span class=\"line\">mediaPlayer.setDataSource(path);</span><br><span class=\"line\">mediaPlayer.prepare();\t</span><br><span class=\"line\">mediaPlayer.setOnCompletionListener(<span class=\"keyword\">new</span> MediaPlayer.OnCompletionListener() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onCompletion</span><span class=\"params\">(MediaPlayer mp)</span> </span>&#123;</span><br><span class=\"line\">        mp.stop();</span><br><span class=\"line\">        mp.release();</span><br><span class=\"line\">        mp = <span class=\"keyword\">null</span>;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"play: complete\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">mediaPlayer.start();</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">    Log.d(TAG, <span class=\"string\">\"play: file_path is wrong.\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 最后勿加stop release等</span></span><br></pre></td></tr></table></figure>\n<br>\n<h2 id=\"linearlayout的动态增删控件\"><a class=\"markdownIt-Anchor\" href=\"#linearlayout的动态增删控件\"></a> LinearLayout的动态增删控件</h2>\n<p>增：addView时需要index参数，getChildCount、getChildAt、indexOfChild是很常用的方法。</p>\n<p>删：removeView、removeViewAt、removeViewAll</p>\n<br>\n<h2 id=\"控件嵌套的parent\"><a class=\"markdownIt-Anchor\" href=\"#控件嵌套的parent\"></a> 控件嵌套的parent</h2>\n<p>控件嵌套，同时只能点击到某个子控件，要通过子控件获取父级控件甚至更高级控件，可以使用onClick的参数view，一路getParent获取，同时使用getClass判断类型。多层嵌套时可能要使用多次getParent。</p>\n<br>\n<h2 id=\"权限框架\"><a class=\"markdownIt-Anchor\" href=\"#权限框架\"></a> 权限框架</h2>\n<p>easypermissions</p>\n<p><a href=\"www.jianshu.com/p/41b093d213fb\">参考博客</a></p>\n<br>\n<h2 id=\"imageview-上下空白区域\"><a class=\"markdownIt-Anchor\" href=\"#imageview-上下空白区域\"></a> ImageView 上下空白区域</h2>\n<p>图片像素大于屏幕像素时，显示有问题。尝试以下设置：android:adjustViewBounds=“true” 。</p>\n<p>Glide注入图片，与androidx/android10可能兼容性较差，出现了奇怪错误。</p>\n<br>\n<h2 id=\"createnewfile\"><a class=\"markdownIt-Anchor\" href=\"#createnewfile\"></a> createNewFile()</h2>\n<p>要在手动建立的文件夹下，才可create</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 建立文件夹</span></span><br><span class=\"line\">String dir_path = Note.<span class=\"keyword\">this</span>.getFilesDir().getPath() + <span class=\"string\">\"/new_dir/\"</span>;</span><br><span class=\"line\">Log.d(TAG, <span class=\"string\">\"onClick: dir: \"</span> + dir_path);</span><br><span class=\"line\">File dir = <span class=\"keyword\">new</span> File(dir_path);</span><br><span class=\"line\"><span class=\"keyword\">if</span>(!dir.exists())&#123;</span><br><span class=\"line\">    dir.mkdirs();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">// 在该文件夹下建文件</span></span><br><span class=\"line\">String filename = dir_path + <span class=\"string\">\"/hi.txt\"</span>;</span><br><span class=\"line\">File des = <span class=\"keyword\">new</span> File(filename);</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (!des.createNewFile()) &#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: file already exists\"</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        Log.d(TAG, <span class=\"string\">\"onClick: test file create done.\"</span>);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (IOException e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<br>\n<h2 id=\"数据库升级\"><a class=\"markdownIt-Anchor\" href=\"#数据库升级\"></a> 数据库升级</h2>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dbHelper = <span class=\"keyword\">new</span> MyDBHelper(<span class=\"keyword\">this</span>, <span class=\"string\">\"Course.db\"</span>, <span class=\"keyword\">null</span>, <span class=\"number\">2</span>);</span><br><span class=\"line\">db = dbHelper.getWritableDatabase();</span><br></pre></td></tr></table></figure>\n<p>首行参数指定新的version_code，DBHelper.class的onUpgrade中，针对不同版本的升级做出判断与操作。</p>\n<br>\n<h2 id=\"urifromfilenew-filepath\"><a class=\"markdownIt-Anchor\" href=\"#urifromfilenew-filepath\"></a> Uri.fromFile(new File(path))</h2>\n<p>报错：java.io.FileNotFoundException: open failed: EACCES (Permission denied)</p>\n<p>解决：<code>android:requestLegacyExternalStorage=&quot;true&quot;</code> application</p>\n<br>\n<h2 id=\"imageviewsetimageuriuri\"><a class=\"markdownIt-Anchor\" href=\"#imageviewsetimageuriuri\"></a> imageView.setImageURI(uri)</h2>\n<p>从库中读取string，setImageURI(Uri.pairse(string))会报错：</p>\n<p>java.lang.SecurityException: Permission Denial: opening provider … that is not exported from UID 10096</p>\n<p>无合适解决方法，改用setImageURI(Uri.fromFile(new File(path)))。</p>\n<p>但是该方法获得的Uri，调用图库查看图片时又会引起FileUriExposedException异常 😓</p>\n<br>\n<h2 id=\"intent向前传递的顺序问题\"><a class=\"markdownIt-Anchor\" href=\"#intent向前传递的顺序问题\"></a> intent向前传递的顺序问题</h2>\n<p>子活动返回result，即setResult()是在被finish()之前。</p>\n<p>子活动setResult()之后，主活动的onActivityResult()就会启动。这就会导致<strong>onActivityResult()先于子活动的onDestroy()</strong>。</p>\n<p>同时，onPause()， onStop()， onDestroy()中调用setResult()也是不安全的，这些步骤可能会在finish()之后。</p>\n<br>\n<h2 id=\"录音设置\"><a class=\"markdownIt-Anchor\" href=\"#录音设置\"></a> 录音设置</h2>\n<p>编码器、输出文件、文件后缀之间的协调：最终采用文件指定后缀、输出文件Default、编码器与文件后缀匹配</p>\n<p><img src=\"/2020/05/15/Android%E6%80%BB%E7%BB%931/zelda.png\" alt></p>"},{"title":"MD5","date":"2020-06-01T12:39:36.000Z","mathjax":true,"_content":"\n\n\n信息安全技术试验\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n[toc]\n\n<br/>\n\n# MD5\n\n信息摘要算法 Message-Digest Algorithm 5\n\n<br/>\n\n## 功能\n\n1. 任意长度信息生成128位信息。\n2. 唯一性\n3. 不可逆\n\n<br/>\n\n## 算法过程\n\n![MD5](MD5/MD5.png)\n\n以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。\n\n1. 填充\n\n\t填充结果由原消息（+ 填充）+消息长度构成。\n\n\t填充位：100…0，负责将结果填充至512b的倍数；\n\n\t消息长度：64b，记录原消息长度。\n\n\t另，填充+消息长度之和要大于64，即若原消息448，也要补充512+64。\n\n2. 分组\n\n\t2.1 按照512b的长度分为L个大组。\n\n\t2.2 将每个大组，分为16个32b的小组。\n\n3. Buffer\n\n\t定义四个32b的数，16进制下为：A=a=01234567，B=b=89ABCDEF，C=c=FEDCBA98，D=d=76543210。\n\n4. 定义函数\n\n\t定义4种函数FF、GG、HH、II，表示对abcd和某一小组的操作与赋值。\n\n\t![FGHI](MD5/FGHI.png)\n\n\t![FFGGHHII](MD5/FFGGHHII.png)\n\n5. 运算\n\n\t进行L次大循环，大循环的输入是上一次大循环的输出与本次大循环所用的大组；输出是ABCD。\n\n\t每个大循环（大组）下进行4次小循环。每次小循环用到一种上述函数与一个小组。每个小循环结束后，将ABCD分别加上abcd。\n\n6. 拼接\n\n\t最后将ABCD连接即可。\n\n","source":"_posts/MD5.md","raw":"---\ntitle: MD5\ndate: 2020-06-01 20:39:36\nmathjax: true\ntags: 信息安全\n---\n\n\n\n信息安全技术试验\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n[toc]\n\n<br/>\n\n# MD5\n\n信息摘要算法 Message-Digest Algorithm 5\n\n<br/>\n\n## 功能\n\n1. 任意长度信息生成128位信息。\n2. 唯一性\n3. 不可逆\n\n<br/>\n\n## 算法过程\n\n![MD5](MD5/MD5.png)\n\n以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。\n\n1. 填充\n\n\t填充结果由原消息（+ 填充）+消息长度构成。\n\n\t填充位：100…0，负责将结果填充至512b的倍数；\n\n\t消息长度：64b，记录原消息长度。\n\n\t另，填充+消息长度之和要大于64，即若原消息448，也要补充512+64。\n\n2. 分组\n\n\t2.1 按照512b的长度分为L个大组。\n\n\t2.2 将每个大组，分为16个32b的小组。\n\n3. Buffer\n\n\t定义四个32b的数，16进制下为：A=a=01234567，B=b=89ABCDEF，C=c=FEDCBA98，D=d=76543210。\n\n4. 定义函数\n\n\t定义4种函数FF、GG、HH、II，表示对abcd和某一小组的操作与赋值。\n\n\t![FGHI](MD5/FGHI.png)\n\n\t![FFGGHHII](MD5/FFGGHHII.png)\n\n5. 运算\n\n\t进行L次大循环，大循环的输入是上一次大循环的输出与本次大循环所用的大组；输出是ABCD。\n\n\t每个大循环（大组）下进行4次小循环。每次小循环用到一种上述函数与一个小组。每个小循环结束后，将ABCD分别加上abcd。\n\n6. 拼接\n\n\t最后将ABCD连接即可。\n\n","slug":"MD5","published":1,"updated":"2020-07-14T14:47:18.229Z","_id":"ckc4xbevj0005i0qv8bew6d48","comments":1,"layout":"post","photos":[],"link":"","content":"<p>信息安全技术试验</p>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#md5\">MD5</a>\n<ul>\n<li><a href=\"#%E5%8A%9F%E8%83%BD\">功能</a></li>\n<li><a href=\"#%E7%AE%97%E6%B3%95%E8%BF%87%E7%A8%8B\">算法过程</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<p>[toc]</p>\n<br>\n<h1><span id=\"md5\"> MD5</span></h1>\n<p>信息摘要算法 Message-Digest Algorithm 5</p>\n<br>\n<h2><span id=\"功能\"> 功能</span></h2>\n<ol>\n<li>任意长度信息生成128位信息。</li>\n<li>唯一性</li>\n<li>不可逆</li>\n</ol>\n<br>\n<h2><span id=\"算法过程\"> 算法过程</span></h2>\n<p><img src=\"/2020/06/01/MD5/MD5.png\" alt=\"MD5\"></p>\n<p>以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。</p>\n<ol>\n<li>\n<p>填充</p>\n<p>填充结果由原消息（+ 填充）+消息长度构成。</p>\n<p>填充位：100…0，负责将结果填充至512b的倍数；</p>\n<p>消息长度：64b，记录原消息长度。</p>\n<p>另，填充+消息长度之和要大于64，即若原消息448，也要补充512+64。</p>\n</li>\n<li>\n<p>分组</p>\n<p>2.1 按照512b的长度分为L个大组。</p>\n<p>2.2 将每个大组，分为16个32b的小组。</p>\n</li>\n<li>\n<p>Buffer</p>\n<p>定义四个32b的数，16进制下为：A=a=01234567，B=b=89ABCDEF，C=c=FEDCBA98，D=d=76543210。</p>\n</li>\n<li>\n<p>定义函数</p>\n<p>定义4种函数FF、GG、HH、II，表示对abcd和某一小组的操作与赋值。</p>\n<p><img src=\"/2020/06/01/MD5/FGHI.png\" alt=\"FGHI\"></p>\n<p><img src=\"/2020/06/01/MD5/FFGGHHII.png\" alt=\"FFGGHHII\"></p>\n</li>\n<li>\n<p>运算</p>\n<p>进行L次大循环，大循环的输入是上一次大循环的输出与本次大循环所用的大组；输出是ABCD。</p>\n<p>每个大循环（大组）下进行4次小循环。每次小循环用到一种上述函数与一个小组。每个小循环结束后，将ABCD分别加上abcd。</p>\n</li>\n<li>\n<p>拼接</p>\n<p>最后将ABCD连接即可。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>信息安全技术试验</p>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#md5\">MD5</a>\n<ul>\n<li><a href=\"#%E5%8A%9F%E8%83%BD\">功能</a></li>\n<li><a href=\"#%E7%AE%97%E6%B3%95%E8%BF%87%E7%A8%8B\">算法过程</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<p>[toc]</p>\n<br>\n<h1 id=\"md5\"><a class=\"markdownIt-Anchor\" href=\"#md5\"></a> MD5</h1>\n<p>信息摘要算法 Message-Digest Algorithm 5</p>\n<br>\n<h2 id=\"功能\"><a class=\"markdownIt-Anchor\" href=\"#功能\"></a> 功能</h2>\n<ol>\n<li>任意长度信息生成128位信息。</li>\n<li>唯一性</li>\n<li>不可逆</li>\n</ol>\n<br>\n<h2 id=\"算法过程\"><a class=\"markdownIt-Anchor\" href=\"#算法过程\"></a> 算法过程</h2>\n<p><img src=\"/2020/06/01/MD5/MD5.png\" alt=\"MD5\"></p>\n<p>以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。</p>\n<ol>\n<li>\n<p>填充</p>\n<p>填充结果由原消息（+ 填充）+消息长度构成。</p>\n<p>填充位：100…0，负责将结果填充至512b的倍数；</p>\n<p>消息长度：64b，记录原消息长度。</p>\n<p>另，填充+消息长度之和要大于64，即若原消息448，也要补充512+64。</p>\n</li>\n<li>\n<p>分组</p>\n<p>2.1 按照512b的长度分为L个大组。</p>\n<p>2.2 将每个大组，分为16个32b的小组。</p>\n</li>\n<li>\n<p>Buffer</p>\n<p>定义四个32b的数，16进制下为：A=a=01234567，B=b=89ABCDEF，C=c=FEDCBA98，D=d=76543210。</p>\n</li>\n<li>\n<p>定义函数</p>\n<p>定义4种函数FF、GG、HH、II，表示对abcd和某一小组的操作与赋值。</p>\n<p><img src=\"/2020/06/01/MD5/FGHI.png\" alt=\"FGHI\"></p>\n<p><img src=\"/2020/06/01/MD5/FFGGHHII.png\" alt=\"FFGGHHII\"></p>\n</li>\n<li>\n<p>运算</p>\n<p>进行L次大循环，大循环的输入是上一次大循环的输出与本次大循环所用的大组；输出是ABCD。</p>\n<p>每个大循环（大组）下进行4次小循环。每次小循环用到一种上述函数与一个小组。每个小循环结束后，将ABCD分别加上abcd。</p>\n</li>\n<li>\n<p>拼接</p>\n<p>最后将ABCD连接即可。</p>\n</li>\n</ol>"},{"title":"MDNet","mathjax":true,"date":"2020-06-18T12:11:11.000Z","_content":"\n\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# MDNet\n\nLearning Multi-Domain Convolutional Neural Networks for Visual Tracking\n\n<br/>\n\n## 背景\n\n* 对于跟踪问题来说，CNN应该是由视频跟踪的数据训练得到的更为合理。所有的跟踪目标，虽然类别各不相同，但其实他们应该都存在某种共性，这是需要网络去学的。\n* 用跟踪数据来训练很难，因为同一个object，在某个序列中是目标，在另外一个序列中可能就是背景，而且每个序列的目标存在相当大的差异，而且会经历各种挑战，比如遮挡、形变等等。\n* 现有的很多训练好的网络主要针对的任务比如目标检测、分类、分割等的网络很大，因为他们要分出很多类别的目标。而在跟踪问题中，一个网络只需要分两类：目标和背景。而且目标一般都相对比较小，那么其实不需要这么大的网络，会增加计算负担。\n\n<br/>\n\n## multi-domain learning/多区域学习\n\n​    训练数据来源于多个domain，domain information被纳入学习过程。是自然语言处理领域一个常见的学习方法（例如用在多个产品的情感分类和多个用户的垃圾邮件过滤等课题中），但很少有人应在计算机视觉领域。\n\n<br/>\n\n## 网络结构\n\n![img](MDNet/MDNet_struct.png)\n\n* Input: 网络的输入是107x107的Bounding box，设置为这个尺寸是为了在卷积层conv3能够得到3x3的feature map。\n* Convolutional layers: 网络的卷积层conv1-conv3来自于VGG-M [1]网络，只是输入的大小做了改变。\n* Fully connected layers: 接下来的两个全连接层fc4,fc5各有512个输出单元，并设计有ReLUs和Dropouts。fc6是一个二分类层**（Domain-specific layers）**，softmax cross-entropy loss，一共有K个，对应K个Branches(即K个不同的视频)，每次训练的时候只有对应该视频的fc6被使用，前面的层都是共享的。**这个二分类层是online的更新。这个二分类层是用来判定一些candidate windows （随机的从上一帧target附近采样出来的） 是否为目标。**\n\n**卷积层是一个相对通用的特征提取器，而fc层更多的是针对task和数据集的不同进行自适应调整**\n\n<br/>\n\n## 小网络在tracking中的适用性：\n\n* tracking旨在区分目标和背景两个类别，这比目前一般的视觉识别问题（如1000类的ImageNet分类）要求的模型复杂程度少得多。\n* 深度CNN对于精确目标定位的效果较差，因为随着网络的深入，空间信息往往会被淡化。\n* 在跟踪任务中通常目标较小，所以输入大小（input size）也就小，网络结构自然也就更浅。\n* 跟踪通常是一个实时任务，一个较小的网络在跟踪问题上明显更有效率，训练和测试都可以在线进行的。 当我们测试更大的网络时，算法不太准确，并且变得更慢。\n\n<br/>\n\n## Domain-specific layers\n\n* 学习共性：算法的目标是训练一个 multi-domain CNN 以在任何 domain 辨别 target 和 background。这并非很直观，因为来源不同 domain的 train data 拥有不同的 target 和 background 的定义。但是，这其中仍然存在着一些共同的属性，如：对光照变化，运动模糊，尺寸变化的鲁棒性等等。为了提取出满足上述属性的特征，作者通过 multi-domain learning framework，从 domain-specific 的信息中分离出 domain-independent 的信息。\n* 训练方式：为了学到不同视频中目标的共性，采用Domain-specific的训练方式：假设用K个视频来做训练，一共做N次循环。在每一次循环中，会做K次迭代，依次用K个视频的mini-batch来做训练。每一个mini-batch的构成是从某一视频中随机采8帧图片，在这8帧图片上随机采32个正样本和96个负样本，即每个mini-batch由某一个视频的128个框来构成。用SGD进行训练，**每个视频会对应自己的fc6层**。通过这样的训练来学得各个视频中目标的共性。\n* 在第k次迭代中，mini-batch中只包含来自第（k mod K）个video的样本，K个domain-specific layers也只激活第（k mod K）个分支。\n* 通过这个学习过程，跟特定domain无关的信息就被学习到并保存在共享层中，这些信息是非常有用的泛化特征表示。\n* **test的时候，会新建一个fc6层，在线fine-tune fc4-fc6层，卷积层保持不变。**\n\n<br/>\n\n## 网络在线更新策略\n\n采用long-term和short-term两种更新方式。对应robustness 和 adaptiveness。\n\n* long-term update：按照常规间隔后使用较长时间内的正样本进行更新。\n* short-term updates：当出现潜在的跟踪失败（预测目标的positive score 小于 0.5）的时候使用短期内收集到的正样本进行更新。\n* 这两种更新的执行依赖于物体外观变化的速度。\n* long-term对应历史的100个样本（超过100个抛弃最早的），固定时间间隔做一次网络的更新（程序中设置为每8帧更新一次）。\n* short-term对应20个（超过20个抛弃最早的），在目标得分低于0.5进行更新。\n* 负样本都是用short-term的方式收集的，因为旧的负样本往往是冗余的或与当前帧无关。\n* 另外在训练中负样本的生成用到了**hard negative mining**，就是让负样本越来越难分，从而使得网络的判别能力越来越强。作者把hard negative mining 的过程融入到minibatch选择阶段：在训练阶段的每一次迭代中，一个mini-batch包含n个正样本和p个困难负样本。如何选择困难负样本？ 用模型测试 M（M >> p）个负样本，sort之后取top p个最困难负样本。\n\n![](MDNet/MDNet_neg_mining.png)\n\n<br/>\n\n## 目标跟踪过程\n\n* 每次新来一帧图片，以上一帧的目标位置为中心，用多维高斯分布（宽，高，尺度三个维度）的形式进行采样256个candidates，将他们大小统一为107x107后，分别作为网络的输入进行计算。\n* 网络的输出是一个二维的向量，分别表示输入的bounding box对应目标和背景的概率。目标最终是确定为目标得分概率最高的那个bounding box：\n* 最后得到的candidate其实不是直接作为目标，还要做一步**bounding box regression**（矫正）。作者说bounding box regression涉及到的细节与R-CNN一样。\n\n![img](MDNet/MDnet_algorithm.png)\n\n","source":"_posts/MDNet.md","raw":"---\ntitle: MDNet\nmathjax: true\ndate: 2020-06-18 20:11:11\ntags: AI\n---\n\n\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# MDNet\n\nLearning Multi-Domain Convolutional Neural Networks for Visual Tracking\n\n<br/>\n\n## 背景\n\n* 对于跟踪问题来说，CNN应该是由视频跟踪的数据训练得到的更为合理。所有的跟踪目标，虽然类别各不相同，但其实他们应该都存在某种共性，这是需要网络去学的。\n* 用跟踪数据来训练很难，因为同一个object，在某个序列中是目标，在另外一个序列中可能就是背景，而且每个序列的目标存在相当大的差异，而且会经历各种挑战，比如遮挡、形变等等。\n* 现有的很多训练好的网络主要针对的任务比如目标检测、分类、分割等的网络很大，因为他们要分出很多类别的目标。而在跟踪问题中，一个网络只需要分两类：目标和背景。而且目标一般都相对比较小，那么其实不需要这么大的网络，会增加计算负担。\n\n<br/>\n\n## multi-domain learning/多区域学习\n\n​    训练数据来源于多个domain，domain information被纳入学习过程。是自然语言处理领域一个常见的学习方法（例如用在多个产品的情感分类和多个用户的垃圾邮件过滤等课题中），但很少有人应在计算机视觉领域。\n\n<br/>\n\n## 网络结构\n\n![img](MDNet/MDNet_struct.png)\n\n* Input: 网络的输入是107x107的Bounding box，设置为这个尺寸是为了在卷积层conv3能够得到3x3的feature map。\n* Convolutional layers: 网络的卷积层conv1-conv3来自于VGG-M [1]网络，只是输入的大小做了改变。\n* Fully connected layers: 接下来的两个全连接层fc4,fc5各有512个输出单元，并设计有ReLUs和Dropouts。fc6是一个二分类层**（Domain-specific layers）**，softmax cross-entropy loss，一共有K个，对应K个Branches(即K个不同的视频)，每次训练的时候只有对应该视频的fc6被使用，前面的层都是共享的。**这个二分类层是online的更新。这个二分类层是用来判定一些candidate windows （随机的从上一帧target附近采样出来的） 是否为目标。**\n\n**卷积层是一个相对通用的特征提取器，而fc层更多的是针对task和数据集的不同进行自适应调整**\n\n<br/>\n\n## 小网络在tracking中的适用性：\n\n* tracking旨在区分目标和背景两个类别，这比目前一般的视觉识别问题（如1000类的ImageNet分类）要求的模型复杂程度少得多。\n* 深度CNN对于精确目标定位的效果较差，因为随着网络的深入，空间信息往往会被淡化。\n* 在跟踪任务中通常目标较小，所以输入大小（input size）也就小，网络结构自然也就更浅。\n* 跟踪通常是一个实时任务，一个较小的网络在跟踪问题上明显更有效率，训练和测试都可以在线进行的。 当我们测试更大的网络时，算法不太准确，并且变得更慢。\n\n<br/>\n\n## Domain-specific layers\n\n* 学习共性：算法的目标是训练一个 multi-domain CNN 以在任何 domain 辨别 target 和 background。这并非很直观，因为来源不同 domain的 train data 拥有不同的 target 和 background 的定义。但是，这其中仍然存在着一些共同的属性，如：对光照变化，运动模糊，尺寸变化的鲁棒性等等。为了提取出满足上述属性的特征，作者通过 multi-domain learning framework，从 domain-specific 的信息中分离出 domain-independent 的信息。\n* 训练方式：为了学到不同视频中目标的共性，采用Domain-specific的训练方式：假设用K个视频来做训练，一共做N次循环。在每一次循环中，会做K次迭代，依次用K个视频的mini-batch来做训练。每一个mini-batch的构成是从某一视频中随机采8帧图片，在这8帧图片上随机采32个正样本和96个负样本，即每个mini-batch由某一个视频的128个框来构成。用SGD进行训练，**每个视频会对应自己的fc6层**。通过这样的训练来学得各个视频中目标的共性。\n* 在第k次迭代中，mini-batch中只包含来自第（k mod K）个video的样本，K个domain-specific layers也只激活第（k mod K）个分支。\n* 通过这个学习过程，跟特定domain无关的信息就被学习到并保存在共享层中，这些信息是非常有用的泛化特征表示。\n* **test的时候，会新建一个fc6层，在线fine-tune fc4-fc6层，卷积层保持不变。**\n\n<br/>\n\n## 网络在线更新策略\n\n采用long-term和short-term两种更新方式。对应robustness 和 adaptiveness。\n\n* long-term update：按照常规间隔后使用较长时间内的正样本进行更新。\n* short-term updates：当出现潜在的跟踪失败（预测目标的positive score 小于 0.5）的时候使用短期内收集到的正样本进行更新。\n* 这两种更新的执行依赖于物体外观变化的速度。\n* long-term对应历史的100个样本（超过100个抛弃最早的），固定时间间隔做一次网络的更新（程序中设置为每8帧更新一次）。\n* short-term对应20个（超过20个抛弃最早的），在目标得分低于0.5进行更新。\n* 负样本都是用short-term的方式收集的，因为旧的负样本往往是冗余的或与当前帧无关。\n* 另外在训练中负样本的生成用到了**hard negative mining**，就是让负样本越来越难分，从而使得网络的判别能力越来越强。作者把hard negative mining 的过程融入到minibatch选择阶段：在训练阶段的每一次迭代中，一个mini-batch包含n个正样本和p个困难负样本。如何选择困难负样本？ 用模型测试 M（M >> p）个负样本，sort之后取top p个最困难负样本。\n\n![](MDNet/MDNet_neg_mining.png)\n\n<br/>\n\n## 目标跟踪过程\n\n* 每次新来一帧图片，以上一帧的目标位置为中心，用多维高斯分布（宽，高，尺度三个维度）的形式进行采样256个candidates，将他们大小统一为107x107后，分别作为网络的输入进行计算。\n* 网络的输出是一个二维的向量，分别表示输入的bounding box对应目标和背景的概率。目标最终是确定为目标得分概率最高的那个bounding box：\n* 最后得到的candidate其实不是直接作为目标，还要做一步**bounding box regression**（矫正）。作者说bounding box regression涉及到的细节与R-CNN一样。\n\n![img](MDNet/MDnet_algorithm.png)\n\n","slug":"MDNet","published":1,"updated":"2020-06-18T12:18:05.249Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbevl0006i0qvaw2scw4e","content":"<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#mdnet\">MDNet</a>\n<ul>\n<li><a href=\"#%E8%83%8C%E6%99%AF\">背景</a></li>\n<li><a href=\"#multi-domain-learning%E5%A4%9A%E5%8C%BA%E5%9F%9F%E5%AD%A6%E4%B9%A0\">multi-domain learning/多区域学习</a></li>\n<li><a href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\">网络结构</a></li>\n<li><a href=\"#%E5%B0%8F%E7%BD%91%E7%BB%9C%E5%9C%A8tracking%E4%B8%AD%E7%9A%84%E9%80%82%E7%94%A8%E6%80%A7\">小网络在tracking中的适用性：</a></li>\n<li><a href=\"#domain-specific-layers\">Domain-specific layers</a></li>\n<li><a href=\"#%E7%BD%91%E7%BB%9C%E5%9C%A8%E7%BA%BF%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5\">网络在线更新策略</a></li>\n<li><a href=\"#%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E8%BF%87%E7%A8%8B\">目标跟踪过程</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"mdnet\"> MDNet</span></h1>\n<p>Learning Multi-Domain Convolutional Neural Networks for Visual Tracking</p>\n<br>\n<h2><span id=\"背景\"> 背景</span></h2>\n<ul>\n<li>对于跟踪问题来说，CNN应该是由视频跟踪的数据训练得到的更为合理。所有的跟踪目标，虽然类别各不相同，但其实他们应该都存在某种共性，这是需要网络去学的。</li>\n<li>用跟踪数据来训练很难，因为同一个object，在某个序列中是目标，在另外一个序列中可能就是背景，而且每个序列的目标存在相当大的差异，而且会经历各种挑战，比如遮挡、形变等等。</li>\n<li>现有的很多训练好的网络主要针对的任务比如目标检测、分类、分割等的网络很大，因为他们要分出很多类别的目标。而在跟踪问题中，一个网络只需要分两类：目标和背景。而且目标一般都相对比较小，那么其实不需要这么大的网络，会增加计算负担。</li>\n</ul>\n<br>\n<h2><span id=\"multi-domain-learning多区域学习\"> multi-domain learning/多区域学习</span></h2>\n<p>​    训练数据来源于多个domain，domain information被纳入学习过程。是自然语言处理领域一个常见的学习方法（例如用在多个产品的情感分类和多个用户的垃圾邮件过滤等课题中），但很少有人应在计算机视觉领域。</p>\n<br>\n<h2><span id=\"网络结构\"> 网络结构</span></h2>\n<p><img src=\"/2020/06/18/MDNet/MDNet_struct.png\" alt=\"img\"></p>\n<ul>\n<li>Input: 网络的输入是107x107的Bounding box，设置为这个尺寸是为了在卷积层conv3能够得到3x3的feature map。</li>\n<li>Convolutional layers: 网络的卷积层conv1-conv3来自于VGG-M [1]网络，只是输入的大小做了改变。</li>\n<li>Fully connected layers: 接下来的两个全连接层fc4,fc5各有512个输出单元，并设计有ReLUs和Dropouts。fc6是一个二分类层**（Domain-specific layers）**，softmax cross-entropy loss，一共有K个，对应K个Branches(即K个不同的视频)，每次训练的时候只有对应该视频的fc6被使用，前面的层都是共享的。<strong>这个二分类层是online的更新。这个二分类层是用来判定一些candidate windows （随机的从上一帧target附近采样出来的） 是否为目标。</strong></li>\n</ul>\n<p><strong>卷积层是一个相对通用的特征提取器，而fc层更多的是针对task和数据集的不同进行自适应调整</strong></p>\n<br>\n<h2><span id=\"小网络在tracking中的适用性\"> 小网络在tracking中的适用性：</span></h2>\n<ul>\n<li>tracking旨在区分目标和背景两个类别，这比目前一般的视觉识别问题（如1000类的ImageNet分类）要求的模型复杂程度少得多。</li>\n<li>深度CNN对于精确目标定位的效果较差，因为随着网络的深入，空间信息往往会被淡化。</li>\n<li>在跟踪任务中通常目标较小，所以输入大小（input size）也就小，网络结构自然也就更浅。</li>\n<li>跟踪通常是一个实时任务，一个较小的网络在跟踪问题上明显更有效率，训练和测试都可以在线进行的。 当我们测试更大的网络时，算法不太准确，并且变得更慢。</li>\n</ul>\n<br>\n<h2><span id=\"domain-specific-layers\"> Domain-specific layers</span></h2>\n<ul>\n<li>学习共性：算法的目标是训练一个 multi-domain CNN 以在任何 domain 辨别 target 和 background。这并非很直观，因为来源不同 domain的 train data 拥有不同的 target 和 background 的定义。但是，这其中仍然存在着一些共同的属性，如：对光照变化，运动模糊，尺寸变化的鲁棒性等等。为了提取出满足上述属性的特征，作者通过 multi-domain learning framework，从 domain-specific 的信息中分离出 domain-independent 的信息。</li>\n<li>训练方式：为了学到不同视频中目标的共性，采用Domain-specific的训练方式：假设用K个视频来做训练，一共做N次循环。在每一次循环中，会做K次迭代，依次用K个视频的mini-batch来做训练。每一个mini-batch的构成是从某一视频中随机采8帧图片，在这8帧图片上随机采32个正样本和96个负样本，即每个mini-batch由某一个视频的128个框来构成。用SGD进行训练，<strong>每个视频会对应自己的fc6层</strong>。通过这样的训练来学得各个视频中目标的共性。</li>\n<li>在第k次迭代中，mini-batch中只包含来自第（k mod K）个video的样本，K个domain-specific layers也只激活第（k mod K）个分支。</li>\n<li>通过这个学习过程，跟特定domain无关的信息就被学习到并保存在共享层中，这些信息是非常有用的泛化特征表示。</li>\n<li><strong>test的时候，会新建一个fc6层，在线fine-tune fc4-fc6层，卷积层保持不变。</strong></li>\n</ul>\n<br>\n<h2><span id=\"网络在线更新策略\"> 网络在线更新策略</span></h2>\n<p>采用long-term和short-term两种更新方式。对应robustness 和 adaptiveness。</p>\n<ul>\n<li>long-term update：按照常规间隔后使用较长时间内的正样本进行更新。</li>\n<li>short-term updates：当出现潜在的跟踪失败（预测目标的positive score 小于 0.5）的时候使用短期内收集到的正样本进行更新。</li>\n<li>这两种更新的执行依赖于物体外观变化的速度。</li>\n<li>long-term对应历史的100个样本（超过100个抛弃最早的），固定时间间隔做一次网络的更新（程序中设置为每8帧更新一次）。</li>\n<li>short-term对应20个（超过20个抛弃最早的），在目标得分低于0.5进行更新。</li>\n<li>负样本都是用short-term的方式收集的，因为旧的负样本往往是冗余的或与当前帧无关。</li>\n<li>另外在训练中负样本的生成用到了<strong>hard negative mining</strong>，就是让负样本越来越难分，从而使得网络的判别能力越来越强。作者把hard negative mining 的过程融入到minibatch选择阶段：在训练阶段的每一次迭代中，一个mini-batch包含n个正样本和p个困难负样本。如何选择困难负样本？ 用模型测试 M（M &gt;&gt; p）个负样本，sort之后取top p个最困难负样本。</li>\n</ul>\n<p><img src=\"/2020/06/18/MDNet/MDNet_neg_mining.png\" alt></p>\n<br>\n<h2><span id=\"目标跟踪过程\"> 目标跟踪过程</span></h2>\n<ul>\n<li>每次新来一帧图片，以上一帧的目标位置为中心，用多维高斯分布（宽，高，尺度三个维度）的形式进行采样256个candidates，将他们大小统一为107x107后，分别作为网络的输入进行计算。</li>\n<li>网络的输出是一个二维的向量，分别表示输入的bounding box对应目标和背景的概率。目标最终是确定为目标得分概率最高的那个bounding box：</li>\n<li>最后得到的candidate其实不是直接作为目标，还要做一步<strong>bounding box regression</strong>（矫正）。作者说bounding box regression涉及到的细节与R-CNN一样。</li>\n</ul>\n<p><img src=\"/2020/06/18/MDNet/MDnet_algorithm.png\" alt=\"img\"></p>\n","site":{"data":{}},"excerpt":"","more":"<!-- toc -->\n<ul>\n<li><a href=\"#mdnet\">MDNet</a>\n<ul>\n<li><a href=\"#%E8%83%8C%E6%99%AF\">背景</a></li>\n<li><a href=\"#multi-domain-learning%E5%A4%9A%E5%8C%BA%E5%9F%9F%E5%AD%A6%E4%B9%A0\">multi-domain learning/多区域学习</a></li>\n<li><a href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\">网络结构</a></li>\n<li><a href=\"#%E5%B0%8F%E7%BD%91%E7%BB%9C%E5%9C%A8tracking%E4%B8%AD%E7%9A%84%E9%80%82%E7%94%A8%E6%80%A7\">小网络在tracking中的适用性：</a></li>\n<li><a href=\"#domain-specific-layers\">Domain-specific layers</a></li>\n<li><a href=\"#%E7%BD%91%E7%BB%9C%E5%9C%A8%E7%BA%BF%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5\">网络在线更新策略</a></li>\n<li><a href=\"#%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E8%BF%87%E7%A8%8B\">目标跟踪过程</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"mdnet\"><a class=\"markdownIt-Anchor\" href=\"#mdnet\"></a> MDNet</h1>\n<p>Learning Multi-Domain Convolutional Neural Networks for Visual Tracking</p>\n<br>\n<h2 id=\"背景\"><a class=\"markdownIt-Anchor\" href=\"#背景\"></a> 背景</h2>\n<ul>\n<li>对于跟踪问题来说，CNN应该是由视频跟踪的数据训练得到的更为合理。所有的跟踪目标，虽然类别各不相同，但其实他们应该都存在某种共性，这是需要网络去学的。</li>\n<li>用跟踪数据来训练很难，因为同一个object，在某个序列中是目标，在另外一个序列中可能就是背景，而且每个序列的目标存在相当大的差异，而且会经历各种挑战，比如遮挡、形变等等。</li>\n<li>现有的很多训练好的网络主要针对的任务比如目标检测、分类、分割等的网络很大，因为他们要分出很多类别的目标。而在跟踪问题中，一个网络只需要分两类：目标和背景。而且目标一般都相对比较小，那么其实不需要这么大的网络，会增加计算负担。</li>\n</ul>\n<br>\n<h2 id=\"multi-domain-learning多区域学习\"><a class=\"markdownIt-Anchor\" href=\"#multi-domain-learning多区域学习\"></a> multi-domain learning/多区域学习</h2>\n<p>​    训练数据来源于多个domain，domain information被纳入学习过程。是自然语言处理领域一个常见的学习方法（例如用在多个产品的情感分类和多个用户的垃圾邮件过滤等课题中），但很少有人应在计算机视觉领域。</p>\n<br>\n<h2 id=\"网络结构\"><a class=\"markdownIt-Anchor\" href=\"#网络结构\"></a> 网络结构</h2>\n<p><img src=\"/2020/06/18/MDNet/MDNet_struct.png\" alt=\"img\"></p>\n<ul>\n<li>Input: 网络的输入是107x107的Bounding box，设置为这个尺寸是为了在卷积层conv3能够得到3x3的feature map。</li>\n<li>Convolutional layers: 网络的卷积层conv1-conv3来自于VGG-M [1]网络，只是输入的大小做了改变。</li>\n<li>Fully connected layers: 接下来的两个全连接层fc4,fc5各有512个输出单元，并设计有ReLUs和Dropouts。fc6是一个二分类层**（Domain-specific layers）**，softmax cross-entropy loss，一共有K个，对应K个Branches(即K个不同的视频)，每次训练的时候只有对应该视频的fc6被使用，前面的层都是共享的。<strong>这个二分类层是online的更新。这个二分类层是用来判定一些candidate windows （随机的从上一帧target附近采样出来的） 是否为目标。</strong></li>\n</ul>\n<p><strong>卷积层是一个相对通用的特征提取器，而fc层更多的是针对task和数据集的不同进行自适应调整</strong></p>\n<br>\n<h2 id=\"小网络在tracking中的适用性\"><a class=\"markdownIt-Anchor\" href=\"#小网络在tracking中的适用性\"></a> 小网络在tracking中的适用性：</h2>\n<ul>\n<li>tracking旨在区分目标和背景两个类别，这比目前一般的视觉识别问题（如1000类的ImageNet分类）要求的模型复杂程度少得多。</li>\n<li>深度CNN对于精确目标定位的效果较差，因为随着网络的深入，空间信息往往会被淡化。</li>\n<li>在跟踪任务中通常目标较小，所以输入大小（input size）也就小，网络结构自然也就更浅。</li>\n<li>跟踪通常是一个实时任务，一个较小的网络在跟踪问题上明显更有效率，训练和测试都可以在线进行的。 当我们测试更大的网络时，算法不太准确，并且变得更慢。</li>\n</ul>\n<br>\n<h2 id=\"domain-specific-layers\"><a class=\"markdownIt-Anchor\" href=\"#domain-specific-layers\"></a> Domain-specific layers</h2>\n<ul>\n<li>学习共性：算法的目标是训练一个 multi-domain CNN 以在任何 domain 辨别 target 和 background。这并非很直观，因为来源不同 domain的 train data 拥有不同的 target 和 background 的定义。但是，这其中仍然存在着一些共同的属性，如：对光照变化，运动模糊，尺寸变化的鲁棒性等等。为了提取出满足上述属性的特征，作者通过 multi-domain learning framework，从 domain-specific 的信息中分离出 domain-independent 的信息。</li>\n<li>训练方式：为了学到不同视频中目标的共性，采用Domain-specific的训练方式：假设用K个视频来做训练，一共做N次循环。在每一次循环中，会做K次迭代，依次用K个视频的mini-batch来做训练。每一个mini-batch的构成是从某一视频中随机采8帧图片，在这8帧图片上随机采32个正样本和96个负样本，即每个mini-batch由某一个视频的128个框来构成。用SGD进行训练，<strong>每个视频会对应自己的fc6层</strong>。通过这样的训练来学得各个视频中目标的共性。</li>\n<li>在第k次迭代中，mini-batch中只包含来自第（k mod K）个video的样本，K个domain-specific layers也只激活第（k mod K）个分支。</li>\n<li>通过这个学习过程，跟特定domain无关的信息就被学习到并保存在共享层中，这些信息是非常有用的泛化特征表示。</li>\n<li><strong>test的时候，会新建一个fc6层，在线fine-tune fc4-fc6层，卷积层保持不变。</strong></li>\n</ul>\n<br>\n<h2 id=\"网络在线更新策略\"><a class=\"markdownIt-Anchor\" href=\"#网络在线更新策略\"></a> 网络在线更新策略</h2>\n<p>采用long-term和short-term两种更新方式。对应robustness 和 adaptiveness。</p>\n<ul>\n<li>long-term update：按照常规间隔后使用较长时间内的正样本进行更新。</li>\n<li>short-term updates：当出现潜在的跟踪失败（预测目标的positive score 小于 0.5）的时候使用短期内收集到的正样本进行更新。</li>\n<li>这两种更新的执行依赖于物体外观变化的速度。</li>\n<li>long-term对应历史的100个样本（超过100个抛弃最早的），固定时间间隔做一次网络的更新（程序中设置为每8帧更新一次）。</li>\n<li>short-term对应20个（超过20个抛弃最早的），在目标得分低于0.5进行更新。</li>\n<li>负样本都是用short-term的方式收集的，因为旧的负样本往往是冗余的或与当前帧无关。</li>\n<li>另外在训练中负样本的生成用到了<strong>hard negative mining</strong>，就是让负样本越来越难分，从而使得网络的判别能力越来越强。作者把hard negative mining 的过程融入到minibatch选择阶段：在训练阶段的每一次迭代中，一个mini-batch包含n个正样本和p个困难负样本。如何选择困难负样本？ 用模型测试 M（M &gt;&gt; p）个负样本，sort之后取top p个最困难负样本。</li>\n</ul>\n<p><img src=\"/2020/06/18/MDNet/MDNet_neg_mining.png\" alt></p>\n<br>\n<h2 id=\"目标跟踪过程\"><a class=\"markdownIt-Anchor\" href=\"#目标跟踪过程\"></a> 目标跟踪过程</h2>\n<ul>\n<li>每次新来一帧图片，以上一帧的目标位置为中心，用多维高斯分布（宽，高，尺度三个维度）的形式进行采样256个candidates，将他们大小统一为107x107后，分别作为网络的输入进行计算。</li>\n<li>网络的输出是一个二维的向量，分别表示输入的bounding box对应目标和背景的概率。目标最终是确定为目标得分概率最高的那个bounding box：</li>\n<li>最后得到的candidate其实不是直接作为目标，还要做一步<strong>bounding box regression</strong>（矫正）。作者说bounding box regression涉及到的细节与R-CNN一样。</li>\n</ul>\n<p><img src=\"/2020/06/18/MDNet/MDnet_algorithm.png\" alt=\"img\"></p>"},{"title":"CS231n笔记","mathjax":true,"date":"2020-06-18T12:25:07.000Z","_content":"\n\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# Project\n\n*   判别式方法 -> 深度学习类\n*   [目标跟踪算法综述](https://wenku.baidu.com/view/552db3a780c758f5f61fb7360b4c2e3f56272517.html)\n*   ![](CS231n笔记/主流.png)\n*   为了扩展CNN在目标跟踪领域的能力，需要大量的训练数据，但这在目标跟踪中是很难做到的。MDNet[14]算法提出了一种解决该问题的思路。算法采用VGG-M作为网络初始化模型，后接多个全连接层用作分类器。训练时，每一个跟踪视频对应一个全连接层，学习普遍的特征表示用来跟踪。跟踪时，去掉训练时的全连接层，使用第一帧样本初始化一个全连接层，新的全连接层在跟踪的过程中继续微调，来适应新的目标变化。这种方法使得特征更适合于目标跟踪，效果大大提升。由此可以看出，通过视频训练的网络更适合目标跟踪这一任务\n*   速度改进：虽然深度特征具有传统特征无法比拟的抗干扰能力，但是一般提取速度较慢，而且特征中存在大量冗余。当算法精度达到一定标准之后，很多方法开始着力解决算法速度问题。**孪生网络**[19]是其中的一个典型例子，采用两路神经网络分别输入目标模板和搜索图像块，用来进行模板匹配或候选样本分类。其中一路神经网络对于模板信息的保存可以提供跟踪物体先验信息，取代网络在线更新，大大节省了速度。另外，**对深度特征进行降维或自适应选择**也是加速算法的有效途径。由于深度神经网络复杂的计算及模型更新时繁琐的系数，现存大部分深度目标跟踪算法速度都比较慢。很多深度目标跟踪算法采用**小型神经网络（如VGG-M）**来提特征。另外，跟踪中只给定第一帧目标位置，缺少跟踪物体先验信息，这就**要求模型实时更新**来确保跟踪精度，而这在深度目标跟踪算法中往往非常耗时。一些算法采用孪生网络结构来保存先验信息，代替模型在线更新，使得算法速度得以提高。深度特征的高维度也会影响跟踪算法的速度，如果能够提出有效的特征压缩方法，不管对算法速度还是精度都会有所帮助。只有高速且有效地算法才具有实际的应用价值\n\n---\n\n\n\n\n\n# CS231n\n\n## Data Driven/数据驱动\n\n*   以数据/样本驱动，训练模型，进行预测\n\n```python\ndef train(images, labels):\n    #Machine learning\n    return model\n\ndef predict(model, test_images):\n    #use model to predict labels\n    return test_labels\n```\n\n*   train_data/训练集：以不同的超参数训练模型\n*   validation_data/验证集：选出效果最优的超参数\n*   test_data/测试集：仅预测算法在未见新数据上的\n\n---\n\n\n\n## Linear Classifier/线性分类\n\n* 将训练数据浓缩于参数W/θ中，但每个类别只能学习一个单独模板\n\n* $f(x,W)=Wx+b$\n * W:$10*3072$ ，有十类时\n\t* x:$3072*1$ ， 图片为$32*32*3$时\n\t* b:$10*1$ ， 有十类时\n\t* 结果得分:$10*1$\n\n---\n\n\n\n## Loss Function/损失函数\n\n* 将W输入，输出得分，定量地估计W的好坏\n* $f(x, W)=Wx$\n* $L=\\frac{1}{N}\\sum_iL_i(f(x_i,W),y_i)+\\lambda R(W)$\n * N：样本数\n\t* $\\lambda R(W)$：正则化项\n* Multi-class SVM LOSS：\n * $L_i=\\sum_{j\\not=y_i}\\max(0,s_j-s_{y_i}+margin)$\n\t* $s=f(x,W)$\n\t* i：当前对第i个样本的得分计算\n\t* $s_j$：当前样本对第j类的得分\n\t* $s_{y_i}$：当前样本对正确分类组的得分\n\t* margin：适当边距\n\t* 释义：不正确分类上损失之和，且正确分类得分超出错误分类得分margin以上时损失为0\n* Softmax Loss：\n * $P(Y=k\\mid X=x_i)=\\frac{e^s k}{\\sum_j e^s j}$\n\t* $s=f(x_i;W)$\n\t* 最小化$L_i=-\\log P(Y=y_i\\mid X=x_i)$\n\t* 希望正确分类的概率趋近1\n\n---\n\n\n\n## Optimization/优化/梯度下降\n\n梯度下降是指，在给定待优化的模型参数$\\theta\\in R^d$和目标函数$J(\\theta)$，算法通过沿梯度 $\\nabla _\\theta J(\\theta)$的相反方向更新$\\theta$来最小化$J(\\theta)$。学习率$\\eta$决定了每一时刻的更新步长。\n\n流程如下：\n\n1. 计算目标函数关于参数的梯度\n\n\t$g_t=\\nabla_\\theta J(\\theta)$\n\n2. 根据历史梯度计算一阶和二阶动量\n\n$m_t=\\phi (g_1,g_2,\\cdots ,g_t)$\n\n$v_t=\\psi(g_1,,g_2,\\cdots ,g_t)$\n\n3. 更新模型参数\n\n$\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{v_t+\\epsilon}}m_t$\n\n* 梯度就是偏导数组成的向量，即多元/多参数、参数为向量时\n* 梯度和X的形状一样，元素告诉我们相关方向上函数f的斜率\n* 梯度指向函数增加最快的方向，负梯度方向即下降最快方向\n* 则位置任意方向斜率=梯度与单位方向向量的点积\n* 根据梯度决定下一次更新方向 \n* $\\nabla_WL=\\frac{1}{N}\\sum_i\\nabla_WL_i(f(x_i,W),y_i)+\\lambda \\nabla_WR(W)$\n* Gradient Descent/梯度下降\n\n```python\nwhile True:\n  dw = compute_grad(loss_fun, data, weights)\n  weight += - step_size * dw\n```\n\n### Stochastic Gradient Descent(SGD)/随机梯度下降\n\n* $m_t=\\eta g_t$\n\n* $v_t=I^2$\n\n\t$\\epsilon=0$\n\n\t$\\theta_{i+1}=\\theta_i-\\eta g_t$\n\n* N过大，只取部分data计算，以估计整体梯度\n\n```python\nwhile True:\n\tdata_batch = sample_training_data(data, 256)\n  dw = compute_grad(loss_fun, data_batch, weights)\n  weight += - step_size * dw\n```\n\n* SGD的问题：\n\n\t* 当对一个方向敏感，对其他方向迟钝，会形成之字形路径，收敛极其缓慢。下图仅二维两个参数\n\n\t\t![](CS231n笔记/sgd_problem.png)\n\n\t* 局部最小值和鞍点处，会卡住。维度增加，鞍点会快速增加\n\n\t\t![](CS231n笔记/sgd_problem2.png)\n\n\t* 易受噪声影响\n\n\t* 步长恒定，速度慢\n\n### SGD+Momentum/结合动量的SGD\n\n* 引入一阶动量\n\n\t$m_t=\\gamma m_{t-1}+\\eta g_t$\n\n```python\nvx = 0\nwhile True:\n  dx = compute_grad(x)\n  vx = rho * vx + learning_rate * dx\n  x -= vx\n```\n\n![](CS231n笔记/sgd_problem1.png)\n\n![SGDM](CS231n笔记/SGDM.jpg)\n\n### SGD+Nesterov\n\n* 不同于SGDM的梯度与速度向量之和的方向作为新的步进方向，Nesterov动量，是先从当前点，沿速度方向步进，在新位置求梯度向量，然后返回起始点向梯度方向步进。\n\n![](CS231n笔记/SGD+Nesterov.png)\n\n* 凸优化问题较好，非凸会有问题\n* $v_{t+1}=\\rho v_t-\\alpha\\nabla f(x_t+\\rho v_t)$\n* $x_{t+1}=x_t+v_{t+1}$\n\n* 以上形式，会导致运算增加。变量代换，便于网络同时求梯度和损失\n\n$y_t=x_t+\\rho v_t$\n\n$v_{t+1}=\\rho v_t-\\alpha\\nabla f(y_t)$\n\n$y_{t+1}=y_t-\\rho v_t + (1+\\rho)v_{t+1}=y_t+v_{t+1}+\\rho(v_{t+1}-v_t)$\n\n```python\ndx = compute_gradient(x)\nold_v = v\nv = rho * v - lr * dx\nx += -rho * old_v + (1 + rho) * v\n```\n\n### AdaGrad  \n\n**SGD、SGD-M均是以相同的学习率去更新$\\theta$的各个分量。而深度学习模型中往往涉及大量的参数，不同参数的更新频率往往有所区别。对于更新不频繁的参数，我们希望单次步长更大，多学习一些知识；对于更新频繁的参数，我们则希望步长较小，使得学习到的参数更稳定，不至于被单个样本影响太多。即自适应学习率。**\n\n* 引入二阶动量，加速非敏方向，减慢敏感方向速度\n\n$v_t=diag(\\sum^t_{i=1}g^2_{i,1},\\sum^t_{i=1}g^2_{i,2},\\cdots,\\sum^t_{i=1}g^2_{i,d})$\n\n$v_t\\in R^{d\\times d}$，对角矩阵，元素为参数第$i$维从初始时刻到$t$时的梯度平方和，学习率等效为$\\eta/\\sqrt{v_t+\\epsilon}$，对此前频繁更新的参数，其二阶动量的对应分量较大，学习率就小，反之同理\n\n```python\ngrad_squared = 0\nwhile True:\n  dx = compute_grad(x)\n  grad_squared += dx * dx\n  x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n* 步长越来越小，凸函数时是好的特性（接近极值时减慢、收敛），非凸时不好（局部极值卡住）\n\n### RMSProp\n\n* 计算二阶动量时只关注最近的下降梯度，其二阶动量采用*指数移动平均公式*计算，这样即可避免二阶动量持续累积的问题。优点保留，但存在平方项持续减少，训练缓慢的隐患\n\n\t$v_t=\\beta_2 v_{t-1}+(1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)​$\n\n```python\ngrad_squared = 0\nwhile True:\n  dx = compute_grad(x)\n  grad_squared = decay_rate * grad_squared + (1 - decay_rate) * dx * dx\n  x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n### Adam\n\n* 对一阶动量也用指数移动平均公式\n\n\t$m_t=\\eta[\\beta_1m_{t-1}+(1-\\beta_1)g_t]$\n\n\t$m_t=\\beta_1m_{t-1}+(1-\\beta_1)g_t$\n\n\t$v_t=\\beta_2 v_{t-1}+（1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)$\n\n\t$\\hat{m_t}=\\frac{m_t}{1-\\beta^t_1}$\n\n\t$\\hat{v_t}=\\frac{v_t}{1-\\beta^t_2}$\n\n\t$\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{\\hat{v_t}+\\epsilon}}\\hat{m_t}$\n\n* 结合了SGD、动量、AdaGrad/RMSProp\n\n\t* 动量momentum：克服鞍点、梯度为0但非极值点等一系列问题\n\t* AdaGrad/RMSProp：减少敏感方向的权重，增加非敏方向权重\n\t* 偏置校正：以防初始化不佳时初期除以很小的数导致步长过长\n\n* 实践证明，虽然在训练早期 Adam 拥有出色的收敛速度，使用其训练的模型的最终泛化能力却并不如使用朴素 SGD 训练的好（体现在 Adam 训练的模型最终收敛时的 test error 更大），结果可能不收敛，可能找不到全局最优解。二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得二阶动量可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nfor t in range(num_iterations):\n  dx = compute_gradient(x)\n  first_moment = rho * first_moment + (1 - rho) * dx\t# Momentum\n  second_moment = decay_rate * second_moment + (1 - decay_rate) * dx * dx\t# AdaGrad/RMSProp\n  first_unbias = first_moment / (1 - rho ** t)\n  second_unbias = second_moment/ (1 - decay_rate ** t)\t# Bias correction\n  x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\t# AdaGrad/RMSProp\n```\n\n* 典型起始参数设置：\n\n\t* beta1 = 0.9\n\t* beta2 = 0.999\n\t* learning_rate = 1e-3 or 5e-4\n\n### GIF\n\n![](CS231n笔记/optimizations on loss surface contours.gif)\n\n不同算法在损失面等高线图中的学习过程，它们均同同一点出发，但沿着不同路径达到最小值点。其中 Adagrad、Adadelta、RMSprop 从最开始就找到了正确的方向并快速收敛；SGD 找到了正确方向但收敛速度很慢；SGD-M 和 NAG 最初都偏离了航道，但也能最终纠正到正确方向，SGD-M 偏离的惯性比 NAG 更大。\n\n![](CS231n笔记/optimizations on saddle point.gif)\n\n不同算法在鞍点处的表现。这里，SGD、SGD-M、NAG 都受到了鞍点的严重影响，尽管后两者最终还是逃离了鞍点；而 Adagrad、RMSprop、Adadelta 都很快找到了正确的方向。\n\n### AdaBound\n\n*Adaptive Gradient Methods with Dynamic Bound of Learning Rate 动态裁剪学习率的自适应梯度下降方法*\n\n#### 背景\n\n* [The Marginal Value of Adaptive Gradient Methods in Machine Learning](http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning). 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。**推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。**\n\n* [On the Convergence of Adam and Beyond](http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ). ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。\n\n\t主要攻击的是 Adam 有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但个人认为这篇 paper 的**意义十分有限，同时有很大误导性**。\n\n\t其一，作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为**这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值**，极端构造下的收敛性，并不意味着什么。\n\n\t其二，作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，**training loss 的意义对于一个模型是十分有限的**。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，**Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差**。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 [Experiments with AMSGrad](http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/) 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。\n\n\t其三，最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。\n\n\t相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的 performance 对模型而言才是更加重要的性质。\n\n* [Improving Generalization Performance by Switching from Adam to SGD](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628). 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。**实验表明训练后期更新步长过小也是原因之一。**\n\n* 综上而言，**在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向**。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。\n\n#### 论文内容\n\n1. 初步试验：\n\n\t使用Adam算法，在ResNet-34（残差网络模型，复杂度低）中随机选取了9个卷积核和1个全连接层偏置向量，并从中再各随机取样一个维度的变量，统计其在CIFAR-10上训练末期的学习率。采样参数的学习率，每个单元格包含一个通过对学习率进行对数运算得到的值。颜色越浅的单元格代表越小的学习率。可见在后期确实存在学习率的极端值。\n\n\t![](CS231n笔记/AdaBound_figure1.png)\n\n2. theorem3 证明极端学习率确实存在潜在的负面影响。\n\n3. 对学习率动态裁剪，将实际学习率限制在下界$\\eta_l$ 和上界$\\eta_u$之间。\n\n  ![](CS231n笔记/AdaBound_clip.png)\n\n  容易发现，SGD 和 Adam 分别是应用梯度裁剪的特殊情况：学习率为$\\alpha^{*}$的SGD可视为$\\eta_𝑙=\\eta_𝑢=𝛼^∗$；Adam可视为 $\\eta_𝑙=0$ ,$\\eta_𝑢=\\infty$。其他取值则介于两者之间。那么，如果用两个关于 t 的函数来取代固定值作为新的上下界，其中$\\eta_l(t)$从0逐渐收敛至$\\alpha^*$，$\\eta_u(t)$从$\\infty$也逐渐收敛至$\\alpha^*$，那么我们就成功实现了从Adam到SGD的动态过渡。在这一设置下，在训练早期由于上下界对学习率的影响很小，算法更加接近于Adam；而随着时间增长裁减区间越来越收紧，模型的学习率逐渐趋于稳定，在末期更加贴近于SGD。\n\n4. 结果在训练前期可以快速且平滑收敛的情况下，同时在末期得到了优秀的最终性能，可以取得与 SGD 类似甚至更好的结果。\n\n5. 对超参数更低的敏感性，更高的鲁棒性。\n\n---\n\n\n\n## Back-propagation/反向传播\n\n* 将复杂函数化为计算图的形式，递归地调用链式法则，计算每个变量的梯度\n\n* 加法门\n\n\t* gradient distributor/梯度传递\n\t* 两下游梯度 = 上游的梯度\n\n* max门\n\n\t* gradient router/梯度路由\n\t* 小的下游梯度为0，大的下游梯度 = 上游的梯度\n\n* 乘法门\n\n\t* gradient switcher/梯度转换\n\t* 获取上游梯度，根据另一下游分支的值对本下游缩放\n\n* 当一个下游节点接两个上游节点时，梯度再次相加\n\n* Jacobian matrix/雅可比矩阵\n\t$$\n\t\\begin{matrix}\n\t\\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n}\\\\\\\n\t\\vdots & \\ddots & \\vdots\\\\\\\n\t\\frac{\\partial y_m}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\\\\\\\n\t\\end{matrix}\n\t$$\n\n* 高维情况时，如输入为向量，梯度变为了雅可比矩阵\n\n* $\\frac{\\partial L}{\\partial x}=\\frac{\\partial f}{\\partial x} \\frac{\\partial L}{\\partial f}$，$\\frac{\\partial f}{\\partial x}$即为雅可比矩阵\n\n* $\n\tq = Wx = \n\t\\begin{pmatrix}\n\tW_{1,1}x_1+\\cdots+W_{1,n}x_n\\\\\\\n\t\\vdots\\\\\\\n\tW_{n,1}x_1+\\cdots+W_{n,n}x_n\\\\\\\n\t\\end{pmatrix}\n\t$\n\n* $\n\t\\frac{\\partial q_k}{\\partial W_{i,j}}=1_{k=j}x_j\n\t$\n\n* $\\frac{\\partial q_k}{\\partial x_i}=W_{k,i}$\n\n* 向量梯度大小与原向量保持一致，梯度的每个元素代表对最终函数的影响大小\n\n---\n\n\n\n## Regularization/正则化\n\n* 减轻模型复杂度，避免过拟合，提高模型效果\n* 增加随机噪声\n* 通常采用Batch Normalization即可，过拟合时采用以下方法\n\n###  Lp范数惩罚\n\n* $L=... + \\lambda R(W)$\n\n* L2 regularization：$R(W)=\\sum_k\\sum_lW_{k,l}^2$\n\t* 对W的欧式范数进行惩罚\n* L1 regularization：$R(W)=\\sum_k\\sum_l\\mid W_{k,l}\\mid$\n\t* 鼓励W稀疏\n\n### Dropout\n\n* 每次正向传递时，在每一层随机将一部分神经元置0，且每次被置0的神经元不完全相同\n\n```python\ndef train_step(X)：\n\tH1 = np.maximum(0, np.dot(W1, X) + b1)\n\tU1 = np.random.rand(*H1.shape) < p # dropout mask\n\tH1 *= U1 # drop!\n  out = np.dot(W2, H1) + b2\n```\n\n* 避免特征相适应，降低过拟合 \n* 单一模型集成学习\n* 测试时，乘以dropout概率\n\n```python\ndef predict(X):\n  H1 = np.maximum(0, np.dot(W1, X) + b1) * p\n  out = np.dot(W2, H1) + b2\n```\n\n### Data Augmentation/数据增强\n\n* 使用翻转、裁剪、色彩抖动等方法处理过的图片进行训练\n\n\n\n---\n\n## Transfer Learing/迁移学习\n\n- 大模型，小数据训练，易过拟合，此法同样解决过拟合\n- 小数据集与大数据集相似时：先在大数据集预训练的模型，要适应小数据集，可先冻结卷积、池化层，仅重新训练全连接层或线性分类器\n- 不相似时要重训练大部分层\n\n\n\n---\n\n\n\n## Neural Network/神经网络\n\n![](CS231n笔记/1062917-20161117212457248-1468090428.png)\n\n*   包含若干个线性层，层与层之间用非线性函数连接\n\n*   2-layer Neural Network $f=W_2*max(0,W_1 x)$\n\n\t*   此处max为非线性函数且有很多可选\n\n*   每个节点接收多个输入，输出为$f(\\sum_i w_i x_i +b)$\n\n\t*   f为activation function/激活函数\n\n*   将每层看作一个向量，一组神经元的集合，进而利用矩阵乘法计算输出结果\n\n\t```python\n\th1 = f(np.dot(W1, x) + b1)\n\tout = np.dot(W2, h1) + b2\n\t```\n\n*   多个输入x1, x2, x3为样本的多个特征值；多个样本时采用vectorization向量化，把样本压缩为向量/矩阵？同时计算。\n\n*   输入$(N,D)$，隐层$(D,H)$，**隐层神经元个数**$H$，从数学角度来说感觉是每个sample都输入所有神经元。\n\n*   前向传播Forward Propagation：从input，经过一层层的layer，不断计算每一层的结果z和激活值a，最后得到输出y^ 的过程，计算出了y^，就可以根据它和真实值y的差别来计算损失（loss）。\n\n\t*   Layer i:\n\t\t*    Z[i] = W[i]·A[i-1] + b[i]\n\t\t*    A[i] = σ(Z[i]) (sigmoid)\n\t*   L(loss)：样本损失\n\t*   J(cost)：样本集的损失，L和的平均\n\t\t*   J(W,b) = ΣL()/n\n\n*   反向传播Backward Propagation：根据L(y^,y)、J(W,b)来反方向地计算每一层的z、a、w、b的偏导数（梯度），从而更新参数。\n\n*   深层神经网络中，常采用RelU激活函数（求梯度更快，防止梯度消失），输出层采用sigmoid。\n\n*   参数维度：m个样本，共L层，当前l层，第l层单元数n[l]，\n\n\t*   W[l]:(n[l],n[l-1]), 即n[l]行、n[l-1]列\n\t*   b[l]:(n[l],1)\n\t*   z[l]:(n[l],1) Z[l]:(n[l],m)\n\t*   a[l]:(n[l],1) A[l]:(n[l],m)\n\t*   X:(n[0],m) Y:(1,m)\n\n---\n\n\n\n## Convolutional Neural Networks, CNN/卷积神经网络\n\n*   保持空间结构；在传统神经网络中每个神经元都要与图片上每个像素相连接，这样的话就会造成权重的数量巨大造成网络难以训练，而在含有卷积层的的神经网络中每个神经元的权重个数都是卷积核的大小，这样就相当于没有神经元只与对应图片部分的像素相连接。这样就极大的减少了权重的数量。\n*   核filter，例如$5*5*3$。参数学习得到。卷积过程中参数不变，**通过一个卷积核的操作提取了原图的不同位置的同样特征。**\n*   **每个卷积核，在输入的整个深度上点积。**运算时，实质上也是先化为一维向量做点积。但有多个卷积核，所以输出为output size * output size * output num。\n*   卷积输出size：$(N-F)/stride+1$\n\t*   N：输入size，F：卷积核size，stride：步长\n*   也有用0填充输入图片四周，使输出size保持不变。\n\n---\n\n\n\n## Pooling/池化\n\n*   对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征\n*   深度不变。通常filter不重叠，不填0\n*   常用：$2*2$ 步长2，或$3*3$ 步长3\n\n---\n\n\n\n## Activation Functions/激活函数\n\n### sigmoid(x)​\n\n![](CS231n笔记/sigmoid.png)\n\n* $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n* 元素压缩至$[0,1]$范围\n* 问题：\n * 饱和神经元使得梯度为0，无法得到合适的梯度流\n\t* 输出不以0为中心，x为正时w总为正或负，梯度更新效率低\n\t* 指数计算代价较大\n\n### tanh(x)​\n\n![](CS231n笔记/tanh.png)\n\n* 压缩至$[-1,1]$\n* 输出以0为中心\n* 问题：饱和时梯度为0 \n\n### ReLU(Rectified Linear Unit)\n\n![](CS231n笔记/relu.png)\n\n* $f(x)=max(0,x)$\n* 正区域不会饱和\n* 函数简单，计算快，收敛快\n* 生物学上更合理\n* 问题\n * 输出不以0为中心\n\t* 负半轴全饱和\n\t* 及其导致的Dead ReLU：反向传播中，大的梯度更新，使w变化，输入负数增加，函数关闭，参数w得不到更新，导致永久关闭\n\n### Leaky ReLU\n\n![](CS231n笔记/leaky relu.png)\n\n* $f(x)=max(0.01x,x)$\n* 不会挂掉\n\n### ELU(Exponential Linear units)\n\n![](CS231n笔记/elu.png)\n\n* $f(x)=\\begin{cases}x\\qquad\\qquad if x>0\\\\\\ \\alpha(e^x-1)\\quad ifx\\leq0 \\end{cases}$\n\n* 输出均值近0\n* 负半轴近似饱和\n\n### Maxout\n\n* $max(w_1^Tx+b_1,w_2^Tx+b_2)$\n* 不提前点积\n* 泛化ReLU，不饱和，不消亡 \n* 问题：参数加倍\n\n### 总结\n\n* 常用ReLU，注意学习率\n* 少用sigmoid\n\n---\n\n\n\n## Data Preprocessing/数据预处理\n\n* zero-centered data/零中心化\n\n\tX -= np.mean(X, axis = 0)\n\n* normalized data/归一化，图像处理不常用\n\n\tX /= np.std(X, axis = 0)\n\n* 减去mean image\n\n* 减去单通道均值\n\n* 训练与预测阶段都需进行同样预处理（应用同样的参数、均值）\n\n---\n\n\n\n## Weight Initialization/初始化权重\n\n* 输入输出方差相同，Xavier initialization\n\n\tW = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in/2)\n\n---\n\n\n\n## Batch Normalization/批量归一化\n\n* 背景：深层网络在非线性变化前，激活的输入值的分布逐渐发生偏移变动。当整体分布靠近激活函数上下限端时，反向传播时的梯度消失，最终导致深层网络收敛越来越慢\n\n* 目的：数据转化为单位高斯数据，降低层之间输入数据分布变化，即使数据落入非线性函数的敏感区域，避免梯度消失，提速\n\n* 带来的问题：每层都通过BN，相当于多层线性函数，深度网络失去意义\n\n* 解决：对经过BN的x：$y=scale*x+shift$。对每个神经元增加两个学习参数，相当于使非线性函数的值从线性区往非线性区偏移挪动。变换重构$y^{(k)}=\\gamma^{(k)}\\hat{x}^{(k)}+\\beta^{(k)}$，则$\\gamma^{(k)}=\\sqrt{Var[x^{(k)}]} \\quad \\beta^{(k)}=E[x^{(k)}]$时可恢复原始数据，控制饱和程度。**核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢**\n\n* 通常在FC、卷积层后插入\n\n* 训练过程：$\\hat{x}^{(k)}=\\frac{x^{(k)}-E[x^{(k)}]}{\\sqrt Var[x^{(k)}]}$\n\n\t![Batch Normalization](CS231n笔记/bn_forward.png \"forward\")\n\n\t![bn_backward](CS231n笔记/bn_backward.jpg \"backward\")\n\n\t预测过程：用从所有训练实例中获得的统计量代表期望和方差\n\n\n$$\nE[x]\\leftarrow E_B[\\mu_B]\t\\\\\nVar[x]\\leftarrow\\frac{m}{m-1}E_B[\\sigma_B^2] \\\\\ny=\\frac{\\gamma}{\\sqrt{Var[x]+\\varepsilon}}*x+(\\beta-\\frac{\\gamma*E[x]}{\\sqrt{Var[x]+\\varepsilon}})\n$$\n\n\n\n---\n\n\n\n## Babysitting the Learning Process/观察学习过程\n\n* 数据预处理\n* 选择网络结构\n* 初始化网络，前向传播\n* 观察损失，和添加正则化项后的损失\n* 从小数据集训练，关闭正则化，sgd，观察loss能否为0、accuracy能否为1\n* 正式训练，全部数据，开启正则化\n* 调整学习率（最重要参数），过小时梯度更新小，loss变化小，$\\eta$常为$1e-3$到$1e-5$之间 \n\n---\n\n## Hyper-parameter Optimization/超参数设置\n\n* 交叉验证，训练集训练，验证集验证\n* 首先几个epoch粗略观察超参是否合理，确定合理区间\n* loss激增时说明方向有误\n\n![](CS231n笔记/loss-learing rate.png \"loss~learning rate\") \n\n\n\n---\n\n## PyTorch\n\n* 定义三个抽象\n\t* Tensor 张量，类似数组\n\t* Variable 变量，计算图中节点，储存数据和梯度\n\t* Module 类/模块，是一个神经网络层，储存状态和参数\n\n### Tensor/张量\n\n```python\n# 简单的神经网络示例(使用张量)\nimport torch\n\n# dtype = torch.FloatTensor\ndtype = torch.cuda.FloatTensor\t# GPU\n\nN, D_in, H, D_out = 64, 1000, 100, 10\nx = torch.randn(N, D_in).type(dtype)\ny = torch.randn(N, D_out).type(dtype)\nw1 = torch.randn(D_in, H).type(dtype)\nw2 = torch.randn(H, D_out).type(dtype)\n\nlearning_rate = 1e-6\nfor t in range(500):\n  h = x.mm(w1)\n  h_relu = h.clamp(min=0)\n  y_pred = h_relu.mm(w2)\n  loss = (y_pred - y).pow(2).sum()\n  \n  grad_y_pred = 2.0 * (y_pred - y)\n  grad_w2 = h_relu.t().mm(grad_y_pred)\n  grad_h_relu = grad_y_pred.mm(w2.t())\n  grad_h = grad_h_relu.clone()\n  grad_h[h < 0] = 0\n  grad_w1 = x.t().mm(grad_h)\n  \n  w1 -= learning_rate * grad_w1\n  w2 -= learning_rate * grad_w2\n```\n\n### Variable/变量\n\n* X.data 张量类型\n* X.grad 变量类型，梯度，与data同shape\n* X.grad.data 张量类型，梯度的张量\n* PyTorch中，张量、变量相同API\n\n```python\nimport torch\nfrom torch.autograd import Variable\n\nN, D_in, H, D_out = 64, 1000, 100, 10\nx = Variable(torch.randn(N, D_in), requires_grad=False)\ny = Variable(torch.randn(N, D_out), requires_grad=False)\nw1 = Variable(torch.randn(D_in, H), requires_grad=True)\nw2 = Variable(torch.randn(H, D_out), requires_grad=True)\n\nlearning_rate = 1e-6\nfor t in range(500):\n  y_prred = x.mm(w1).clamp(min=0).mm(w2)\n  loss = (y_pred - y).pow(2).sum()\n  \n  if w1.grad: w1.grad.data.zero_()\n  if w2.grad: w2.grad.data.zero_()\n  loss.backward()\n  \n  w1.data -= learning_rate * w1.grad.data\n  w2.data -= learning_rate * w2.grad.data\n```\n\n### nn/高级封装\n\n```python\nimport torch\nfrom torch.autograd import Varible\n\nN, D_in, H, D_out = 64, 1000, 100, 10\nx = Variable(torch.randn(N, D_in))\ny = Variable(torch.randn(N, D_out), requires_grad=False)\n\n# 把模型定义为层的序列\nmodel = torch.nn.Sequential(torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out))\n# nn中定义了一些损失函数\nloss_fn = torch.nn.MSELoss(size_average=False)\n\n# 给模型喂数据，得到预测以计算损失\nlearning_rate = 1e-4\nfor t in tange(500):\n  y_pred = model(x)\n  loss = loss_fn(y_pred, y)\n  \n  # 计算梯度\n  model.zero_grad()\n  loss.backward()\n  \n  # 在所有参数上循环，更新参数 \n  for param in model.parameters():\n    param.data -= learning_rate * param.grad.data\n```\n\n### optimizer/优化器\n\n* 将参数更新的流程抽象出来，并执行更新法则\n\n* 以上例为基础：\n\n* 14行后添加如下，意为要对参数采用此法则、此学习率更新\n\n\t`optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)`\n\n* 23~25行的参数更新改为：`optimizer.step()`\n\n### Module/类\n\n* 神经网络层，输入输出为变量类型\n* 包含参数或其他模块\n* 可以使用autograd定义新Module\n\n```python\nimport torch\nform torch.autograd import Variable\n\n# 这个类把整个模型定义成nn类中的一个新类，\nclass TwoLayerNet(torch.nn.Module):\n  def _init_(self, D_in, H, D_out):\n    super(TwoLayerNet, self)._init_()\n    self.linear1 = torch.nn.Linear(D_in, H)\n    self.linear2 = torch.nn.Linear(H, D_out)\n    \n  def forward(self, x):\n    h_relu = self.linear1(x).clamp(min=0)\n    y_pred = self.linear2(h_relu)\n    return y_pred\n  \nN, D_in, H, D_out = 64, 1000, 100, 10\n\nx = Variable(torch.randn(N, D_in))\ny = Variable(torch.randn(N, D_out), requires_grad=False)\n\nmodel = TwoLayerNet(D_in,, H, D_out)\n\ncriterion = torch.nn.MSELoss(size_average=False)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\nfor t in range(500):\n  y_pred = model(x)\n  loss = criterion(y_pred, y)\n  \n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()\n```\n\n### DataLoader/数据加载\n\n* 可以建立分批处理，也可以执行多线程 \n\n```python\nimport torch\nfrom torch.autograd import Variable\nform torch.utils.data import TensorDataset, DataLoader\n\nN, D_in, H, D_out = 64, 1000, 100, 10\n\nx = torch.randn(N, D_in)\ny = torch.randn(N, D_out)\n\nloader = DataLoader(TensorDataset(x, y), batch_size=8)\n\nmodel = TwoLayerNet(D_in, H, D_out)\n\nceiterion = torch.nn.MSELoss(size_average=False)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\nfor epoch in range(10):\n  for x_batch, y_batch in loader:\n    x_var, y_var = Variable(x), Variable(y)\n    y_pred = model(x_var)\n    loss = criterion(y_pred, y_var)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n```\n\n### Pretrained Model/预训练模型\n\n```python\nimport torch\nimport torchvision\n\nalexnet = torchvision.models.alexnet(pretrained=True)\n```\n\n### else/其他\n\n* visdom 可视化的包\n* 可以通过重写前向、反向传播函数定义新的Autograd Function\n\n```python\nclass ReLU(torch.autograd.Function):\n  def forwar(self, x):\n    self.save_for_backward(x)\n    return x.clamp(min=0)\n  \n  def backward(self, grad_y):\n    x, = self.saved_tensors\n    grad_input = grad_y.clone()\n    grad_input[x < 0] = 0\n    return grad_input\n```\n\n","source":"_posts/CS231n笔记.md","raw":"---\ntitle: CS231n笔记\nmathjax: true\ndate: 2020-06-18 20:25:07\ntags: AI\n---\n\n\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# Project\n\n*   判别式方法 -> 深度学习类\n*   [目标跟踪算法综述](https://wenku.baidu.com/view/552db3a780c758f5f61fb7360b4c2e3f56272517.html)\n*   ![](CS231n笔记/主流.png)\n*   为了扩展CNN在目标跟踪领域的能力，需要大量的训练数据，但这在目标跟踪中是很难做到的。MDNet[14]算法提出了一种解决该问题的思路。算法采用VGG-M作为网络初始化模型，后接多个全连接层用作分类器。训练时，每一个跟踪视频对应一个全连接层，学习普遍的特征表示用来跟踪。跟踪时，去掉训练时的全连接层，使用第一帧样本初始化一个全连接层，新的全连接层在跟踪的过程中继续微调，来适应新的目标变化。这种方法使得特征更适合于目标跟踪，效果大大提升。由此可以看出，通过视频训练的网络更适合目标跟踪这一任务\n*   速度改进：虽然深度特征具有传统特征无法比拟的抗干扰能力，但是一般提取速度较慢，而且特征中存在大量冗余。当算法精度达到一定标准之后，很多方法开始着力解决算法速度问题。**孪生网络**[19]是其中的一个典型例子，采用两路神经网络分别输入目标模板和搜索图像块，用来进行模板匹配或候选样本分类。其中一路神经网络对于模板信息的保存可以提供跟踪物体先验信息，取代网络在线更新，大大节省了速度。另外，**对深度特征进行降维或自适应选择**也是加速算法的有效途径。由于深度神经网络复杂的计算及模型更新时繁琐的系数，现存大部分深度目标跟踪算法速度都比较慢。很多深度目标跟踪算法采用**小型神经网络（如VGG-M）**来提特征。另外，跟踪中只给定第一帧目标位置，缺少跟踪物体先验信息，这就**要求模型实时更新**来确保跟踪精度，而这在深度目标跟踪算法中往往非常耗时。一些算法采用孪生网络结构来保存先验信息，代替模型在线更新，使得算法速度得以提高。深度特征的高维度也会影响跟踪算法的速度，如果能够提出有效的特征压缩方法，不管对算法速度还是精度都会有所帮助。只有高速且有效地算法才具有实际的应用价值\n\n---\n\n\n\n\n\n# CS231n\n\n## Data Driven/数据驱动\n\n*   以数据/样本驱动，训练模型，进行预测\n\n```python\ndef train(images, labels):\n    #Machine learning\n    return model\n\ndef predict(model, test_images):\n    #use model to predict labels\n    return test_labels\n```\n\n*   train_data/训练集：以不同的超参数训练模型\n*   validation_data/验证集：选出效果最优的超参数\n*   test_data/测试集：仅预测算法在未见新数据上的\n\n---\n\n\n\n## Linear Classifier/线性分类\n\n* 将训练数据浓缩于参数W/θ中，但每个类别只能学习一个单独模板\n\n* $f(x,W)=Wx+b$\n * W:$10*3072$ ，有十类时\n\t* x:$3072*1$ ， 图片为$32*32*3$时\n\t* b:$10*1$ ， 有十类时\n\t* 结果得分:$10*1$\n\n---\n\n\n\n## Loss Function/损失函数\n\n* 将W输入，输出得分，定量地估计W的好坏\n* $f(x, W)=Wx$\n* $L=\\frac{1}{N}\\sum_iL_i(f(x_i,W),y_i)+\\lambda R(W)$\n * N：样本数\n\t* $\\lambda R(W)$：正则化项\n* Multi-class SVM LOSS：\n * $L_i=\\sum_{j\\not=y_i}\\max(0,s_j-s_{y_i}+margin)$\n\t* $s=f(x,W)$\n\t* i：当前对第i个样本的得分计算\n\t* $s_j$：当前样本对第j类的得分\n\t* $s_{y_i}$：当前样本对正确分类组的得分\n\t* margin：适当边距\n\t* 释义：不正确分类上损失之和，且正确分类得分超出错误分类得分margin以上时损失为0\n* Softmax Loss：\n * $P(Y=k\\mid X=x_i)=\\frac{e^s k}{\\sum_j e^s j}$\n\t* $s=f(x_i;W)$\n\t* 最小化$L_i=-\\log P(Y=y_i\\mid X=x_i)$\n\t* 希望正确分类的概率趋近1\n\n---\n\n\n\n## Optimization/优化/梯度下降\n\n梯度下降是指，在给定待优化的模型参数$\\theta\\in R^d$和目标函数$J(\\theta)$，算法通过沿梯度 $\\nabla _\\theta J(\\theta)$的相反方向更新$\\theta$来最小化$J(\\theta)$。学习率$\\eta$决定了每一时刻的更新步长。\n\n流程如下：\n\n1. 计算目标函数关于参数的梯度\n\n\t$g_t=\\nabla_\\theta J(\\theta)$\n\n2. 根据历史梯度计算一阶和二阶动量\n\n$m_t=\\phi (g_1,g_2,\\cdots ,g_t)$\n\n$v_t=\\psi(g_1,,g_2,\\cdots ,g_t)$\n\n3. 更新模型参数\n\n$\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{v_t+\\epsilon}}m_t$\n\n* 梯度就是偏导数组成的向量，即多元/多参数、参数为向量时\n* 梯度和X的形状一样，元素告诉我们相关方向上函数f的斜率\n* 梯度指向函数增加最快的方向，负梯度方向即下降最快方向\n* 则位置任意方向斜率=梯度与单位方向向量的点积\n* 根据梯度决定下一次更新方向 \n* $\\nabla_WL=\\frac{1}{N}\\sum_i\\nabla_WL_i(f(x_i,W),y_i)+\\lambda \\nabla_WR(W)$\n* Gradient Descent/梯度下降\n\n```python\nwhile True:\n  dw = compute_grad(loss_fun, data, weights)\n  weight += - step_size * dw\n```\n\n### Stochastic Gradient Descent(SGD)/随机梯度下降\n\n* $m_t=\\eta g_t$\n\n* $v_t=I^2$\n\n\t$\\epsilon=0$\n\n\t$\\theta_{i+1}=\\theta_i-\\eta g_t$\n\n* N过大，只取部分data计算，以估计整体梯度\n\n```python\nwhile True:\n\tdata_batch = sample_training_data(data, 256)\n  dw = compute_grad(loss_fun, data_batch, weights)\n  weight += - step_size * dw\n```\n\n* SGD的问题：\n\n\t* 当对一个方向敏感，对其他方向迟钝，会形成之字形路径，收敛极其缓慢。下图仅二维两个参数\n\n\t\t![](CS231n笔记/sgd_problem.png)\n\n\t* 局部最小值和鞍点处，会卡住。维度增加，鞍点会快速增加\n\n\t\t![](CS231n笔记/sgd_problem2.png)\n\n\t* 易受噪声影响\n\n\t* 步长恒定，速度慢\n\n### SGD+Momentum/结合动量的SGD\n\n* 引入一阶动量\n\n\t$m_t=\\gamma m_{t-1}+\\eta g_t$\n\n```python\nvx = 0\nwhile True:\n  dx = compute_grad(x)\n  vx = rho * vx + learning_rate * dx\n  x -= vx\n```\n\n![](CS231n笔记/sgd_problem1.png)\n\n![SGDM](CS231n笔记/SGDM.jpg)\n\n### SGD+Nesterov\n\n* 不同于SGDM的梯度与速度向量之和的方向作为新的步进方向，Nesterov动量，是先从当前点，沿速度方向步进，在新位置求梯度向量，然后返回起始点向梯度方向步进。\n\n![](CS231n笔记/SGD+Nesterov.png)\n\n* 凸优化问题较好，非凸会有问题\n* $v_{t+1}=\\rho v_t-\\alpha\\nabla f(x_t+\\rho v_t)$\n* $x_{t+1}=x_t+v_{t+1}$\n\n* 以上形式，会导致运算增加。变量代换，便于网络同时求梯度和损失\n\n$y_t=x_t+\\rho v_t$\n\n$v_{t+1}=\\rho v_t-\\alpha\\nabla f(y_t)$\n\n$y_{t+1}=y_t-\\rho v_t + (1+\\rho)v_{t+1}=y_t+v_{t+1}+\\rho(v_{t+1}-v_t)$\n\n```python\ndx = compute_gradient(x)\nold_v = v\nv = rho * v - lr * dx\nx += -rho * old_v + (1 + rho) * v\n```\n\n### AdaGrad  \n\n**SGD、SGD-M均是以相同的学习率去更新$\\theta$的各个分量。而深度学习模型中往往涉及大量的参数，不同参数的更新频率往往有所区别。对于更新不频繁的参数，我们希望单次步长更大，多学习一些知识；对于更新频繁的参数，我们则希望步长较小，使得学习到的参数更稳定，不至于被单个样本影响太多。即自适应学习率。**\n\n* 引入二阶动量，加速非敏方向，减慢敏感方向速度\n\n$v_t=diag(\\sum^t_{i=1}g^2_{i,1},\\sum^t_{i=1}g^2_{i,2},\\cdots,\\sum^t_{i=1}g^2_{i,d})$\n\n$v_t\\in R^{d\\times d}$，对角矩阵，元素为参数第$i$维从初始时刻到$t$时的梯度平方和，学习率等效为$\\eta/\\sqrt{v_t+\\epsilon}$，对此前频繁更新的参数，其二阶动量的对应分量较大，学习率就小，反之同理\n\n```python\ngrad_squared = 0\nwhile True:\n  dx = compute_grad(x)\n  grad_squared += dx * dx\n  x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n* 步长越来越小，凸函数时是好的特性（接近极值时减慢、收敛），非凸时不好（局部极值卡住）\n\n### RMSProp\n\n* 计算二阶动量时只关注最近的下降梯度，其二阶动量采用*指数移动平均公式*计算，这样即可避免二阶动量持续累积的问题。优点保留，但存在平方项持续减少，训练缓慢的隐患\n\n\t$v_t=\\beta_2 v_{t-1}+(1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)​$\n\n```python\ngrad_squared = 0\nwhile True:\n  dx = compute_grad(x)\n  grad_squared = decay_rate * grad_squared + (1 - decay_rate) * dx * dx\n  x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n```\n\n### Adam\n\n* 对一阶动量也用指数移动平均公式\n\n\t$m_t=\\eta[\\beta_1m_{t-1}+(1-\\beta_1)g_t]$\n\n\t$m_t=\\beta_1m_{t-1}+(1-\\beta_1)g_t$\n\n\t$v_t=\\beta_2 v_{t-1}+（1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)$\n\n\t$\\hat{m_t}=\\frac{m_t}{1-\\beta^t_1}$\n\n\t$\\hat{v_t}=\\frac{v_t}{1-\\beta^t_2}$\n\n\t$\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{\\hat{v_t}+\\epsilon}}\\hat{m_t}$\n\n* 结合了SGD、动量、AdaGrad/RMSProp\n\n\t* 动量momentum：克服鞍点、梯度为0但非极值点等一系列问题\n\t* AdaGrad/RMSProp：减少敏感方向的权重，增加非敏方向权重\n\t* 偏置校正：以防初始化不佳时初期除以很小的数导致步长过长\n\n* 实践证明，虽然在训练早期 Adam 拥有出色的收敛速度，使用其训练的模型的最终泛化能力却并不如使用朴素 SGD 训练的好（体现在 Adam 训练的模型最终收敛时的 test error 更大），结果可能不收敛，可能找不到全局最优解。二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得二阶动量可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。\n\n```python\nfirst_moment = 0\nsecond_moment = 0\nfor t in range(num_iterations):\n  dx = compute_gradient(x)\n  first_moment = rho * first_moment + (1 - rho) * dx\t# Momentum\n  second_moment = decay_rate * second_moment + (1 - decay_rate) * dx * dx\t# AdaGrad/RMSProp\n  first_unbias = first_moment / (1 - rho ** t)\n  second_unbias = second_moment/ (1 - decay_rate ** t)\t# Bias correction\n  x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\t# AdaGrad/RMSProp\n```\n\n* 典型起始参数设置：\n\n\t* beta1 = 0.9\n\t* beta2 = 0.999\n\t* learning_rate = 1e-3 or 5e-4\n\n### GIF\n\n![](CS231n笔记/optimizations on loss surface contours.gif)\n\n不同算法在损失面等高线图中的学习过程，它们均同同一点出发，但沿着不同路径达到最小值点。其中 Adagrad、Adadelta、RMSprop 从最开始就找到了正确的方向并快速收敛；SGD 找到了正确方向但收敛速度很慢；SGD-M 和 NAG 最初都偏离了航道，但也能最终纠正到正确方向，SGD-M 偏离的惯性比 NAG 更大。\n\n![](CS231n笔记/optimizations on saddle point.gif)\n\n不同算法在鞍点处的表现。这里，SGD、SGD-M、NAG 都受到了鞍点的严重影响，尽管后两者最终还是逃离了鞍点；而 Adagrad、RMSprop、Adadelta 都很快找到了正确的方向。\n\n### AdaBound\n\n*Adaptive Gradient Methods with Dynamic Bound of Learning Rate 动态裁剪学习率的自适应梯度下降方法*\n\n#### 背景\n\n* [The Marginal Value of Adaptive Gradient Methods in Machine Learning](http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning). 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。**推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。**\n\n* [On the Convergence of Adam and Beyond](http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ). ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。\n\n\t主要攻击的是 Adam 有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但个人认为这篇 paper 的**意义十分有限，同时有很大误导性**。\n\n\t其一，作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为**这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值**，极端构造下的收敛性，并不意味着什么。\n\n\t其二，作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，**training loss 的意义对于一个模型是十分有限的**。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，**Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差**。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 [Experiments with AMSGrad](http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/) 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。\n\n\t其三，最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。\n\n\t相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的 performance 对模型而言才是更加重要的性质。\n\n* [Improving Generalization Performance by Switching from Adam to SGD](http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628). 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。**实验表明训练后期更新步长过小也是原因之一。**\n\n* 综上而言，**在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向**。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。\n\n#### 论文内容\n\n1. 初步试验：\n\n\t使用Adam算法，在ResNet-34（残差网络模型，复杂度低）中随机选取了9个卷积核和1个全连接层偏置向量，并从中再各随机取样一个维度的变量，统计其在CIFAR-10上训练末期的学习率。采样参数的学习率，每个单元格包含一个通过对学习率进行对数运算得到的值。颜色越浅的单元格代表越小的学习率。可见在后期确实存在学习率的极端值。\n\n\t![](CS231n笔记/AdaBound_figure1.png)\n\n2. theorem3 证明极端学习率确实存在潜在的负面影响。\n\n3. 对学习率动态裁剪，将实际学习率限制在下界$\\eta_l$ 和上界$\\eta_u$之间。\n\n  ![](CS231n笔记/AdaBound_clip.png)\n\n  容易发现，SGD 和 Adam 分别是应用梯度裁剪的特殊情况：学习率为$\\alpha^{*}$的SGD可视为$\\eta_𝑙=\\eta_𝑢=𝛼^∗$；Adam可视为 $\\eta_𝑙=0$ ,$\\eta_𝑢=\\infty$。其他取值则介于两者之间。那么，如果用两个关于 t 的函数来取代固定值作为新的上下界，其中$\\eta_l(t)$从0逐渐收敛至$\\alpha^*$，$\\eta_u(t)$从$\\infty$也逐渐收敛至$\\alpha^*$，那么我们就成功实现了从Adam到SGD的动态过渡。在这一设置下，在训练早期由于上下界对学习率的影响很小，算法更加接近于Adam；而随着时间增长裁减区间越来越收紧，模型的学习率逐渐趋于稳定，在末期更加贴近于SGD。\n\n4. 结果在训练前期可以快速且平滑收敛的情况下，同时在末期得到了优秀的最终性能，可以取得与 SGD 类似甚至更好的结果。\n\n5. 对超参数更低的敏感性，更高的鲁棒性。\n\n---\n\n\n\n## Back-propagation/反向传播\n\n* 将复杂函数化为计算图的形式，递归地调用链式法则，计算每个变量的梯度\n\n* 加法门\n\n\t* gradient distributor/梯度传递\n\t* 两下游梯度 = 上游的梯度\n\n* max门\n\n\t* gradient router/梯度路由\n\t* 小的下游梯度为0，大的下游梯度 = 上游的梯度\n\n* 乘法门\n\n\t* gradient switcher/梯度转换\n\t* 获取上游梯度，根据另一下游分支的值对本下游缩放\n\n* 当一个下游节点接两个上游节点时，梯度再次相加\n\n* Jacobian matrix/雅可比矩阵\n\t$$\n\t\\begin{matrix}\n\t\\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n}\\\\\\\n\t\\vdots & \\ddots & \\vdots\\\\\\\n\t\\frac{\\partial y_m}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\\\\\\\n\t\\end{matrix}\n\t$$\n\n* 高维情况时，如输入为向量，梯度变为了雅可比矩阵\n\n* $\\frac{\\partial L}{\\partial x}=\\frac{\\partial f}{\\partial x} \\frac{\\partial L}{\\partial f}$，$\\frac{\\partial f}{\\partial x}$即为雅可比矩阵\n\n* $\n\tq = Wx = \n\t\\begin{pmatrix}\n\tW_{1,1}x_1+\\cdots+W_{1,n}x_n\\\\\\\n\t\\vdots\\\\\\\n\tW_{n,1}x_1+\\cdots+W_{n,n}x_n\\\\\\\n\t\\end{pmatrix}\n\t$\n\n* $\n\t\\frac{\\partial q_k}{\\partial W_{i,j}}=1_{k=j}x_j\n\t$\n\n* $\\frac{\\partial q_k}{\\partial x_i}=W_{k,i}$\n\n* 向量梯度大小与原向量保持一致，梯度的每个元素代表对最终函数的影响大小\n\n---\n\n\n\n## Regularization/正则化\n\n* 减轻模型复杂度，避免过拟合，提高模型效果\n* 增加随机噪声\n* 通常采用Batch Normalization即可，过拟合时采用以下方法\n\n###  Lp范数惩罚\n\n* $L=... + \\lambda R(W)$\n\n* L2 regularization：$R(W)=\\sum_k\\sum_lW_{k,l}^2$\n\t* 对W的欧式范数进行惩罚\n* L1 regularization：$R(W)=\\sum_k\\sum_l\\mid W_{k,l}\\mid$\n\t* 鼓励W稀疏\n\n### Dropout\n\n* 每次正向传递时，在每一层随机将一部分神经元置0，且每次被置0的神经元不完全相同\n\n```python\ndef train_step(X)：\n\tH1 = np.maximum(0, np.dot(W1, X) + b1)\n\tU1 = np.random.rand(*H1.shape) < p # dropout mask\n\tH1 *= U1 # drop!\n  out = np.dot(W2, H1) + b2\n```\n\n* 避免特征相适应，降低过拟合 \n* 单一模型集成学习\n* 测试时，乘以dropout概率\n\n```python\ndef predict(X):\n  H1 = np.maximum(0, np.dot(W1, X) + b1) * p\n  out = np.dot(W2, H1) + b2\n```\n\n### Data Augmentation/数据增强\n\n* 使用翻转、裁剪、色彩抖动等方法处理过的图片进行训练\n\n\n\n---\n\n## Transfer Learing/迁移学习\n\n- 大模型，小数据训练，易过拟合，此法同样解决过拟合\n- 小数据集与大数据集相似时：先在大数据集预训练的模型，要适应小数据集，可先冻结卷积、池化层，仅重新训练全连接层或线性分类器\n- 不相似时要重训练大部分层\n\n\n\n---\n\n\n\n## Neural Network/神经网络\n\n![](CS231n笔记/1062917-20161117212457248-1468090428.png)\n\n*   包含若干个线性层，层与层之间用非线性函数连接\n\n*   2-layer Neural Network $f=W_2*max(0,W_1 x)$\n\n\t*   此处max为非线性函数且有很多可选\n\n*   每个节点接收多个输入，输出为$f(\\sum_i w_i x_i +b)$\n\n\t*   f为activation function/激活函数\n\n*   将每层看作一个向量，一组神经元的集合，进而利用矩阵乘法计算输出结果\n\n\t```python\n\th1 = f(np.dot(W1, x) + b1)\n\tout = np.dot(W2, h1) + b2\n\t```\n\n*   多个输入x1, x2, x3为样本的多个特征值；多个样本时采用vectorization向量化，把样本压缩为向量/矩阵？同时计算。\n\n*   输入$(N,D)$，隐层$(D,H)$，**隐层神经元个数**$H$，从数学角度来说感觉是每个sample都输入所有神经元。\n\n*   前向传播Forward Propagation：从input，经过一层层的layer，不断计算每一层的结果z和激活值a，最后得到输出y^ 的过程，计算出了y^，就可以根据它和真实值y的差别来计算损失（loss）。\n\n\t*   Layer i:\n\t\t*    Z[i] = W[i]·A[i-1] + b[i]\n\t\t*    A[i] = σ(Z[i]) (sigmoid)\n\t*   L(loss)：样本损失\n\t*   J(cost)：样本集的损失，L和的平均\n\t\t*   J(W,b) = ΣL()/n\n\n*   反向传播Backward Propagation：根据L(y^,y)、J(W,b)来反方向地计算每一层的z、a、w、b的偏导数（梯度），从而更新参数。\n\n*   深层神经网络中，常采用RelU激活函数（求梯度更快，防止梯度消失），输出层采用sigmoid。\n\n*   参数维度：m个样本，共L层，当前l层，第l层单元数n[l]，\n\n\t*   W[l]:(n[l],n[l-1]), 即n[l]行、n[l-1]列\n\t*   b[l]:(n[l],1)\n\t*   z[l]:(n[l],1) Z[l]:(n[l],m)\n\t*   a[l]:(n[l],1) A[l]:(n[l],m)\n\t*   X:(n[0],m) Y:(1,m)\n\n---\n\n\n\n## Convolutional Neural Networks, CNN/卷积神经网络\n\n*   保持空间结构；在传统神经网络中每个神经元都要与图片上每个像素相连接，这样的话就会造成权重的数量巨大造成网络难以训练，而在含有卷积层的的神经网络中每个神经元的权重个数都是卷积核的大小，这样就相当于没有神经元只与对应图片部分的像素相连接。这样就极大的减少了权重的数量。\n*   核filter，例如$5*5*3$。参数学习得到。卷积过程中参数不变，**通过一个卷积核的操作提取了原图的不同位置的同样特征。**\n*   **每个卷积核，在输入的整个深度上点积。**运算时，实质上也是先化为一维向量做点积。但有多个卷积核，所以输出为output size * output size * output num。\n*   卷积输出size：$(N-F)/stride+1$\n\t*   N：输入size，F：卷积核size，stride：步长\n*   也有用0填充输入图片四周，使输出size保持不变。\n\n---\n\n\n\n## Pooling/池化\n\n*   对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征\n*   深度不变。通常filter不重叠，不填0\n*   常用：$2*2$ 步长2，或$3*3$ 步长3\n\n---\n\n\n\n## Activation Functions/激活函数\n\n### sigmoid(x)​\n\n![](CS231n笔记/sigmoid.png)\n\n* $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n* 元素压缩至$[0,1]$范围\n* 问题：\n * 饱和神经元使得梯度为0，无法得到合适的梯度流\n\t* 输出不以0为中心，x为正时w总为正或负，梯度更新效率低\n\t* 指数计算代价较大\n\n### tanh(x)​\n\n![](CS231n笔记/tanh.png)\n\n* 压缩至$[-1,1]$\n* 输出以0为中心\n* 问题：饱和时梯度为0 \n\n### ReLU(Rectified Linear Unit)\n\n![](CS231n笔记/relu.png)\n\n* $f(x)=max(0,x)$\n* 正区域不会饱和\n* 函数简单，计算快，收敛快\n* 生物学上更合理\n* 问题\n * 输出不以0为中心\n\t* 负半轴全饱和\n\t* 及其导致的Dead ReLU：反向传播中，大的梯度更新，使w变化，输入负数增加，函数关闭，参数w得不到更新，导致永久关闭\n\n### Leaky ReLU\n\n![](CS231n笔记/leaky relu.png)\n\n* $f(x)=max(0.01x,x)$\n* 不会挂掉\n\n### ELU(Exponential Linear units)\n\n![](CS231n笔记/elu.png)\n\n* $f(x)=\\begin{cases}x\\qquad\\qquad if x>0\\\\\\ \\alpha(e^x-1)\\quad ifx\\leq0 \\end{cases}$\n\n* 输出均值近0\n* 负半轴近似饱和\n\n### Maxout\n\n* $max(w_1^Tx+b_1,w_2^Tx+b_2)$\n* 不提前点积\n* 泛化ReLU，不饱和，不消亡 \n* 问题：参数加倍\n\n### 总结\n\n* 常用ReLU，注意学习率\n* 少用sigmoid\n\n---\n\n\n\n## Data Preprocessing/数据预处理\n\n* zero-centered data/零中心化\n\n\tX -= np.mean(X, axis = 0)\n\n* normalized data/归一化，图像处理不常用\n\n\tX /= np.std(X, axis = 0)\n\n* 减去mean image\n\n* 减去单通道均值\n\n* 训练与预测阶段都需进行同样预处理（应用同样的参数、均值）\n\n---\n\n\n\n## Weight Initialization/初始化权重\n\n* 输入输出方差相同，Xavier initialization\n\n\tW = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in/2)\n\n---\n\n\n\n## Batch Normalization/批量归一化\n\n* 背景：深层网络在非线性变化前，激活的输入值的分布逐渐发生偏移变动。当整体分布靠近激活函数上下限端时，反向传播时的梯度消失，最终导致深层网络收敛越来越慢\n\n* 目的：数据转化为单位高斯数据，降低层之间输入数据分布变化，即使数据落入非线性函数的敏感区域，避免梯度消失，提速\n\n* 带来的问题：每层都通过BN，相当于多层线性函数，深度网络失去意义\n\n* 解决：对经过BN的x：$y=scale*x+shift$。对每个神经元增加两个学习参数，相当于使非线性函数的值从线性区往非线性区偏移挪动。变换重构$y^{(k)}=\\gamma^{(k)}\\hat{x}^{(k)}+\\beta^{(k)}$，则$\\gamma^{(k)}=\\sqrt{Var[x^{(k)}]} \\quad \\beta^{(k)}=E[x^{(k)}]$时可恢复原始数据，控制饱和程度。**核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢**\n\n* 通常在FC、卷积层后插入\n\n* 训练过程：$\\hat{x}^{(k)}=\\frac{x^{(k)}-E[x^{(k)}]}{\\sqrt Var[x^{(k)}]}$\n\n\t![Batch Normalization](CS231n笔记/bn_forward.png \"forward\")\n\n\t![bn_backward](CS231n笔记/bn_backward.jpg \"backward\")\n\n\t预测过程：用从所有训练实例中获得的统计量代表期望和方差\n\n\n$$\nE[x]\\leftarrow E_B[\\mu_B]\t\\\\\nVar[x]\\leftarrow\\frac{m}{m-1}E_B[\\sigma_B^2] \\\\\ny=\\frac{\\gamma}{\\sqrt{Var[x]+\\varepsilon}}*x+(\\beta-\\frac{\\gamma*E[x]}{\\sqrt{Var[x]+\\varepsilon}})\n$$\n\n\n\n---\n\n\n\n## Babysitting the Learning Process/观察学习过程\n\n* 数据预处理\n* 选择网络结构\n* 初始化网络，前向传播\n* 观察损失，和添加正则化项后的损失\n* 从小数据集训练，关闭正则化，sgd，观察loss能否为0、accuracy能否为1\n* 正式训练，全部数据，开启正则化\n* 调整学习率（最重要参数），过小时梯度更新小，loss变化小，$\\eta$常为$1e-3$到$1e-5$之间 \n\n---\n\n## Hyper-parameter Optimization/超参数设置\n\n* 交叉验证，训练集训练，验证集验证\n* 首先几个epoch粗略观察超参是否合理，确定合理区间\n* loss激增时说明方向有误\n\n![](CS231n笔记/loss-learing rate.png \"loss~learning rate\") \n\n\n\n---\n\n## PyTorch\n\n* 定义三个抽象\n\t* Tensor 张量，类似数组\n\t* Variable 变量，计算图中节点，储存数据和梯度\n\t* Module 类/模块，是一个神经网络层，储存状态和参数\n\n### Tensor/张量\n\n```python\n# 简单的神经网络示例(使用张量)\nimport torch\n\n# dtype = torch.FloatTensor\ndtype = torch.cuda.FloatTensor\t# GPU\n\nN, D_in, H, D_out = 64, 1000, 100, 10\nx = torch.randn(N, D_in).type(dtype)\ny = torch.randn(N, D_out).type(dtype)\nw1 = torch.randn(D_in, H).type(dtype)\nw2 = torch.randn(H, D_out).type(dtype)\n\nlearning_rate = 1e-6\nfor t in range(500):\n  h = x.mm(w1)\n  h_relu = h.clamp(min=0)\n  y_pred = h_relu.mm(w2)\n  loss = (y_pred - y).pow(2).sum()\n  \n  grad_y_pred = 2.0 * (y_pred - y)\n  grad_w2 = h_relu.t().mm(grad_y_pred)\n  grad_h_relu = grad_y_pred.mm(w2.t())\n  grad_h = grad_h_relu.clone()\n  grad_h[h < 0] = 0\n  grad_w1 = x.t().mm(grad_h)\n  \n  w1 -= learning_rate * grad_w1\n  w2 -= learning_rate * grad_w2\n```\n\n### Variable/变量\n\n* X.data 张量类型\n* X.grad 变量类型，梯度，与data同shape\n* X.grad.data 张量类型，梯度的张量\n* PyTorch中，张量、变量相同API\n\n```python\nimport torch\nfrom torch.autograd import Variable\n\nN, D_in, H, D_out = 64, 1000, 100, 10\nx = Variable(torch.randn(N, D_in), requires_grad=False)\ny = Variable(torch.randn(N, D_out), requires_grad=False)\nw1 = Variable(torch.randn(D_in, H), requires_grad=True)\nw2 = Variable(torch.randn(H, D_out), requires_grad=True)\n\nlearning_rate = 1e-6\nfor t in range(500):\n  y_prred = x.mm(w1).clamp(min=0).mm(w2)\n  loss = (y_pred - y).pow(2).sum()\n  \n  if w1.grad: w1.grad.data.zero_()\n  if w2.grad: w2.grad.data.zero_()\n  loss.backward()\n  \n  w1.data -= learning_rate * w1.grad.data\n  w2.data -= learning_rate * w2.grad.data\n```\n\n### nn/高级封装\n\n```python\nimport torch\nfrom torch.autograd import Varible\n\nN, D_in, H, D_out = 64, 1000, 100, 10\nx = Variable(torch.randn(N, D_in))\ny = Variable(torch.randn(N, D_out), requires_grad=False)\n\n# 把模型定义为层的序列\nmodel = torch.nn.Sequential(torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out))\n# nn中定义了一些损失函数\nloss_fn = torch.nn.MSELoss(size_average=False)\n\n# 给模型喂数据，得到预测以计算损失\nlearning_rate = 1e-4\nfor t in tange(500):\n  y_pred = model(x)\n  loss = loss_fn(y_pred, y)\n  \n  # 计算梯度\n  model.zero_grad()\n  loss.backward()\n  \n  # 在所有参数上循环，更新参数 \n  for param in model.parameters():\n    param.data -= learning_rate * param.grad.data\n```\n\n### optimizer/优化器\n\n* 将参数更新的流程抽象出来，并执行更新法则\n\n* 以上例为基础：\n\n* 14行后添加如下，意为要对参数采用此法则、此学习率更新\n\n\t`optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)`\n\n* 23~25行的参数更新改为：`optimizer.step()`\n\n### Module/类\n\n* 神经网络层，输入输出为变量类型\n* 包含参数或其他模块\n* 可以使用autograd定义新Module\n\n```python\nimport torch\nform torch.autograd import Variable\n\n# 这个类把整个模型定义成nn类中的一个新类，\nclass TwoLayerNet(torch.nn.Module):\n  def _init_(self, D_in, H, D_out):\n    super(TwoLayerNet, self)._init_()\n    self.linear1 = torch.nn.Linear(D_in, H)\n    self.linear2 = torch.nn.Linear(H, D_out)\n    \n  def forward(self, x):\n    h_relu = self.linear1(x).clamp(min=0)\n    y_pred = self.linear2(h_relu)\n    return y_pred\n  \nN, D_in, H, D_out = 64, 1000, 100, 10\n\nx = Variable(torch.randn(N, D_in))\ny = Variable(torch.randn(N, D_out), requires_grad=False)\n\nmodel = TwoLayerNet(D_in,, H, D_out)\n\ncriterion = torch.nn.MSELoss(size_average=False)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\nfor t in range(500):\n  y_pred = model(x)\n  loss = criterion(y_pred, y)\n  \n  optimizer.zero_grad()\n  loss.backward()\n  optimizer.step()\n```\n\n### DataLoader/数据加载\n\n* 可以建立分批处理，也可以执行多线程 \n\n```python\nimport torch\nfrom torch.autograd import Variable\nform torch.utils.data import TensorDataset, DataLoader\n\nN, D_in, H, D_out = 64, 1000, 100, 10\n\nx = torch.randn(N, D_in)\ny = torch.randn(N, D_out)\n\nloader = DataLoader(TensorDataset(x, y), batch_size=8)\n\nmodel = TwoLayerNet(D_in, H, D_out)\n\nceiterion = torch.nn.MSELoss(size_average=False)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\nfor epoch in range(10):\n  for x_batch, y_batch in loader:\n    x_var, y_var = Variable(x), Variable(y)\n    y_pred = model(x_var)\n    loss = criterion(y_pred, y_var)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n```\n\n### Pretrained Model/预训练模型\n\n```python\nimport torch\nimport torchvision\n\nalexnet = torchvision.models.alexnet(pretrained=True)\n```\n\n### else/其他\n\n* visdom 可视化的包\n* 可以通过重写前向、反向传播函数定义新的Autograd Function\n\n```python\nclass ReLU(torch.autograd.Function):\n  def forwar(self, x):\n    self.save_for_backward(x)\n    return x.clamp(min=0)\n  \n  def backward(self, grad_y):\n    x, = self.saved_tensors\n    grad_input = grad_y.clone()\n    grad_input[x < 0] = 0\n    return grad_input\n```\n\n","slug":"CS231n笔记","published":1,"updated":"2020-06-18T12:27:08.737Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbevn0009i0qveu53hnp5","content":"<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#project\">Project</a></li>\n<li><a href=\"#cs231n\">CS231n</a>\n<ul>\n<li><a href=\"#data-driven%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8\">Data Driven/数据驱动</a></li>\n<li><a href=\"#linear-classifier%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB\">Linear Classifier/线性分类</a></li>\n<li><a href=\"#loss-function%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\">Loss Function/损失函数</a></li>\n<li><a href=\"#optimization%E4%BC%98%E5%8C%96%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">Optimization/优化/梯度下降</a>\n<ul>\n<li><a href=\"#stochastic-gradient-descentsgd%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">Stochastic Gradient Descent(SGD)/随机梯度下降</a></li>\n<li><a href=\"#sgdmomentum%E7%BB%93%E5%90%88%E5%8A%A8%E9%87%8F%E7%9A%84sgd\">SGD+Momentum/结合动量的SGD</a></li>\n<li><a href=\"#sgdnesterov\">SGD+Nesterov</a></li>\n<li><a href=\"#adagrad\">AdaGrad</a></li>\n<li><a href=\"#rmsprop\">RMSProp</a></li>\n<li><a href=\"#adam\">Adam</a></li>\n<li><a href=\"#gif\">GIF</a></li>\n<li><a href=\"#adabound\">AdaBound</a>\n<ul>\n<li><a href=\"#%E8%83%8C%E6%99%AF\">背景</a></li>\n<li><a href=\"#%E8%AE%BA%E6%96%87%E5%86%85%E5%AE%B9\">论文内容</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#back-propagation%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD\">Back-propagation/反向传播</a></li>\n<li><a href=\"#regularization%E6%AD%A3%E5%88%99%E5%8C%96\">Regularization/正则化</a>\n<ul>\n<li><a href=\"#lp%E8%8C%83%E6%95%B0%E6%83%A9%E7%BD%9A\">Lp范数惩罚</a></li>\n<li><a href=\"#dropout\">Dropout</a></li>\n<li><a href=\"#data-augmentation%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\">Data Augmentation/数据增强</a></li>\n</ul>\n</li>\n<li><a href=\"#transfer-learing%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0\">Transfer Learing/迁移学习</a></li>\n<li><a href=\"#neural-network%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">Neural Network/神经网络</a></li>\n<li><a href=\"#convolutional-neural-networks-cnn%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">Convolutional Neural Networks, CNN/卷积神经网络</a></li>\n<li><a href=\"#pooling%E6%B1%A0%E5%8C%96\">Pooling/池化</a></li>\n<li><a href=\"#activation-functions%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0\">Activation Functions/激活函数</a>\n<ul>\n<li><a href=\"#sigmoidx\">sigmoid(x)​</a></li>\n<li><a href=\"#tanhx\">tanh(x)​</a></li>\n<li><a href=\"#relurectified-linear-unit\">ReLU(Rectified Linear Unit)</a></li>\n<li><a href=\"#leaky-relu\">Leaky ReLU</a></li>\n<li><a href=\"#eluexponential-linear-units\">ELU(Exponential Linear units)</a></li>\n<li><a href=\"#maxout\">Maxout</a></li>\n<li><a href=\"#%E6%80%BB%E7%BB%93\">总结</a></li>\n</ul>\n</li>\n<li><a href=\"#data-preprocessing%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\">Data Preprocessing/数据预处理</a></li>\n<li><a href=\"#weight-initialization%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8D\">Weight Initialization/初始化权重</a></li>\n<li><a href=\"#batch-normalization%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96\">Batch Normalization/批量归一化</a></li>\n<li><a href=\"#babysitting-the-learning-process%E8%A7%82%E5%AF%9F%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B\">Babysitting the Learning Process/观察学习过程</a></li>\n<li><a href=\"#hyper-parameter-optimization%E8%B6%85%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE\">Hyper-parameter Optimization/超参数设置</a></li>\n<li><a href=\"#pytorch\">PyTorch</a>\n<ul>\n<li><a href=\"#tensor%E5%BC%A0%E9%87%8F\">Tensor/张量</a></li>\n<li><a href=\"#variable%E5%8F%98%E9%87%8F\">Variable/变量</a></li>\n<li><a href=\"#nn%E9%AB%98%E7%BA%A7%E5%B0%81%E8%A3%85\">nn/高级封装</a></li>\n<li><a href=\"#optimizer%E4%BC%98%E5%8C%96%E5%99%A8\">optimizer/优化器</a></li>\n<li><a href=\"#module%E7%B1%BB\">Module/类</a></li>\n<li><a href=\"#dataloader%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD\">DataLoader/数据加载</a></li>\n<li><a href=\"#pretrained-model%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B\">Pretrained Model/预训练模型</a></li>\n<li><a href=\"#else%E5%85%B6%E4%BB%96\">else/其他</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"project\"> Project</span></h1>\n<ul>\n<li>判别式方法 -&gt; 深度学习类</li>\n<li><a href=\"https://wenku.baidu.com/view/552db3a780c758f5f61fb7360b4c2e3f56272517.html\" target=\"_blank\" rel=\"noopener\">目标跟踪算法综述</a></li>\n<li><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/%E4%B8%BB%E6%B5%81.png\" alt></li>\n<li>为了扩展CNN在目标跟踪领域的能力，需要大量的训练数据，但这在目标跟踪中是很难做到的。MDNet[14]算法提出了一种解决该问题的思路。算法采用VGG-M作为网络初始化模型，后接多个全连接层用作分类器。训练时，每一个跟踪视频对应一个全连接层，学习普遍的特征表示用来跟踪。跟踪时，去掉训练时的全连接层，使用第一帧样本初始化一个全连接层，新的全连接层在跟踪的过程中继续微调，来适应新的目标变化。这种方法使得特征更适合于目标跟踪，效果大大提升。由此可以看出，通过视频训练的网络更适合目标跟踪这一任务</li>\n<li>速度改进：虽然深度特征具有传统特征无法比拟的抗干扰能力，但是一般提取速度较慢，而且特征中存在大量冗余。当算法精度达到一定标准之后，很多方法开始着力解决算法速度问题。<strong>孪生网络</strong>[19]是其中的一个典型例子，采用两路神经网络分别输入目标模板和搜索图像块，用来进行模板匹配或候选样本分类。其中一路神经网络对于模板信息的保存可以提供跟踪物体先验信息，取代网络在线更新，大大节省了速度。另外，<strong>对深度特征进行降维或自适应选择</strong>也是加速算法的有效途径。由于深度神经网络复杂的计算及模型更新时繁琐的系数，现存大部分深度目标跟踪算法速度都比较慢。很多深度目标跟踪算法采用<strong>小型神经网络（如VGG-M）<strong>来提特征。另外，跟踪中只给定第一帧目标位置，缺少跟踪物体先验信息，这就</strong>要求模型实时更新</strong>来确保跟踪精度，而这在深度目标跟踪算法中往往非常耗时。一些算法采用孪生网络结构来保存先验信息，代替模型在线更新，使得算法速度得以提高。深度特征的高维度也会影响跟踪算法的速度，如果能够提出有效的特征压缩方法，不管对算法速度还是精度都会有所帮助。只有高速且有效地算法才具有实际的应用价值</li>\n</ul>\n<hr>\n<h1><span id=\"cs231n\"> CS231n</span></h1>\n<h2><span id=\"data-driven数据驱动\"> Data Driven/数据驱动</span></h2>\n<ul>\n<li>以数据/样本驱动，训练模型，进行预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">(images, labels)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\">#Machine learning</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">predict</span><span class=\"params\">(model, test_images)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\">#use model to predict labels</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> test_labels</span><br></pre></td></tr></table></figure>\n<ul>\n<li>train_data/训练集：以不同的超参数训练模型</li>\n<li>validation_data/验证集：选出效果最优的超参数</li>\n<li>test_data/测试集：仅预测算法在未见新数据上的</li>\n</ul>\n<hr>\n<h2><span id=\"linear-classifier线性分类\"> Linear Classifier/线性分类</span></h2>\n<ul>\n<li>\n<p>将训练数据浓缩于参数W/θ中，但每个类别只能学习一个单独模板</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>W</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">f(x,W)=Wx+b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span></span></span></span></p>\n</li>\n<li>\n<p>W:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>10</mn><mo>∗</mo><mn>3072</mn></mrow><annotation encoding=\"application/x-tex\">10*3072</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">0</span><span class=\"mord\">7</span><span class=\"mord\">2</span></span></span></span> ，有十类时</p>\n<ul>\n<li>x:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>3072</mn><mo>∗</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">3072*1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">0</span><span class=\"mord\">7</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> ， 图片为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>32</mn><mo>∗</mo><mn>32</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">32*32*3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span>时</li>\n<li>b:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>10</mn><mo>∗</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">10*1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> ， 有十类时</li>\n<li>结果得分:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>10</mn><mo>∗</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">10*1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2><span id=\"loss-function损失函数\"> Loss Function/损失函数</span></h2>\n<ul>\n<li>将W输入，输出得分，定量地估计W的好坏</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>W</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">f(x, W)=Wx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathdefault\">x</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=\"false\">(</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L=\\frac{1}{N}\\sum_iL_i(f(x_i,W),y_i)+\\lambda R(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>N：样本数\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\lambda R(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span>：正则化项</li>\n</ul>\n</li>\n<li>Multi-class SVM LOSS：</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></msub><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><msub><mi>s</mi><mi>j</mi></msub><mo>−</mo><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub><mo>+</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L_i=\\sum_{j\\not=y_i}\\max(0,s_j-s_{y_i}+margin)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.185818em;vertical-align:-0.43581800000000004em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18639799999999984em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\"><span class=\"mord mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"rlap mtight\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel mtight\"></span></span><span class=\"fix\"></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8694379999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span></span></span></span>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>s</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">s=f(x,W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>i：当前对第i个样本的得分计算</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>：当前样本对第j类的得分</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub></mrow><annotation encoding=\"application/x-tex\">s_{y_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>：当前样本对正确分类组的得分</li>\n<li>margin：适当边距</li>\n<li>释义：不正确分类上损失之和，且正确分类得分超出错误分类得分margin以上时损失为0</li>\n</ul>\n</li>\n<li>Softmax Loss：</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>=</mo><mi>k</mi><mo>∣</mo><mi>X</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>s</mi></msup><mi>k</mi></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><mi>s</mi></msup><mi>j</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(Y=k\\mid X=x_i)=\\frac{e^s k}{\\sum_j e^s j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.578207em;vertical-align:-0.667227em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.91098em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mop mtight\"><span class=\"mop op-symbol small-op mtight\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14964714285714287em;\"><span style=\"top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.46032428571428574em;\"><span></span></span></span></span></span></span><span class=\"mspace mtight\" style=\"margin-right:0.19516666666666668em;\"></span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span></span></span></span></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7385428571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span></span></span></span></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.667227em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>s</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">;</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">s=f(x_i;W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>最小化<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><mi>X</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L_i=-\\log P(Y=y_i\\mid X=x_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>希望正确分类的概率趋近1</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2><span id=\"optimization优化梯度下降\"> Optimization/优化/梯度下降</span></h2>\n<p>梯度下降是指，在给定待优化的模型参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\theta\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>和目标函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>，算法通过沿梯度 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\nabla _\\theta J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>的相反方向更新<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>来最小化<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>。学习率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span></span></span></span>决定了每一时刻的更新步长。</p>\n<p>流程如下：</p>\n<ol>\n<li>\n<p>计算目标函数关于参数的梯度</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>g</mi><mi>t</mi></msub><mo>=</mo><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g_t=\\nabla_\\theta J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span></p>\n</li>\n<li>\n<p>根据历史梯度计算一阶和二阶动量</p>\n</li>\n</ol>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>g</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">m_t=\\phi (g_1,g_2,\\cdots ,g_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><mi>ψ</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo separator=\"true\">,</mo><msub><mi>g</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_t=\\psi(g_1,,g_2,\\cdots ,g_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ψ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<ol start=\"3\">\n<li>更新模型参数</li>\n</ol>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>t</mi></msub><mo>−</mo><mfrac><mn>1</mn><msqrt><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><msub><mi>m</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{v_t+\\epsilon}}m_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.383108em;vertical-align:-0.538em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6224469999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.81079em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathdefault mtight\">ϵ</span></span></span><span style=\"top:-2.77079em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.22921000000000002em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.538em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>梯度就是偏导数组成的向量，即多元/多参数、参数为向量时</li>\n<li>梯度和X的形状一样，元素告诉我们相关方向上函数f的斜率</li>\n<li>梯度指向函数增加最快的方向，负梯度方向即下降最快方向</li>\n<li>则位置任意方向斜率=梯度与单位方向向量的点积</li>\n<li>根据梯度决定下一次更新方向</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi mathvariant=\"normal\">∇</mi><mi>W</mi></msub><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msub><mo>∑</mo><mi>i</mi></msub><msub><mi mathvariant=\"normal\">∇</mi><mi>W</mi></msub><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=\"false\">(</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mi>λ</mi><msub><mi mathvariant=\"normal\">∇</mi><mi>W</mi></msub><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\nabla_WL=\\frac{1}{N}\\sum_i\\nabla_WL_i(f(x_i,W),y_i)+\\lambda \\nabla_WR(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>Gradient Descent/梯度下降</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dw = compute_grad(loss_fun, data, weights)</span><br><span class=\"line\">  weight += - step_size * dw</span><br></pre></td></tr></table></figure>\n<h3><span id=\"stochastic-gradient-descentsgd随机梯度下降\"> Stochastic Gradient Descent(SGD)/随机梯度下降</span></h3>\n<ul>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>η</mi><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">m_t=\\eta g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><msup><mi>I</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">v_t=I^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\epsilon=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>i</mi></msub><mo>−</mo><mi>η</mi><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{i+1}=\\theta_i-\\eta g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>N过大，只取部分data计算，以估计整体梯度</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">\tdata_batch = sample_training_data(data, <span class=\"number\">256</span>)</span><br><span class=\"line\">  dw = compute_grad(loss_fun, data_batch, weights)</span><br><span class=\"line\">  weight += - step_size * dw</span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>SGD的问题：</p>\n<ul>\n<li>\n<p>当对一个方向敏感，对其他方向迟钝，会形成之字形路径，收敛极其缓慢。下图仅二维两个参数</p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sgd_problem.png\" alt></p>\n</li>\n<li>\n<p>局部最小值和鞍点处，会卡住。维度增加，鞍点会快速增加</p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sgd_problem2.png\" alt></p>\n</li>\n<li>\n<p>易受噪声影响</p>\n</li>\n<li>\n<p>步长恒定，速度慢</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"sgdmomentum结合动量的sgd\"> SGD+Momentum/结合动量的SGD</span></h3>\n<ul>\n<li>\n<p>引入一阶动量</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>γ</mi><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>η</mi><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">m_t=\\gamma m_{t-1}+\\eta g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.791661em;vertical-align:-0.208331em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vx = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dx = compute_grad(x)</span><br><span class=\"line\">  vx = rho * vx + learning_rate * dx</span><br><span class=\"line\">  x -= vx</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sgd_problem1.png\" alt></p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/SGDM.jpg\" alt=\"SGDM\"></p>\n<h3><span id=\"sgdnesterov\"> SGD+Nesterov</span></h3>\n<ul>\n<li>不同于SGDM的梯度与速度向量之和的方向作为新的步进方向，Nesterov动量，是先从当前点，沿速度方向步进，在新位置求梯度向量，然后返回起始点向梯度方向步进。</li>\n</ul>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/SGD+Nesterov.png\" alt></p>\n<ul>\n<li>\n<p>凸优化问题较好，非凸会有问题</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo>−</mo><mi>α</mi><mi mathvariant=\"normal\">∇</mi><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_{t+1}=\\rho v_t-\\alpha\\nabla f(x_t+\\rho v_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">∇</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">x_{t+1}=x_t+v_{t+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>以上形式，会导致运算增加。变量代换，便于网络同时求梯度和损失</p>\n</li>\n</ul>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_t=x_t+\\rho v_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo>−</mo><mi>α</mi><mi mathvariant=\"normal\">∇</mi><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_{t+1}=\\rho v_t-\\alpha\\nabla f(y_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">∇</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mi>ρ</mi><mo stretchy=\"false\">)</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub><mo>+</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>ρ</mi><mo stretchy=\"false\">(</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>v</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y_{t+1}=y_t-\\rho v_t + (1+\\rho)v_{t+1}=y_t+v_{t+1}+\\rho(v_{t+1}-v_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.791661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dx = compute_gradient(x)</span><br><span class=\"line\">old_v = v</span><br><span class=\"line\">v = rho * v - lr * dx</span><br><span class=\"line\">x += -rho * old_v + (<span class=\"number\">1</span> + rho) * v</span><br></pre></td></tr></table></figure>\n<h3><span id=\"adagrad\"> AdaGrad</span></h3>\n<p><strong>SGD、SGD-M均是以相同的学习率去更新<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>的各个分量。而深度学习模型中往往涉及大量的参数，不同参数的更新频率往往有所区别。对于更新不频繁的参数，我们希望单次步长更大，多学习一些知识；对于更新频繁的参数，我们则希望步长较小，使得学习到的参数更稳定，不至于被单个样本影响太多。即自适应学习率。</strong></p>\n<ul>\n<li>引入二阶动量，加速非敏方向，减慢敏感方向速度</li>\n</ul>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy=\"false\">(</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn></mrow><mn>2</mn></msubsup><mo separator=\"true\">,</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>d</mi></mrow><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_t=diag(\\sum^t_{i=1}g^2_{i,1},\\sum^t_{i=1}g^2_{i,2},\\cdots,\\sum^t_{i=1}g^2_{i,d})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3526719999999999em;vertical-align:-0.4192159999999999em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.394772em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.394772em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">d</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4192159999999999em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">v_t\\in R^{d\\times d}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6891em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span></span>，对角矩阵，元素为参数第<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">i</span></span></span></span>维从初始时刻到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时的梯度平方和，学习率等效为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>η</mi><mi mathvariant=\"normal\">/</mi><msqrt><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\eta/\\sqrt{v_t+\\epsilon}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.051665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8016650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">ϵ</span></span></span><span style=\"top:-2.761665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.23833499999999996em;\"><span></span></span></span></span></span></span></span></span>，对此前频繁更新的参数，其二阶动量的对应分量较大，学习率就小，反之同理</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grad_squared = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dx = compute_grad(x)</span><br><span class=\"line\">  grad_squared += dx * dx</span><br><span class=\"line\">  x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"number\">1e-7</span>)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>步长越来越小，凸函数时是好的特性（接近极值时减慢、收敛），非凸时不好（局部极值卡住）</li>\n</ul>\n<h3><span id=\"rmsprop\"> RMSProp</span></h3>\n<ul>\n<li>\n<p>计算二阶动量时只关注最近的下降梯度，其二阶动量采用<em>指数移动平均公式</em>计算，这样即可避免二阶动量持续累积的问题。优点保留，但存在平方项持续减少，训练缓慢的隐患</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>v</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mi>t</mi></msub><mo>⨀</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">​</mi></mrow><annotation encoding=\"application/x-tex\">v_t=\\beta_2 v_{t-1}+(1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)​</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">⨀</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">​</span></span></span></span></p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grad_squared = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dx = compute_grad(x)</span><br><span class=\"line\">  grad_squared = decay_rate * grad_squared + (<span class=\"number\">1</span> - decay_rate) * dx * dx</span><br><span class=\"line\">  x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"number\">1e-7</span>)</span><br></pre></td></tr></table></figure>\n<h3><span id=\"adam\"> Adam</span></h3>\n<ul>\n<li>\n<p>对一阶动量也用指数移动平均公式</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>η</mi><mo stretchy=\"false\">[</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">m_t=\\eta[\\beta_1m_{t-1}+(1-\\beta_1)g_t]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">m_t=\\beta_1m_{t-1}+(1-\\beta_1)g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>v</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant=\"normal\">（</mi><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mi>t</mi></msub><mo>⨀</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_t=\\beta_2 v_{t-1}+（1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord cjk_fallback\">（</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">⨀</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><msub><mi>m</mi><mi>t</mi></msub><mo>^</mo></mover><mo>=</mo><mfrac><msub><mi>m</mi><mi>t</mi></msub><mrow><mn>1</mn><mo>−</mo><msubsup><mi>β</mi><mn>1</mn><mi>t</mi></msubsup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{m_t}=\\frac{m_t}{1-\\beta^t_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.288452em;vertical-align:-0.5769599999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7114919999999999em;\"><span style=\"top:-2.6411000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7841428571428571em;\"><span style=\"top:-2.188485714285714em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31151428571428574em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4101em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5769599999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><msub><mi>v</mi><mi>t</mi></msub><mo>^</mo></mover><mo>=</mo><mfrac><msub><mi>v</mi><mi>t</mi></msub><mrow><mn>1</mn><mo>−</mo><msubsup><mi>β</mi><mn>2</mn><mi>t</mi></msubsup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{v_t}=\\frac{v_t}{1-\\beta^t_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.288452em;vertical-align:-0.5769599999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7114919999999999em;\"><span style=\"top:-2.6411000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7841428571428571em;\"><span style=\"top:-2.188485714285714em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31151428571428574em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4101em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5769599999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>t</mi></msub><mo>−</mo><mfrac><mn>1</mn><msqrt><mrow><mover accent=\"true\"><msub><mi>v</mi><mi>t</mi></msub><mo>^</mo></mover><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mover accent=\"true\"><msub><mi>m</mi><mi>t</mi></msub><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{\\hat{v_t}+\\epsilon}}\\hat{m_t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.383108em;vertical-align:-0.5379999999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.5835585em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.866345em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord accent mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mtight\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathdefault mtight\">ϵ</span></span></span><span style=\"top:-2.826345em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.173655em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5379999999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>结合了SGD、动量、AdaGrad/RMSProp</p>\n<ul>\n<li>动量momentum：克服鞍点、梯度为0但非极值点等一系列问题</li>\n<li>AdaGrad/RMSProp：减少敏感方向的权重，增加非敏方向权重</li>\n<li>偏置校正：以防初始化不佳时初期除以很小的数导致步长过长</li>\n</ul>\n</li>\n<li>\n<p>实践证明，虽然在训练早期 Adam 拥有出色的收敛速度，使用其训练的模型的最终泛化能力却并不如使用朴素 SGD 训练的好（体现在 Adam 训练的模型最终收敛时的 test error 更大），结果可能不收敛，可能找不到全局最优解。二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得二阶动量可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">first_moment = <span class=\"number\">0</span></span><br><span class=\"line\">second_moment = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(num_iterations):</span><br><span class=\"line\">  dx = compute_gradient(x)</span><br><span class=\"line\">  first_moment = rho * first_moment + (<span class=\"number\">1</span> - rho) * dx\t<span class=\"comment\"># Momentum</span></span><br><span class=\"line\">  second_moment = decay_rate * second_moment + (<span class=\"number\">1</span> - decay_rate) * dx * dx\t<span class=\"comment\"># AdaGrad/RMSProp</span></span><br><span class=\"line\">  first_unbias = first_moment / (<span class=\"number\">1</span> - rho ** t)</span><br><span class=\"line\">  second_unbias = second_moment/ (<span class=\"number\">1</span> - decay_rate ** t)\t<span class=\"comment\"># Bias correction</span></span><br><span class=\"line\">  x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + <span class=\"number\">1e-7</span>)\t<span class=\"comment\"># AdaGrad/RMSProp</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>典型起始参数设置：</p>\n<ul>\n<li>beta1 = 0.9</li>\n<li>beta2 = 0.999</li>\n<li>learning_rate = 1e-3 or 5e-4</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"gif\"> GIF</span></h3>\n<p>![](CS231n笔记/optimizations on loss surface contours.gif)</p>\n<p>不同算法在损失面等高线图中的学习过程，它们均同同一点出发，但沿着不同路径达到最小值点。其中 Adagrad、Adadelta、RMSprop 从最开始就找到了正确的方向并快速收敛；SGD 找到了正确方向但收敛速度很慢；SGD-M 和 NAG 最初都偏离了航道，但也能最终纠正到正确方向，SGD-M 偏离的惯性比 NAG 更大。</p>\n<p>![](CS231n笔记/optimizations on saddle point.gif)</p>\n<p>不同算法在鞍点处的表现。这里，SGD、SGD-M、NAG 都受到了鞍点的严重影响，尽管后两者最终还是逃离了鞍点；而 Adagrad、RMSprop、Adadelta 都很快找到了正确的方向。</p>\n<h3><span id=\"adabound\"> AdaBound</span></h3>\n<p><em>Adaptive Gradient Methods with Dynamic Bound of Learning Rate 动态裁剪学习率的自适应梯度下降方法</em></p>\n<h4><span id=\"背景\"> 背景</span></h4>\n<ul>\n<li>\n<p><a href=\"http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning\">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a>. 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。<strong>推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。</strong></p>\n</li>\n<li>\n<p><a href=\"http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ\">On the Convergence of Adam and Beyond</a>. ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。</p>\n<p>主要攻击的是 Adam 有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但个人认为这篇 paper 的<strong>意义十分有限，同时有很大误导性</strong>。</p>\n<p>其一，作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为<strong>这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值</strong>，极端构造下的收敛性，并不意味着什么。</p>\n<p>其二，作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，<strong>training loss 的意义对于一个模型是十分有限的</strong>。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，<strong>Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差</strong>。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 <a href=\"http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/\">Experiments with AMSGrad</a> 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。</p>\n<p>其三，最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。</p>\n<p>相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的 performance 对模型而言才是更加重要的性质。</p>\n</li>\n<li>\n<p><a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628\">Improving Generalization Performance by Switching from Adam to SGD</a>. 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。<strong>实验表明训练后期更新步长过小也是原因之一。</strong></p>\n</li>\n<li>\n<p>综上而言，<strong>在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向</strong>。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。</p>\n</li>\n</ul>\n<h4><span id=\"论文内容\"> 论文内容</span></h4>\n<ol>\n<li>\n<p>初步试验：</p>\n<p>使用Adam算法，在ResNet-34（残差网络模型，复杂度低）中随机选取了9个卷积核和1个全连接层偏置向量，并从中再各随机取样一个维度的变量，统计其在CIFAR-10上训练末期的学习率。采样参数的学习率，每个单元格包含一个通过对学习率进行对数运算得到的值。颜色越浅的单元格代表越小的学习率。可见在后期确实存在学习率的极端值。</p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/AdaBound_figure1.png\" alt></p>\n</li>\n<li>\n<p>theorem3 证明极端学习率确实存在潜在的负面影响。</p>\n</li>\n<li>\n<p>对学习率动态裁剪，将实际学习率限制在下界<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和上界<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>之间。</p>\n</li>\n</ol>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/AdaBound_clip.png\" alt></p>\n<p>容易发现，SGD 和 Adam 分别是应用梯度裁剪的特殊情况：学习率为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^{*}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></span>的SGD可视为<span class=\"katex-error\" title=\"Error: Font metrics not found for font: .\">\\eta_𝑙=\\eta_𝑢=𝛼^∗</span>；Adam可视为 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>𝑙</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\eta_𝑙=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> ,<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>𝑢</mi></msub><mo>=</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\eta_𝑢=\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。其他取值则介于两者之间。那么，如果用两个关于 t 的函数来取代固定值作为新的上下界，其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\eta_l(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>从0逐渐收敛至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\eta_u(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>从<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>也逐渐收敛至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>，那么我们就成功实现了从Adam到SGD的动态过渡。在这一设置下，在训练早期由于上下界对学习率的影响很小，算法更加接近于Adam；而随着时间增长裁减区间越来越收紧，模型的学习率逐渐趋于稳定，在末期更加贴近于SGD。</p>\n<ol start=\"4\">\n<li>\n<p>结果在训练前期可以快速且平滑收敛的情况下，同时在末期得到了优秀的最终性能，可以取得与 SGD 类似甚至更好的结果。</p>\n</li>\n<li>\n<p>对超参数更低的敏感性，更高的鲁棒性。</p>\n</li>\n</ol>\n<hr>\n<h2><span id=\"back-propagation反向传播\"> Back-propagation/反向传播</span></h2>\n<ul>\n<li>\n<p>将复杂函数化为计算图的形式，递归地调用链式法则，计算每个变量的梯度</p>\n</li>\n<li>\n<p>加法门</p>\n<ul>\n<li>gradient distributor/梯度传递</li>\n<li>两下游梯度 = 上游的梯度</li>\n</ul>\n</li>\n<li>\n<p>max门</p>\n<ul>\n<li>gradient router/梯度路由</li>\n<li>小的下游梯度为0，大的下游梯度 = 上游的梯度</li>\n</ul>\n</li>\n<li>\n<p>乘法门</p>\n<ul>\n<li>gradient switcher/梯度转换</li>\n<li>获取上游梯度，根据另一下游分支的值对本下游缩放</li>\n</ul>\n</li>\n<li>\n<p>当一个下游节点接两个上游节点时，梯度再次相加</p>\n</li>\n<li>\n<p>Jacobian matrix/雅可比矩阵</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\frac{\\partial y_1}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial y_1}{\\partial x_n}\\<br>\n\\vdots &amp; \\ddots &amp; \\vdots\\<br>\n\\frac{\\partial y_m}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial y_m}{\\partial x_n}\\<br>\n\\end{matrix}</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>x</mi></mrow></mfrac><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>f</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial L}{\\partial x}=\\frac{\\partial f}{\\partial x} \\frac{\\partial L}{\\partial f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2251079999999999em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.4133239999999998em;vertical-align:-0.481108em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial f}{\\partial x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>即为雅可比矩阵</p>\n</li>\n<li>\n<p>$<br>\nq = Wx =<br>\n\\begin{pmatrix}<br>\nW_{1,1}x_1+\\cdots+W_{1,n}x_n\\<br>\n\\vdots\\<br>\nW_{n,1}x_1+\\cdots+W_{n,n}x_n\\<br>\n\\end{pmatrix}<br>\n$</p>\n</li>\n<li>\n<p>$<br>\n\\frac{\\partial q_k}{\\partial W_{i,j}}=1_{k=j}x_j<br>\n$</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>q</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><msub><mi>W</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial q_k}{\\partial x_i}=W_{k,i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.377316em;vertical-align:-0.44509999999999994em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.44509999999999994em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>向量梯度大小与原向量保持一致，梯度的每个元素代表对最终函数的影响大小</p>\n</li>\n</ul>\n<hr>\n<h2><span id=\"regularization正则化\"> Regularization/正则化</span></h2>\n<ul>\n<li>减轻模型复杂度，避免过拟合，提高模型效果</li>\n<li>增加随机噪声</li>\n<li>通常采用Batch Normalization即可，过拟合时采用以下方法</li>\n</ul>\n<h3><span id=\"lp范数惩罚\"> Lp范数惩罚</span></h3>\n<ul>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L=... + \\lambda R(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></p>\n</li>\n<li>\n<p>L2 regularization：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><msubsup><mi>W</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>l</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">R(W)=\\sum_k\\sum_lW_{k,l}^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2333239999999999em;vertical-align:-0.4192159999999999em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4192159999999999em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>对W的欧式范数进行惩罚</li>\n</ul>\n</li>\n<li>\n<p>L1 regularization：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><mo>∣</mo><msub><mi>W</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>l</mi></mrow></msub><mo>∣</mo></mrow><annotation encoding=\"application/x-tex\">R(W)=\\sum_k\\sum_l\\mid W_{k,l}\\mid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0497100000000001em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span></span></span></span></p>\n<ul>\n<li>鼓励W稀疏</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"dropout\"> Dropout</span></h3>\n<ul>\n<li>每次正向传递时，在每一层随机将一部分神经元置0，且每次被置0的神经元不完全相同</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_step</span><span class=\"params\">(X)</span>：</span></span><br><span class=\"line\">\tH1 = np.maximum(0, np.dot(W1, X) + b1)</span><br><span class=\"line\">\tU1 = np.random.rand(*H1.shape) &lt; p <span class=\"comment\"># dropout mask</span></span><br><span class=\"line\">\tH1 *= U1 <span class=\"comment\"># drop!</span></span><br><span class=\"line\">  out = np.dot(W2, H1) + b2</span><br></pre></td></tr></table></figure>\n<ul>\n<li>避免特征相适应，降低过拟合</li>\n<li>单一模型集成学习</li>\n<li>测试时，乘以dropout概率</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">predict</span><span class=\"params\">(X)</span>:</span></span><br><span class=\"line\">  H1 = np.maximum(<span class=\"number\">0</span>, np.dot(W1, X) + b1) * p</span><br><span class=\"line\">  out = np.dot(W2, H1) + b2</span><br></pre></td></tr></table></figure>\n<h3><span id=\"data-augmentation数据增强\"> Data Augmentation/数据增强</span></h3>\n<ul>\n<li>使用翻转、裁剪、色彩抖动等方法处理过的图片进行训练</li>\n</ul>\n<hr>\n<h2><span id=\"transfer-learing迁移学习\"> Transfer Learing/迁移学习</span></h2>\n<ul>\n<li>大模型，小数据训练，易过拟合，此法同样解决过拟合</li>\n<li>小数据集与大数据集相似时：先在大数据集预训练的模型，要适应小数据集，可先冻结卷积、池化层，仅重新训练全连接层或线性分类器</li>\n<li>不相似时要重训练大部分层</li>\n</ul>\n<hr>\n<h2><span id=\"neural-network神经网络\"> Neural Network/神经网络</span></h2>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/1062917-20161117212457248-1468090428.png\" alt></p>\n<ul>\n<li>\n<p>包含若干个线性层，层与层之间用非线性函数连接</p>\n</li>\n<li>\n<p>2-layer Neural Network <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo>=</mo><msub><mi>W</mi><mn>2</mn></msub><mo>∗</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><msub><mi>W</mi><mn>1</mn></msub><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f=W_2*max(0,W_1 x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></p>\n<ul>\n<li>此处max为非线性函数且有很多可选</li>\n</ul>\n</li>\n<li>\n<p>每个节点接收多个输入，输出为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(\\sum_i w_i x_i +b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0497100000000001em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">)</span></span></span></span></p>\n<ul>\n<li>f为activation function/激活函数</li>\n</ul>\n</li>\n<li>\n<p>将每层看作一个向量，一组神经元的集合，进而利用矩阵乘法计算输出结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">h1 = f(np.dot(W1, x) + b1)</span><br><span class=\"line\">out = np.dot(W2, h1) + b2</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>多个输入x1, x2, x3为样本的多个特征值；多个样本时采用vectorization向量化，把样本压缩为向量/矩阵？同时计算。</p>\n</li>\n<li>\n<p>输入<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>D</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(N,D)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span></span></span></span>，隐层<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>D</mi><mo separator=\"true\">,</mo><mi>H</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(D,H)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span><span class=\"mclose\">)</span></span></span></span>，<strong>隐层神经元个数</strong><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>H</mi></mrow><annotation encoding=\"application/x-tex\">H</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span></span></span></span>，从数学角度来说感觉是每个sample都输入所有神经元。</p>\n</li>\n<li>\n<p>前向传播Forward Propagation：从input，经过一层层的layer，不断计算每一层的结果z和激活值a，最后得到输出y^ 的过程，计算出了y^，就可以根据它和真实值y的差别来计算损失（loss）。</p>\n<ul>\n<li>Layer i:\n<ul>\n<li>Z[i] = W[i]·A[i-1] + b[i]</li>\n<li>A[i] = σ(Z[i]) (sigmoid)</li>\n</ul>\n</li>\n<li>L(loss)：样本损失</li>\n<li>J(cost)：样本集的损失，L和的平均\n<ul>\n<li>J(W,b) = ΣL()/n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>反向传播Backward Propagation：根据L(y^,y)、J(W,b)来反方向地计算每一层的z、a、w、b的偏导数（梯度），从而更新参数。</p>\n</li>\n<li>\n<p>深层神经网络中，常采用RelU激活函数（求梯度更快，防止梯度消失），输出层采用sigmoid。</p>\n</li>\n<li>\n<p>参数维度：m个样本，共L层，当前l层，第l层单元数n[l]，</p>\n<ul>\n<li>W[l]:(n[l],n[l-1]), 即n[l]行、n[l-1]列</li>\n<li>b[l]:(n[l],1)</li>\n<li>z[l]:(n[l],1) Z[l]:(n[l],m)</li>\n<li>a[l]:(n[l],1) A[l]:(n[l],m)</li>\n<li>X:(n[0],m) Y:(1,m)</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2><span id=\"convolutional-neural-networks-cnn卷积神经网络\"> Convolutional Neural Networks, CNN/卷积神经网络</span></h2>\n<ul>\n<li>保持空间结构；在传统神经网络中每个神经元都要与图片上每个像素相连接，这样的话就会造成权重的数量巨大造成网络难以训练，而在含有卷积层的的神经网络中每个神经元的权重个数都是卷积核的大小，这样就相当于没有神经元只与对应图片部分的像素相连接。这样就极大的减少了权重的数量。</li>\n<li>核filter，例如<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">5*5*3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span>。参数学习得到。卷积过程中参数不变，<strong>通过一个卷积核的操作提取了原图的不同位置的同样特征。</strong></li>\n<li>**每个卷积核，在输入的整个深度上点积。**运算时，实质上也是先化为一维向量做点积。但有多个卷积核，所以输出为output size * output size * output num。</li>\n<li>卷积输出size：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mi>F</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">(N-F)/stride+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>\n<ul>\n<li>N：输入size，F：卷积核size，stride：步长</li>\n</ul>\n</li>\n<li>也有用0填充输入图片四周，使输出size保持不变。</li>\n</ul>\n<hr>\n<h2><span id=\"pooling池化\"> Pooling/池化</span></h2>\n<ul>\n<li>对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征</li>\n<li>深度不变。通常filter不重叠，不填0</li>\n<li>常用：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">2*2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span> 步长2，或<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>3</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">3*3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> 步长3</li>\n</ul>\n<hr>\n<h2><span id=\"activation-functions激活函数\"> Activation Functions/激活函数</span></h2>\n<h3><span id=\"sigmoidx\"> sigmoid(x)​</span></h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sigmoid.png\" alt></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma(x) = \\frac{1}{1+e^{-x}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2484389999999999em;vertical-align:-0.403331em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7026642857142857em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathdefault mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></li>\n<li>元素压缩至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span></span></span></span>范围</li>\n<li>问题：</li>\n<li>饱和神经元使得梯度为0，无法得到合适的梯度流\n<ul>\n<li>输出不以0为中心，x为正时w总为正或负，梯度更新效率低</li>\n<li>指数计算代价较大</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"tanhx\"> tanh(x)​</span></h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/tanh.png\" alt></p>\n<ul>\n<li>压缩至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-1,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">−</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span></span></span></span></li>\n<li>输出以0为中心</li>\n<li>问题：饱和时梯度为0</li>\n</ul>\n<h3><span id=\"relurectified-linear-unit\"> ReLU(Rectified Linear Unit)</span></h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/relu.png\" alt></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)=max(0,x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>正区域不会饱和</li>\n<li>函数简单，计算快，收敛快</li>\n<li>生物学上更合理</li>\n<li>问题</li>\n<li>输出不以0为中心\n<ul>\n<li>负半轴全饱和</li>\n<li>及其导致的Dead ReLU：反向传播中，大的梯度更新，使w变化，输入负数增加，函数关闭，参数w得不到更新，导致永久关闭</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"leaky-relu\"> Leaky ReLU</span></h3>\n<p>![](CS231n笔记/leaky relu.png)</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0.01</mn><mi>x</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)=max(0.01x,x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">0</span><span class=\"mord\">1</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>不会挂掉</li>\n</ul>\n<h3><span id=\"eluexponential-linear-units\"> ELU(Exponential Linear units)</span></h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/elu.png\" alt></p>\n<ul>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\">{</mo><mtable rowspacing=\"0.3599999999999999em\" columnalign=\"left left\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>x</mi><mspace width=\"2em\"><mspace width=\"2em\"><mi>i</mi><mi>f</mi><mi>x</mi><mo>&gt;</mo><mn>0</mn></mspace></mspace></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mtext> </mtext><mi>α</mi><mo stretchy=\"false\">(</mo><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mspace width=\"1em\"><mi>i</mi><mi>f</mi><mi>x</mi><mo>≤</mo><mn>0</mn></mspace></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding=\"application/x-tex\">f(x)=\\begin{cases}x\\qquad\\qquad if x&gt;0\\\\\\ \\alpha(e^x-1)\\quad ifx\\leq0 \\end{cases}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0000299999999998em;vertical-align:-1.25003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">{</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.69em;\"><span style=\"top:-3.69em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:2em;\"></span><span class=\"mspace\" style=\"margin-right:2em;\"></span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\">0</span></span></span><span style=\"top:-2.25em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mspace\"> </span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.19em;\"><span></span></span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n</li>\n<li>\n<p>输出均值近0</p>\n</li>\n<li>\n<p>负半轴近似饱和</p>\n</li>\n</ul>\n<h3><span id=\"maxout\"> Maxout</span></h3>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><msubsup><mi>w</mi><mn>1</mn><mi>T</mi></msubsup><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msubsup><mi>w</mi><mn>2</mn><mi>T</mi></msubsup><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">max(w_1^Tx+b_1,w_2^Tx+b_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0894389999999998em;vertical-align:-0.24810799999999997em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>不提前点积</li>\n<li>泛化ReLU，不饱和，不消亡</li>\n<li>问题：参数加倍</li>\n</ul>\n<h3><span id=\"总结\"> 总结</span></h3>\n<ul>\n<li>常用ReLU，注意学习率</li>\n<li>少用sigmoid</li>\n</ul>\n<hr>\n<h2><span id=\"data-preprocessing数据预处理\"> Data Preprocessing/数据预处理</span></h2>\n<ul>\n<li>\n<p>zero-centered data/零中心化</p>\n<p>X -= np.mean(X, axis = 0)</p>\n</li>\n<li>\n<p>normalized data/归一化，图像处理不常用</p>\n<p>X /= np.std(X, axis = 0)</p>\n</li>\n<li>\n<p>减去mean image</p>\n</li>\n<li>\n<p>减去单通道均值</p>\n</li>\n<li>\n<p>训练与预测阶段都需进行同样预处理（应用同样的参数、均值）</p>\n</li>\n</ul>\n<hr>\n<h2><span id=\"weight-initialization初始化权重\"> Weight Initialization/初始化权重</span></h2>\n<ul>\n<li>\n<p>输入输出方差相同，Xavier initialization</p>\n<p>W = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in/2)</p>\n</li>\n</ul>\n<hr>\n<h2><span id=\"batch-normalization批量归一化\"> Batch Normalization/批量归一化</span></h2>\n<ul>\n<li>\n<p>背景：深层网络在非线性变化前，激活的输入值的分布逐渐发生偏移变动。当整体分布靠近激活函数上下限端时，反向传播时的梯度消失，最终导致深层网络收敛越来越慢</p>\n</li>\n<li>\n<p>目的：数据转化为单位高斯数据，降低层之间输入数据分布变化，即使数据落入非线性函数的敏感区域，避免梯度消失，提速</p>\n</li>\n<li>\n<p>带来的问题：每层都通过BN，相当于多层线性函数，深度网络失去意义</p>\n</li>\n<li>\n<p>解决：对经过BN的x：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>∗</mo><mi>x</mi><mo>+</mo><mi>s</mi><mi>h</mi><mi>i</mi><mi>f</mi><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">y=scale*x+shift</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">h</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">t</span></span></span></span>。对每个神经元增加两个学习参数，相当于使非线性函数的值从线性区往非线性区偏移挪动。变换重构<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msup><mi>γ</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><msup><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>+</mo><msup><mi>β</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">y^{(k)}=\\gamma^{(k)}\\hat{x}^{(k)}+\\beta^{(k)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span>，则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>γ</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mrow></msqrt><mspace width=\"1em\"><msup><mi>β</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>E</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mspace></mrow><annotation encoding=\"application/x-tex\">\\gamma^{(k)}=\\sqrt{Var[x^{(k)}]} \\quad \\beta^{(k)}=E[x^{(k)}]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.2729999999999999em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9670000000000001em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span><span style=\"top:-2.9270000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2729999999999999em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>时可恢复原始数据，控制饱和程度。<strong>核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢</strong></p>\n</li>\n<li>\n<p>通常在FC、卷积层后插入</p>\n</li>\n<li>\n<p>训练过程：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>−</mo><mi>E</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mrow><mrow><msqrt><mi>V</mi></msqrt><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{x}^{(k)}=\\frac{x^{(k)}-E[x^{(k)}]}{\\sqrt Var[x^{(k)}]}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.799303em;vertical-align:-0.637603em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1617em;\"><span style=\"top:-2.537397em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322900000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.22222em;padding-left:0.833em;\">V</span></span><span style=\"top:-2.89229em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.10770999999999997em;\"><span></span></span></span></span></span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen mtight\">[</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8220357142857143em;\"><span style=\"top:-2.8220357142857138em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose mtight\">]</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9667142857142857em;\"><span style=\"top:-2.966714285714285em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen mtight\">[</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9667142857142857em;\"><span style=\"top:-2.966714285714285em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose mtight\">]</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.637603em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/bn_forward.png\" alt=\"Batch Normalization\" title=\"forward\"></p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/bn_backward.jpg\" alt=\"bn_backward\" title=\"backward\"></p>\n<p>预测过程：用从所有训练实例中获得的统计量代表期望和方差</p>\n</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>E</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>←</mo><msub><mi>E</mi><mi>B</mi></msub><mo stretchy=\"false\">[</mo><msub><mi>μ</mi><mi>B</mi></msub><mo stretchy=\"false\">]</mo><mspace linebreak=\"newline\"></mspace><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>←</mo><mfrac><mi>m</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></mfrac><msub><mi>E</mi><mi>B</mi></msub><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">]</mo><mspace linebreak=\"newline\"></mspace><mi>y</mi><mo>=</mo><mfrac><mi>γ</mi><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>+</mo><mi>ε</mi></mrow></msqrt></mfrac><mo>∗</mo><mi>x</mi><mo>+</mo><mo stretchy=\"false\">(</mo><mi>β</mi><mo>−</mo><mfrac><mrow><mi>γ</mi><mo>∗</mo><mi>E</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo></mrow><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>+</mo><mi>ε</mi></mrow></msqrt></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">E[x]\\leftarrow E_B[\\mu_B]\t\\\\\nVar[x]\\leftarrow\\frac{m}{m-1}E_B[\\sigma_B^2] \\\\\ny=\\frac{\\gamma}{\\sqrt{Var[x]+\\varepsilon}}*x+(\\beta-\\frac{\\gamma*E[x]}{\\sqrt{Var[x]+\\varepsilon}})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8768900000000002em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.10756em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.2375599999999998em;vertical-align:-1.13em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.175em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.935em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">ε</span></span></span><span style=\"top:-2.8950000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30499999999999994em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.13em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.557em;vertical-align:-1.13em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.175em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.935em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">ε</span></span></span><span style=\"top:-2.8950000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30499999999999994em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.13em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<hr>\n<h2><span id=\"babysitting-the-learning-process观察学习过程\"> Babysitting the Learning Process/观察学习过程</span></h2>\n<ul>\n<li>数据预处理</li>\n<li>选择网络结构</li>\n<li>初始化网络，前向传播</li>\n<li>观察损失，和添加正则化项后的损失</li>\n<li>从小数据集训练，关闭正则化，sgd，观察loss能否为0、accuracy能否为1</li>\n<li>正式训练，全部数据，开启正则化</li>\n<li>调整学习率（最重要参数），过小时梯度更新小，loss变化小，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span></span></span></span>常为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn><mi>e</mi><mo>−</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">1e-3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span>到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn><mi>e</mi><mo>−</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">1e-5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span></span></span></span>之间</li>\n</ul>\n<hr>\n<h2><span id=\"hyper-parameter-optimization超参数设置\"> Hyper-parameter Optimization/超参数设置</span></h2>\n<ul>\n<li>交叉验证，训练集训练，验证集验证</li>\n<li>首先几个epoch粗略观察超参是否合理，确定合理区间</li>\n<li>loss激增时说明方向有误</li>\n</ul>\n<p>![](CS231n笔记/loss-learing rate.png “loss~learning rate”)</p>\n<hr>\n<h2><span id=\"pytorch\"> PyTorch</span></h2>\n<ul>\n<li>定义三个抽象\n<ul>\n<li>Tensor 张量，类似数组</li>\n<li>Variable 变量，计算图中节点，储存数据和梯度</li>\n<li>Module 类/模块，是一个神经网络层，储存状态和参数</li>\n</ul>\n</li>\n</ul>\n<h3><span id=\"tensor张量\"> Tensor/张量</span></h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 简单的神经网络示例(使用张量)</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dtype = torch.FloatTensor</span></span><br><span class=\"line\">dtype = torch.cuda.FloatTensor\t<span class=\"comment\"># GPU</span></span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\">x = torch.randn(N, D_in).type(dtype)</span><br><span class=\"line\">y = torch.randn(N, D_out).type(dtype)</span><br><span class=\"line\">w1 = torch.randn(D_in, H).type(dtype)</span><br><span class=\"line\">w2 = torch.randn(H, D_out).type(dtype)</span><br><span class=\"line\"></span><br><span class=\"line\">learning_rate = <span class=\"number\">1e-6</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">500</span>):</span><br><span class=\"line\">  h = x.mm(w1)</span><br><span class=\"line\">  h_relu = h.clamp(min=<span class=\"number\">0</span>)</span><br><span class=\"line\">  y_pred = h_relu.mm(w2)</span><br><span class=\"line\">  loss = (y_pred - y).pow(<span class=\"number\">2</span>).sum()</span><br><span class=\"line\">  </span><br><span class=\"line\">  grad_y_pred = <span class=\"number\">2.0</span> * (y_pred - y)</span><br><span class=\"line\">  grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class=\"line\">  grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class=\"line\">  grad_h = grad_h_relu.clone()</span><br><span class=\"line\">  grad_h[h &lt; <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">  grad_w1 = x.t().mm(grad_h)</span><br><span class=\"line\">  </span><br><span class=\"line\">  w1 -= learning_rate * grad_w1</span><br><span class=\"line\">  w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>\n<h3><span id=\"variable变量\"> Variable/变量</span></h3>\n<ul>\n<li>X.data 张量类型</li>\n<li>X.grad 变量类型，梯度，与data同shape</li>\n<li>X.grad.data 张量类型，梯度的张量</li>\n<li>PyTorch中，张量、变量相同API</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\">x = Variable(torch.randn(N, D_in), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">y = Variable(torch.randn(N, D_out), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">w1 = Variable(torch.randn(D_in, H), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">w2 = Variable(torch.randn(H, D_out), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">learning_rate = <span class=\"number\">1e-6</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">500</span>):</span><br><span class=\"line\">  y_prred = x.mm(w1).clamp(min=<span class=\"number\">0</span>).mm(w2)</span><br><span class=\"line\">  loss = (y_pred - y).pow(<span class=\"number\">2</span>).sum()</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">if</span> w1.grad: w1.grad.data.zero_()</span><br><span class=\"line\">  <span class=\"keyword\">if</span> w2.grad: w2.grad.data.zero_()</span><br><span class=\"line\">  loss.backward()</span><br><span class=\"line\">  </span><br><span class=\"line\">  w1.data -= learning_rate * w1.grad.data</span><br><span class=\"line\">  w2.data -= learning_rate * w2.grad.data</span><br></pre></td></tr></table></figure>\n<h3><span id=\"nn高级封装\"> nn/高级封装</span></h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Varible</span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\">x = Variable(torch.randn(N, D_in))</span><br><span class=\"line\">y = Variable(torch.randn(N, D_out), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把模型定义为层的序列</span></span><br><span class=\"line\">model = torch.nn.Sequential(torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out))</span><br><span class=\"line\"><span class=\"comment\"># nn中定义了一些损失函数</span></span><br><span class=\"line\">loss_fn = torch.nn.MSELoss(size_average=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 给模型喂数据，得到预测以计算损失</span></span><br><span class=\"line\">learning_rate = <span class=\"number\">1e-4</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> tange(<span class=\"number\">500</span>):</span><br><span class=\"line\">  y_pred = model(x)</span><br><span class=\"line\">  loss = loss_fn(y_pred, y)</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># 计算梯度</span></span><br><span class=\"line\">  model.zero_grad()</span><br><span class=\"line\">  loss.backward()</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># 在所有参数上循环，更新参数 </span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> model.parameters():</span><br><span class=\"line\">    param.data -= learning_rate * param.grad.data</span><br></pre></td></tr></table></figure>\n<h3><span id=\"optimizer优化器\"> optimizer/优化器</span></h3>\n<ul>\n<li>\n<p>将参数更新的流程抽象出来，并执行更新法则</p>\n</li>\n<li>\n<p>以上例为基础：</p>\n</li>\n<li>\n<p>14行后添加如下，意为要对参数采用此法则、此学习率更新</p>\n<p><code>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</code></p>\n</li>\n<li>\n<p>23~25行的参数更新改为：<code>optimizer.step()</code></p>\n</li>\n</ul>\n<h3><span id=\"module类\"> Module/类</span></h3>\n<ul>\n<li>神经网络层，输入输出为变量类型</li>\n<li>包含参数或其他模块</li>\n<li>可以使用autograd定义新Module</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">form torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这个类把整个模型定义成nn类中的一个新类，</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TwoLayerNet</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_</span><span class=\"params\">(self, D_in, H, D_out)</span>:</span></span><br><span class=\"line\">    super(TwoLayerNet, self)._init_()</span><br><span class=\"line\">    self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class=\"line\">    self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class=\"line\">    </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">    h_relu = self.linear1(x).clamp(min=<span class=\"number\">0</span>)</span><br><span class=\"line\">    y_pred = self.linear2(h_relu)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> y_pred</span><br><span class=\"line\">  </span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">x = Variable(torch.randn(N, D_in))</span><br><span class=\"line\">y = Variable(torch.randn(N, D_out), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = TwoLayerNet(D_in,, H, D_out)</span><br><span class=\"line\"></span><br><span class=\"line\">criterion = torch.nn.MSELoss(size_average=<span class=\"literal\">False</span>)</span><br><span class=\"line\">optimizer = torch.optim.SGD(model.parameters(), lr=<span class=\"number\">1e-4</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">500</span>):</span><br><span class=\"line\">  y_pred = model(x)</span><br><span class=\"line\">  loss = criterion(y_pred, y)</span><br><span class=\"line\">  </span><br><span class=\"line\">  optimizer.zero_grad()</span><br><span class=\"line\">  loss.backward()</span><br><span class=\"line\">  optimizer.step()</span><br></pre></td></tr></table></figure>\n<h3><span id=\"dataloader数据加载\"> DataLoader/数据加载</span></h3>\n<ul>\n<li>可以建立分批处理，也可以执行多线程</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\">form torch.utils.data <span class=\"keyword\">import</span> TensorDataset, DataLoader</span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.randn(N, D_in)</span><br><span class=\"line\">y = torch.randn(N, D_out)</span><br><span class=\"line\"></span><br><span class=\"line\">loader = DataLoader(TensorDataset(x, y), batch_size=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = TwoLayerNet(D_in, H, D_out)</span><br><span class=\"line\"></span><br><span class=\"line\">ceiterion = torch.nn.MSELoss(size_average=<span class=\"literal\">False</span>)</span><br><span class=\"line\">optimizer = torch.optim.SGD(model.parameters(), lr=<span class=\"number\">1e-4</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>):</span><br><span class=\"line\">  <span class=\"keyword\">for</span> x_batch, y_batch <span class=\"keyword\">in</span> loader:</span><br><span class=\"line\">    x_var, y_var = Variable(x), Variable(y)</span><br><span class=\"line\">    y_pred = model(x_var)</span><br><span class=\"line\">    loss = criterion(y_pred, y_var)</span><br><span class=\"line\">    </span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br></pre></td></tr></table></figure>\n<h3><span id=\"pretrained-model预训练模型\"> Pretrained Model/预训练模型</span></h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"></span><br><span class=\"line\">alexnet = torchvision.models.alexnet(pretrained=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<h3><span id=\"else其他\"> else/其他</span></h3>\n<ul>\n<li>visdom 可视化的包</li>\n<li>可以通过重写前向、反向传播函数定义新的Autograd Function</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ReLU</span><span class=\"params\">(torch.autograd.Function)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forwar</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">    self.save_for_backward(x)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x.clamp(min=<span class=\"number\">0</span>)</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">backward</span><span class=\"params\">(self, grad_y)</span>:</span></span><br><span class=\"line\">    x, = self.saved_tensors</span><br><span class=\"line\">    grad_input = grad_y.clone()</span><br><span class=\"line\">    grad_input[x &lt; <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> grad_input</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<!-- toc -->\n<ul>\n<li><a href=\"#project\">Project</a></li>\n<li><a href=\"#cs231n\">CS231n</a>\n<ul>\n<li><a href=\"#data-driven%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8\">Data Driven/数据驱动</a></li>\n<li><a href=\"#linear-classifier%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB\">Linear Classifier/线性分类</a></li>\n<li><a href=\"#loss-function%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\">Loss Function/损失函数</a></li>\n<li><a href=\"#optimization%E4%BC%98%E5%8C%96%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">Optimization/优化/梯度下降</a>\n<ul>\n<li><a href=\"#stochastic-gradient-descentsgd%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">Stochastic Gradient Descent(SGD)/随机梯度下降</a></li>\n<li><a href=\"#sgdmomentum%E7%BB%93%E5%90%88%E5%8A%A8%E9%87%8F%E7%9A%84sgd\">SGD+Momentum/结合动量的SGD</a></li>\n<li><a href=\"#sgdnesterov\">SGD+Nesterov</a></li>\n<li><a href=\"#adagrad\">AdaGrad</a></li>\n<li><a href=\"#rmsprop\">RMSProp</a></li>\n<li><a href=\"#adam\">Adam</a></li>\n<li><a href=\"#gif\">GIF</a></li>\n<li><a href=\"#adabound\">AdaBound</a>\n<ul>\n<li><a href=\"#%E8%83%8C%E6%99%AF\">背景</a></li>\n<li><a href=\"#%E8%AE%BA%E6%96%87%E5%86%85%E5%AE%B9\">论文内容</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#back-propagation%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD\">Back-propagation/反向传播</a></li>\n<li><a href=\"#regularization%E6%AD%A3%E5%88%99%E5%8C%96\">Regularization/正则化</a>\n<ul>\n<li><a href=\"#lp%E8%8C%83%E6%95%B0%E6%83%A9%E7%BD%9A\">Lp范数惩罚</a></li>\n<li><a href=\"#dropout\">Dropout</a></li>\n<li><a href=\"#data-augmentation%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\">Data Augmentation/数据增强</a></li>\n</ul>\n</li>\n<li><a href=\"#transfer-learing%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0\">Transfer Learing/迁移学习</a></li>\n<li><a href=\"#neural-network%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">Neural Network/神经网络</a></li>\n<li><a href=\"#convolutional-neural-networks-cnn%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\">Convolutional Neural Networks, CNN/卷积神经网络</a></li>\n<li><a href=\"#pooling%E6%B1%A0%E5%8C%96\">Pooling/池化</a></li>\n<li><a href=\"#activation-functions%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0\">Activation Functions/激活函数</a>\n<ul>\n<li><a href=\"#sigmoidx\">sigmoid(x)​</a></li>\n<li><a href=\"#tanhx\">tanh(x)​</a></li>\n<li><a href=\"#relurectified-linear-unit\">ReLU(Rectified Linear Unit)</a></li>\n<li><a href=\"#leaky-relu\">Leaky ReLU</a></li>\n<li><a href=\"#eluexponential-linear-units\">ELU(Exponential Linear units)</a></li>\n<li><a href=\"#maxout\">Maxout</a></li>\n<li><a href=\"#%E6%80%BB%E7%BB%93\">总结</a></li>\n</ul>\n</li>\n<li><a href=\"#data-preprocessing%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\">Data Preprocessing/数据预处理</a></li>\n<li><a href=\"#weight-initialization%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9D%83%E9%87%8D\">Weight Initialization/初始化权重</a></li>\n<li><a href=\"#batch-normalization%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96\">Batch Normalization/批量归一化</a></li>\n<li><a href=\"#babysitting-the-learning-process%E8%A7%82%E5%AF%9F%E5%AD%A6%E4%B9%A0%E8%BF%87%E7%A8%8B\">Babysitting the Learning Process/观察学习过程</a></li>\n<li><a href=\"#hyper-parameter-optimization%E8%B6%85%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE\">Hyper-parameter Optimization/超参数设置</a></li>\n<li><a href=\"#pytorch\">PyTorch</a>\n<ul>\n<li><a href=\"#tensor%E5%BC%A0%E9%87%8F\">Tensor/张量</a></li>\n<li><a href=\"#variable%E5%8F%98%E9%87%8F\">Variable/变量</a></li>\n<li><a href=\"#nn%E9%AB%98%E7%BA%A7%E5%B0%81%E8%A3%85\">nn/高级封装</a></li>\n<li><a href=\"#optimizer%E4%BC%98%E5%8C%96%E5%99%A8\">optimizer/优化器</a></li>\n<li><a href=\"#module%E7%B1%BB\">Module/类</a></li>\n<li><a href=\"#dataloader%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD\">DataLoader/数据加载</a></li>\n<li><a href=\"#pretrained-model%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B\">Pretrained Model/预训练模型</a></li>\n<li><a href=\"#else%E5%85%B6%E4%BB%96\">else/其他</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"project\"><a class=\"markdownIt-Anchor\" href=\"#project\"></a> Project</h1>\n<ul>\n<li>判别式方法 -&gt; 深度学习类</li>\n<li><a href=\"https://wenku.baidu.com/view/552db3a780c758f5f61fb7360b4c2e3f56272517.html\" target=\"_blank\" rel=\"noopener\">目标跟踪算法综述</a></li>\n<li><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/%E4%B8%BB%E6%B5%81.png\" alt></li>\n<li>为了扩展CNN在目标跟踪领域的能力，需要大量的训练数据，但这在目标跟踪中是很难做到的。MDNet[14]算法提出了一种解决该问题的思路。算法采用VGG-M作为网络初始化模型，后接多个全连接层用作分类器。训练时，每一个跟踪视频对应一个全连接层，学习普遍的特征表示用来跟踪。跟踪时，去掉训练时的全连接层，使用第一帧样本初始化一个全连接层，新的全连接层在跟踪的过程中继续微调，来适应新的目标变化。这种方法使得特征更适合于目标跟踪，效果大大提升。由此可以看出，通过视频训练的网络更适合目标跟踪这一任务</li>\n<li>速度改进：虽然深度特征具有传统特征无法比拟的抗干扰能力，但是一般提取速度较慢，而且特征中存在大量冗余。当算法精度达到一定标准之后，很多方法开始着力解决算法速度问题。<strong>孪生网络</strong>[19]是其中的一个典型例子，采用两路神经网络分别输入目标模板和搜索图像块，用来进行模板匹配或候选样本分类。其中一路神经网络对于模板信息的保存可以提供跟踪物体先验信息，取代网络在线更新，大大节省了速度。另外，<strong>对深度特征进行降维或自适应选择</strong>也是加速算法的有效途径。由于深度神经网络复杂的计算及模型更新时繁琐的系数，现存大部分深度目标跟踪算法速度都比较慢。很多深度目标跟踪算法采用<strong>小型神经网络（如VGG-M）<strong>来提特征。另外，跟踪中只给定第一帧目标位置，缺少跟踪物体先验信息，这就</strong>要求模型实时更新</strong>来确保跟踪精度，而这在深度目标跟踪算法中往往非常耗时。一些算法采用孪生网络结构来保存先验信息，代替模型在线更新，使得算法速度得以提高。深度特征的高维度也会影响跟踪算法的速度，如果能够提出有效的特征压缩方法，不管对算法速度还是精度都会有所帮助。只有高速且有效地算法才具有实际的应用价值</li>\n</ul>\n<hr>\n<h1 id=\"cs231n\"><a class=\"markdownIt-Anchor\" href=\"#cs231n\"></a> CS231n</h1>\n<h2 id=\"data-driven数据驱动\"><a class=\"markdownIt-Anchor\" href=\"#data-driven数据驱动\"></a> Data Driven/数据驱动</h2>\n<ul>\n<li>以数据/样本驱动，训练模型，进行预测</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">(images, labels)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\">#Machine learning</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> model</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">predict</span><span class=\"params\">(model, test_images)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\">#use model to predict labels</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> test_labels</span><br></pre></td></tr></table></figure>\n<ul>\n<li>train_data/训练集：以不同的超参数训练模型</li>\n<li>validation_data/验证集：选出效果最优的超参数</li>\n<li>test_data/测试集：仅预测算法在未见新数据上的</li>\n</ul>\n<hr>\n<h2 id=\"linear-classifier线性分类\"><a class=\"markdownIt-Anchor\" href=\"#linear-classifier线性分类\"></a> Linear Classifier/线性分类</h2>\n<ul>\n<li>\n<p>将训练数据浓缩于参数W/θ中，但每个类别只能学习一个单独模板</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>W</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">f(x,W)=Wx+b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span></span></span></span></p>\n</li>\n<li>\n<p>W:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>10</mn><mo>∗</mo><mn>3072</mn></mrow><annotation encoding=\"application/x-tex\">10*3072</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">0</span><span class=\"mord\">7</span><span class=\"mord\">2</span></span></span></span> ，有十类时</p>\n<ul>\n<li>x:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>3072</mn><mo>∗</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">3072*1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">0</span><span class=\"mord\">7</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> ， 图片为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>32</mn><mo>∗</mo><mn>32</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">32*32*3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span>时</li>\n<li>b:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>10</mn><mo>∗</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">10*1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span> ， 有十类时</li>\n<li>结果得分:<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>10</mn><mo>∗</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">10*1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"loss-function损失函数\"><a class=\"markdownIt-Anchor\" href=\"#loss-function损失函数\"></a> Loss Function/损失函数</h2>\n<ul>\n<li>将W输入，输出得分，定量地估计W的好坏</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>W</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">f(x, W)=Wx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathdefault\">x</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=\"false\">(</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L=\\frac{1}{N}\\sum_iL_i(f(x_i,W),y_i)+\\lambda R(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>N：样本数\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\lambda R(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span>：正则化项</li>\n</ul>\n</li>\n<li>Multi-class SVM LOSS：</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><msub><mo>∑</mo><mrow><mi>j</mi><mo>≠</mo><msub><mi>y</mi><mi>i</mi></msub></mrow></msub><mi>max</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><msub><mi>s</mi><mi>j</mi></msub><mo>−</mo><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub><mo>+</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L_i=\\sum_{j\\not=y_i}\\max(0,s_j-s_{y_i}+margin)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.185818em;vertical-align:-0.43581800000000004em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.18639799999999984em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span><span class=\"mrel mtight\"><span class=\"mord mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"rlap mtight\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel mtight\"></span></span><span class=\"fix\"></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.43581800000000004em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">max</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8694379999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span></span></span></span>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>s</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">s=f(x,W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>i：当前对第i个样本的得分计算</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><mi>j</mi></msub></mrow><annotation encoding=\"application/x-tex\">s_j</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>：当前样本对第j类的得分</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>s</mi><msub><mi>y</mi><mi>i</mi></msub></msub></mrow><annotation encoding=\"application/x-tex\">s_{y_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>：当前样本对正确分类组的得分</li>\n<li>margin：适当边距</li>\n<li>释义：不正确分类上损失之和，且正确分类得分超出错误分类得分margin以上时损失为0</li>\n</ul>\n</li>\n<li>Softmax Loss：</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>=</mo><mi>k</mi><mo>∣</mo><mi>X</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>s</mi></msup><mi>k</mi></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><msup><mi>e</mi><mi>s</mi></msup><mi>j</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">P(Y=k\\mid X=x_i)=\\frac{e^s k}{\\sum_j e^s j}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.578207em;vertical-align:-0.667227em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.91098em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mop mtight\"><span class=\"mop op-symbol small-op mtight\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.14964714285714287em;\"><span style=\"top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.46032428571428574em;\"><span></span></span></span></span></span></span><span class=\"mspace mtight\" style=\"margin-right:0.19516666666666668em;\"></span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5935428571428571em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span></span></span></span></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7385428571428572em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span></span></span></span></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.667227em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>s</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">;</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">s=f(x_i;W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>最小化<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy=\"false\">(</mo><mi>Y</mi><mo>=</mo><msub><mi>y</mi><mi>i</mi></msub><mo>∣</mo><mi>X</mi><mo>=</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L_i=-\\log P(Y=y_i\\mid X=x_i)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\">lo<span style=\"margin-right:0.01389em;\">g</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">Y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>希望正确分类的概率趋近1</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"optimization优化梯度下降\"><a class=\"markdownIt-Anchor\" href=\"#optimization优化梯度下降\"></a> Optimization/优化/梯度下降</h2>\n<p>梯度下降是指，在给定待优化的模型参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi><mo>∈</mo><msup><mi>R</mi><mi>d</mi></msup></mrow><annotation encoding=\"application/x-tex\">\\theta\\in R^d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.73354em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span>和目标函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>，算法通过沿梯度 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\nabla _\\theta J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>的相反方向更新<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>来最小化<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span>。学习率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span></span></span></span>决定了每一时刻的更新步长。</p>\n<p>流程如下：</p>\n<ol>\n<li>\n<p>计算目标函数关于参数的梯度</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>g</mi><mi>t</mi></msub><mo>=</mo><msub><mi mathvariant=\"normal\">∇</mi><mi>θ</mi></msub><mi>J</mi><mo stretchy=\"false\">(</mo><mi>θ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">g_t=\\nabla_\\theta J(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span></p>\n</li>\n<li>\n<p>根据历史梯度计算一阶和二阶动量</p>\n</li>\n</ol>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>g</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">m_t=\\phi (g_1,g_2,\\cdots ,g_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><mi>ψ</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo separator=\"true\">,</mo><msub><mi>g</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_t=\\psi(g_1,,g_2,\\cdots ,g_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">ψ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<ol start=\"3\">\n<li>更新模型参数</li>\n</ol>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>t</mi></msub><mo>−</mo><mfrac><mn>1</mn><msqrt><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><msub><mi>m</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{v_t+\\epsilon}}m_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.383108em;vertical-align:-0.538em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6224469999999998em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.81079em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathdefault mtight\">ϵ</span></span></span><span style=\"top:-2.77079em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.22921000000000002em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.538em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>梯度就是偏导数组成的向量，即多元/多参数、参数为向量时</li>\n<li>梯度和X的形状一样，元素告诉我们相关方向上函数f的斜率</li>\n<li>梯度指向函数增加最快的方向，负梯度方向即下降最快方向</li>\n<li>则位置任意方向斜率=梯度与单位方向向量的点积</li>\n<li>根据梯度决定下一次更新方向</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi mathvariant=\"normal\">∇</mi><mi>W</mi></msub><mi>L</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msub><mo>∑</mo><mi>i</mi></msub><msub><mi mathvariant=\"normal\">∇</mi><mi>W</mi></msub><msub><mi>L</mi><mi>i</mi></msub><mo stretchy=\"false\">(</mo><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo separator=\"true\">,</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy=\"false\">)</mo><mo>+</mo><mi>λ</mi><msub><mi mathvariant=\"normal\">∇</mi><mi>W</mi></msub><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\nabla_WL=\\frac{1}{N}\\sum_i\\nabla_WL_i(f(x_i,W),y_i)+\\lambda \\nabla_WR(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord\"><span class=\"mord\">∇</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>Gradient Descent/梯度下降</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dw = compute_grad(loss_fun, data, weights)</span><br><span class=\"line\">  weight += - step_size * dw</span><br></pre></td></tr></table></figure>\n<h3 id=\"stochastic-gradient-descentsgd随机梯度下降\"><a class=\"markdownIt-Anchor\" href=\"#stochastic-gradient-descentsgd随机梯度下降\"></a> Stochastic Gradient Descent(SGD)/随机梯度下降</h3>\n<ul>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>η</mi><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">m_t=\\eta g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><msup><mi>I</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">v_t=I^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">I</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϵ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\epsilon=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>i</mi></msub><mo>−</mo><mi>η</mi><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_{i+1}=\\theta_i-\\eta g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>N过大，只取部分data计算，以估计整体梯度</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">\tdata_batch = sample_training_data(data, <span class=\"number\">256</span>)</span><br><span class=\"line\">  dw = compute_grad(loss_fun, data_batch, weights)</span><br><span class=\"line\">  weight += - step_size * dw</span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>SGD的问题：</p>\n<ul>\n<li>\n<p>当对一个方向敏感，对其他方向迟钝，会形成之字形路径，收敛极其缓慢。下图仅二维两个参数</p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sgd_problem.png\" alt></p>\n</li>\n<li>\n<p>局部最小值和鞍点处，会卡住。维度增加，鞍点会快速增加</p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sgd_problem2.png\" alt></p>\n</li>\n<li>\n<p>易受噪声影响</p>\n</li>\n<li>\n<p>步长恒定，速度慢</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"sgdmomentum结合动量的sgd\"><a class=\"markdownIt-Anchor\" href=\"#sgdmomentum结合动量的sgd\"></a> SGD+Momentum/结合动量的SGD</h3>\n<ul>\n<li>\n<p>引入一阶动量</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>γ</mi><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>η</mi><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">m_t=\\gamma m_{t-1}+\\eta g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.791661em;vertical-align:-0.208331em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vx = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dx = compute_grad(x)</span><br><span class=\"line\">  vx = rho * vx + learning_rate * dx</span><br><span class=\"line\">  x -= vx</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sgd_problem1.png\" alt></p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/SGDM.jpg\" alt=\"SGDM\"></p>\n<h3 id=\"sgdnesterov\"><a class=\"markdownIt-Anchor\" href=\"#sgdnesterov\"></a> SGD+Nesterov</h3>\n<ul>\n<li>不同于SGDM的梯度与速度向量之和的方向作为新的步进方向，Nesterov动量，是先从当前点，沿速度方向步进，在新位置求梯度向量，然后返回起始点向梯度方向步进。</li>\n</ul>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/SGD+Nesterov.png\" alt></p>\n<ul>\n<li>\n<p>凸优化问题较好，非凸会有问题</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo>−</mo><mi>α</mi><mi mathvariant=\"normal\">∇</mi><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_{t+1}=\\rho v_t-\\alpha\\nabla f(x_t+\\rho v_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">∇</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding=\"application/x-tex\">x_{t+1}=x_t+v_{t+1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>以上形式，会导致运算增加。变量代换，便于网络同时求梯度和损失</p>\n</li>\n</ul>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_t=x_t+\\rho v_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo>−</mo><mi>α</mi><mi mathvariant=\"normal\">∇</mi><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mi>y</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_{t+1}=\\rho v_t-\\alpha\\nabla f(y_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\">∇</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>y</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub><mo>−</mo><mi>ρ</mi><msub><mi>v</mi><mi>t</mi></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mi>ρ</mi><mo stretchy=\"false\">)</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>y</mi><mi>t</mi></msub><mo>+</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><mi>ρ</mi><mo stretchy=\"false\">(</mo><msub><mi>v</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>v</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y_{t+1}=y_t-\\rho v_t + (1+\\rho)v_{t+1}=y_t+v_{t+1}+\\rho(v_{t+1}-v_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.638891em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7777700000000001em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.791661em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ρ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dx = compute_gradient(x)</span><br><span class=\"line\">old_v = v</span><br><span class=\"line\">v = rho * v - lr * dx</span><br><span class=\"line\">x += -rho * old_v + (<span class=\"number\">1</span> + rho) * v</span><br></pre></td></tr></table></figure>\n<h3 id=\"adagrad\"><a class=\"markdownIt-Anchor\" href=\"#adagrad\"></a> AdaGrad</h3>\n<p><strong>SGD、SGD-M均是以相同的学习率去更新<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>的各个分量。而深度学习模型中往往涉及大量的参数，不同参数的更新频率往往有所区别。对于更新不频繁的参数，我们希望单次步长更大，多学习一些知识；对于更新频繁的参数，我们则希望步长较小，使得学习到的参数更稳定，不至于被单个样本影响太多。即自适应学习率。</strong></p>\n<ul>\n<li>引入二阶动量，加速非敏方向，减慢敏感方向速度</li>\n</ul>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy=\"false\">(</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>1</mn></mrow><mn>2</mn></msubsup><mo separator=\"true\">,</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mn>2</mn></mrow><mn>2</mn></msubsup><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>t</mi></msubsup><msubsup><mi>g</mi><mrow><mi>i</mi><mo separator=\"true\">,</mo><mi>d</mi></mrow><mn>2</mn></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_t=diag(\\sum^t_{i=1}g^2_{i,1},\\sum^t_{i=1}g^2_{i,2},\\cdots,\\sum^t_{i=1}g^2_{i,d})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3526719999999999em;vertical-align:-0.4192159999999999em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.394772em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.441336em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.394772em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.933456em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">d</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4192159999999999em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>d</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">v_t\\in R^{d\\times d}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6891em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span></span></span></span>，对角矩阵，元素为参数第<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.65952em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">i</span></span></span></span>维从初始时刻到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时的梯度平方和，学习率等效为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>η</mi><mi mathvariant=\"normal\">/</mi><msqrt><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\eta/\\sqrt{v_t+\\epsilon}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.051665em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\">/</span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8016650000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">ϵ</span></span></span><span style=\"top:-2.761665em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.23833499999999996em;\"><span></span></span></span></span></span></span></span></span>，对此前频繁更新的参数，其二阶动量的对应分量较大，学习率就小，反之同理</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grad_squared = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dx = compute_grad(x)</span><br><span class=\"line\">  grad_squared += dx * dx</span><br><span class=\"line\">  x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"number\">1e-7</span>)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>步长越来越小，凸函数时是好的特性（接近极值时减慢、收敛），非凸时不好（局部极值卡住）</li>\n</ul>\n<h3 id=\"rmsprop\"><a class=\"markdownIt-Anchor\" href=\"#rmsprop\"></a> RMSProp</h3>\n<ul>\n<li>\n<p>计算二阶动量时只关注最近的下降梯度，其二阶动量采用<em>指数移动平均公式</em>计算，这样即可避免二阶动量持续累积的问题。优点保留，但存在平方项持续减少，训练缓慢的隐患</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>v</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mi>t</mi></msub><mo>⨀</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">​</mi></mrow><annotation encoding=\"application/x-tex\">v_t=\\beta_2 v_{t-1}+(1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)​</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">⨀</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">​</span></span></span></span></p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">grad_squared = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">  dx = compute_grad(x)</span><br><span class=\"line\">  grad_squared = decay_rate * grad_squared + (<span class=\"number\">1</span> - decay_rate) * dx * dx</span><br><span class=\"line\">  x -= learning_rate * dx / (np.sqrt(grad_squared) + <span class=\"number\">1e-7</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"adam\"><a class=\"markdownIt-Anchor\" href=\"#adam\"></a> Adam</h3>\n<ul>\n<li>\n<p>对一阶动量也用指数移动平均公式</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><mi>η</mi><mo stretchy=\"false\">[</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">m_t=\\eta[\\beta_1m_{t-1}+(1-\\beta_1)g_t]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>m</mi><mi>t</mi></msub><mo>=</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>m</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>g</mi><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">m_t=\\beta_1m_{t-1}+(1-\\beta_1)g_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>v</mi><mi>t</mi></msub><mo>=</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>v</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><mi mathvariant=\"normal\">（</mi><mn>1</mn><mo>−</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>⋅</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy=\"false\">(</mo><msub><mi>g</mi><mi>t</mi></msub><mo>⨀</mo><msub><mi>g</mi><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">v_t=\\beta_2 v_{t-1}+（1-\\beta_2)\\cdot diag(g_t\\bigodot g_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord cjk_fallback\">（</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.00001em;vertical-align:-0.25001em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">⨀</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><msub><mi>m</mi><mi>t</mi></msub><mo>^</mo></mover><mo>=</mo><mfrac><msub><mi>m</mi><mi>t</mi></msub><mrow><mn>1</mn><mo>−</mo><msubsup><mi>β</mi><mn>1</mn><mi>t</mi></msubsup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{m_t}=\\frac{m_t}{1-\\beta^t_1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.288452em;vertical-align:-0.5769599999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7114919999999999em;\"><span style=\"top:-2.6411000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7841428571428571em;\"><span style=\"top:-2.188485714285714em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31151428571428574em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4101em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5769599999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><msub><mi>v</mi><mi>t</mi></msub><mo>^</mo></mover><mo>=</mo><mfrac><msub><mi>v</mi><mi>t</mi></msub><mrow><mn>1</mn><mo>−</mo><msubsup><mi>β</mi><mn>2</mn><mi>t</mi></msubsup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{v_t}=\\frac{v_t}{1-\\beta^t_2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.288452em;vertical-align:-0.5769599999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7114919999999999em;\"><span style=\"top:-2.6411000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7841428571428571em;\"><span style=\"top:-2.188485714285714em;margin-left:-0.05278em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-2.8448em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31151428571428574em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4101em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5769599999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>=</mo><msub><mi>θ</mi><mi>t</mi></msub><mo>−</mo><mfrac><mn>1</mn><msqrt><mrow><mover accent=\"true\"><msub><mi>v</mi><mi>t</mi></msub><mo>^</mo></mover><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mfrac><mover accent=\"true\"><msub><mi>m</mi><mi>t</mi></msub><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\theta_{t+1}=\\theta_t-\\frac{1}{\\sqrt{\\hat{v_t}+\\epsilon}}\\hat{m_t}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.383108em;vertical-align:-0.5379999999999999em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.5835585em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.866345em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord accent mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mtight\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathdefault mtight\">ϵ</span></span></span><span style=\"top:-2.826345em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.173655em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.5379999999999999em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>结合了SGD、动量、AdaGrad/RMSProp</p>\n<ul>\n<li>动量momentum：克服鞍点、梯度为0但非极值点等一系列问题</li>\n<li>AdaGrad/RMSProp：减少敏感方向的权重，增加非敏方向权重</li>\n<li>偏置校正：以防初始化不佳时初期除以很小的数导致步长过长</li>\n</ul>\n</li>\n<li>\n<p>实践证明，虽然在训练早期 Adam 拥有出色的收敛速度，使用其训练的模型的最终泛化能力却并不如使用朴素 SGD 训练的好（体现在 Adam 训练的模型最终收敛时的 test error 更大），结果可能不收敛，可能找不到全局最优解。二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得二阶动量可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">first_moment = <span class=\"number\">0</span></span><br><span class=\"line\">second_moment = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(num_iterations):</span><br><span class=\"line\">  dx = compute_gradient(x)</span><br><span class=\"line\">  first_moment = rho * first_moment + (<span class=\"number\">1</span> - rho) * dx\t<span class=\"comment\"># Momentum</span></span><br><span class=\"line\">  second_moment = decay_rate * second_moment + (<span class=\"number\">1</span> - decay_rate) * dx * dx\t<span class=\"comment\"># AdaGrad/RMSProp</span></span><br><span class=\"line\">  first_unbias = first_moment / (<span class=\"number\">1</span> - rho ** t)</span><br><span class=\"line\">  second_unbias = second_moment/ (<span class=\"number\">1</span> - decay_rate ** t)\t<span class=\"comment\"># Bias correction</span></span><br><span class=\"line\">  x -= learning_rate * first_unbias / (np.sqrt(second_unbias) + <span class=\"number\">1e-7</span>)\t<span class=\"comment\"># AdaGrad/RMSProp</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p>典型起始参数设置：</p>\n<ul>\n<li>beta1 = 0.9</li>\n<li>beta2 = 0.999</li>\n<li>learning_rate = 1e-3 or 5e-4</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"gif\"><a class=\"markdownIt-Anchor\" href=\"#gif\"></a> GIF</h3>\n<p>![](CS231n笔记/optimizations on loss surface contours.gif)</p>\n<p>不同算法在损失面等高线图中的学习过程，它们均同同一点出发，但沿着不同路径达到最小值点。其中 Adagrad、Adadelta、RMSprop 从最开始就找到了正确的方向并快速收敛；SGD 找到了正确方向但收敛速度很慢；SGD-M 和 NAG 最初都偏离了航道，但也能最终纠正到正确方向，SGD-M 偏离的惯性比 NAG 更大。</p>\n<p>![](CS231n笔记/optimizations on saddle point.gif)</p>\n<p>不同算法在鞍点处的表现。这里，SGD、SGD-M、NAG 都受到了鞍点的严重影响，尽管后两者最终还是逃离了鞍点；而 Adagrad、RMSprop、Adadelta 都很快找到了正确的方向。</p>\n<h3 id=\"adabound\"><a class=\"markdownIt-Anchor\" href=\"#adabound\"></a> AdaBound</h3>\n<p><em>Adaptive Gradient Methods with Dynamic Bound of Learning Rate 动态裁剪学习率的自适应梯度下降方法</em></p>\n<h4 id=\"背景\"><a class=\"markdownIt-Anchor\" href=\"#背景\"></a> 背景</h4>\n<ul>\n<li>\n<p><a href=\"http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning\">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a>. 作者给出了一个有趣的二分类问题构造，证明了在此构造下 SGD 可以收敛至最优解而 Adaptive 方法会收敛至一个泛化能力很差的结果（模型对所有输入都会始终预测为true）；并在若干个经典任务上实验证实 SGD 方法都达到了最低的test error。<strong>推测Adaptive方法泛化能力不强的原因是各个参数的更新步长不同所致。</strong></p>\n</li>\n<li>\n<p><a href=\"http://link.zhihu.com/?target=https%3A//openreview.net/forum%3Fid%3DryQu7f-RZ\">On the Convergence of Adam and Beyond</a>. ICLR 2018 best paper。文章包含了大量理论推导，证明了在特定初始条件下 Adam 存在收敛问题，并将问题归因于更新步长不是单调下降的；作者给出了一个修正方案保证了单调性，声称可以达到更低的 training loss。</p>\n<p>主要攻击的是 Adam 有可能无法收敛至全局最优解。虽然本文荣获 ICLR 2018 best paper，但个人认为这篇 paper 的<strong>意义十分有限，同时有很大误导性</strong>。</p>\n<p>其一，作者通过构造一个非常极端的例子证明 Adam 可能不收敛，但该构造是极其极端且不应该在实际情况中出现的：拥有少量频次非常低的、梯度却非常大的数据点的数据 —— 在实际应用中，这些点难道不就是 outlier 么？如果按作者的构造，一百份数据中才有一组这样的数据，而如果这本身不是由于数据的 bias 造成的，那模型理应去拟合数量多的数据以达到更好的泛化能力。同时，在作者的构造下，如果去除这些罕见数据点，那么 Adam 会与不去除一样收敛到相同位置；而 AMSGrad (作者提出的新方法) 则会因为罕见数据点是否存在的不同而收敛到完全不同的结果。个人认为<strong>这个构造反而是证明了 Adam 比 AMSGrad 更能应对 outlier 值</strong>，极端构造下的收敛性，并不意味着什么。</p>\n<p>其二，作者的实验中用修正方法 AMSGrad 和原始 Adam 进行比较，证明修正方案可以获得比 Adam 更低的 training loss。然而，<strong>training loss 的意义对于一个模型是十分有限的</strong>。模型的 test loss 和 test performance (通常用与 loss function 不同的评价指标反映，例如分类问题中使用 accuracy 而不是 cross entropy) 远比 training loss 重要。事实上，<strong>Adam 很多时候都能在训练集上获得比 SGD 更低的 loss 却在测试集上表现更差</strong>。 追求低的 training loss 很有可能是本末倒置的。有同样质疑的人也对文章进行了复现，博客 <a href=\"http://link.zhihu.com/?target=https%3A//fdlm.github.io/post/amsgrad/\">Experiments with AMSGrad</a> 也通过实验打脸作者 claim 的 「AMSGrad training loss 低也带来 test loss 低」的说法是错误的。</p>\n<p>其三，最后说作者的修正方案，是通过手动维护二阶动量单调增从而使得更新步长单调减。而这与我的实验直觉是相悖的：Adam 最后的步长往往不是过大而是过小了。事实上，[3] 中的实验也证明了 Adam 训练末期过小的步长是导致泛化性能差的重要原因。</p>\n<p>相对于收敛性，泛化能力，也即模型在未知数据（狭义的讲，即测试集）上的 performance 对模型而言才是更加重要的性质。</p>\n</li>\n<li>\n<p><a href=\"http://link.zhihu.com/?target=https%3A//arxiv.org/abs/1712.07628\">Improving Generalization Performance by Switching from Adam to SGD</a>. 该文章指出了 Adam 最终的 test error 往往小于 SGD 的现象，给出一个先用 Adam 在初期进行训练加速收敛，并在合适时机切换为 SGD，追求更好的最终泛化能力的训练策略。<strong>实验表明训练后期更新步长过小也是原因之一。</strong></p>\n</li>\n<li>\n<p>综上而言，<strong>在训练后期通过限制更新步长下界并且想办法使得各个参数更新步长相近，是修正 Adam 的大的方向</strong>。先用 Adam 后切 SGD 固然是可行的，但仍然显得不够优雅，如果能用一个统一的迭代算法兼顾Adam的快速收敛能力和SGD的好的泛化能力那就很棒了。</p>\n</li>\n</ul>\n<h4 id=\"论文内容\"><a class=\"markdownIt-Anchor\" href=\"#论文内容\"></a> 论文内容</h4>\n<ol>\n<li>\n<p>初步试验：</p>\n<p>使用Adam算法，在ResNet-34（残差网络模型，复杂度低）中随机选取了9个卷积核和1个全连接层偏置向量，并从中再各随机取样一个维度的变量，统计其在CIFAR-10上训练末期的学习率。采样参数的学习率，每个单元格包含一个通过对学习率进行对数运算得到的值。颜色越浅的单元格代表越小的学习率。可见在后期确实存在学习率的极端值。</p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/AdaBound_figure1.png\" alt></p>\n</li>\n<li>\n<p>theorem3 证明极端学习率确实存在潜在的负面影响。</p>\n</li>\n<li>\n<p>对学习率动态裁剪，将实际学习率限制在下界<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span> 和上界<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\eta_u</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>之间。</p>\n</li>\n</ol>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/AdaBound_clip.png\" alt></p>\n<p>容易发现，SGD 和 Adam 分别是应用梯度裁剪的特殊情况：学习率为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^{*}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">∗</span></span></span></span></span></span></span></span></span></span></span></span>的SGD可视为<span class=\"katex-error\" title=\"Error: Font metrics not found for font: .\">\\eta_𝑙=\\eta_𝑢=𝛼^∗</span>；Adam可视为 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>𝑙</mi></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\eta_𝑙=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span> ,<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>𝑢</mi></msub><mo>=</mo><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\eta_𝑢=\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>。其他取值则介于两者之间。那么，如果用两个关于 t 的函数来取代固定值作为新的上下界，其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>l</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\eta_l(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>从0逐渐收敛至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>η</mi><mi>u</mi></msub><mo stretchy=\"false\">(</mo><mi>t</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\eta_u(t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">u</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span></span>从<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi mathvariant=\"normal\">∞</mi></mrow><annotation encoding=\"application/x-tex\">\\infty</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord\">∞</span></span></span></span>也逐渐收敛至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>α</mi><mo>∗</mo></msup></mrow><annotation encoding=\"application/x-tex\">\\alpha^*</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.688696em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.688696em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mbin mtight\">∗</span></span></span></span></span></span></span></span></span></span></span>，那么我们就成功实现了从Adam到SGD的动态过渡。在这一设置下，在训练早期由于上下界对学习率的影响很小，算法更加接近于Adam；而随着时间增长裁减区间越来越收紧，模型的学习率逐渐趋于稳定，在末期更加贴近于SGD。</p>\n<ol start=\"4\">\n<li>\n<p>结果在训练前期可以快速且平滑收敛的情况下，同时在末期得到了优秀的最终性能，可以取得与 SGD 类似甚至更好的结果。</p>\n</li>\n<li>\n<p>对超参数更低的敏感性，更高的鲁棒性。</p>\n</li>\n</ol>\n<hr>\n<h2 id=\"back-propagation反向传播\"><a class=\"markdownIt-Anchor\" href=\"#back-propagation反向传播\"></a> Back-propagation/反向传播</h2>\n<ul>\n<li>\n<p>将复杂函数化为计算图的形式，递归地调用链式法则，计算每个变量的梯度</p>\n</li>\n<li>\n<p>加法门</p>\n<ul>\n<li>gradient distributor/梯度传递</li>\n<li>两下游梯度 = 上游的梯度</li>\n</ul>\n</li>\n<li>\n<p>max门</p>\n<ul>\n<li>gradient router/梯度路由</li>\n<li>小的下游梯度为0，大的下游梯度 = 上游的梯度</li>\n</ul>\n</li>\n<li>\n<p>乘法门</p>\n<ul>\n<li>gradient switcher/梯度转换</li>\n<li>获取上游梯度，根据另一下游分支的值对本下游缩放</li>\n</ul>\n</li>\n<li>\n<p>当一个下游节点接两个上游节点时，梯度再次相加</p>\n</li>\n<li>\n<p>Jacobian matrix/雅可比矩阵</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\frac{\\partial y_1}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial y_1}{\\partial x_n}\\<br>\n\\vdots &amp; \\ddots &amp; \\vdots\\<br>\n\\frac{\\partial y_m}{\\partial x_1} &amp; \\cdots &amp; \\frac{\\partial y_m}{\\partial x_n}\\<br>\n\\end{matrix}</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>x</mi></mrow></mfrac><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>f</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial L}{\\partial x}=\\frac{\\partial f}{\\partial x} \\frac{\\partial L}{\\partial f}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2251079999999999em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.4133239999999998em;vertical-align:-0.481108em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant=\"normal\">∂</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial f}{\\partial x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>即为雅可比矩阵</p>\n</li>\n<li>\n<p>$<br>\nq = Wx =<br>\n\\begin{pmatrix}<br>\nW_{1,1}x_1+\\cdots+W_{1,n}x_n\\<br>\n\\vdots\\<br>\nW_{n,1}x_1+\\cdots+W_{n,n}x_n\\<br>\n\\end{pmatrix}<br>\n$</p>\n</li>\n<li>\n<p>$<br>\n\\frac{\\partial q_k}{\\partial W_{i,j}}=1_{k=j}x_j<br>\n$</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>q</mi><mi>k</mi></msub></mrow><mrow><mi mathvariant=\"normal\">∂</mi><msub><mi>x</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><msub><mi>W</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\frac{\\partial q_k}{\\partial x_i}=W_{k,i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.377316em;vertical-align:-0.44509999999999994em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\" style=\"margin-right:0.05556em;\">∂</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">q</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.44509999999999994em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></p>\n</li>\n<li>\n<p>向量梯度大小与原向量保持一致，梯度的每个元素代表对最终函数的影响大小</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"regularization正则化\"><a class=\"markdownIt-Anchor\" href=\"#regularization正则化\"></a> Regularization/正则化</h2>\n<ul>\n<li>减轻模型复杂度，避免过拟合，提高模型效果</li>\n<li>增加随机噪声</li>\n<li>通常采用Batch Normalization即可，过拟合时采用以下方法</li>\n</ul>\n<h3 id=\"lp范数惩罚\"><a class=\"markdownIt-Anchor\" href=\"#lp范数惩罚\"></a> Lp范数惩罚</h3>\n<ul>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo>+</mo><mi>λ</mi><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L=... + \\lambda R(W)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mord\">.</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span></span></span></span></p>\n</li>\n<li>\n<p>L2 regularization：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><msubsup><mi>W</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>l</mi></mrow><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">R(W)=\\sum_k\\sum_lW_{k,l}^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2333239999999999em;vertical-align:-0.4192159999999999em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4168920000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4192159999999999em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>对W的欧式范数进行惩罚</li>\n</ul>\n</li>\n<li>\n<p>L1 regularization：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mo>∑</mo><mi>l</mi></msub><mo>∣</mo><msub><mi>W</mi><mrow><mi>k</mi><mo separator=\"true\">,</mo><mi>l</mi></mrow></msub><mo>∣</mo></mrow><annotation encoding=\"application/x-tex\">R(W)=\\sum_k\\sum_l\\mid W_{k,l}\\mid</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0497100000000001em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1863979999999999em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∣</span></span></span></span></p>\n<ul>\n<li>鼓励W稀疏</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"dropout\"><a class=\"markdownIt-Anchor\" href=\"#dropout\"></a> Dropout</h3>\n<ul>\n<li>每次正向传递时，在每一层随机将一部分神经元置0，且每次被置0的神经元不完全相同</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train_step</span><span class=\"params\">(X)</span>：</span></span><br><span class=\"line\">\tH1 = np.maximum(0, np.dot(W1, X) + b1)</span><br><span class=\"line\">\tU1 = np.random.rand(*H1.shape) &lt; p <span class=\"comment\"># dropout mask</span></span><br><span class=\"line\">\tH1 *= U1 <span class=\"comment\"># drop!</span></span><br><span class=\"line\">  out = np.dot(W2, H1) + b2</span><br></pre></td></tr></table></figure>\n<ul>\n<li>避免特征相适应，降低过拟合</li>\n<li>单一模型集成学习</li>\n<li>测试时，乘以dropout概率</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">predict</span><span class=\"params\">(X)</span>:</span></span><br><span class=\"line\">  H1 = np.maximum(<span class=\"number\">0</span>, np.dot(W1, X) + b1) * p</span><br><span class=\"line\">  out = np.dot(W2, H1) + b2</span><br></pre></td></tr></table></figure>\n<h3 id=\"data-augmentation数据增强\"><a class=\"markdownIt-Anchor\" href=\"#data-augmentation数据增强\"></a> Data Augmentation/数据增强</h3>\n<ul>\n<li>使用翻转、裁剪、色彩抖动等方法处理过的图片进行训练</li>\n</ul>\n<hr>\n<h2 id=\"transfer-learing迁移学习\"><a class=\"markdownIt-Anchor\" href=\"#transfer-learing迁移学习\"></a> Transfer Learing/迁移学习</h2>\n<ul>\n<li>大模型，小数据训练，易过拟合，此法同样解决过拟合</li>\n<li>小数据集与大数据集相似时：先在大数据集预训练的模型，要适应小数据集，可先冻结卷积、池化层，仅重新训练全连接层或线性分类器</li>\n<li>不相似时要重训练大部分层</li>\n</ul>\n<hr>\n<h2 id=\"neural-network神经网络\"><a class=\"markdownIt-Anchor\" href=\"#neural-network神经网络\"></a> Neural Network/神经网络</h2>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/1062917-20161117212457248-1468090428.png\" alt></p>\n<ul>\n<li>\n<p>包含若干个线性层，层与层之间用非线性函数连接</p>\n</li>\n<li>\n<p>2-layer Neural Network <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo>=</mo><msub><mi>W</mi><mn>2</mn></msub><mo>∗</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><msub><mi>W</mi><mn>1</mn></msub><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f=W_2*max(0,W_1 x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></p>\n<ul>\n<li>此处max为非线性函数且有很多可选</li>\n</ul>\n</li>\n<li>\n<p>每个节点接收多个输入，输出为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(\\sum_i w_i x_i +b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0497100000000001em;vertical-align:-0.29971000000000003em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.16195399999999993em;\"><span style=\"top:-2.40029em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29971000000000003em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">)</span></span></span></span></p>\n<ul>\n<li>f为activation function/激活函数</li>\n</ul>\n</li>\n<li>\n<p>将每层看作一个向量，一组神经元的集合，进而利用矩阵乘法计算输出结果</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">h1 = f(np.dot(W1, x) + b1)</span><br><span class=\"line\">out = np.dot(W2, h1) + b2</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>多个输入x1, x2, x3为样本的多个特征值；多个样本时采用vectorization向量化，把样本压缩为向量/矩阵？同时计算。</p>\n</li>\n<li>\n<p>输入<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo separator=\"true\">,</mo><mi>D</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(N,D)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mclose\">)</span></span></span></span>，隐层<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>D</mi><mo separator=\"true\">,</mo><mi>H</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(D,H)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span><span class=\"mclose\">)</span></span></span></span>，<strong>隐层神经元个数</strong><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>H</mi></mrow><annotation encoding=\"application/x-tex\">H</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span></span></span></span>，从数学角度来说感觉是每个sample都输入所有神经元。</p>\n</li>\n<li>\n<p>前向传播Forward Propagation：从input，经过一层层的layer，不断计算每一层的结果z和激活值a，最后得到输出y^ 的过程，计算出了y^，就可以根据它和真实值y的差别来计算损失（loss）。</p>\n<ul>\n<li>Layer i:\n<ul>\n<li>Z[i] = W[i]·A[i-1] + b[i]</li>\n<li>A[i] = σ(Z[i]) (sigmoid)</li>\n</ul>\n</li>\n<li>L(loss)：样本损失</li>\n<li>J(cost)：样本集的损失，L和的平均\n<ul>\n<li>J(W,b) = ΣL()/n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>反向传播Backward Propagation：根据L(y^,y)、J(W,b)来反方向地计算每一层的z、a、w、b的偏导数（梯度），从而更新参数。</p>\n</li>\n<li>\n<p>深层神经网络中，常采用RelU激活函数（求梯度更快，防止梯度消失），输出层采用sigmoid。</p>\n</li>\n<li>\n<p>参数维度：m个样本，共L层，当前l层，第l层单元数n[l]，</p>\n<ul>\n<li>W[l]:(n[l],n[l-1]), 即n[l]行、n[l-1]列</li>\n<li>b[l]:(n[l],1)</li>\n<li>z[l]:(n[l],1) Z[l]:(n[l],m)</li>\n<li>a[l]:(n[l],1) A[l]:(n[l],m)</li>\n<li>X:(n[0],m) Y:(1,m)</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"convolutional-neural-networks-cnn卷积神经网络\"><a class=\"markdownIt-Anchor\" href=\"#convolutional-neural-networks-cnn卷积神经网络\"></a> Convolutional Neural Networks, CNN/卷积神经网络</h2>\n<ul>\n<li>保持空间结构；在传统神经网络中每个神经元都要与图片上每个像素相连接，这样的话就会造成权重的数量巨大造成网络难以训练，而在含有卷积层的的神经网络中每个神经元的权重个数都是卷积核的大小，这样就相当于没有神经元只与对应图片部分的像素相连接。这样就极大的减少了权重的数量。</li>\n<li>核filter，例如<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>5</mn><mo>∗</mo><mn>5</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">5*5*3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span>。参数学习得到。卷积过程中参数不变，<strong>通过一个卷积核的操作提取了原图的不同位置的同样特征。</strong></li>\n<li>**每个卷积核，在输入的整个深度上点积。**运算时，实质上也是先化为一维向量做点积。但有多个卷积核，所以输出为output size * output size * output num。</li>\n<li>卷积输出size：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mi>F</mi><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">(N-F)/stride+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">F</span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>\n<ul>\n<li>N：输入size，F：卷积核size，stride：步长</li>\n</ul>\n</li>\n<li>也有用0填充输入图片四周，使输出size保持不变。</li>\n</ul>\n<hr>\n<h2 id=\"pooling池化\"><a class=\"markdownIt-Anchor\" href=\"#pooling池化\"></a> Pooling/池化</h2>\n<ul>\n<li>对输入的特征图进行压缩，一方面使特征图变小，简化网络计算复杂度；一方面进行特征压缩，提取主要特征</li>\n<li>深度不变。通常filter不重叠，不填0</li>\n<li>常用：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn></mrow><annotation encoding=\"application/x-tex\">2*2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span></span></span></span> 步长2，或<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>3</mn><mo>∗</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">3*3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span> 步长3</li>\n</ul>\n<hr>\n<h2 id=\"activation-functions激活函数\"><a class=\"markdownIt-Anchor\" href=\"#activation-functions激活函数\"></a> Activation Functions/激活函数</h2>\n<h3 id=\"sigmoidx\"><a class=\"markdownIt-Anchor\" href=\"#sigmoidx\"></a> sigmoid(x)​</h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/sigmoid.png\" alt></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>σ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>x</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\sigma(x) = \\frac{1}{1+e^{-x}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2484389999999999em;vertical-align:-0.403331em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7026642857142857em;\"><span style=\"top:-2.786em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathdefault mtight\">x</span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.403331em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></li>\n<li>元素压缩至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[0,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span></span></span></span>范围</li>\n<li>问题：</li>\n<li>饱和神经元使得梯度为0，无法得到合适的梯度流\n<ul>\n<li>输出不以0为中心，x为正时w总为正或负，梯度更新效率低</li>\n<li>指数计算代价较大</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"tanhx\"><a class=\"markdownIt-Anchor\" href=\"#tanhx\"></a> tanh(x)​</h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/tanh.png\" alt></p>\n<ul>\n<li>压缩至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[-1,1]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">−</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">]</span></span></span></span></li>\n<li>输出以0为中心</li>\n<li>问题：饱和时梯度为0</li>\n</ul>\n<h3 id=\"relurectified-linear-unit\"><a class=\"markdownIt-Anchor\" href=\"#relurectified-linear-unit\"></a> ReLU(Rectified Linear Unit)</h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/relu.png\" alt></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)=max(0,x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>正区域不会饱和</li>\n<li>函数简单，计算快，收敛快</li>\n<li>生物学上更合理</li>\n<li>问题</li>\n<li>输出不以0为中心\n<ul>\n<li>负半轴全饱和</li>\n<li>及其导致的Dead ReLU：反向传播中，大的梯度更新，使w变化，输入负数增加，函数关闭，参数w得不到更新，导致永久关闭</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"leaky-relu\"><a class=\"markdownIt-Anchor\" href=\"#leaky-relu\"></a> Leaky ReLU</h3>\n<p>![](CS231n笔记/leaky relu.png)</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0.01</mn><mi>x</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)=max(0.01x,x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">0</span><span class=\"mord\">1</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>不会挂掉</li>\n</ul>\n<h3 id=\"eluexponential-linear-units\"><a class=\"markdownIt-Anchor\" href=\"#eluexponential-linear-units\"></a> ELU(Exponential Linear units)</h3>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/elu.png\" alt></p>\n<ul>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\">{</mo><mtable rowspacing=\"0.3599999999999999em\" columnalign=\"left left\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mi>x</mi><mspace width=\"2em\"><mspace width=\"2em\"><mi>i</mi><mi>f</mi><mi>x</mi><mo>&gt;</mo><mn>0</mn></mspace></mspace></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mtext> </mtext><mi>α</mi><mo stretchy=\"false\">(</mo><msup><mi>e</mi><mi>x</mi></msup><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mspace width=\"1em\"><mi>i</mi><mi>f</mi><mi>x</mi><mo>≤</mo><mn>0</mn></mspace></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding=\"application/x-tex\">f(x)=\\begin{cases}x\\qquad\\qquad if x&gt;0\\\\\\ \\alpha(e^x-1)\\quad ifx\\leq0 \\end{cases}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.0000299999999998em;vertical-align:-1.25003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">{</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-l\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.69em;\"><span style=\"top:-3.69em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:2em;\"></span><span class=\"mspace\" style=\"margin-right:2em;\"></span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\">0</span></span></span><span style=\"top:-2.25em;\"><span class=\"pstrut\" style=\"height:3.008em;\"></span><span class=\"mord\"><span class=\"mspace\"> </span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">e</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.19em;\"><span></span></span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n</li>\n<li>\n<p>输出均值近0</p>\n</li>\n<li>\n<p>负半轴近似饱和</p>\n</li>\n</ul>\n<h3 id=\"maxout\"><a class=\"markdownIt-Anchor\" href=\"#maxout\"></a> Maxout</h3>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><msubsup><mi>w</mi><mn>1</mn><mi>T</mi></msubsup><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msubsup><mi>w</mi><mn>2</mn><mi>T</mi></msubsup><mi>x</mi><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">max(w_1^Tx+b_1,w_2^Tx+b_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0913309999999998em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0894389999999998em;vertical-align:-0.24810799999999997em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.4518920000000004em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>不提前点积</li>\n<li>泛化ReLU，不饱和，不消亡</li>\n<li>问题：参数加倍</li>\n</ul>\n<h3 id=\"总结\"><a class=\"markdownIt-Anchor\" href=\"#总结\"></a> 总结</h3>\n<ul>\n<li>常用ReLU，注意学习率</li>\n<li>少用sigmoid</li>\n</ul>\n<hr>\n<h2 id=\"data-preprocessing数据预处理\"><a class=\"markdownIt-Anchor\" href=\"#data-preprocessing数据预处理\"></a> Data Preprocessing/数据预处理</h2>\n<ul>\n<li>\n<p>zero-centered data/零中心化</p>\n<p>X -= np.mean(X, axis = 0)</p>\n</li>\n<li>\n<p>normalized data/归一化，图像处理不常用</p>\n<p>X /= np.std(X, axis = 0)</p>\n</li>\n<li>\n<p>减去mean image</p>\n</li>\n<li>\n<p>减去单通道均值</p>\n</li>\n<li>\n<p>训练与预测阶段都需进行同样预处理（应用同样的参数、均值）</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"weight-initialization初始化权重\"><a class=\"markdownIt-Anchor\" href=\"#weight-initialization初始化权重\"></a> Weight Initialization/初始化权重</h2>\n<ul>\n<li>\n<p>输入输出方差相同，Xavier initialization</p>\n<p>W = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in/2)</p>\n</li>\n</ul>\n<hr>\n<h2 id=\"batch-normalization批量归一化\"><a class=\"markdownIt-Anchor\" href=\"#batch-normalization批量归一化\"></a> Batch Normalization/批量归一化</h2>\n<ul>\n<li>\n<p>背景：深层网络在非线性变化前，激活的输入值的分布逐渐发生偏移变动。当整体分布靠近激活函数上下限端时，反向传播时的梯度消失，最终导致深层网络收敛越来越慢</p>\n</li>\n<li>\n<p>目的：数据转化为单位高斯数据，降低层之间输入数据分布变化，即使数据落入非线性函数的敏感区域，避免梯度消失，提速</p>\n</li>\n<li>\n<p>带来的问题：每层都通过BN，相当于多层线性函数，深度网络失去意义</p>\n</li>\n<li>\n<p>解决：对经过BN的x：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>s</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>e</mi><mo>∗</mo><mi>x</mi><mo>+</mo><mi>s</mi><mi>h</mi><mi>i</mi><mi>f</mi><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">y=scale*x+shift</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">h</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">t</span></span></span></span>。对每个神经元增加两个学习参数，相当于使非线性函数的值从线性区往非线性区偏移挪动。变换重构<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msup><mi>γ</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><msup><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>+</mo><msup><mi>β</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">y^{(k)}=\\gamma^{(k)}\\hat{x}^{(k)}+\\beta^{(k)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span>，则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>γ</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mrow></msqrt><mspace width=\"1em\"><msup><mi>β</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mi>E</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mspace></mrow><annotation encoding=\"application/x-tex\">\\gamma^{(k)}=\\sqrt{Var[x^{(k)}]} \\quad \\beta^{(k)}=E[x^{(k)}]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.2729999999999999em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9670000000000001em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.814em;\"><span style=\"top:-2.989em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span><span style=\"top:-2.9270000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2729999999999999em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.138em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>时可恢复原始数据，控制饱和程度。<strong>核心思想应该是想找到一个线性和非线性的较好平衡点，既能享受非线性的较强表达能力的好处，又避免太靠非线性区两头使得网络收敛速度太慢</strong></p>\n</li>\n<li>\n<p>通常在FC、卷积层后插入</p>\n</li>\n<li>\n<p>训练过程：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>=</mo><mfrac><mrow><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>−</mo><mi>E</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mrow><mrow><msqrt><mi>V</mi></msqrt><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>k</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">]</mo></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\hat{x}^{(k)}=\\frac{x^{(k)}-E[x^{(k)}]}{\\sqrt Var[x^{(k)}]}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8879999999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.799303em;vertical-align:-0.637603em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1617em;\"><span style=\"top:-2.537397em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322900000000001em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.22222em;padding-left:0.833em;\">V</span></span><span style=\"top:-2.89229em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg width=\"400em\" height=\"1.08em\" viewbox=\"0 0 400000 1080\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M95,702c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,\n-10,-9.5,-14c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54c44.2,-33.3,65.8,\n-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10s173,378,173,378c0.7,0,\n35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429c69,-144,104.5,-217.7,106.5,\n-221c5.3,-9.3,12,-14,20,-14H400000v40H845.2724s-225.272,467,-225.272,467\ns-235,486,-235,486c-2.7,4.7,-9,7,-19,7c-6,0,-10,-1,-12,-3s-194,-422,-194,-422\ns-65,47,-65,47z M834 80H400000v40H845z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.10770999999999997em;\"><span></span></span></span></span></span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen mtight\">[</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8220357142857143em;\"><span style=\"top:-2.8220357142857138em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose mtight\">]</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9667142857142857em;\"><span style=\"top:-2.966714285714285em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen mtight\">[</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9667142857142857em;\"><span style=\"top:-2.966714285714285em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5357142857142856em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose mtight\">]</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.637603em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/bn_forward.png\" alt=\"Batch Normalization\" title=\"forward\"></p>\n<p><img src=\"/2020/06/18/CS231n%E7%AC%94%E8%AE%B0/bn_backward.jpg\" alt=\"bn_backward\" title=\"backward\"></p>\n<p>预测过程：用从所有训练实例中获得的统计量代表期望和方差</p>\n</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>E</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>←</mo><msub><mi>E</mi><mi>B</mi></msub><mo stretchy=\"false\">[</mo><msub><mi>μ</mi><mi>B</mi></msub><mo stretchy=\"false\">]</mo><mspace linebreak=\"newline\"></mspace><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>←</mo><mfrac><mi>m</mi><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow></mfrac><msub><mi>E</mi><mi>B</mi></msub><mo stretchy=\"false\">[</mo><msubsup><mi>σ</mi><mi>B</mi><mn>2</mn></msubsup><mo stretchy=\"false\">]</mo><mspace linebreak=\"newline\"></mspace><mi>y</mi><mo>=</mo><mfrac><mi>γ</mi><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>+</mo><mi>ε</mi></mrow></msqrt></mfrac><mo>∗</mo><mi>x</mi><mo>+</mo><mo stretchy=\"false\">(</mo><mi>β</mi><mo>−</mo><mfrac><mrow><mi>γ</mi><mo>∗</mo><mi>E</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo></mrow><msqrt><mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo stretchy=\"false\">[</mo><mi>x</mi><mo stretchy=\"false\">]</mo><mo>+</mo><mi>ε</mi></mrow></msqrt></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">E[x]\\leftarrow E_B[\\mu_B]\t\\\\\nVar[x]\\leftarrow\\frac{m}{m-1}E_B[\\sigma_B^2] \\\\\ny=\\frac{\\gamma}{\\sqrt{Var[x]+\\varepsilon}}*x+(\\beta-\\frac{\\gamma*E[x]}{\\sqrt{Var[x]+\\varepsilon}})\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">μ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">←</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8768900000000002em;vertical-align:-0.7693300000000001em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.10756em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\">1</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7693300000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05017em;\">B</span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.2375599999999998em;vertical-align:-1.13em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1075599999999999em;\"><span style=\"top:-2.175em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.935em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">ε</span></span></span><span style=\"top:-2.8950000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30499999999999994em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.13em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.557em;vertical-align:-1.13em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.427em;\"><span style=\"top:-2.175em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.935em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">ε</span></span></span><span style=\"top:-2.8950000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width=\"400em\" height=\"1.28em\" viewbox=\"0 0 400000 1296\" preserveaspectratio=\"xMinYMin slice\"><path d=\"M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,\n158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067\nc4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,\n175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71\nc-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,\n-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26\ns76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z\"/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30499999999999994em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05556em;\">γ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">]</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.13em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<hr>\n<h2 id=\"babysitting-the-learning-process观察学习过程\"><a class=\"markdownIt-Anchor\" href=\"#babysitting-the-learning-process观察学习过程\"></a> Babysitting the Learning Process/观察学习过程</h2>\n<ul>\n<li>数据预处理</li>\n<li>选择网络结构</li>\n<li>初始化网络，前向传播</li>\n<li>观察损失，和添加正则化项后的损失</li>\n<li>从小数据集训练，关闭正则化，sgd，观察loss能否为0、accuracy能否为1</li>\n<li>正式训练，全部数据，开启正则化</li>\n<li>调整学习率（最重要参数），过小时梯度更新小，loss变化小，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">η</span></span></span></span>常为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn><mi>e</mi><mo>−</mo><mn>3</mn></mrow><annotation encoding=\"application/x-tex\">1e-3</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">3</span></span></span></span>到<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn><mi>e</mi><mo>−</mo><mn>5</mn></mrow><annotation encoding=\"application/x-tex\">1e-5</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">1</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span></span></span></span>之间</li>\n</ul>\n<hr>\n<h2 id=\"hyper-parameter-optimization超参数设置\"><a class=\"markdownIt-Anchor\" href=\"#hyper-parameter-optimization超参数设置\"></a> Hyper-parameter Optimization/超参数设置</h2>\n<ul>\n<li>交叉验证，训练集训练，验证集验证</li>\n<li>首先几个epoch粗略观察超参是否合理，确定合理区间</li>\n<li>loss激增时说明方向有误</li>\n</ul>\n<p>![](CS231n笔记/loss-learing rate.png “loss~learning rate”)</p>\n<hr>\n<h2 id=\"pytorch\"><a class=\"markdownIt-Anchor\" href=\"#pytorch\"></a> PyTorch</h2>\n<ul>\n<li>定义三个抽象\n<ul>\n<li>Tensor 张量，类似数组</li>\n<li>Variable 变量，计算图中节点，储存数据和梯度</li>\n<li>Module 类/模块，是一个神经网络层，储存状态和参数</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"tensor张量\"><a class=\"markdownIt-Anchor\" href=\"#tensor张量\"></a> Tensor/张量</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 简单的神经网络示例(使用张量)</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dtype = torch.FloatTensor</span></span><br><span class=\"line\">dtype = torch.cuda.FloatTensor\t<span class=\"comment\"># GPU</span></span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\">x = torch.randn(N, D_in).type(dtype)</span><br><span class=\"line\">y = torch.randn(N, D_out).type(dtype)</span><br><span class=\"line\">w1 = torch.randn(D_in, H).type(dtype)</span><br><span class=\"line\">w2 = torch.randn(H, D_out).type(dtype)</span><br><span class=\"line\"></span><br><span class=\"line\">learning_rate = <span class=\"number\">1e-6</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">500</span>):</span><br><span class=\"line\">  h = x.mm(w1)</span><br><span class=\"line\">  h_relu = h.clamp(min=<span class=\"number\">0</span>)</span><br><span class=\"line\">  y_pred = h_relu.mm(w2)</span><br><span class=\"line\">  loss = (y_pred - y).pow(<span class=\"number\">2</span>).sum()</span><br><span class=\"line\">  </span><br><span class=\"line\">  grad_y_pred = <span class=\"number\">2.0</span> * (y_pred - y)</span><br><span class=\"line\">  grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class=\"line\">  grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class=\"line\">  grad_h = grad_h_relu.clone()</span><br><span class=\"line\">  grad_h[h &lt; <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">  grad_w1 = x.t().mm(grad_h)</span><br><span class=\"line\">  </span><br><span class=\"line\">  w1 -= learning_rate * grad_w1</span><br><span class=\"line\">  w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>\n<h3 id=\"variable变量\"><a class=\"markdownIt-Anchor\" href=\"#variable变量\"></a> Variable/变量</h3>\n<ul>\n<li>X.data 张量类型</li>\n<li>X.grad 变量类型，梯度，与data同shape</li>\n<li>X.grad.data 张量类型，梯度的张量</li>\n<li>PyTorch中，张量、变量相同API</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\">x = Variable(torch.randn(N, D_in), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">y = Variable(torch.randn(N, D_out), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\">w1 = Variable(torch.randn(D_in, H), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\">w2 = Variable(torch.randn(H, D_out), requires_grad=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">learning_rate = <span class=\"number\">1e-6</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">500</span>):</span><br><span class=\"line\">  y_prred = x.mm(w1).clamp(min=<span class=\"number\">0</span>).mm(w2)</span><br><span class=\"line\">  loss = (y_pred - y).pow(<span class=\"number\">2</span>).sum()</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"keyword\">if</span> w1.grad: w1.grad.data.zero_()</span><br><span class=\"line\">  <span class=\"keyword\">if</span> w2.grad: w2.grad.data.zero_()</span><br><span class=\"line\">  loss.backward()</span><br><span class=\"line\">  </span><br><span class=\"line\">  w1.data -= learning_rate * w1.grad.data</span><br><span class=\"line\">  w2.data -= learning_rate * w2.grad.data</span><br></pre></td></tr></table></figure>\n<h3 id=\"nn高级封装\"><a class=\"markdownIt-Anchor\" href=\"#nn高级封装\"></a> nn/高级封装</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Varible</span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\">x = Variable(torch.randn(N, D_in))</span><br><span class=\"line\">y = Variable(torch.randn(N, D_out), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 把模型定义为层的序列</span></span><br><span class=\"line\">model = torch.nn.Sequential(torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out))</span><br><span class=\"line\"><span class=\"comment\"># nn中定义了一些损失函数</span></span><br><span class=\"line\">loss_fn = torch.nn.MSELoss(size_average=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 给模型喂数据，得到预测以计算损失</span></span><br><span class=\"line\">learning_rate = <span class=\"number\">1e-4</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> tange(<span class=\"number\">500</span>):</span><br><span class=\"line\">  y_pred = model(x)</span><br><span class=\"line\">  loss = loss_fn(y_pred, y)</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># 计算梯度</span></span><br><span class=\"line\">  model.zero_grad()</span><br><span class=\"line\">  loss.backward()</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"comment\"># 在所有参数上循环，更新参数 </span></span><br><span class=\"line\">  <span class=\"keyword\">for</span> param <span class=\"keyword\">in</span> model.parameters():</span><br><span class=\"line\">    param.data -= learning_rate * param.grad.data</span><br></pre></td></tr></table></figure>\n<h3 id=\"optimizer优化器\"><a class=\"markdownIt-Anchor\" href=\"#optimizer优化器\"></a> optimizer/优化器</h3>\n<ul>\n<li>\n<p>将参数更新的流程抽象出来，并执行更新法则</p>\n</li>\n<li>\n<p>以上例为基础：</p>\n</li>\n<li>\n<p>14行后添加如下，意为要对参数采用此法则、此学习率更新</p>\n<p><code>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</code></p>\n</li>\n<li>\n<p>23~25行的参数更新改为：<code>optimizer.step()</code></p>\n</li>\n</ul>\n<h3 id=\"module类\"><a class=\"markdownIt-Anchor\" href=\"#module类\"></a> Module/类</h3>\n<ul>\n<li>神经网络层，输入输出为变量类型</li>\n<li>包含参数或其他模块</li>\n<li>可以使用autograd定义新Module</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">form torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 这个类把整个模型定义成nn类中的一个新类，</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TwoLayerNet</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">_init_</span><span class=\"params\">(self, D_in, H, D_out)</span>:</span></span><br><span class=\"line\">    super(TwoLayerNet, self)._init_()</span><br><span class=\"line\">    self.linear1 = torch.nn.Linear(D_in, H)</span><br><span class=\"line\">    self.linear2 = torch.nn.Linear(H, D_out)</span><br><span class=\"line\">    </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">    h_relu = self.linear1(x).clamp(min=<span class=\"number\">0</span>)</span><br><span class=\"line\">    y_pred = self.linear2(h_relu)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> y_pred</span><br><span class=\"line\">  </span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">x = Variable(torch.randn(N, D_in))</span><br><span class=\"line\">y = Variable(torch.randn(N, D_out), requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = TwoLayerNet(D_in,, H, D_out)</span><br><span class=\"line\"></span><br><span class=\"line\">criterion = torch.nn.MSELoss(size_average=<span class=\"literal\">False</span>)</span><br><span class=\"line\">optimizer = torch.optim.SGD(model.parameters(), lr=<span class=\"number\">1e-4</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> range(<span class=\"number\">500</span>):</span><br><span class=\"line\">  y_pred = model(x)</span><br><span class=\"line\">  loss = criterion(y_pred, y)</span><br><span class=\"line\">  </span><br><span class=\"line\">  optimizer.zero_grad()</span><br><span class=\"line\">  loss.backward()</span><br><span class=\"line\">  optimizer.step()</span><br></pre></td></tr></table></figure>\n<h3 id=\"dataloader数据加载\"><a class=\"markdownIt-Anchor\" href=\"#dataloader数据加载\"></a> DataLoader/数据加载</h3>\n<ul>\n<li>可以建立分批处理，也可以执行多线程</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\">form torch.utils.data <span class=\"keyword\">import</span> TensorDataset, DataLoader</span><br><span class=\"line\"></span><br><span class=\"line\">N, D_in, H, D_out = <span class=\"number\">64</span>, <span class=\"number\">1000</span>, <span class=\"number\">100</span>, <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">x = torch.randn(N, D_in)</span><br><span class=\"line\">y = torch.randn(N, D_out)</span><br><span class=\"line\"></span><br><span class=\"line\">loader = DataLoader(TensorDataset(x, y), batch_size=<span class=\"number\">8</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model = TwoLayerNet(D_in, H, D_out)</span><br><span class=\"line\"></span><br><span class=\"line\">ceiterion = torch.nn.MSELoss(size_average=<span class=\"literal\">False</span>)</span><br><span class=\"line\">optimizer = torch.optim.SGD(model.parameters(), lr=<span class=\"number\">1e-4</span>)</span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range(<span class=\"number\">10</span>):</span><br><span class=\"line\">  <span class=\"keyword\">for</span> x_batch, y_batch <span class=\"keyword\">in</span> loader:</span><br><span class=\"line\">    x_var, y_var = Variable(x), Variable(y)</span><br><span class=\"line\">    y_pred = model(x_var)</span><br><span class=\"line\">    loss = criterion(y_pred, y_var)</span><br><span class=\"line\">    </span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br></pre></td></tr></table></figure>\n<h3 id=\"pretrained-model预训练模型\"><a class=\"markdownIt-Anchor\" href=\"#pretrained-model预训练模型\"></a> Pretrained Model/预训练模型</h3>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision</span><br><span class=\"line\"></span><br><span class=\"line\">alexnet = torchvision.models.alexnet(pretrained=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"else其他\"><a class=\"markdownIt-Anchor\" href=\"#else其他\"></a> else/其他</h3>\n<ul>\n<li>visdom 可视化的包</li>\n<li>可以通过重写前向、反向传播函数定义新的Autograd Function</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ReLU</span><span class=\"params\">(torch.autograd.Function)</span>:</span></span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forwar</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">    self.save_for_backward(x)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> x.clamp(min=<span class=\"number\">0</span>)</span><br><span class=\"line\">  </span><br><span class=\"line\">  <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">backward</span><span class=\"params\">(self, grad_y)</span>:</span></span><br><span class=\"line\">    x, = self.saved_tensors</span><br><span class=\"line\">    grad_input = grad_y.clone()</span><br><span class=\"line\">    grad_input[x &lt; <span class=\"number\">0</span>] = <span class=\"number\">0</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> grad_input</span><br></pre></td></tr></table></figure>"},{"title":"RSA","date":"2020-05-30T12:09:02.000Z","mathjax":true,"_content":"\n\n\n信息安全技术实验4\n\n<!--more-->\n\n\n\n<!-- toc -->\n\n\n\n<br/>\n\n\n\n# RSA\n\n## 单向陷门函数与公钥密码\n\n* 单向陷门函数：\n\n1. 给定$x$，计算$y=f(x)$是容易的；\n2. 给定$y$, 计算$x$使$x=f-1(y)$是不可行的；\n3. 存在陷门$t$，已知$t$时，对给定的任何$y$，若相应的原象$x$存在，则计算$x$是容易的。\n\n* 加密：使用函数$f(x)$作为公钥，陷门$t$作为私钥。加密明文$m$得到密文$y=f(m)$。仅有知道私钥时可求出原文。\n\n<br/>\n\n## 欧拉函数\n\n1. 在$[1,n]$中，不大于$n$，且与其互素的正整数的个数，记为$\\phi(x)$\n2. $p$为素数时， $\\phi(p^k)=p^{k-1}(p-1)$\n3. 若$(m_1, m_2)=1$，则$\\phi(m_1 m_2)=\\phi(m_1) \\phi(m_2)$\n4. 若自变量为普通数字，则可改写为素数幂的乘积的形式。之后由3.中公式分解。\n\n<br/>\n\n## RSA步骤\n\n1. 随机生成两个不同大素数$p$, $q$;\n2. 计算$n=pq$, $\\phi(n)=(p-1)(q-1)$;\n3. 随机选取整数$e$, $1<e<\\phi(n)$,满足$(e,\\phi(n))=1$;\n4. 利用扩展欧基里德算法求出满足$ed=1 mod(\\phi(n))$的整数$d$;\n5. 公开$(n,e)$，保密$(p,q,\\phi(n),d)$。其中$e$就是加密密钥，而$d$就是解密密钥，$n$称为模数；\n6. 加密：$c=m^e \\ mod \\ n$ （若明文长度超过$n$，则分组）\n7. 解密：$m=c^d \\ mod \\ n$\n\n<br/>\n\n## 使用mpir实现短数据加解密\n\n```c++\n//随机生成一个1024素数\nvoid gen_prime(mpz_t prime)  \n{                                         \n    gmp_randstate_t grt;                  \n    gmp_randinit_default(grt);    \n    gmp_randseed_ui(grt, time(NULL));     \n      \n    mpz_t p;   \n    mpz_init(p);\n    mpz_urandomb(p, grt, 1024); //随机生成1024位的大整数                \n    mpz_nextprime(prime, p);  //使用GMP自带的素数生成函数  \n    mpz_clear(p);   \n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n\tmpz_t p, q, n, e, d, phi, sp, sq, m, c, m1;\n\tmpz_t one, a, b;\n\tmpz_init(n);\n\tmpz_init(e);\n\tmpz_init(d);\n\tmpz_init(phi);\n\tmpz_init(sp);\n\tmpz_init(sq);\n\tmpz_init(a);\n\tmpz_init(b);\n\tmpz_init(one);\n        mpz_init(p);\n\tmpz_init(q);\n\tmpz_init(m);\n\tmpz_init(c);\n\tmpz_init(m1);\n\n\t// 生成p和q\n\tgen_prime(p);\n\tgmp_printf (\"p:\\n%Zd\\n\\n\", p);\n\tSleep(500);\t// 以防因时间相同导致生成的pq相同\n\tgen_prime(q);\n        gmp_printf (\"q:\\n%Zd\\n\\n\", q);\n\n\t// 计算n和phi(n)\n\tmpz_sub_ui(sp, p, 1);\n\tmpz_sub_ui(sq, q, 1);\n\tmpz_mul(n, p, q);\n\tmpz_mul(phi, sp, sq);\n\t\n\t// 选取整数e（公钥）\n\tmpz_set_ui(e, 65537);\n\n\t// 求私钥d\n\tmpz_invert(d, e, phi);\n\n\t// 短数据加密\n\tchar * message = \"1234567890ABCDEF\";\n\tmpz_set_str(m, message, 16);\n\tgmp_printf(\"原文:\\n%Zd\\n\", m);\n\tmpz_powm(c, m, e, n);\n\tgmp_printf(\"\\n密文:\\n%Zd\\n\", c);\n\n\t// 短数据解密\n\tmpz_powm(m1, c, d, n);\n\tgmp_printf(\"\\n解密:\\n%Zd\\n\\n\", m1);\n \n\treturn 0;\n}\n```\n\n\n\n![](RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png)","source":"_posts/RSA.md","raw":"---\ntitle: RSA\ndate: 2020-05-30 20:09:02\nmathjax: true\ntags: 信息安全\n---\n\n\n\n信息安全技术实验4\n\n<!--more-->\n\n\n\n<!-- toc -->\n\n\n\n<br/>\n\n\n\n# RSA\n\n## 单向陷门函数与公钥密码\n\n* 单向陷门函数：\n\n1. 给定$x$，计算$y=f(x)$是容易的；\n2. 给定$y$, 计算$x$使$x=f-1(y)$是不可行的；\n3. 存在陷门$t$，已知$t$时，对给定的任何$y$，若相应的原象$x$存在，则计算$x$是容易的。\n\n* 加密：使用函数$f(x)$作为公钥，陷门$t$作为私钥。加密明文$m$得到密文$y=f(m)$。仅有知道私钥时可求出原文。\n\n<br/>\n\n## 欧拉函数\n\n1. 在$[1,n]$中，不大于$n$，且与其互素的正整数的个数，记为$\\phi(x)$\n2. $p$为素数时， $\\phi(p^k)=p^{k-1}(p-1)$\n3. 若$(m_1, m_2)=1$，则$\\phi(m_1 m_2)=\\phi(m_1) \\phi(m_2)$\n4. 若自变量为普通数字，则可改写为素数幂的乘积的形式。之后由3.中公式分解。\n\n<br/>\n\n## RSA步骤\n\n1. 随机生成两个不同大素数$p$, $q$;\n2. 计算$n=pq$, $\\phi(n)=(p-1)(q-1)$;\n3. 随机选取整数$e$, $1<e<\\phi(n)$,满足$(e,\\phi(n))=1$;\n4. 利用扩展欧基里德算法求出满足$ed=1 mod(\\phi(n))$的整数$d$;\n5. 公开$(n,e)$，保密$(p,q,\\phi(n),d)$。其中$e$就是加密密钥，而$d$就是解密密钥，$n$称为模数；\n6. 加密：$c=m^e \\ mod \\ n$ （若明文长度超过$n$，则分组）\n7. 解密：$m=c^d \\ mod \\ n$\n\n<br/>\n\n## 使用mpir实现短数据加解密\n\n```c++\n//随机生成一个1024素数\nvoid gen_prime(mpz_t prime)  \n{                                         \n    gmp_randstate_t grt;                  \n    gmp_randinit_default(grt);    \n    gmp_randseed_ui(grt, time(NULL));     \n      \n    mpz_t p;   \n    mpz_init(p);\n    mpz_urandomb(p, grt, 1024); //随机生成1024位的大整数                \n    mpz_nextprime(prime, p);  //使用GMP自带的素数生成函数  \n    mpz_clear(p);   \n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n\tmpz_t p, q, n, e, d, phi, sp, sq, m, c, m1;\n\tmpz_t one, a, b;\n\tmpz_init(n);\n\tmpz_init(e);\n\tmpz_init(d);\n\tmpz_init(phi);\n\tmpz_init(sp);\n\tmpz_init(sq);\n\tmpz_init(a);\n\tmpz_init(b);\n\tmpz_init(one);\n        mpz_init(p);\n\tmpz_init(q);\n\tmpz_init(m);\n\tmpz_init(c);\n\tmpz_init(m1);\n\n\t// 生成p和q\n\tgen_prime(p);\n\tgmp_printf (\"p:\\n%Zd\\n\\n\", p);\n\tSleep(500);\t// 以防因时间相同导致生成的pq相同\n\tgen_prime(q);\n        gmp_printf (\"q:\\n%Zd\\n\\n\", q);\n\n\t// 计算n和phi(n)\n\tmpz_sub_ui(sp, p, 1);\n\tmpz_sub_ui(sq, q, 1);\n\tmpz_mul(n, p, q);\n\tmpz_mul(phi, sp, sq);\n\t\n\t// 选取整数e（公钥）\n\tmpz_set_ui(e, 65537);\n\n\t// 求私钥d\n\tmpz_invert(d, e, phi);\n\n\t// 短数据加密\n\tchar * message = \"1234567890ABCDEF\";\n\tmpz_set_str(m, message, 16);\n\tgmp_printf(\"原文:\\n%Zd\\n\", m);\n\tmpz_powm(c, m, e, n);\n\tgmp_printf(\"\\n密文:\\n%Zd\\n\", c);\n\n\t// 短数据解密\n\tmpz_powm(m1, c, d, n);\n\tgmp_printf(\"\\n解密:\\n%Zd\\n\\n\", m1);\n \n\treturn 0;\n}\n```\n\n\n\n![](RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png)","slug":"RSA","published":1,"updated":"2020-07-14T14:47:04.633Z","_id":"ckc4xbevp000bi0qvc3fvf3l8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>信息安全技术实验4</p>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#rsa\">RSA</a>\n<ul>\n<li><a href=\"#%E5%8D%95%E5%90%91%E9%99%B7%E9%97%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E5%85%AC%E9%92%A5%E5%AF%86%E7%A0%81\">单向陷门函数与公钥密码</a></li>\n<li><a href=\"#%E6%AC%A7%E6%8B%89%E5%87%BD%E6%95%B0\">欧拉函数</a></li>\n<li><a href=\"#rsa%E6%AD%A5%E9%AA%A4\">RSA步骤</a></li>\n<li><a href=\"#%E4%BD%BF%E7%94%A8mpir%E5%AE%9E%E7%8E%B0%E7%9F%AD%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%A7%A3%E5%AF%86\">使用mpir实现短数据加解密</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"rsa\"> RSA</span></h1>\n<h2><span id=\"单向陷门函数与公钥密码\"> 单向陷门函数与公钥密码</span></h2>\n<ul>\n<li>单向陷门函数：</li>\n</ul>\n<ol>\n<li>给定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>，计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y=f(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>是容易的；</li>\n<li>给定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>, 计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>使<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mo>=</mo><mi>f</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x=f-1(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span>是不可行的；</li>\n<li>存在陷门<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>，已知<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时，对给定的任何<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>，若相应的原象<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>存在，则计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>是容易的。</li>\n</ol>\n<ul>\n<li>加密：使用函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>作为公钥，陷门<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>作为私钥。加密明文<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">m</span></span></span></span>得到密文<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y=f(m)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">m</span><span class=\"mclose\">)</span></span></span></span>。仅有知道私钥时可求出原文。</li>\n</ul>\n<br>\n<h2><span id=\"欧拉函数\"> 欧拉函数</span></h2>\n<ol>\n<li>在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mi>n</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[1,n]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">]</span></span></span></span>中，不大于<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span>，且与其互素的正整数的个数，记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span>为素数时， <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msup><mi>p</mi><mi>k</mi></msup><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>p</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">(</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(p^k)=p^{k-1}(p-1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0991079999999998em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>若<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>m</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">(m_1, m_2)=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>，则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>1</mn></msub><msub><mi>m</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(m_1 m_2)=\\phi(m_1) \\phi(m_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>若自变量为普通数字，则可改写为素数幂的乘积的形式。之后由3.中公式分解。</li>\n</ol>\n<br>\n<h2><span id=\"rsa步骤\"> RSA步骤</span></h2>\n<ol>\n<li>随机生成两个不同大素数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span>;</li>\n<li>计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi><mo>=</mo><mi>p</mi><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">n=pq</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><mi>q</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(n)=(p-1)(q-1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span>;</li>\n<li>随机选取整数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn><mo>&lt;</mo><mi>e</mi><mo>&lt;</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">1&lt;e&lt;\\phi(n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68354em;vertical-align:-0.0391em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span></span></span></span>,满足<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>e</mi><mo separator=\"true\">,</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">(e,\\phi(n))=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>;</li>\n<li>利用扩展欧基里德算法求出满足<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>e</mi><mi>d</mi><mo>=</mo><mn>1</mn><mi>m</mi><mi>o</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">ed=1 mod(\\phi(n))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span>的整数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>;</li>\n<li>公开<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo separator=\"true\">,</mo><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n,e)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mclose\">)</span></span></span></span>，保密<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mo separator=\"true\">,</mo><mi>q</mi><mo separator=\"true\">,</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(p,q,\\phi(n),d)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mclose\">)</span></span></span></span>。其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span></span></span></span>就是加密密钥，而<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>就是解密密钥，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span>称为模数；</li>\n<li>加密：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>c</mi><mo>=</mo><msup><mi>m</mi><mi>e</mi></msup><mtext> </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mtext> </mtext><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">c=m^e \\ mod \\ n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">e</span></span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">n</span></span></span></span> （若明文长度超过<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span>，则分组）</li>\n<li>解密：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mo>=</mo><msup><mi>c</mi><mi>d</mi></msup><mtext> </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mtext> </mtext><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">m=c^d \\ mod \\ n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">n</span></span></span></span></li>\n</ol>\n<br>\n<h2><span id=\"使用mpir实现短数据加解密\"> 使用mpir实现短数据加解密</span></h2>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//随机生成一个1024素数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">gen_prime</span><span class=\"params\">(<span class=\"keyword\">mpz_t</span> prime)</span>  </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;                                         </span><br><span class=\"line\">    <span class=\"keyword\">gmp_randstate_t</span> grt;                  </span><br><span class=\"line\">    gmp_randinit_default(grt);    </span><br><span class=\"line\">    gmp_randseed_ui(grt, time(<span class=\"literal\">NULL</span>));     </span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">mpz_t</span> p;   </span><br><span class=\"line\">    mpz_init(p);</span><br><span class=\"line\">    mpz_urandomb(p, grt, <span class=\"number\">1024</span>); <span class=\"comment\">//随机生成1024位的大整数                </span></span><br><span class=\"line\">    mpz_nextprime(prime, p);  <span class=\"comment\">//使用GMP自带的素数生成函数  </span></span><br><span class=\"line\">    mpz_clear(p);   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> _tmain(<span class=\"keyword\">int</span> argc, _TCHAR* argv[])</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">mpz_t</span> p, q, n, e, d, phi, sp, sq, m, c, m1;</span><br><span class=\"line\">\t<span class=\"keyword\">mpz_t</span> one, a, b;</span><br><span class=\"line\">\tmpz_init(n);</span><br><span class=\"line\">\tmpz_init(e);</span><br><span class=\"line\">\tmpz_init(d);</span><br><span class=\"line\">\tmpz_init(phi);</span><br><span class=\"line\">\tmpz_init(sp);</span><br><span class=\"line\">\tmpz_init(sq);</span><br><span class=\"line\">\tmpz_init(a);</span><br><span class=\"line\">\tmpz_init(b);</span><br><span class=\"line\">\tmpz_init(one);</span><br><span class=\"line\">        mpz_init(p);</span><br><span class=\"line\">\tmpz_init(q);</span><br><span class=\"line\">\tmpz_init(m);</span><br><span class=\"line\">\tmpz_init(c);</span><br><span class=\"line\">\tmpz_init(m1);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 生成p和q</span></span><br><span class=\"line\">\tgen_prime(p);</span><br><span class=\"line\">\tgmp_printf (<span class=\"string\">\"p:\\n%Zd\\n\\n\"</span>, p);</span><br><span class=\"line\">\tSleep(<span class=\"number\">500</span>);\t<span class=\"comment\">// 以防因时间相同导致生成的pq相同</span></span><br><span class=\"line\">\tgen_prime(q);</span><br><span class=\"line\">        gmp_printf (<span class=\"string\">\"q:\\n%Zd\\n\\n\"</span>, q);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 计算n和phi(n)</span></span><br><span class=\"line\">\tmpz_sub_ui(sp, p, <span class=\"number\">1</span>);</span><br><span class=\"line\">\tmpz_sub_ui(sq, q, <span class=\"number\">1</span>);</span><br><span class=\"line\">\tmpz_mul(n, p, q);</span><br><span class=\"line\">\tmpz_mul(phi, sp, sq);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 选取整数e（公钥）</span></span><br><span class=\"line\">\tmpz_set_ui(e, <span class=\"number\">65537</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 求私钥d</span></span><br><span class=\"line\">\tmpz_invert(d, e, phi);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 短数据加密</span></span><br><span class=\"line\">\t<span class=\"keyword\">char</span> * message = <span class=\"string\">\"1234567890ABCDEF\"</span>;</span><br><span class=\"line\">\tmpz_set_str(m, message, <span class=\"number\">16</span>);</span><br><span class=\"line\">\tgmp_printf(<span class=\"string\">\"原文:\\n%Zd\\n\"</span>, m);</span><br><span class=\"line\">\tmpz_powm(c, m, e, n);</span><br><span class=\"line\">\tgmp_printf(<span class=\"string\">\"\\n密文:\\n%Zd\\n\"</span>, c);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 短数据解密</span></span><br><span class=\"line\">\tmpz_powm(m1, c, d, n);</span><br><span class=\"line\">\tgmp_printf(<span class=\"string\">\"\\n解密:\\n%Zd\\n\\n\"</span>, m1);</span><br><span class=\"line\"> </span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2020/05/30/RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png\" alt></p>\n","site":{"data":{}},"excerpt":"<p>信息安全技术实验4</p>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#rsa\">RSA</a>\n<ul>\n<li><a href=\"#%E5%8D%95%E5%90%91%E9%99%B7%E9%97%A8%E5%87%BD%E6%95%B0%E4%B8%8E%E5%85%AC%E9%92%A5%E5%AF%86%E7%A0%81\">单向陷门函数与公钥密码</a></li>\n<li><a href=\"#%E6%AC%A7%E6%8B%89%E5%87%BD%E6%95%B0\">欧拉函数</a></li>\n<li><a href=\"#rsa%E6%AD%A5%E9%AA%A4\">RSA步骤</a></li>\n<li><a href=\"#%E4%BD%BF%E7%94%A8mpir%E5%AE%9E%E7%8E%B0%E7%9F%AD%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%A7%A3%E5%AF%86\">使用mpir实现短数据加解密</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"rsa\"><a class=\"markdownIt-Anchor\" href=\"#rsa\"></a> RSA</h1>\n<h2 id=\"单向陷门函数与公钥密码\"><a class=\"markdownIt-Anchor\" href=\"#单向陷门函数与公钥密码\"></a> 单向陷门函数与公钥密码</h2>\n<ul>\n<li>单向陷门函数：</li>\n</ul>\n<ol>\n<li>给定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>，计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y=f(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>是容易的；</li>\n<li>给定<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>, 计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>使<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi><mo>=</mo><mi>f</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">(</mo><mi>y</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x=f-1(y)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose\">)</span></span></span></span>是不可行的；</li>\n<li>存在陷门<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>，已知<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>时，对给定的任何<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>，若相应的原象<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>存在，则计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>是容易的。</li>\n</ol>\n<ul>\n<li>加密：使用函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>作为公钥，陷门<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>t</mi></mrow><annotation encoding=\"application/x-tex\">t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.61508em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">t</span></span></span></span>作为私钥。加密明文<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">m</span></span></span></span>得到密文<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>y</mi><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>m</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y=f(m)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">m</span><span class=\"mclose\">)</span></span></span></span>。仅有知道私钥时可求出原文。</li>\n</ul>\n<br>\n<h2 id=\"欧拉函数\"><a class=\"markdownIt-Anchor\" href=\"#欧拉函数\"></a> 欧拉函数</h2>\n<ol>\n<li>在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mi>n</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[1,n]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">]</span></span></span></span>中，不大于<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span>，且与其互素的正整数的个数，记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span></li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span>为素数时， <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msup><mi>p</mi><mi>k</mi></msup><mo stretchy=\"false\">)</mo><mo>=</mo><msup><mi>p</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">(</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(p^k)=p^{k-1}(p-1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0991079999999998em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></li>\n<li>若<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>m</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">(m_1, m_2)=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>，则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>1</mn></msub><msub><mi>m</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo>=</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msub><mi>m</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(m_1 m_2)=\\phi(m_1) \\phi(m_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></li>\n<li>若自变量为普通数字，则可改写为素数幂的乘积的形式。之后由3.中公式分解。</li>\n</ol>\n<br>\n<h2 id=\"rsa步骤\"><a class=\"markdownIt-Anchor\" href=\"#rsa步骤\"></a> RSA步骤</h2>\n<ol>\n<li>随机生成两个不同大素数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding=\"application/x-tex\">p</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">q</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span>;</li>\n<li>计算<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi><mo>=</mo><mi>p</mi><mi>q</mi></mrow><annotation encoding=\"application/x-tex\">n=pq</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo stretchy=\"false\">(</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><mi>q</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(n)=(p-1)(q-1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span>;</li>\n<li>随机选取整数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span></span></span></span>, <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>1</mn><mo>&lt;</mo><mi>e</mi><mo>&lt;</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">1&lt;e&lt;\\phi(n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68354em;vertical-align:-0.0391em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span></span></span></span>,满足<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>e</mi><mo separator=\"true\">,</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">(e,\\phi(n))=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">e</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span></span></span></span>;</li>\n<li>利用扩展欧基里德算法求出满足<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>e</mi><mi>d</mi><mo>=</mo><mn>1</mn><mi>m</mi><mi>o</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">ed=1 mod(\\phi(n))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span>的整数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>;</li>\n<li>公开<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>n</mi><mo separator=\"true\">,</mo><mi>e</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(n,e)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">e</span><span class=\"mclose\">)</span></span></span></span>，保密<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">(</mo><mi>p</mi><mo separator=\"true\">,</mo><mi>q</mi><mo separator=\"true\">,</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>d</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(p,q,\\phi(n),d)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">p</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mclose\">)</span></span></span></span>。其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>e</mi></mrow><annotation encoding=\"application/x-tex\">e</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">e</span></span></span></span>就是加密密钥，而<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span></span></span></span>就是解密密钥，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span>称为模数；</li>\n<li>加密：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>c</mi><mo>=</mo><msup><mi>m</mi><mi>e</mi></msup><mtext> </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mtext> </mtext><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">c=m^e \\ mod \\ n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">c</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">m</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.664392em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">e</span></span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">n</span></span></span></span> （若明文长度超过<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">n</span></span></span></span>，则分组）</li>\n<li>解密：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>m</mi><mo>=</mo><msup><mi>c</mi><mi>d</mi></msup><mtext> </mtext><mi>m</mi><mi>o</mi><mi>d</mi><mtext> </mtext><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">m=c^d \\ mod \\ n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.849108em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">c</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mspace\"> </span><span class=\"mord mathdefault\">n</span></span></span></span></li>\n</ol>\n<br>\n<h2 id=\"使用mpir实现短数据加解密\"><a class=\"markdownIt-Anchor\" href=\"#使用mpir实现短数据加解密\"></a> 使用mpir实现短数据加解密</h2>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//随机生成一个1024素数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">gen_prime</span><span class=\"params\">(<span class=\"keyword\">mpz_t</span> prime)</span>  </span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;                                         </span><br><span class=\"line\">    <span class=\"keyword\">gmp_randstate_t</span> grt;                  </span><br><span class=\"line\">    gmp_randinit_default(grt);    </span><br><span class=\"line\">    gmp_randseed_ui(grt, time(<span class=\"literal\">NULL</span>));     </span><br><span class=\"line\">      </span><br><span class=\"line\">    <span class=\"keyword\">mpz_t</span> p;   </span><br><span class=\"line\">    mpz_init(p);</span><br><span class=\"line\">    mpz_urandomb(p, grt, <span class=\"number\">1024</span>); <span class=\"comment\">//随机生成1024位的大整数                </span></span><br><span class=\"line\">    mpz_nextprime(prime, p);  <span class=\"comment\">//使用GMP自带的素数生成函数  </span></span><br><span class=\"line\">    mpz_clear(p);   </span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> _tmain(<span class=\"keyword\">int</span> argc, _TCHAR* argv[])</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">mpz_t</span> p, q, n, e, d, phi, sp, sq, m, c, m1;</span><br><span class=\"line\">\t<span class=\"keyword\">mpz_t</span> one, a, b;</span><br><span class=\"line\">\tmpz_init(n);</span><br><span class=\"line\">\tmpz_init(e);</span><br><span class=\"line\">\tmpz_init(d);</span><br><span class=\"line\">\tmpz_init(phi);</span><br><span class=\"line\">\tmpz_init(sp);</span><br><span class=\"line\">\tmpz_init(sq);</span><br><span class=\"line\">\tmpz_init(a);</span><br><span class=\"line\">\tmpz_init(b);</span><br><span class=\"line\">\tmpz_init(one);</span><br><span class=\"line\">        mpz_init(p);</span><br><span class=\"line\">\tmpz_init(q);</span><br><span class=\"line\">\tmpz_init(m);</span><br><span class=\"line\">\tmpz_init(c);</span><br><span class=\"line\">\tmpz_init(m1);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 生成p和q</span></span><br><span class=\"line\">\tgen_prime(p);</span><br><span class=\"line\">\tgmp_printf (<span class=\"string\">\"p:\\n%Zd\\n\\n\"</span>, p);</span><br><span class=\"line\">\tSleep(<span class=\"number\">500</span>);\t<span class=\"comment\">// 以防因时间相同导致生成的pq相同</span></span><br><span class=\"line\">\tgen_prime(q);</span><br><span class=\"line\">        gmp_printf (<span class=\"string\">\"q:\\n%Zd\\n\\n\"</span>, q);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 计算n和phi(n)</span></span><br><span class=\"line\">\tmpz_sub_ui(sp, p, <span class=\"number\">1</span>);</span><br><span class=\"line\">\tmpz_sub_ui(sq, q, <span class=\"number\">1</span>);</span><br><span class=\"line\">\tmpz_mul(n, p, q);</span><br><span class=\"line\">\tmpz_mul(phi, sp, sq);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 选取整数e（公钥）</span></span><br><span class=\"line\">\tmpz_set_ui(e, <span class=\"number\">65537</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 求私钥d</span></span><br><span class=\"line\">\tmpz_invert(d, e, phi);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 短数据加密</span></span><br><span class=\"line\">\t<span class=\"keyword\">char</span> * message = <span class=\"string\">\"1234567890ABCDEF\"</span>;</span><br><span class=\"line\">\tmpz_set_str(m, message, <span class=\"number\">16</span>);</span><br><span class=\"line\">\tgmp_printf(<span class=\"string\">\"原文:\\n%Zd\\n\"</span>, m);</span><br><span class=\"line\">\tmpz_powm(c, m, e, n);</span><br><span class=\"line\">\tgmp_printf(<span class=\"string\">\"\\n密文:\\n%Zd\\n\"</span>, c);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 短数据解密</span></span><br><span class=\"line\">\tmpz_powm(m1, c, d, n);</span><br><span class=\"line\">\tgmp_printf(<span class=\"string\">\"\\n解密:\\n%Zd\\n\\n\"</span>, m1);</span><br><span class=\"line\"> </span><br><span class=\"line\">\t<span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2020/05/30/RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png\" alt></p>"},{"title":"SiamDW","date":"2020-03-04T15:22:25.000Z","mathjax":true,"_content":"\nDeeper and Wider Siamese Networks for Real-Time Visual Tracking\n\n<!--more-->\n\n<!-- toc -->\n\n[toc]\n\n[作者讲解视频&PPT](https://www.bilibili.com/video/av52113951)\n\n<br/>\n\n# siam特点\n\n1. 共享权重\n2. 做检索，对比相似性。information经过相同网络，在空间中产生表征向量，计算距离代表相似性\n3. 以pair对形式进入网络，两两组合，相当于增加数据量\n\n![simple_siam](SiamDW/simple_siam.png)\n\n<br/>\n\n# Siam历史\n\n1. SINT：在图像中抽取很多候选目标，经过同一网络，与模板比较，选择距离最小（最相似）\n\n\t![SINT](SiamDW/SINT.png)\n\n2. SiamFC：Cross-correlation互相关，与卷积类似，滑窗，计算相似性\n\n\t![SiamFC_1](SiamDW/SiamFC_1.png)\n\n3. SiamRPN：通过RPN，解决了SiamFC中的僵硬的尺度估计：手动设定几个scale\n\n\t![SiamRPN_net](SiamDW/SiamRPN_net.png)\n\n\n\n<br/>\n\n# Motivation\n\n原有backbone很浅，改用深层，performance降低及思考：\n\n1. backbone的基本模块：res、inception、卷积\n2. stride：分类大，精细任务小\n3. padding：SiamFC中padding全部去掉，而深层backbone的padding是必要的\n4. 输出尺寸：AlexNet 6×6、而后者为16或32\n\n![motivation](SiamDW/motivation.png)\n\n<br/>\n\n# Analysis & Guidelines\n\n通过修改感受野、步长、输出特征尺寸、padding与否、backbone类型，进行实验，发现padding会降点\n\n## padding/PAD\n\n![padding_test](SiamDW/padding_test.png)\n\npadding导致掉点（但输出尺寸不一致，不能说完全都是padding影响）\n\n1. 无padding：\n\n\t![without_padding](SiamDW/without_padding.png)\n\t$$\n\tR1=\\phi(A)·\\phi(E) \\\\\n\tR2=\\phi(B)·\\phi(E) \\\\\n\tR1 = R2\n\t$$\n\n\t1. $E$：模板\n\t  2. $A B$：目标位置\n\t  3. $\\phi$：backbone，提取特征向量\n\t  4. $·$：cross-correlation\n\t  5. $R$：响应\n\t  6. 因为E相同、A和B是同一目标提取向量所得，相同，故两响应相同，满足平移不变性\n\n2. 有padding：\n\n\t![with_padding](SiamDW/with_padding.png)\n\t$$\n\tR1=\\phi(A')·\\phi(E') \\\\\n\tR2=\\phi(B')·\\phi(E') \\\\\n\tR1 \\not= R2\n\t$$\n\n\t1. padding引入外层感受野，目标位置变大，模板变大\n\t2. 扩大后的目标**仍在**画面中时，没有变化\n\t3. 扩大后的目标**不在**画面中时，$\\phi(A')\\not=\\phi(B')$，最终导致两响应不同，破坏平移不变性\n\t4. **而深层网络中，感受野会快速扩大，很容易就会超出画面**\n\n## 步长STR\n\n![other_test](SiamDW/other_test.png)\n\n跟踪的位移较小，使用小步长捕捉微小变化（siam跟踪通常为8）\n\n## 感受野RF和输出尺寸OFS\n\n1. 二者具有相关性，互影响，所以一起讨论\n\n2. 在实验中，performance出现“单峰”，表示RF和OFS大小适中为好\n\n3. 后续分析：\n\n\t![analysis](SiamDW/analysis.png)\n\n\t1. feature map中的element，所对应的RF太小，表示网络太浅，提取特征能力差；而RF太大，不仅捕捉不到细节，而且element之间的重叠率overlap ratio上升，导致特征信息冗余，也会降低feature的判别\n\t2. 故感受野合适大小才行\n\n## Guidelines\n\n1. 步长：小，4或8，捕捉运动变化（4较慢）\n2. 感受野：feature与输入的尺寸比在60%~80%\n3. 步长、感受野、输出尺寸，应作为整体考虑，最终performance是每个环节共同决定。实验中不去掉padding，而通过CIR修改输出尺寸，也能获得不错的效果\n\n<br/>\n\n# Method\n\n根据以上guidelines，设计新的网络\n\n1. 1×1卷积：调整维度，减少参数\n\n\t[![1times1conv](SiamDW/1times1conv.png)](https://zhuanlan.zhihu.com/p/27642620 \"源网址\")\n\n2. cropping-inside residual unit\n\n\t1. CIR Module：原始残差单元中，两个1×1用于维度调整，3×3卷积，因为padding为1、stride为1，输出feature map中仅最外一圈受padding影响，故本文中移去。此法除了消除padding影响，而且因为减小了feature大小，有提速作用。\n\n\t\t![CIR](SiamDW/CIR.png)\n\n\t2. CIR-Downsampling Module：原始残差网络的深层下采样单元，采用conv中增大步长的方式减小feature map大小；本文不同于传统认为的conv+大步长会减轻信息丢失，而是采用了小步长+最大池化的下采样方法。\n\n\t\t![CIR-D](SiamDW/CIR-D.png)\n\n\t\t原因：传统方法结合crop消去最外层feature后，剩余feature map的感受野不足以覆盖完整图片。改为stride1后，紫色映射范围向左上移动一位，覆盖完全。\n\n\t\t以原本的stride2 conv3的方式下采样：\n\n\t\t![CIR-D_2](SiamDW/CIR-D_2.png)\n\n\t\t![loss_feature_with_str](SiamDW/loss_feature_with_str-1583335627710.png)\n\n3. 构建新网络\n\n\t通过在不同网络、不同深度下的组合测试（实验中注意不能一味追求深度，要注意输出尺寸）\n\n\t1. 确定步长：3-stage网络步长为8；2-stage网络步长为4\n\t2. 堆叠CIR单元：合理控制CIR、CIR-D单元数，确保最终层神经元感受野在原图的60%~80%（并非全部都是CIR单元，具体见论文描述）\n\t3. 深度增加，感受野超过合理区间时，减半步长至4\n\n\t最终确定了深度为22层。\n\n4. 加宽channel\n\n\t作者尝试在ResNet的unit的1、 3、 1卷积中加宽通道数以提升性能，结果过高的通道数造成掉点。作者认为过高的通道对cross-correlation并不友好，最终在256或512为宜。","source":"_posts/SiamDW.md","raw":"---\ntitle: SiamDW\ndate: 2020-03-04 23:22:25\nmathjax: true\ntags: AI\n---\n\nDeeper and Wider Siamese Networks for Real-Time Visual Tracking\n\n<!--more-->\n\n<!-- toc -->\n\n[toc]\n\n[作者讲解视频&PPT](https://www.bilibili.com/video/av52113951)\n\n<br/>\n\n# siam特点\n\n1. 共享权重\n2. 做检索，对比相似性。information经过相同网络，在空间中产生表征向量，计算距离代表相似性\n3. 以pair对形式进入网络，两两组合，相当于增加数据量\n\n![simple_siam](SiamDW/simple_siam.png)\n\n<br/>\n\n# Siam历史\n\n1. SINT：在图像中抽取很多候选目标，经过同一网络，与模板比较，选择距离最小（最相似）\n\n\t![SINT](SiamDW/SINT.png)\n\n2. SiamFC：Cross-correlation互相关，与卷积类似，滑窗，计算相似性\n\n\t![SiamFC_1](SiamDW/SiamFC_1.png)\n\n3. SiamRPN：通过RPN，解决了SiamFC中的僵硬的尺度估计：手动设定几个scale\n\n\t![SiamRPN_net](SiamDW/SiamRPN_net.png)\n\n\n\n<br/>\n\n# Motivation\n\n原有backbone很浅，改用深层，performance降低及思考：\n\n1. backbone的基本模块：res、inception、卷积\n2. stride：分类大，精细任务小\n3. padding：SiamFC中padding全部去掉，而深层backbone的padding是必要的\n4. 输出尺寸：AlexNet 6×6、而后者为16或32\n\n![motivation](SiamDW/motivation.png)\n\n<br/>\n\n# Analysis & Guidelines\n\n通过修改感受野、步长、输出特征尺寸、padding与否、backbone类型，进行实验，发现padding会降点\n\n## padding/PAD\n\n![padding_test](SiamDW/padding_test.png)\n\npadding导致掉点（但输出尺寸不一致，不能说完全都是padding影响）\n\n1. 无padding：\n\n\t![without_padding](SiamDW/without_padding.png)\n\t$$\n\tR1=\\phi(A)·\\phi(E) \\\\\n\tR2=\\phi(B)·\\phi(E) \\\\\n\tR1 = R2\n\t$$\n\n\t1. $E$：模板\n\t  2. $A B$：目标位置\n\t  3. $\\phi$：backbone，提取特征向量\n\t  4. $·$：cross-correlation\n\t  5. $R$：响应\n\t  6. 因为E相同、A和B是同一目标提取向量所得，相同，故两响应相同，满足平移不变性\n\n2. 有padding：\n\n\t![with_padding](SiamDW/with_padding.png)\n\t$$\n\tR1=\\phi(A')·\\phi(E') \\\\\n\tR2=\\phi(B')·\\phi(E') \\\\\n\tR1 \\not= R2\n\t$$\n\n\t1. padding引入外层感受野，目标位置变大，模板变大\n\t2. 扩大后的目标**仍在**画面中时，没有变化\n\t3. 扩大后的目标**不在**画面中时，$\\phi(A')\\not=\\phi(B')$，最终导致两响应不同，破坏平移不变性\n\t4. **而深层网络中，感受野会快速扩大，很容易就会超出画面**\n\n## 步长STR\n\n![other_test](SiamDW/other_test.png)\n\n跟踪的位移较小，使用小步长捕捉微小变化（siam跟踪通常为8）\n\n## 感受野RF和输出尺寸OFS\n\n1. 二者具有相关性，互影响，所以一起讨论\n\n2. 在实验中，performance出现“单峰”，表示RF和OFS大小适中为好\n\n3. 后续分析：\n\n\t![analysis](SiamDW/analysis.png)\n\n\t1. feature map中的element，所对应的RF太小，表示网络太浅，提取特征能力差；而RF太大，不仅捕捉不到细节，而且element之间的重叠率overlap ratio上升，导致特征信息冗余，也会降低feature的判别\n\t2. 故感受野合适大小才行\n\n## Guidelines\n\n1. 步长：小，4或8，捕捉运动变化（4较慢）\n2. 感受野：feature与输入的尺寸比在60%~80%\n3. 步长、感受野、输出尺寸，应作为整体考虑，最终performance是每个环节共同决定。实验中不去掉padding，而通过CIR修改输出尺寸，也能获得不错的效果\n\n<br/>\n\n# Method\n\n根据以上guidelines，设计新的网络\n\n1. 1×1卷积：调整维度，减少参数\n\n\t[![1times1conv](SiamDW/1times1conv.png)](https://zhuanlan.zhihu.com/p/27642620 \"源网址\")\n\n2. cropping-inside residual unit\n\n\t1. CIR Module：原始残差单元中，两个1×1用于维度调整，3×3卷积，因为padding为1、stride为1，输出feature map中仅最外一圈受padding影响，故本文中移去。此法除了消除padding影响，而且因为减小了feature大小，有提速作用。\n\n\t\t![CIR](SiamDW/CIR.png)\n\n\t2. CIR-Downsampling Module：原始残差网络的深层下采样单元，采用conv中增大步长的方式减小feature map大小；本文不同于传统认为的conv+大步长会减轻信息丢失，而是采用了小步长+最大池化的下采样方法。\n\n\t\t![CIR-D](SiamDW/CIR-D.png)\n\n\t\t原因：传统方法结合crop消去最外层feature后，剩余feature map的感受野不足以覆盖完整图片。改为stride1后，紫色映射范围向左上移动一位，覆盖完全。\n\n\t\t以原本的stride2 conv3的方式下采样：\n\n\t\t![CIR-D_2](SiamDW/CIR-D_2.png)\n\n\t\t![loss_feature_with_str](SiamDW/loss_feature_with_str-1583335627710.png)\n\n3. 构建新网络\n\n\t通过在不同网络、不同深度下的组合测试（实验中注意不能一味追求深度，要注意输出尺寸）\n\n\t1. 确定步长：3-stage网络步长为8；2-stage网络步长为4\n\t2. 堆叠CIR单元：合理控制CIR、CIR-D单元数，确保最终层神经元感受野在原图的60%~80%（并非全部都是CIR单元，具体见论文描述）\n\t3. 深度增加，感受野超过合理区间时，减半步长至4\n\n\t最终确定了深度为22层。\n\n4. 加宽channel\n\n\t作者尝试在ResNet的unit的1、 3、 1卷积中加宽通道数以提升性能，结果过高的通道数造成掉点。作者认为过高的通道对cross-correlation并不友好，最终在256或512为宜。","slug":"SiamDW","published":1,"updated":"2020-07-14T14:46:50.373Z","_id":"ckc4xbevv000ei0qv8f3s0nn7","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Deeper and Wider Siamese Networks for Real-Time Visual Tracking</p>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#siam%E7%89%B9%E7%82%B9\">siam特点</a></li>\n<li><a href=\"#siam%E5%8E%86%E5%8F%B2\">Siam历史</a></li>\n<li><a href=\"#motivation\">Motivation</a></li>\n<li><a href=\"#analysis-guidelines\">Analysis &amp; Guidelines</a>\n<ul>\n<li><a href=\"#paddingpad\">padding/PAD</a></li>\n<li><a href=\"#%E6%AD%A5%E9%95%BFstr\">步长STR</a></li>\n<li><a href=\"#%E6%84%9F%E5%8F%97%E9%87%8Erf%E5%92%8C%E8%BE%93%E5%87%BA%E5%B0%BA%E5%AF%B8ofs\">感受野RF和输出尺寸OFS</a></li>\n<li><a href=\"#guidelines\">Guidelines</a></li>\n</ul>\n</li>\n<li><a href=\"#method\">Method</a></li>\n</ul>\n<!-- tocstop -->\n<p>[toc]</p>\n<p><a href=\"https://www.bilibili.com/video/av52113951\" target=\"_blank\" rel=\"noopener\">作者讲解视频&amp;PPT</a></p>\n<br>\n<h1><span id=\"siam特点\"> siam特点</span></h1>\n<ol>\n<li>共享权重</li>\n<li>做检索，对比相似性。information经过相同网络，在空间中产生表征向量，计算距离代表相似性</li>\n<li>以pair对形式进入网络，两两组合，相当于增加数据量</li>\n</ol>\n<p><img src=\"/2020/03/04/SiamDW/simple_siam.png\" alt=\"simple_siam\"></p>\n<br>\n<h1><span id=\"siam历史\"> Siam历史</span></h1>\n<ol>\n<li>\n<p>SINT：在图像中抽取很多候选目标，经过同一网络，与模板比较，选择距离最小（最相似）</p>\n<p><img src=\"/2020/03/04/SiamDW/SINT.png\" alt=\"SINT\"></p>\n</li>\n<li>\n<p>SiamFC：Cross-correlation互相关，与卷积类似，滑窗，计算相似性</p>\n<p><img src=\"/2020/03/04/SiamDW/SiamFC_1.png\" alt=\"SiamFC_1\"></p>\n</li>\n<li>\n<p>SiamRPN：通过RPN，解决了SiamFC中的僵硬的尺度估计：手动设定几个scale</p>\n<p><img src=\"/2020/03/04/SiamDW/SiamRPN_net.png\" alt=\"SiamRPN_net\"></p>\n</li>\n</ol>\n<br>\n<h1><span id=\"motivation\"> Motivation</span></h1>\n<p>原有backbone很浅，改用深层，performance降低及思考：</p>\n<ol>\n<li>backbone的基本模块：res、inception、卷积</li>\n<li>stride：分类大，精细任务小</li>\n<li>padding：SiamFC中padding全部去掉，而深层backbone的padding是必要的</li>\n<li>输出尺寸：AlexNet 6×6、而后者为16或32</li>\n</ol>\n<p><img src=\"/2020/03/04/SiamDW/motivation.png\" alt=\"motivation\"></p>\n<br>\n<h1><span id=\"analysis-amp-guidelines\"> Analysis &amp; Guidelines</span></h1>\n<p>通过修改感受野、步长、输出特征尺寸、padding与否、backbone类型，进行实验，发现padding会降点</p>\n<h2><span id=\"paddingpad\"> padding/PAD</span></h2>\n<p><img src=\"/2020/03/04/SiamDW/padding_test.png\" alt=\"padding_test\"></p>\n<p>padding导致掉点（但输出尺寸不一致，不能说完全都是padding影响）</p>\n<ol>\n<li>\n<p>无padding：</p>\n<p><img src=\"/2020/03/04/SiamDW/without_padding.png\" alt=\"without_padding\"></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>R2=\\phi(B)·\\phi(E) \\<br>\nR1 = R2</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<ol start=\"2\">\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">A B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span></span></span></span>：目标位置</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding=\"application/x-tex\">\\phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ϕ</span></span></span></span>：backbone，提取特征向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo separator=\"true\">⋅</mo></mrow><annotation encoding=\"application/x-tex\">·</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.44445em;vertical-align:0em;\"></span><span class=\"mpunct\">⋅</span></span></span></span>：cross-correlation</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span></span></span></span>：响应</li>\n<li>因为E相同、A和B是同一目标提取向量所得，相同，故两响应相同，满足平移不变性</li>\n</ol>\n</li>\n<li>\n<p>有padding：</p>\n<p><img src=\"/2020/03/04/SiamDW/with_padding.png\" alt=\"with_padding\"></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>R2=\\phi(B’)·\\phi(E’) \\<br>\nR1 \\not= R2</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<ol start=\"2\">\n<li>扩大后的目标<strong>仍在</strong>画面中时，没有变化</li>\n<li>扩大后的目标<strong>不在</strong>画面中时，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msup><mi>A</mi><mo mathvariant=\"normal\">′</mo></msup><mo stretchy=\"false\">)</mo><mo>≠</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msup><mi>B</mi><mo mathvariant=\"normal\">′</mo></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(A&#x27;)\\not=\\phi(B&#x27;)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\"><span class=\"mord\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel\"></span></span><span class=\"fix\"></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，最终导致两响应不同，破坏平移不变性</li>\n<li><strong>而深层网络中，感受野会快速扩大，很容易就会超出画面</strong></li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"步长str\"> 步长STR</span></h2>\n<p><img src=\"/2020/03/04/SiamDW/other_test.png\" alt=\"other_test\"></p>\n<p>跟踪的位移较小，使用小步长捕捉微小变化（siam跟踪通常为8）</p>\n<h2><span id=\"感受野rf和输出尺寸ofs\"> 感受野RF和输出尺寸OFS</span></h2>\n<ol>\n<li>\n<p>二者具有相关性，互影响，所以一起讨论</p>\n</li>\n<li>\n<p>在实验中，performance出现“单峰”，表示RF和OFS大小适中为好</p>\n</li>\n<li>\n<p>后续分析：</p>\n<p><img src=\"/2020/03/04/SiamDW/analysis.png\" alt=\"analysis\"></p>\n<ol>\n<li>feature map中的element，所对应的RF太小，表示网络太浅，提取特征能力差；而RF太大，不仅捕捉不到细节，而且element之间的重叠率overlap ratio上升，导致特征信息冗余，也会降低feature的判别</li>\n<li>故感受野合适大小才行</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"guidelines\"> Guidelines</span></h2>\n<ol>\n<li>步长：小，4或8，捕捉运动变化（4较慢）</li>\n<li>感受野：feature与输入的尺寸比在60%~80%</li>\n<li>步长、感受野、输出尺寸，应作为整体考虑，最终performance是每个环节共同决定。实验中不去掉padding，而通过CIR修改输出尺寸，也能获得不错的效果</li>\n</ol>\n<br>\n<h1><span id=\"method\"> Method</span></h1>\n<p>根据以上guidelines，设计新的网络</p>\n<ol>\n<li>\n<p>1×1卷积：调整维度，减少参数</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/27642620\" target=\"_blank\" rel=\"noopener\" title=\"源网址\"><img src=\"/2020/03/04/SiamDW/1times1conv.png\" alt=\"1times1conv\"></a></p>\n</li>\n<li>\n<p>cropping-inside residual unit</p>\n<ol>\n<li>\n<p>CIR Module：原始残差单元中，两个1×1用于维度调整，3×3卷积，因为padding为1、stride为1，输出feature map中仅最外一圈受padding影响，故本文中移去。此法除了消除padding影响，而且因为减小了feature大小，有提速作用。</p>\n<p><img src=\"/2020/03/04/SiamDW/CIR.png\" alt=\"CIR\"></p>\n</li>\n<li>\n<p>CIR-Downsampling Module：原始残差网络的深层下采样单元，采用conv中增大步长的方式减小feature map大小；本文不同于传统认为的conv+大步长会减轻信息丢失，而是采用了小步长+最大池化的下采样方法。</p>\n<p><img src=\"/2020/03/04/SiamDW/CIR-D.png\" alt=\"CIR-D\"></p>\n<p>原因：传统方法结合crop消去最外层feature后，剩余feature map的感受野不足以覆盖完整图片。改为stride1后，紫色映射范围向左上移动一位，覆盖完全。</p>\n<p>以原本的stride2 conv3的方式下采样：</p>\n<p><img src=\"/2020/03/04/SiamDW/CIR-D_2.png\" alt=\"CIR-D_2\"></p>\n<p><img src=\"/2020/03/04/SiamDW/loss_feature_with_str-1583335627710.png\" alt=\"loss_feature_with_str\"></p>\n</li>\n</ol>\n</li>\n<li>\n<p>构建新网络</p>\n<p>通过在不同网络、不同深度下的组合测试（实验中注意不能一味追求深度，要注意输出尺寸）</p>\n<ol>\n<li>确定步长：3-stage网络步长为8；2-stage网络步长为4</li>\n<li>堆叠CIR单元：合理控制CIR、CIR-D单元数，确保最终层神经元感受野在原图的60%~80%（并非全部都是CIR单元，具体见论文描述）</li>\n<li>深度增加，感受野超过合理区间时，减半步长至4</li>\n</ol>\n<p>最终确定了深度为22层。</p>\n</li>\n<li>\n<p>加宽channel</p>\n<p>作者尝试在ResNet的unit的1、 3、 1卷积中加宽通道数以提升性能，结果过高的通道数造成掉点。作者认为过高的通道对cross-correlation并不友好，最终在256或512为宜。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>Deeper and Wider Siamese Networks for Real-Time Visual Tracking</p>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#siam%E7%89%B9%E7%82%B9\">siam特点</a></li>\n<li><a href=\"#siam%E5%8E%86%E5%8F%B2\">Siam历史</a></li>\n<li><a href=\"#motivation\">Motivation</a></li>\n<li><a href=\"#analysis-guidelines\">Analysis &amp; Guidelines</a>\n<ul>\n<li><a href=\"#paddingpad\">padding/PAD</a></li>\n<li><a href=\"#%E6%AD%A5%E9%95%BFstr\">步长STR</a></li>\n<li><a href=\"#%E6%84%9F%E5%8F%97%E9%87%8Erf%E5%92%8C%E8%BE%93%E5%87%BA%E5%B0%BA%E5%AF%B8ofs\">感受野RF和输出尺寸OFS</a></li>\n<li><a href=\"#guidelines\">Guidelines</a></li>\n</ul>\n</li>\n<li><a href=\"#method\">Method</a></li>\n</ul>\n<!-- tocstop -->\n<p>[toc]</p>\n<p><a href=\"https://www.bilibili.com/video/av52113951\" target=\"_blank\" rel=\"noopener\">作者讲解视频&amp;PPT</a></p>\n<br>\n<h1 id=\"siam特点\"><a class=\"markdownIt-Anchor\" href=\"#siam特点\"></a> siam特点</h1>\n<ol>\n<li>共享权重</li>\n<li>做检索，对比相似性。information经过相同网络，在空间中产生表征向量，计算距离代表相似性</li>\n<li>以pair对形式进入网络，两两组合，相当于增加数据量</li>\n</ol>\n<p><img src=\"/2020/03/04/SiamDW/simple_siam.png\" alt=\"simple_siam\"></p>\n<br>\n<h1 id=\"siam历史\"><a class=\"markdownIt-Anchor\" href=\"#siam历史\"></a> Siam历史</h1>\n<ol>\n<li>\n<p>SINT：在图像中抽取很多候选目标，经过同一网络，与模板比较，选择距离最小（最相似）</p>\n<p><img src=\"/2020/03/04/SiamDW/SINT.png\" alt=\"SINT\"></p>\n</li>\n<li>\n<p>SiamFC：Cross-correlation互相关，与卷积类似，滑窗，计算相似性</p>\n<p><img src=\"/2020/03/04/SiamDW/SiamFC_1.png\" alt=\"SiamFC_1\"></p>\n</li>\n<li>\n<p>SiamRPN：通过RPN，解决了SiamFC中的僵硬的尺度估计：手动设定几个scale</p>\n<p><img src=\"/2020/03/04/SiamDW/SiamRPN_net.png\" alt=\"SiamRPN_net\"></p>\n</li>\n</ol>\n<br>\n<h1 id=\"motivation\"><a class=\"markdownIt-Anchor\" href=\"#motivation\"></a> Motivation</h1>\n<p>原有backbone很浅，改用深层，performance降低及思考：</p>\n<ol>\n<li>backbone的基本模块：res、inception、卷积</li>\n<li>stride：分类大，精细任务小</li>\n<li>padding：SiamFC中padding全部去掉，而深层backbone的padding是必要的</li>\n<li>输出尺寸：AlexNet 6×6、而后者为16或32</li>\n</ol>\n<p><img src=\"/2020/03/04/SiamDW/motivation.png\" alt=\"motivation\"></p>\n<br>\n<h1 id=\"analysis-guidelines\"><a class=\"markdownIt-Anchor\" href=\"#analysis-guidelines\"></a> Analysis &amp; Guidelines</h1>\n<p>通过修改感受野、步长、输出特征尺寸、padding与否、backbone类型，进行实验，发现padding会降点</p>\n<h2 id=\"paddingpad\"><a class=\"markdownIt-Anchor\" href=\"#paddingpad\"></a> padding/PAD</h2>\n<p><img src=\"/2020/03/04/SiamDW/padding_test.png\" alt=\"padding_test\"></p>\n<p>padding导致掉点（但输出尺寸不一致，不能说完全都是padding影响）</p>\n<ol>\n<li>\n<p>无padding：</p>\n<p><img src=\"/2020/03/04/SiamDW/without_padding.png\" alt=\"without_padding\"></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>R2=\\phi(B)·\\phi(E) \\<br>\nR1 = R2</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<ol start=\"2\">\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mi>B</mi></mrow><annotation encoding=\"application/x-tex\">A B</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span></span></span></span>：目标位置</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding=\"application/x-tex\">\\phi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">ϕ</span></span></span></span>：backbone，提取特征向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo separator=\"true\">⋅</mo></mrow><annotation encoding=\"application/x-tex\">·</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.44445em;vertical-align:0em;\"></span><span class=\"mpunct\">⋅</span></span></span></span>：cross-correlation</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi></mrow><annotation encoding=\"application/x-tex\">R</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span></span></span></span>：响应</li>\n<li>因为E相同、A和B是同一目标提取向量所得，相同，故两响应相同，满足平移不变性</li>\n</ol>\n</li>\n<li>\n<p>有padding：</p>\n<p><img src=\"/2020/03/04/SiamDW/with_padding.png\" alt=\"with_padding\"></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>R2=\\phi(B’)·\\phi(E’) \\<br>\nR1 \\not= R2</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<ol start=\"2\">\n<li>扩大后的目标<strong>仍在</strong>画面中时，没有变化</li>\n<li>扩大后的目标<strong>不在</strong>画面中时，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msup><mi>A</mi><mo mathvariant=\"normal\">′</mo></msup><mo stretchy=\"false\">)</mo><mo>≠</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><msup><mi>B</mi><mo mathvariant=\"normal\">′</mo></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\phi(A&#x27;)\\not=\\phi(B&#x27;)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\"><span class=\"mord\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"rlap\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"inner\"><span class=\"mrel\"></span></span><span class=\"fix\"></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.36687em;vertical-align:0em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.001892em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.751892em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>，最终导致两响应不同，破坏平移不变性</li>\n<li><strong>而深层网络中，感受野会快速扩大，很容易就会超出画面</strong></li>\n</ol>\n</li>\n</ol>\n<h2 id=\"步长str\"><a class=\"markdownIt-Anchor\" href=\"#步长str\"></a> 步长STR</h2>\n<p><img src=\"/2020/03/04/SiamDW/other_test.png\" alt=\"other_test\"></p>\n<p>跟踪的位移较小，使用小步长捕捉微小变化（siam跟踪通常为8）</p>\n<h2 id=\"感受野rf和输出尺寸ofs\"><a class=\"markdownIt-Anchor\" href=\"#感受野rf和输出尺寸ofs\"></a> 感受野RF和输出尺寸OFS</h2>\n<ol>\n<li>\n<p>二者具有相关性，互影响，所以一起讨论</p>\n</li>\n<li>\n<p>在实验中，performance出现“单峰”，表示RF和OFS大小适中为好</p>\n</li>\n<li>\n<p>后续分析：</p>\n<p><img src=\"/2020/03/04/SiamDW/analysis.png\" alt=\"analysis\"></p>\n<ol>\n<li>feature map中的element，所对应的RF太小，表示网络太浅，提取特征能力差；而RF太大，不仅捕捉不到细节，而且element之间的重叠率overlap ratio上升，导致特征信息冗余，也会降低feature的判别</li>\n<li>故感受野合适大小才行</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"guidelines\"><a class=\"markdownIt-Anchor\" href=\"#guidelines\"></a> Guidelines</h2>\n<ol>\n<li>步长：小，4或8，捕捉运动变化（4较慢）</li>\n<li>感受野：feature与输入的尺寸比在60%~80%</li>\n<li>步长、感受野、输出尺寸，应作为整体考虑，最终performance是每个环节共同决定。实验中不去掉padding，而通过CIR修改输出尺寸，也能获得不错的效果</li>\n</ol>\n<br>\n<h1 id=\"method\"><a class=\"markdownIt-Anchor\" href=\"#method\"></a> Method</h1>\n<p>根据以上guidelines，设计新的网络</p>\n<ol>\n<li>\n<p>1×1卷积：调整维度，减少参数</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/27642620\" target=\"_blank\" rel=\"noopener\" title=\"源网址\"><img src=\"/2020/03/04/SiamDW/1times1conv.png\" alt=\"1times1conv\"></a></p>\n</li>\n<li>\n<p>cropping-inside residual unit</p>\n<ol>\n<li>\n<p>CIR Module：原始残差单元中，两个1×1用于维度调整，3×3卷积，因为padding为1、stride为1，输出feature map中仅最外一圈受padding影响，故本文中移去。此法除了消除padding影响，而且因为减小了feature大小，有提速作用。</p>\n<p><img src=\"/2020/03/04/SiamDW/CIR.png\" alt=\"CIR\"></p>\n</li>\n<li>\n<p>CIR-Downsampling Module：原始残差网络的深层下采样单元，采用conv中增大步长的方式减小feature map大小；本文不同于传统认为的conv+大步长会减轻信息丢失，而是采用了小步长+最大池化的下采样方法。</p>\n<p><img src=\"/2020/03/04/SiamDW/CIR-D.png\" alt=\"CIR-D\"></p>\n<p>原因：传统方法结合crop消去最外层feature后，剩余feature map的感受野不足以覆盖完整图片。改为stride1后，紫色映射范围向左上移动一位，覆盖完全。</p>\n<p>以原本的stride2 conv3的方式下采样：</p>\n<p><img src=\"/2020/03/04/SiamDW/CIR-D_2.png\" alt=\"CIR-D_2\"></p>\n<p><img src=\"/2020/03/04/SiamDW/loss_feature_with_str-1583335627710.png\" alt=\"loss_feature_with_str\"></p>\n</li>\n</ol>\n</li>\n<li>\n<p>构建新网络</p>\n<p>通过在不同网络、不同深度下的组合测试（实验中注意不能一味追求深度，要注意输出尺寸）</p>\n<ol>\n<li>确定步长：3-stage网络步长为8；2-stage网络步长为4</li>\n<li>堆叠CIR单元：合理控制CIR、CIR-D单元数，确保最终层神经元感受野在原图的60%~80%（并非全部都是CIR单元，具体见论文描述）</li>\n<li>深度增加，感受野超过合理区间时，减半步长至4</li>\n</ol>\n<p>最终确定了深度为22层。</p>\n</li>\n<li>\n<p>加宽channel</p>\n<p>作者尝试在ResNet的unit的1、 3、 1卷积中加宽通道数以提升性能，结果过高的通道数造成掉点。作者认为过高的通道对cross-correlation并不友好，最终在256或512为宜。</p>\n</li>\n</ol>"},{"title":"RT-MDNet","mathjax":false,"date":"2020-06-18T12:04:20.000Z","_content":"\n\n\n\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n\n\n# Real-Time MDNet\n\n## Adaptive RoIAlign\n\n​    对于前面的全卷积特征映射，用RoIAlign层提取对象表示：构建高分辨率特征图，扩大每个激活的感受野。\n\n<br/>\n\n### RoIPooling\n\n​    用于Faster RCNN，使生成的候选框region proposal映射产生固定大小的feature map。\n\n![RoIPooling](RT-MDNet/RoIPooling.png) \n\n1. 800*800的原图经过VGG16，stride=32，得到800/32=25.\n2. 原图中一个665*665的候选框，变为655/32=20.78。此处有一次取整（量化），变为20.\n3. 此处，对RoI继续池化，变为7*7。即从400格变为49格。20/7=2.86，此处进行第二次量化，为2.\n4. 即，最终从RoI的每2*2的部分中取max作为代表组成7 * 7的结果（池化）。\n\n​    两次量化自然会带来很大的偏差，影响后面的回归定位。\n\n<br/>\n\n### RoIAlign\n\n​    Mask RCNN中使用，目的相同。\n\n1. 类似上图，对于20.78*20.78，不取整，保留。\n2. 池化时，20.78/7=2.97，得到每2.97*2.97部分，选一个代表。\n3. 假定一个超参数——采样点数为4，表示对上述小部分，平分为4份，每份取中心点的像素，max则作为代表被选中。\n4. 每份中心点的像素，采用双线性插值法进行计算。\n\n![RoIAlign](RT-MDNet/RoIAlign.png)\n\n​    因小目标相较大目标对于偏差更敏感，故小目标上效果更好。\n\n<br/>\n\n### Adaptive RoIAlign\n\n​    RT-MDnet提出，以解决原始RoIAlign提取特征粗略，和双线性差值仅使用临近格点计算导致大目标的信息损失的问题。\n\n![](RT-MDNet/Adaptive RoIAlign.png)\n\n* 移除MaxPool层，以r=3的空洞卷积得到两倍于原尺寸的conv3。\n* 双线性差值的带宽由RoI的siaze决定（自适应），与$\\frac{w}{w`}$成比例。\n\t* $w$：conv3后的RoI宽度\n\t* $w`$：RoIAlign后的RoI宽度\n\t* $[·]$：舍入算子\n* Adaptive RoIAlign输出7*7的map，后接一最大池化层生成3 * 3map。\n\n​    feature map放大， 提高了特征质量，避免了跟踪过程中的错误累计。\n\n---\n\n<br/>\n\n## 内嵌判别实例的预训练\n\n​    MDNet**无法区分**其具有**相似语义信息**的**前景目标**。本文中在预训练阶段引入嵌入损失，并聚合到原MDNet中二分类损失中。\n\n​    在共享特征空间中，不同域中的目标嵌入时互相远离。将多个视频中的前景对象嵌入进去。即，使得不同域的目标在特征空间的距离相互更远，loss中嵌入了其他视频中的目标来使相互之间更有判别力。\n\n$L = L_{cls} + \\alpha·L_{inst}$\n\n* $L_{cls}$：判断前景、背景的二分类得分（原始Loss）\n* $L_{inst}$：判别损失\n* $\\alpha$：权重，0.1\n\n![](RT-MDNet/inst_loss.png)\n\n---\n\n<br/>\n\n## 参考博客\n\n[RoIPooling、RoIAlign笔记](https://www.cnblogs.com/wangyong/p/8523814.html \"RoIPooling、RoIAlign笔记\")\n\n[RT-MDNet深度跟踪网络](https://blog.csdn.net/weixin_39467358/article/details/84990609)\n\n[【小白笔记】目标跟踪 Real-Time MDNet](https://blog.csdn.net/sinat_27318881/article/details/83622344)\n\n[【目标跟踪】Real-Time MDNet](https://blog.csdn.net/qinhuai1994/article/details/82663107)","source":"_posts/RT-MDNet.md","raw":"---\ntitle: RT-MDNet\nmathjax: false\ndate: 2020-06-18 20:04:20\ntags: AI\n---\n\n\n\n\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n\n\n# Real-Time MDNet\n\n## Adaptive RoIAlign\n\n​    对于前面的全卷积特征映射，用RoIAlign层提取对象表示：构建高分辨率特征图，扩大每个激活的感受野。\n\n<br/>\n\n### RoIPooling\n\n​    用于Faster RCNN，使生成的候选框region proposal映射产生固定大小的feature map。\n\n![RoIPooling](RT-MDNet/RoIPooling.png) \n\n1. 800*800的原图经过VGG16，stride=32，得到800/32=25.\n2. 原图中一个665*665的候选框，变为655/32=20.78。此处有一次取整（量化），变为20.\n3. 此处，对RoI继续池化，变为7*7。即从400格变为49格。20/7=2.86，此处进行第二次量化，为2.\n4. 即，最终从RoI的每2*2的部分中取max作为代表组成7 * 7的结果（池化）。\n\n​    两次量化自然会带来很大的偏差，影响后面的回归定位。\n\n<br/>\n\n### RoIAlign\n\n​    Mask RCNN中使用，目的相同。\n\n1. 类似上图，对于20.78*20.78，不取整，保留。\n2. 池化时，20.78/7=2.97，得到每2.97*2.97部分，选一个代表。\n3. 假定一个超参数——采样点数为4，表示对上述小部分，平分为4份，每份取中心点的像素，max则作为代表被选中。\n4. 每份中心点的像素，采用双线性插值法进行计算。\n\n![RoIAlign](RT-MDNet/RoIAlign.png)\n\n​    因小目标相较大目标对于偏差更敏感，故小目标上效果更好。\n\n<br/>\n\n### Adaptive RoIAlign\n\n​    RT-MDnet提出，以解决原始RoIAlign提取特征粗略，和双线性差值仅使用临近格点计算导致大目标的信息损失的问题。\n\n![](RT-MDNet/Adaptive RoIAlign.png)\n\n* 移除MaxPool层，以r=3的空洞卷积得到两倍于原尺寸的conv3。\n* 双线性差值的带宽由RoI的siaze决定（自适应），与$\\frac{w}{w`}$成比例。\n\t* $w$：conv3后的RoI宽度\n\t* $w`$：RoIAlign后的RoI宽度\n\t* $[·]$：舍入算子\n* Adaptive RoIAlign输出7*7的map，后接一最大池化层生成3 * 3map。\n\n​    feature map放大， 提高了特征质量，避免了跟踪过程中的错误累计。\n\n---\n\n<br/>\n\n## 内嵌判别实例的预训练\n\n​    MDNet**无法区分**其具有**相似语义信息**的**前景目标**。本文中在预训练阶段引入嵌入损失，并聚合到原MDNet中二分类损失中。\n\n​    在共享特征空间中，不同域中的目标嵌入时互相远离。将多个视频中的前景对象嵌入进去。即，使得不同域的目标在特征空间的距离相互更远，loss中嵌入了其他视频中的目标来使相互之间更有判别力。\n\n$L = L_{cls} + \\alpha·L_{inst}$\n\n* $L_{cls}$：判断前景、背景的二分类得分（原始Loss）\n* $L_{inst}$：判别损失\n* $\\alpha$：权重，0.1\n\n![](RT-MDNet/inst_loss.png)\n\n---\n\n<br/>\n\n## 参考博客\n\n[RoIPooling、RoIAlign笔记](https://www.cnblogs.com/wangyong/p/8523814.html \"RoIPooling、RoIAlign笔记\")\n\n[RT-MDNet深度跟踪网络](https://blog.csdn.net/weixin_39467358/article/details/84990609)\n\n[【小白笔记】目标跟踪 Real-Time MDNet](https://blog.csdn.net/sinat_27318881/article/details/83622344)\n\n[【目标跟踪】Real-Time MDNet](https://blog.csdn.net/qinhuai1994/article/details/82663107)","slug":"RT-MDNet","published":1,"updated":"2020-06-18T12:06:44.436Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbevy000gi0qv5bgl288s","content":"<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#real-time-mdnet\">Real-Time MDNet</a>\n<ul>\n<li><a href=\"#adaptive-roialign\">Adaptive RoIAlign</a>\n<ul>\n<li><a href=\"#roipooling\">RoIPooling</a></li>\n<li><a href=\"#roialign\">RoIAlign</a></li>\n<li><a href=\"#adaptive-roialign-1\">Adaptive RoIAlign</a></li>\n</ul>\n</li>\n<li><a href=\"#%E5%86%85%E5%B5%8C%E5%88%A4%E5%88%AB%E5%AE%9E%E4%BE%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83\">内嵌判别实例的预训练</a></li>\n<li><a href=\"#%E5%8F%82%E8%80%83%E5%8D%9A%E5%AE%A2\">参考博客</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"real-time-mdnet\"> Real-Time MDNet</span></h1>\n<h2><span id=\"adaptive-roialign\"> Adaptive RoIAlign</span></h2>\n<p>​    对于前面的全卷积特征映射，用RoIAlign层提取对象表示：构建高分辨率特征图，扩大每个激活的感受野。</p>\n<br>\n<h3><span id=\"roipooling\"> RoIPooling</span></h3>\n<p>​    用于Faster RCNN，使生成的候选框region proposal映射产生固定大小的feature map。</p>\n<p><img src=\"/2020/06/18/RT-MDNet/RoIPooling.png\" alt=\"RoIPooling\"></p>\n<ol>\n<li>800*800的原图经过VGG16，stride=32，得到800/32=25.</li>\n<li>原图中一个665*665的候选框，变为655/32=20.78。此处有一次取整（量化），变为20.</li>\n<li>此处，对RoI继续池化，变为7*7。即从400格变为49格。20/7=2.86，此处进行第二次量化，为2.</li>\n<li>即，最终从RoI的每2*2的部分中取max作为代表组成7 * 7的结果（池化）。</li>\n</ol>\n<p>​    两次量化自然会带来很大的偏差，影响后面的回归定位。</p>\n<br>\n<h3><span id=\"roialign\"> RoIAlign</span></h3>\n<p>​    Mask RCNN中使用，目的相同。</p>\n<ol>\n<li>类似上图，对于20.78*20.78，不取整，保留。</li>\n<li>池化时，20.78/7=2.97，得到每2.97*2.97部分，选一个代表。</li>\n<li>假定一个超参数——采样点数为4，表示对上述小部分，平分为4份，每份取中心点的像素，max则作为代表被选中。</li>\n<li>每份中心点的像素，采用双线性插值法进行计算。</li>\n</ol>\n<p><img src=\"/2020/06/18/RT-MDNet/RoIAlign.png\" alt=\"RoIAlign\"></p>\n<p>​    因小目标相较大目标对于偏差更敏感，故小目标上效果更好。</p>\n<br>\n<h3><span id=\"adaptive-roialign\"> Adaptive RoIAlign</span></h3>\n<p>​    RT-MDnet提出，以解决原始RoIAlign提取特征粗略，和双线性差值仅使用临近格点计算导致大目标的信息损失的问题。</p>\n<p>![](RT-MDNet/Adaptive RoIAlign.png)</p>\n<ul>\n<li>移除MaxPool层，以r=3的空洞卷积得到两倍于原尺寸的conv3。</li>\n<li>双线性差值的带宽由RoI的siaze决定（自适应），与<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mi>w</mi><mrow><mi>w</mi><mi mathvariant=\"normal\">‘</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{w}{w`}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.040392em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.695392em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mtight\">‘</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>成比例。\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>：conv3后的RoI宽度</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>w</mi><mi mathvariant=\"normal\">‘</mi></mrow><annotation encoding=\"application/x-tex\">w`</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord\">‘</span></span></span></span>：RoIAlign后的RoI宽度</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mo separator=\"true\">⋅</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[·]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mclose\">]</span></span></span></span>：舍入算子</li>\n</ul>\n</li>\n<li>Adaptive RoIAlign输出7*7的map，后接一最大池化层生成3 * 3map。</li>\n</ul>\n<p>​    feature map放大， 提高了特征质量，避免了跟踪过程中的错误累计。</p>\n<hr>\n<br>\n<h2><span id=\"内嵌判别实例的预训练\"> 内嵌判别实例的预训练</span></h2>\n<p>​    MDNet<strong>无法区分</strong>其具有<strong>相似语义信息</strong>的<strong>前景目标</strong>。本文中在预训练阶段引入嵌入损失，并聚合到原MDNet中二分类损失中。</p>\n<p>​    在共享特征空间中，不同域中的目标嵌入时互相远离。将多个视频中的前景对象嵌入进去。即，使得不同域的目标在特征空间的距离相互更远，loss中嵌入了其他视频中的目标来使相互之间更有判别力。</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo>+</mo><mi>α</mi><mo separator=\"true\">⋅</mo><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>s</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">L = L_{cls} + \\alpha·L_{inst}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">c</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">L_{cls}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">c</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：判断前景、背景的二分类得分（原始Loss）</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>s</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">L_{inst}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：判别损失</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span></span></span></span>：权重，0.1</li>\n</ul>\n<p><img src=\"/2020/06/18/RT-MDNet/inst_loss.png\" alt></p>\n<hr>\n<br>\n<h2><span id=\"参考博客\"> 参考博客</span></h2>\n<p><a href=\"https://www.cnblogs.com/wangyong/p/8523814.html\" target=\"_blank\" rel=\"noopener\" title=\"RoIPooling、RoIAlign笔记\">RoIPooling、RoIAlign笔记</a></p>\n<p><a href=\"https://blog.csdn.net/weixin_39467358/article/details/84990609\" target=\"_blank\" rel=\"noopener\">RT-MDNet深度跟踪网络</a></p>\n<p><a href=\"https://blog.csdn.net/sinat_27318881/article/details/83622344\" target=\"_blank\" rel=\"noopener\">【小白笔记】目标跟踪 Real-Time MDNet</a></p>\n<p><a href=\"https://blog.csdn.net/qinhuai1994/article/details/82663107\" target=\"_blank\" rel=\"noopener\">【目标跟踪】Real-Time MDNet</a></p>\n","site":{"data":{}},"excerpt":"","more":"<!-- toc -->\n<ul>\n<li><a href=\"#real-time-mdnet\">Real-Time MDNet</a>\n<ul>\n<li><a href=\"#adaptive-roialign\">Adaptive RoIAlign</a>\n<ul>\n<li><a href=\"#roipooling\">RoIPooling</a></li>\n<li><a href=\"#roialign\">RoIAlign</a></li>\n<li><a href=\"#adaptive-roialign-1\">Adaptive RoIAlign</a></li>\n</ul>\n</li>\n<li><a href=\"#%E5%86%85%E5%B5%8C%E5%88%A4%E5%88%AB%E5%AE%9E%E4%BE%8B%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83\">内嵌判别实例的预训练</a></li>\n<li><a href=\"#%E5%8F%82%E8%80%83%E5%8D%9A%E5%AE%A2\">参考博客</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"real-time-mdnet\"><a class=\"markdownIt-Anchor\" href=\"#real-time-mdnet\"></a> Real-Time MDNet</h1>\n<h2 id=\"adaptive-roialign\"><a class=\"markdownIt-Anchor\" href=\"#adaptive-roialign\"></a> Adaptive RoIAlign</h2>\n<p>​    对于前面的全卷积特征映射，用RoIAlign层提取对象表示：构建高分辨率特征图，扩大每个激活的感受野。</p>\n<br>\n<h3 id=\"roipooling\"><a class=\"markdownIt-Anchor\" href=\"#roipooling\"></a> RoIPooling</h3>\n<p>​    用于Faster RCNN，使生成的候选框region proposal映射产生固定大小的feature map。</p>\n<p><img src=\"/2020/06/18/RT-MDNet/RoIPooling.png\" alt=\"RoIPooling\"></p>\n<ol>\n<li>800*800的原图经过VGG16，stride=32，得到800/32=25.</li>\n<li>原图中一个665*665的候选框，变为655/32=20.78。此处有一次取整（量化），变为20.</li>\n<li>此处，对RoI继续池化，变为7*7。即从400格变为49格。20/7=2.86，此处进行第二次量化，为2.</li>\n<li>即，最终从RoI的每2*2的部分中取max作为代表组成7 * 7的结果（池化）。</li>\n</ol>\n<p>​    两次量化自然会带来很大的偏差，影响后面的回归定位。</p>\n<br>\n<h3 id=\"roialign\"><a class=\"markdownIt-Anchor\" href=\"#roialign\"></a> RoIAlign</h3>\n<p>​    Mask RCNN中使用，目的相同。</p>\n<ol>\n<li>类似上图，对于20.78*20.78，不取整，保留。</li>\n<li>池化时，20.78/7=2.97，得到每2.97*2.97部分，选一个代表。</li>\n<li>假定一个超参数——采样点数为4，表示对上述小部分，平分为4份，每份取中心点的像素，max则作为代表被选中。</li>\n<li>每份中心点的像素，采用双线性插值法进行计算。</li>\n</ol>\n<p><img src=\"/2020/06/18/RT-MDNet/RoIAlign.png\" alt=\"RoIAlign\"></p>\n<p>​    因小目标相较大目标对于偏差更敏感，故小目标上效果更好。</p>\n<br>\n<h3 id=\"adaptive-roialign-2\"><a class=\"markdownIt-Anchor\" href=\"#adaptive-roialign-2\"></a> Adaptive RoIAlign</h3>\n<p>​    RT-MDnet提出，以解决原始RoIAlign提取特征粗略，和双线性差值仅使用临近格点计算导致大目标的信息损失的问题。</p>\n<p>![](RT-MDNet/Adaptive RoIAlign.png)</p>\n<ul>\n<li>移除MaxPool层，以r=3的空洞卷积得到两倍于原尺寸的conv3。</li>\n<li>双线性差值的带宽由RoI的siaze决定（自适应），与<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mi>w</mi><mrow><mi>w</mi><mi mathvariant=\"normal\">‘</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{w}{w`}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.040392em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.695392em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mtight\">‘</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>成比例。\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>：conv3后的RoI宽度</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>w</mi><mi mathvariant=\"normal\">‘</mi></mrow><annotation encoding=\"application/x-tex\">w`</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord\">‘</span></span></span></span>：RoIAlign后的RoI宽度</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mo separator=\"true\">⋅</mo><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[·]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mclose\">]</span></span></span></span>：舍入算子</li>\n</ul>\n</li>\n<li>Adaptive RoIAlign输出7*7的map，后接一最大池化层生成3 * 3map。</li>\n</ul>\n<p>​    feature map放大， 提高了特征质量，避免了跟踪过程中的错误累计。</p>\n<hr>\n<br>\n<h2 id=\"内嵌判别实例的预训练\"><a class=\"markdownIt-Anchor\" href=\"#内嵌判别实例的预训练\"></a> 内嵌判别实例的预训练</h2>\n<p>​    MDNet<strong>无法区分</strong>其具有<strong>相似语义信息</strong>的<strong>前景目标</strong>。本文中在预训练阶段引入嵌入损失，并聚合到原MDNet中二分类损失中。</p>\n<p>​    在共享特征空间中，不同域中的目标嵌入时互相远离。将多个视频中的前景对象嵌入进去。即，使得不同域的目标在特征空间的距离相互更远，loss中嵌入了其他视频中的目标来使相互之间更有判别力。</p>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo>+</mo><mi>α</mi><mo separator=\"true\">⋅</mo><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>s</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">L = L_{cls} + \\alpha·L_{inst}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">c</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">L_{cls}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">c</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：判断前景、背景的二分类得分（原始Loss）</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>i</mi><mi>n</mi><mi>s</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">L_{inst}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>：判别损失</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.0037em;\">α</span></span></span></span>：权重，0.1</li>\n</ul>\n<p><img src=\"/2020/06/18/RT-MDNet/inst_loss.png\" alt></p>\n<hr>\n<br>\n<h2 id=\"参考博客\"><a class=\"markdownIt-Anchor\" href=\"#参考博客\"></a> 参考博客</h2>\n<p><a href=\"https://www.cnblogs.com/wangyong/p/8523814.html\" target=\"_blank\" rel=\"noopener\" title=\"RoIPooling、RoIAlign笔记\">RoIPooling、RoIAlign笔记</a></p>\n<p><a href=\"https://blog.csdn.net/weixin_39467358/article/details/84990609\" target=\"_blank\" rel=\"noopener\">RT-MDNet深度跟踪网络</a></p>\n<p><a href=\"https://blog.csdn.net/sinat_27318881/article/details/83622344\" target=\"_blank\" rel=\"noopener\">【小白笔记】目标跟踪 Real-Time MDNet</a></p>\n<p><a href=\"https://blog.csdn.net/qinhuai1994/article/details/82663107\" target=\"_blank\" rel=\"noopener\">【目标跟踪】Real-Time MDNet</a></p>"},{"title":"Siamese系列","mathjax":true,"date":"2020-06-18T12:07:30.000Z","_content":"\n\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n## Siamese\n\n* Siamese和Chinese有点像。Siam是古时候泰国的称呼，中文译作暹罗。Siamese也就是“暹罗”人或“泰国”人。十九世纪泰国出生了一对连体婴儿，当时的医学技术无法使两人分离出来，于是两人顽强地生活了一生，两人均于63岁离开人间。两人的肝至今仍保存在费城的[马特博物馆](https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E9%A9%AC%E7%89%B9%E5%8D%9A%E7%89%A9%E9%A6%86%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163)内。从此之后“[暹罗双胞胎](https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E6%9A%B9%E7%BD%97%E5%8F%8C%E8%83%9E%E8%83%8E%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163)”（Siamese twins）就成了连体人的代名词\n\n![Siamese twins](Siamese系列\\Siamese twins.jpg)\n\n<br/>\n\n## Siamese Network\n\n* 判断两个输入相似性，核心思想是，两个子体网络通过权重共享来实现连体，寻找一个映射函数，能够将输入图像转换到一个特征空间，每幅图像对应一个特征向量，通过一些简单的“距离度量”（比如欧式距离）来表示向量之间的差异，最后通过这个距离来拟合输入图像的相似度差异（语义差异）\n* 对比损失Contrastive Loss：\n\t*  $d=||a_n-b_n||_2$，代表两个样本特征的欧氏距离，\n\t*  d也可使用cosine距离，d=cos=x*y/|x||y|\n\t*  y为两个样本是否匹配的标签，y=1代表两个样本相似或者匹配，y=0则代表不匹配，\n\t*  margin为设定的阈值\n\t*  这种损失函数可以很好的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。当y=1（即样本相似）时，损失函数只剩下∑d2，即原本相似的样本，如果在特征空间的欧式距离较大，则说明当前的模型不好，因此加大损失。而当y=0时（即样本不相似）时，损失函数为∑max(margin−d,0)2，即当样本不相似时，其特征空间的欧式距离反而小的话（d小，margin-d大），损失值会变大，这也正好符合我们的要求。\n\t*  图3表示的就是损失函数值与样本特征的欧式距离之间的关系，其中红色虚线表示的是相似样本的损失值，蓝色实线表示的不相似样本的损失值。\n\n![Siamese Net](Siamese系列/Siamese Net.png)\n\n![Siamese Net_loss](Siamese系列/Siamese Net_loss.png)\n\n![Siamese Net_loss1](Siamese系列/Siamese Net_loss1.png)\n\n---\n\n<br/>\n\n## SiamFC\n\nhttps://blog.csdn.net/nightmare_dimple/article/details/74210147\n\n* 全卷积孪生网络 fully-convolutional siamese networks for object tracking\n* AlexNet\n* 以往：相关滤波之网络一层作为特征，深度学习之梯度下降，在线学习，存在问题；本法离线学习，tracking时只需进行相似性判断，计算量很小\n* 细节：在初始离线阶段把深度卷积网络看成一个更通用的**相似性学习**问题，然后在跟踪时对这个问题进行在线的简单估计。训练了一个孪生网络在一个较大的搜索区域搜索样本图片。本文另一个贡献在于，新的孪生网络结构是一个关于搜索区域的**全卷积网络**：密集高效的滑动窗口估计可通过计算两个输入的互相关性并插值得到。\n* 相似性学习：学习一个函数$f(x,z)$来比较样本图像（目标）z和搜索图像（画面）x的相似性\n* 用深度神经网络模拟$f$，深度卷积网络中**相似性学习最典型的就是孪生结构**。孪生网络对两个输入z和x进行相同的变换$\\varphi$，然后将得到的输出送入函数g，最后得到相似性度量函数为：*f*(*z*,*x*)=*g*(*φ*(*z*),*φ*(*x*))\n\t* 1.函数g是一个简单的距离或相似性度量\n\t* 2.φ相当于特征提取器\n* 全卷积网络的优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。\n\n![](Siamese系列/SiamFC_1.png)\n\n* 搜索图像的确定：跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图\n* 正负样本的确定：和目标距离不超过阈值\n* 在经过卷积神经层提取特征后，SiameseFC使用cross-correlation（交叉相关）作为相似度的度量，计算两个feature map各个位置（区域）上的相似度，得到一个score map（或者说heat map）。最后对这个score map进行插值（这里使用的是双三线性插值），获得和原图像一样的空间分辨率，根据该score map，即可定位到跟踪目标在新一帧（检测图像）中的精确位置。\n* **训练数据：**从视频的两个帧中提取图像，这两个帧都包含对象并且最多相隔T帧。训练时忽略目标的类别。在不破坏图像的纵横比的情况下对每个图像内的对象的比例进行归一化 。如果得分图中的元素距离中心半径在![R](https://math.jianshu.com/math?formula=R)（根据网络步长![k](https://math.jianshu.com/math?formula=k)决定）以内，就认为是正样本。\n\n![](Siamese系列\\SiamFC_training_pairs.png)\n\n* 余弦惩罚：在获得score map之后，SiameseFC会在上面应用一个余弦窗，以对那些不正常的较大位移进行惩罚（余弦窗具有边缘抑制的作用，如果目标是一个正常的位移，那么检测热点应该是在heatmap的中心区域附近，如果检测热点跑到heatmap的边缘，则说明目标发生了瞬时的长位移，这很大可能是由检测错误导致的，因此该检测结果需要被抑制和惩罚）。\n\n* 多尺度检测：通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。\n\n* 优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。\n\n* 本文的相似度函数使用互相关，公式如下*f*(*z*,*x*)=*φ*(*z*)∗*φ*(*x*)+*b*1\n\t* *b*1 表示在得分图中每个位置的取值\n\t* 上式可将φ(z)看成卷积核，在φ(x)上进行卷积\n\n* 跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图f，将得分最大的位置乘以步长即可得到当前目标的位置\n\n* phi：五层卷积，提取特征\n\n* 卷积：卷积以实现相似性度量\n\n![](Siamese系列/SiamFC_3.jpg) \n\n![SiamFC_2](Siamese系列/SiamFC_2.jpg) \n\n* 损失函数：每一个候选子窗口，其实相当于一个样本，而它的得分，输出的就是它是正/负样本的概率。使用逻辑回归来表示的话，这就是一个应用逻辑回归的典型二分类问题，对于得分矩阵中的每一个点u有：其中*v*是实际输出,*y*是真实标签{+1，-1}\n\n![SiamFC_loss](Siamese系列/SiamFC_loss.png)\n\n* 定位目标区域/tracking：相似性矩阵，经双三次插值，变为255²矩阵，定位。\n\n* 目标图像在线不更新，提取高层语义特征\n\n* 5尺度搜索 1.025（-2，-1,0,1,2）。尺度检测是扩大或缩小检测区域，但检测图像都要缩放到255*255*3，也就是说尺度检测是天然可以并行的，SiamFC通过设置mini-batch的方式实现，一次性完成3或5个尺度样本检测。多尺度检测通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。\n\n* long term与short term：SiameseFC在预测的时候，不在线更新模板图像。这使得SiameseFC的计算速度很快，但同时也要求SiameseFC中使用的特征需要具有足够的鲁棒性（通常是高层特征，分辨率较低，计算复杂度较大），以便在后续帧中能够应对各种变换。而在另一方面，不在线更新模板图像的策略，可以确保跟踪目标的不变性和纯净性，在long-term跟踪算法上具有天然的优势。\n\n\t还有一类visual tracker，在预测时，使用的是在线更新模板图像的策略。这种策略的优点是对特征的鲁棒性要求较低（通常是低层特征，分辨率较高，计算复杂度较小），能适时地学习到目标和背景的变化，但也带来了其他的缺点：在目标跟踪的过程中，如果中间跟丢或跟错了目标（由于遮挡或失败等原因，会导致学习到背景，而不是目标），就无法再恢复到正确的跟踪目标上了；而如果在目标跟踪的过程中，学习到了错误的特征（如来自外界的噪声），则会导致跟踪目标被污染，在后续帧中，跟踪能力降低，甚至逐渐丧失（跟踪目标的累积污染增加）。因此这种更新策略更多地用于short-term跟踪算法上。\n\n* 双三次差值 https://blog.csdn.net/datase/article/details/80576054\n\n---\n\n<br/>\n\n## RPN\n\nRegion Proposal Network 区域推荐网络\n\n* 本质是 “ 基于滑窗的无类别obejct检测器 ”\n\n* 用于目标检测。把一个任意尺度的图片作为输入，输出一系列的矩形object proposals，每个object proposals都带一个objectness score。分为两个支路，一个用于分类前景和背景，一个用于边界框回归。通俗来讲，就是用RPN来选择感兴趣区域的，即proposal extraction。例如，如果一个区域的p>0.5，则认为这个区域中可能是我们想要的类别中的某一类，具体是哪一类现在还不清楚。到此为止，网络只需要把这些可能含有物体的区域选取出来就可以了，这些被选取出来的区域又叫做ROI （Region of Interests），即感兴趣的区域。当然了，RPN同时也会在feature map上框定这些ROI感兴趣区域的大致位置，即输出Bounding Box。\n* 一种更加简单的方法来预测 objects 的边界框，即，学习相对于**参考GT的偏移量**\n\n* anchor的一种理解（anchor的特征图与原始图像的联系）：应该是特征图的某一个像素与对应在原始图像的某一个像素，即**本质上指的是特征图上当前滑窗的中心在原像素空间的映射点称为anchor**，即anchor是在原始图像上的\n* 在特征的每个位置，考虑多个可能的候选窗口：窗口数=面积数×比例数，称为anchors。下图中3种面积×3种比例，每个位置9个anchors\n\n![anchors](Siamese系列\\anchors.jpg)\n\n* 计算每个像素（256-d）的k个尺度下的值，得到k个anchor，我们给每个anchor分配一个二进制的标签（前景背景），由其与GT重叠度决定。则标记后输出2×k纬度，表示每个位置有2k个cls（classification）分数；同时每个anchor又与GT对应四个偏移量[x, y, w, h]，代表中心点的坐标、框的宽高，则回归组reg（regression）为4k纬度\n* anchor会很多，选取部分正、负anchor训练\n\n---\n\n<br/>\n\n## SiamRPN\n\nhttps://blog.csdn.net/fzp95/article/details/80982201\n\nhttps://www.jianshu.com/p/a3786b61031c\n\nhttps://blog.csdn.net/leviopku/article/details/81068487\n\nhttps://blog.csdn.net/leviopku/article/details/80875368\n\n* 孪生候选区域生成网络 High Performance Visual Tracking with Siamese Region Proposal Network\n* Siamese部分基于预训练的AlexNet\n* SiamFC缺点：只能得到目标的中心位置，但是得不到目标的尺寸，所以只能采取简单的多尺度加回归，这即增加了计算量，同时也不够精确。\n* 改进：输出两个分支，分别用于分类和回归（SiamFC没有回归，而是用多尺度测试，增加了计算量且不够精确），帧率160fps（不需要在线微调）\n* 摘要：这个结构包含用于特征提取的孪生子网络（Siamese subnetwork）和候选区域生成网络（region proposal subnetwork），其中候选区域生成网络包含分类和回归两条支路。在跟踪阶段，作者提出的方法被构造成为单样本检测任务（one-shot detection task）。作者预先计算孪生子网络中的模板支路，也就是第一帧，并且将它构造成一个检测支路中区域提取网络里面的一个卷积层，用于在线跟踪。传统的多尺度测试和在线微调可以被舍弃，这样做也大大提高了速度。\n* 此方法不更新模型，是离线训练好的基于深度学习跟踪器，在相关特征图谱上提取候选区域，然后作者将模板分支上的目标外观信息编码到RPN特征中来判别前景和背景。在跟踪阶段，作者将此任务视为单目标检测任务（one-shot detection），什么意思呢，就是把第一帧的BB视为检测的样例，在其余帧里面检测与它相似的目标。\n* anchor box：具有不同规格（大小，长宽比，本文有一种大小，五种长宽比[0.33,0.5,1,2,3]），锚点由卷积过程中卷积核中心确定，每个锚点对应数个锚点框（不同规格）。则检测问题由“哪里有物体”变为“锚点框是否框住物体，框住多少，离得多远”。\n* 如下图：RPN网络主要用于生成region proposals，首先生成一堆Anchor box，对其进行裁剪过滤后通过softmax判断anchors属于前景(foreground)或者后景(background)，即是物体or不是物体，所以这是一个二分类；同时，另一分支bounding box regression修正anchor box，形成较精确的proposal\n\n![RPN](Siamese系列/RPN.jpg)\n\n* 分类组：在RPN的分类分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的2k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为2k份，作为2k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为2k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为2的score map，两个维度分别对应anchor中前景（目标）和后景（背景）的分类分数，是关于目标的置信度。\n* 回归组： 在RPN的回归分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的4k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为4k份，作为4k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为4k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为4的score map，四个维度分别对应anchor的（x,y,w,h），是关于目标的坐标及尺寸。\n* RPN的引入，使得Siamese网络自然拥有了多尺度检测的能力（通过anchor机制cover各种size），并且可以准确地回归出目标的位置及大小\n* k：anchor box 锚点框数量；\n\t* 本文为5，不同长宽比[0.33, 0.5, 1, 2, 3]\n\t* 模板帧：因要分为目标、背景两类，故2k\n\t* 检测帧：[x, y, w, h]，故4k\n\n![](Siamese系列/SiamRPN_net.png)\n\n* 不同于SiamFC，可对多个多个anchor box判断。\n* RPN部分卷积：3×3进一步集中特征，然后多个/一个1×1提高通道数\n* 分类组：每个点表示正负得分，softmax分类（anchor box和真实目标重叠且IOU大于阈值）\n* 回归组：每个点表示anchor和ground truth之间的dx,dy,dw,dh（anchor相比于groundtruth的偏移量），通过smooth L1 loss:\n\n![smooth loss](Siamese系列\\smooth loss.png)\n\n* tracking as one shot detection：对于一个类别，如果只提供一个或者少量训练样本的情况下，如何检测？解决方法就是：让模型学习，得到一个相似性函数，这样的模型输出的值不是类别，而是两幅图像的相似度。\n* 始终用第一帧当做模板帧，只需进行detection分支，提速。从分类组的奇数层（目标）中，选取最大的K的建议候选框，**后经距离、余弦窗和尺度变化惩罚因子对proposal进行取舍和重新排序，NMS**得到最佳位置。\n* 若无回归组，则与FC类似，得分图的叠加。\n\n![SiamRPN_tracking](Siamese系列\\SiamRPN_tracking.png)\n\n---\n\n<br/>\n\n## DaSiamRPN\n\nDistractor-aware Siamese Networks for Visual Object Tracking 添加干扰的\n\nhttps://zhuanlan.zhihu.com/p/42546692\n\nhttps://blog.csdn.net/fzp95/article/details/82380261\n\n* SiamRPN的缺点：\n\t* 响应分数不可靠：跟丢后分类得分仍很高，推测为SiamRPN只能学到（有语义的）物体与非物体的区分，或者理解为区分前景背景，而非学习一个实例级别的表示方法。导致背景有其他物体时易被干扰（csdn提问、feature map）\n\t* 跟踪阶段不更新模型，精度换速度\n\t* 长时间跟踪中，遮挡、消失效果差\n\n![SiamRPN_shortcoming2](Siamese系列\\SiamRPN_shortcoming2.png)\n\n![SiamRPN_shortcoming1](Siamese系列\\SiamRPN_shortcoming1.png)\n\n* 总结来说就是样本不均衡：\n\t* 正样本种类不够多：添加检测图片数据集，进行数据增益（图片的变换）。增强分辨能力与回归准确性，增强泛化能力\n\t* 负样本简单（无语义）、同类：从同类别、不同类别中增加负样本对，使得框选更准，减轻漂移\n\t* 这就是说，训练过程中不再让模板 (Template) 和搜索区域 (Search Region) 是相同目标；是让网络学习判别能力，去搜索区域里找模版更相似的物体，而不是一个简单的有语义的物体。\n* 干扰模型，增量学习：17∗17∗5 proposals，选择与模板帧相似度大于某个阈值的错误实例作为干扰项，\n* long-term跟踪：丢失时增大搜索区域\n\n---\n\n<br/>\n\n## SiamRPN++\n\n Evolution of Siamese Visual Tracking with Very Deep Networks\n\nhttps://blog.csdn.net/baidu_36669549/article/details/85719585\n\nhttps://zhuanlan.zhihu.com/p/56254712\n\n**https://blog.csdn.net/zjc910997316/article/details/90749967?tdsourcetag=s_pctim_aiomsg**\n\n* 以往问题：\n\t* 浅层网络：Alexnet（无padding）\n\t* 精度差\n\t* 尝试深层网络ResNet效果不佳（有padding）\n\t* 核心原因：绝对平移不变形的破坏\n* 孪生的相关操作（A☆B）要求：\n\n\t* $f(z,x)=g(\\phi(z), \\phi(x))$，即f/g应满足以下\n\t* 要求1：绝对平移不变性 $f(z, x[\\Delta \\tau_j]) = f(z, x)[\\Delta \\tau_j]$ 平移移位子窗口操作器，检测帧的移动，结果也应移动。如果在图像中平移一个目标，那么proposal也会跟着平移，这时，同一个函数需要能够在任何位置都预测到这个proposal。\n\t* 要求2：基于correlation操作计算相似度的神经网络需要具备对称性。即：将模板图像和检测图像互换，计算出的两者之间的相似度应该是不变的。因为相似度计算本身就是一个对称操作。SiamRPN的监督在于回归的偏移量和分类的分数，而不再是相似度。而对这两个变量的计算都不是对称操作。因此会使神经网络丧失对称性。\n* 问题1：平移不变性之padding影响：边缘的patch会由于padding带来黑边，而靠近中心的patch则不会有。所以网络的预测本身是不满足全卷积性质的，也就是在边缘卷出来的和中心卷出来的内容是不一致的。这就可能导致训练过程中，网络倾向于通过padding的pattern来确定目标在哪，即padding少的位置接近中心，更可能是目标。因此如果一个神经网络使用了padding，且在用于训练的图像里，正样本（目标）都位于图像的中心，那么当该神经网络在检测图像上预测目标时，会由于训练样本中目标的分布特性，学习到对图像中心位置的预测偏好。不管目标移动到图像中的哪一处，网络都只会预测中心区域的位置。这也是利用ResNet加深网络后，跟踪性能不升反降的原因。SiamRPN++利用了padding会让网络学习到位置偏好这个特点，用正样本均匀分布在图像中各个位置的数据作为训练集，让网络对各个位置都学习到一定的偏好（相当于没有偏好），从而使网络的跟踪性能不会随着网络的加深而下降（若预测位置一直固定在一个地方，即相当于失去了跟踪能力）。\n* 解决1：采样的实现：训练的时候search region会移动，以前是以目标为中心crop 255的图片，现在是以目标周围的某个点为中心，让目标不再是search region的中心。这个只和训练有关，测试还是以上一帧目标位置为中心\n\n### 深度交叉相关\n\n* 问题2：由于在SiamRPN的回归分支和分类分支上，都对模板图像的feature map进行了channel升维，导致模板图像的feature map的channel维度分别是检测图像的feature map的channel维度的2k倍和4k倍，因此，来自模板图像和检测图像的特征维度不对称（参数量不等），即两组特征并不是从相同的特征提取器中提取出来的，所以若将模板图像和检测图像互换再进行相关操作，必然会输出不同的结果，即失去操作的对称性。这种非对称性会给网络的训练优化带来困难，不利于训练的稳定性和网络的整体性能。\n* 解决2：depthwise cross-correlation 深度交叉相关。\n\n\t* adj：模板图像和检测图像的feature map，在回归分支和分类分支中，都首先分别经过一个卷积神经层（由conv层和bn层构成），得到一样的空间分辨率和channel维度。该卷积神经层不同于SiamRPN中的卷积神经层，其不对feature map进行channel升维，只是对两组feature map都进行了finetune，使其维度对称。\n\t* DW：在经过卷积神经层之后，模板图像和检测图像的feature map进行depthwise的相关操作，即是逐个channel的两者的分量之间进行相关操作，输出和channel数相等数量的score map。\n\t* Head：最后，对于不同任务分支输出的相同分辨率和channel维度的score map，再分别使用不同的1*1卷积进行维度调整，以获得不同任务对应的不同维度的输出（分类任务对应channel维度为2k的输出，回归任务对应channel维度为4k的输出）。\n* 对于depthwise cross-correlation输出的和channel数相等个数的score map，各个score map分别代表在不同语义上的响应分布。\n\t* 而在进行了1*1卷积后，对于回归分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor各自的(x,y,w,h)；对于分类分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor里面各自的前后景分类分数。\n\n* 第一种交叉相关：SiamFC 模版特征在搜索区域上按照滑窗的方式获取不同位置的响应值，最终获得一个一维的响应映射图。\n\t* 第二种提升通道交叉相关：用于SiamRPN中，和Cross Correlation操作不同的是在做correlation操作之前多了两个卷积层，通道个数分别为256和256x2k，其中k表示每一个锚点上面的anchor个数。其中一个用来提升通道数，而另一个则保持不变。之后通过卷积的方式，得到最终的输出。通过控制升维的卷积来实现最终输出特征图的通道数。\n\t* 这里的改进主要源自于up channel的方法中，升维卷积参数量极大， 256x(256*2k)x3x3， 光分类分支就有接近6M的参数，回归分支12M。其次升维操作造成了两支参数量的极度不平衡，模版分支是搜索支参数量的 2k/4k 倍，造成了整个网络训练困难的问题。而改为Depthwise版本以后，参数量能够急剧下降；同时整体训练也更为稳定，整体性能也得到了加强。\n\n![](Siamese系列\\SiamRPN++_correlation.png)\n\n![SiamRPN++_RPN](Siamese系列\\SiamRPN++_RPN.png)\n\n\n","source":"_posts/Siamese系列.md","raw":"---\ntitle: Siamese系列\nmathjax: true\ndate: 2020-06-18 20:07:30\ntags: AI\n---\n\n\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n## Siamese\n\n* Siamese和Chinese有点像。Siam是古时候泰国的称呼，中文译作暹罗。Siamese也就是“暹罗”人或“泰国”人。十九世纪泰国出生了一对连体婴儿，当时的医学技术无法使两人分离出来，于是两人顽强地生活了一生，两人均于63岁离开人间。两人的肝至今仍保存在费城的[马特博物馆](https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E9%A9%AC%E7%89%B9%E5%8D%9A%E7%89%A9%E9%A6%86%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163)内。从此之后“[暹罗双胞胎](https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E6%9A%B9%E7%BD%97%E5%8F%8C%E8%83%9E%E8%83%8E%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163)”（Siamese twins）就成了连体人的代名词\n\n![Siamese twins](Siamese系列\\Siamese twins.jpg)\n\n<br/>\n\n## Siamese Network\n\n* 判断两个输入相似性，核心思想是，两个子体网络通过权重共享来实现连体，寻找一个映射函数，能够将输入图像转换到一个特征空间，每幅图像对应一个特征向量，通过一些简单的“距离度量”（比如欧式距离）来表示向量之间的差异，最后通过这个距离来拟合输入图像的相似度差异（语义差异）\n* 对比损失Contrastive Loss：\n\t*  $d=||a_n-b_n||_2$，代表两个样本特征的欧氏距离，\n\t*  d也可使用cosine距离，d=cos=x*y/|x||y|\n\t*  y为两个样本是否匹配的标签，y=1代表两个样本相似或者匹配，y=0则代表不匹配，\n\t*  margin为设定的阈值\n\t*  这种损失函数可以很好的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。当y=1（即样本相似）时，损失函数只剩下∑d2，即原本相似的样本，如果在特征空间的欧式距离较大，则说明当前的模型不好，因此加大损失。而当y=0时（即样本不相似）时，损失函数为∑max(margin−d,0)2，即当样本不相似时，其特征空间的欧式距离反而小的话（d小，margin-d大），损失值会变大，这也正好符合我们的要求。\n\t*  图3表示的就是损失函数值与样本特征的欧式距离之间的关系，其中红色虚线表示的是相似样本的损失值，蓝色实线表示的不相似样本的损失值。\n\n![Siamese Net](Siamese系列/Siamese Net.png)\n\n![Siamese Net_loss](Siamese系列/Siamese Net_loss.png)\n\n![Siamese Net_loss1](Siamese系列/Siamese Net_loss1.png)\n\n---\n\n<br/>\n\n## SiamFC\n\nhttps://blog.csdn.net/nightmare_dimple/article/details/74210147\n\n* 全卷积孪生网络 fully-convolutional siamese networks for object tracking\n* AlexNet\n* 以往：相关滤波之网络一层作为特征，深度学习之梯度下降，在线学习，存在问题；本法离线学习，tracking时只需进行相似性判断，计算量很小\n* 细节：在初始离线阶段把深度卷积网络看成一个更通用的**相似性学习**问题，然后在跟踪时对这个问题进行在线的简单估计。训练了一个孪生网络在一个较大的搜索区域搜索样本图片。本文另一个贡献在于，新的孪生网络结构是一个关于搜索区域的**全卷积网络**：密集高效的滑动窗口估计可通过计算两个输入的互相关性并插值得到。\n* 相似性学习：学习一个函数$f(x,z)$来比较样本图像（目标）z和搜索图像（画面）x的相似性\n* 用深度神经网络模拟$f$，深度卷积网络中**相似性学习最典型的就是孪生结构**。孪生网络对两个输入z和x进行相同的变换$\\varphi$，然后将得到的输出送入函数g，最后得到相似性度量函数为：*f*(*z*,*x*)=*g*(*φ*(*z*),*φ*(*x*))\n\t* 1.函数g是一个简单的距离或相似性度量\n\t* 2.φ相当于特征提取器\n* 全卷积网络的优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。\n\n![](Siamese系列/SiamFC_1.png)\n\n* 搜索图像的确定：跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图\n* 正负样本的确定：和目标距离不超过阈值\n* 在经过卷积神经层提取特征后，SiameseFC使用cross-correlation（交叉相关）作为相似度的度量，计算两个feature map各个位置（区域）上的相似度，得到一个score map（或者说heat map）。最后对这个score map进行插值（这里使用的是双三线性插值），获得和原图像一样的空间分辨率，根据该score map，即可定位到跟踪目标在新一帧（检测图像）中的精确位置。\n* **训练数据：**从视频的两个帧中提取图像，这两个帧都包含对象并且最多相隔T帧。训练时忽略目标的类别。在不破坏图像的纵横比的情况下对每个图像内的对象的比例进行归一化 。如果得分图中的元素距离中心半径在![R](https://math.jianshu.com/math?formula=R)（根据网络步长![k](https://math.jianshu.com/math?formula=k)决定）以内，就认为是正样本。\n\n![](Siamese系列\\SiamFC_training_pairs.png)\n\n* 余弦惩罚：在获得score map之后，SiameseFC会在上面应用一个余弦窗，以对那些不正常的较大位移进行惩罚（余弦窗具有边缘抑制的作用，如果目标是一个正常的位移，那么检测热点应该是在heatmap的中心区域附近，如果检测热点跑到heatmap的边缘，则说明目标发生了瞬时的长位移，这很大可能是由检测错误导致的，因此该检测结果需要被抑制和惩罚）。\n\n* 多尺度检测：通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。\n\n* 优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。\n\n* 本文的相似度函数使用互相关，公式如下*f*(*z*,*x*)=*φ*(*z*)∗*φ*(*x*)+*b*1\n\t* *b*1 表示在得分图中每个位置的取值\n\t* 上式可将φ(z)看成卷积核，在φ(x)上进行卷积\n\n* 跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图f，将得分最大的位置乘以步长即可得到当前目标的位置\n\n* phi：五层卷积，提取特征\n\n* 卷积：卷积以实现相似性度量\n\n![](Siamese系列/SiamFC_3.jpg) \n\n![SiamFC_2](Siamese系列/SiamFC_2.jpg) \n\n* 损失函数：每一个候选子窗口，其实相当于一个样本，而它的得分，输出的就是它是正/负样本的概率。使用逻辑回归来表示的话，这就是一个应用逻辑回归的典型二分类问题，对于得分矩阵中的每一个点u有：其中*v*是实际输出,*y*是真实标签{+1，-1}\n\n![SiamFC_loss](Siamese系列/SiamFC_loss.png)\n\n* 定位目标区域/tracking：相似性矩阵，经双三次插值，变为255²矩阵，定位。\n\n* 目标图像在线不更新，提取高层语义特征\n\n* 5尺度搜索 1.025（-2，-1,0,1,2）。尺度检测是扩大或缩小检测区域，但检测图像都要缩放到255*255*3，也就是说尺度检测是天然可以并行的，SiamFC通过设置mini-batch的方式实现，一次性完成3或5个尺度样本检测。多尺度检测通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。\n\n* long term与short term：SiameseFC在预测的时候，不在线更新模板图像。这使得SiameseFC的计算速度很快，但同时也要求SiameseFC中使用的特征需要具有足够的鲁棒性（通常是高层特征，分辨率较低，计算复杂度较大），以便在后续帧中能够应对各种变换。而在另一方面，不在线更新模板图像的策略，可以确保跟踪目标的不变性和纯净性，在long-term跟踪算法上具有天然的优势。\n\n\t还有一类visual tracker，在预测时，使用的是在线更新模板图像的策略。这种策略的优点是对特征的鲁棒性要求较低（通常是低层特征，分辨率较高，计算复杂度较小），能适时地学习到目标和背景的变化，但也带来了其他的缺点：在目标跟踪的过程中，如果中间跟丢或跟错了目标（由于遮挡或失败等原因，会导致学习到背景，而不是目标），就无法再恢复到正确的跟踪目标上了；而如果在目标跟踪的过程中，学习到了错误的特征（如来自外界的噪声），则会导致跟踪目标被污染，在后续帧中，跟踪能力降低，甚至逐渐丧失（跟踪目标的累积污染增加）。因此这种更新策略更多地用于short-term跟踪算法上。\n\n* 双三次差值 https://blog.csdn.net/datase/article/details/80576054\n\n---\n\n<br/>\n\n## RPN\n\nRegion Proposal Network 区域推荐网络\n\n* 本质是 “ 基于滑窗的无类别obejct检测器 ”\n\n* 用于目标检测。把一个任意尺度的图片作为输入，输出一系列的矩形object proposals，每个object proposals都带一个objectness score。分为两个支路，一个用于分类前景和背景，一个用于边界框回归。通俗来讲，就是用RPN来选择感兴趣区域的，即proposal extraction。例如，如果一个区域的p>0.5，则认为这个区域中可能是我们想要的类别中的某一类，具体是哪一类现在还不清楚。到此为止，网络只需要把这些可能含有物体的区域选取出来就可以了，这些被选取出来的区域又叫做ROI （Region of Interests），即感兴趣的区域。当然了，RPN同时也会在feature map上框定这些ROI感兴趣区域的大致位置，即输出Bounding Box。\n* 一种更加简单的方法来预测 objects 的边界框，即，学习相对于**参考GT的偏移量**\n\n* anchor的一种理解（anchor的特征图与原始图像的联系）：应该是特征图的某一个像素与对应在原始图像的某一个像素，即**本质上指的是特征图上当前滑窗的中心在原像素空间的映射点称为anchor**，即anchor是在原始图像上的\n* 在特征的每个位置，考虑多个可能的候选窗口：窗口数=面积数×比例数，称为anchors。下图中3种面积×3种比例，每个位置9个anchors\n\n![anchors](Siamese系列\\anchors.jpg)\n\n* 计算每个像素（256-d）的k个尺度下的值，得到k个anchor，我们给每个anchor分配一个二进制的标签（前景背景），由其与GT重叠度决定。则标记后输出2×k纬度，表示每个位置有2k个cls（classification）分数；同时每个anchor又与GT对应四个偏移量[x, y, w, h]，代表中心点的坐标、框的宽高，则回归组reg（regression）为4k纬度\n* anchor会很多，选取部分正、负anchor训练\n\n---\n\n<br/>\n\n## SiamRPN\n\nhttps://blog.csdn.net/fzp95/article/details/80982201\n\nhttps://www.jianshu.com/p/a3786b61031c\n\nhttps://blog.csdn.net/leviopku/article/details/81068487\n\nhttps://blog.csdn.net/leviopku/article/details/80875368\n\n* 孪生候选区域生成网络 High Performance Visual Tracking with Siamese Region Proposal Network\n* Siamese部分基于预训练的AlexNet\n* SiamFC缺点：只能得到目标的中心位置，但是得不到目标的尺寸，所以只能采取简单的多尺度加回归，这即增加了计算量，同时也不够精确。\n* 改进：输出两个分支，分别用于分类和回归（SiamFC没有回归，而是用多尺度测试，增加了计算量且不够精确），帧率160fps（不需要在线微调）\n* 摘要：这个结构包含用于特征提取的孪生子网络（Siamese subnetwork）和候选区域生成网络（region proposal subnetwork），其中候选区域生成网络包含分类和回归两条支路。在跟踪阶段，作者提出的方法被构造成为单样本检测任务（one-shot detection task）。作者预先计算孪生子网络中的模板支路，也就是第一帧，并且将它构造成一个检测支路中区域提取网络里面的一个卷积层，用于在线跟踪。传统的多尺度测试和在线微调可以被舍弃，这样做也大大提高了速度。\n* 此方法不更新模型，是离线训练好的基于深度学习跟踪器，在相关特征图谱上提取候选区域，然后作者将模板分支上的目标外观信息编码到RPN特征中来判别前景和背景。在跟踪阶段，作者将此任务视为单目标检测任务（one-shot detection），什么意思呢，就是把第一帧的BB视为检测的样例，在其余帧里面检测与它相似的目标。\n* anchor box：具有不同规格（大小，长宽比，本文有一种大小，五种长宽比[0.33,0.5,1,2,3]），锚点由卷积过程中卷积核中心确定，每个锚点对应数个锚点框（不同规格）。则检测问题由“哪里有物体”变为“锚点框是否框住物体，框住多少，离得多远”。\n* 如下图：RPN网络主要用于生成region proposals，首先生成一堆Anchor box，对其进行裁剪过滤后通过softmax判断anchors属于前景(foreground)或者后景(background)，即是物体or不是物体，所以这是一个二分类；同时，另一分支bounding box regression修正anchor box，形成较精确的proposal\n\n![RPN](Siamese系列/RPN.jpg)\n\n* 分类组：在RPN的分类分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的2k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为2k份，作为2k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为2k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为2的score map，两个维度分别对应anchor中前景（目标）和后景（背景）的分类分数，是关于目标的置信度。\n* 回归组： 在RPN的回归分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的4k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为4k份，作为4k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为4k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为4的score map，四个维度分别对应anchor的（x,y,w,h），是关于目标的坐标及尺寸。\n* RPN的引入，使得Siamese网络自然拥有了多尺度检测的能力（通过anchor机制cover各种size），并且可以准确地回归出目标的位置及大小\n* k：anchor box 锚点框数量；\n\t* 本文为5，不同长宽比[0.33, 0.5, 1, 2, 3]\n\t* 模板帧：因要分为目标、背景两类，故2k\n\t* 检测帧：[x, y, w, h]，故4k\n\n![](Siamese系列/SiamRPN_net.png)\n\n* 不同于SiamFC，可对多个多个anchor box判断。\n* RPN部分卷积：3×3进一步集中特征，然后多个/一个1×1提高通道数\n* 分类组：每个点表示正负得分，softmax分类（anchor box和真实目标重叠且IOU大于阈值）\n* 回归组：每个点表示anchor和ground truth之间的dx,dy,dw,dh（anchor相比于groundtruth的偏移量），通过smooth L1 loss:\n\n![smooth loss](Siamese系列\\smooth loss.png)\n\n* tracking as one shot detection：对于一个类别，如果只提供一个或者少量训练样本的情况下，如何检测？解决方法就是：让模型学习，得到一个相似性函数，这样的模型输出的值不是类别，而是两幅图像的相似度。\n* 始终用第一帧当做模板帧，只需进行detection分支，提速。从分类组的奇数层（目标）中，选取最大的K的建议候选框，**后经距离、余弦窗和尺度变化惩罚因子对proposal进行取舍和重新排序，NMS**得到最佳位置。\n* 若无回归组，则与FC类似，得分图的叠加。\n\n![SiamRPN_tracking](Siamese系列\\SiamRPN_tracking.png)\n\n---\n\n<br/>\n\n## DaSiamRPN\n\nDistractor-aware Siamese Networks for Visual Object Tracking 添加干扰的\n\nhttps://zhuanlan.zhihu.com/p/42546692\n\nhttps://blog.csdn.net/fzp95/article/details/82380261\n\n* SiamRPN的缺点：\n\t* 响应分数不可靠：跟丢后分类得分仍很高，推测为SiamRPN只能学到（有语义的）物体与非物体的区分，或者理解为区分前景背景，而非学习一个实例级别的表示方法。导致背景有其他物体时易被干扰（csdn提问、feature map）\n\t* 跟踪阶段不更新模型，精度换速度\n\t* 长时间跟踪中，遮挡、消失效果差\n\n![SiamRPN_shortcoming2](Siamese系列\\SiamRPN_shortcoming2.png)\n\n![SiamRPN_shortcoming1](Siamese系列\\SiamRPN_shortcoming1.png)\n\n* 总结来说就是样本不均衡：\n\t* 正样本种类不够多：添加检测图片数据集，进行数据增益（图片的变换）。增强分辨能力与回归准确性，增强泛化能力\n\t* 负样本简单（无语义）、同类：从同类别、不同类别中增加负样本对，使得框选更准，减轻漂移\n\t* 这就是说，训练过程中不再让模板 (Template) 和搜索区域 (Search Region) 是相同目标；是让网络学习判别能力，去搜索区域里找模版更相似的物体，而不是一个简单的有语义的物体。\n* 干扰模型，增量学习：17∗17∗5 proposals，选择与模板帧相似度大于某个阈值的错误实例作为干扰项，\n* long-term跟踪：丢失时增大搜索区域\n\n---\n\n<br/>\n\n## SiamRPN++\n\n Evolution of Siamese Visual Tracking with Very Deep Networks\n\nhttps://blog.csdn.net/baidu_36669549/article/details/85719585\n\nhttps://zhuanlan.zhihu.com/p/56254712\n\n**https://blog.csdn.net/zjc910997316/article/details/90749967?tdsourcetag=s_pctim_aiomsg**\n\n* 以往问题：\n\t* 浅层网络：Alexnet（无padding）\n\t* 精度差\n\t* 尝试深层网络ResNet效果不佳（有padding）\n\t* 核心原因：绝对平移不变形的破坏\n* 孪生的相关操作（A☆B）要求：\n\n\t* $f(z,x)=g(\\phi(z), \\phi(x))$，即f/g应满足以下\n\t* 要求1：绝对平移不变性 $f(z, x[\\Delta \\tau_j]) = f(z, x)[\\Delta \\tau_j]$ 平移移位子窗口操作器，检测帧的移动，结果也应移动。如果在图像中平移一个目标，那么proposal也会跟着平移，这时，同一个函数需要能够在任何位置都预测到这个proposal。\n\t* 要求2：基于correlation操作计算相似度的神经网络需要具备对称性。即：将模板图像和检测图像互换，计算出的两者之间的相似度应该是不变的。因为相似度计算本身就是一个对称操作。SiamRPN的监督在于回归的偏移量和分类的分数，而不再是相似度。而对这两个变量的计算都不是对称操作。因此会使神经网络丧失对称性。\n* 问题1：平移不变性之padding影响：边缘的patch会由于padding带来黑边，而靠近中心的patch则不会有。所以网络的预测本身是不满足全卷积性质的，也就是在边缘卷出来的和中心卷出来的内容是不一致的。这就可能导致训练过程中，网络倾向于通过padding的pattern来确定目标在哪，即padding少的位置接近中心，更可能是目标。因此如果一个神经网络使用了padding，且在用于训练的图像里，正样本（目标）都位于图像的中心，那么当该神经网络在检测图像上预测目标时，会由于训练样本中目标的分布特性，学习到对图像中心位置的预测偏好。不管目标移动到图像中的哪一处，网络都只会预测中心区域的位置。这也是利用ResNet加深网络后，跟踪性能不升反降的原因。SiamRPN++利用了padding会让网络学习到位置偏好这个特点，用正样本均匀分布在图像中各个位置的数据作为训练集，让网络对各个位置都学习到一定的偏好（相当于没有偏好），从而使网络的跟踪性能不会随着网络的加深而下降（若预测位置一直固定在一个地方，即相当于失去了跟踪能力）。\n* 解决1：采样的实现：训练的时候search region会移动，以前是以目标为中心crop 255的图片，现在是以目标周围的某个点为中心，让目标不再是search region的中心。这个只和训练有关，测试还是以上一帧目标位置为中心\n\n### 深度交叉相关\n\n* 问题2：由于在SiamRPN的回归分支和分类分支上，都对模板图像的feature map进行了channel升维，导致模板图像的feature map的channel维度分别是检测图像的feature map的channel维度的2k倍和4k倍，因此，来自模板图像和检测图像的特征维度不对称（参数量不等），即两组特征并不是从相同的特征提取器中提取出来的，所以若将模板图像和检测图像互换再进行相关操作，必然会输出不同的结果，即失去操作的对称性。这种非对称性会给网络的训练优化带来困难，不利于训练的稳定性和网络的整体性能。\n* 解决2：depthwise cross-correlation 深度交叉相关。\n\n\t* adj：模板图像和检测图像的feature map，在回归分支和分类分支中，都首先分别经过一个卷积神经层（由conv层和bn层构成），得到一样的空间分辨率和channel维度。该卷积神经层不同于SiamRPN中的卷积神经层，其不对feature map进行channel升维，只是对两组feature map都进行了finetune，使其维度对称。\n\t* DW：在经过卷积神经层之后，模板图像和检测图像的feature map进行depthwise的相关操作，即是逐个channel的两者的分量之间进行相关操作，输出和channel数相等数量的score map。\n\t* Head：最后，对于不同任务分支输出的相同分辨率和channel维度的score map，再分别使用不同的1*1卷积进行维度调整，以获得不同任务对应的不同维度的输出（分类任务对应channel维度为2k的输出，回归任务对应channel维度为4k的输出）。\n* 对于depthwise cross-correlation输出的和channel数相等个数的score map，各个score map分别代表在不同语义上的响应分布。\n\t* 而在进行了1*1卷积后，对于回归分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor各自的(x,y,w,h)；对于分类分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor里面各自的前后景分类分数。\n\n* 第一种交叉相关：SiamFC 模版特征在搜索区域上按照滑窗的方式获取不同位置的响应值，最终获得一个一维的响应映射图。\n\t* 第二种提升通道交叉相关：用于SiamRPN中，和Cross Correlation操作不同的是在做correlation操作之前多了两个卷积层，通道个数分别为256和256x2k，其中k表示每一个锚点上面的anchor个数。其中一个用来提升通道数，而另一个则保持不变。之后通过卷积的方式，得到最终的输出。通过控制升维的卷积来实现最终输出特征图的通道数。\n\t* 这里的改进主要源自于up channel的方法中，升维卷积参数量极大， 256x(256*2k)x3x3， 光分类分支就有接近6M的参数，回归分支12M。其次升维操作造成了两支参数量的极度不平衡，模版分支是搜索支参数量的 2k/4k 倍，造成了整个网络训练困难的问题。而改为Depthwise版本以后，参数量能够急剧下降；同时整体训练也更为稳定，整体性能也得到了加强。\n\n![](Siamese系列\\SiamRPN++_correlation.png)\n\n![SiamRPN++_RPN](Siamese系列\\SiamRPN++_RPN.png)\n\n\n","slug":"Siamese系列","published":1,"updated":"2020-06-18T12:10:38.468Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbew3000ji0qv4m0rbgd8","content":"<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#siamese\">Siamese</a></li>\n<li><a href=\"#siamese-network\">Siamese Network</a></li>\n<li><a href=\"#siamfc\">SiamFC</a></li>\n<li><a href=\"#rpn\">RPN</a></li>\n<li><a href=\"#siamrpn\">SiamRPN</a></li>\n<li><a href=\"#dasiamrpn\">DaSiamRPN</a></li>\n<li><a href=\"#siamrpn\">SiamRPN++</a>\n<ul>\n<li><a href=\"#%E6%B7%B1%E5%BA%A6%E4%BA%A4%E5%8F%89%E7%9B%B8%E5%85%B3\">深度交叉相关</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h2><span id=\"siamese\"> Siamese</span></h2>\n<ul>\n<li>Siamese和Chinese有点像。Siam是古时候泰国的称呼，中文译作暹罗。Siamese也就是“暹罗”人或“泰国”人。十九世纪泰国出生了一对连体婴儿，当时的医学技术无法使两人分离出来，于是两人顽强地生活了一生，两人均于63岁离开人间。两人的肝至今仍保存在费城的<a href=\"https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E9%A9%AC%E7%89%B9%E5%8D%9A%E7%89%A9%E9%A6%86%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163\" target=\"_blank\" rel=\"noopener\">马特博物馆</a>内。从此之后“<a href=\"https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E6%9A%B9%E7%BD%97%E5%8F%8C%E8%83%9E%E8%83%8E%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163\" target=\"_blank\" rel=\"noopener\">暹罗双胞胎</a>”（Siamese twins）就成了连体人的代名词</li>\n</ul>\n<p>![Siamese twins](Siamese系列\\Siamese twins.jpg)</p>\n<br>\n<h2><span id=\"siamese-network\"> Siamese Network</span></h2>\n<ul>\n<li>判断两个输入相似性，核心思想是，两个子体网络通过权重共享来实现连体，寻找一个映射函数，能够将输入图像转换到一个特征空间，每幅图像对应一个特征向量，通过一些简单的“距离度量”（比如欧式距离）来表示向量之间的差异，最后通过这个距离来拟合输入图像的相似度差异（语义差异）</li>\n<li>对比损失Contrastive Loss：\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mo>=</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mi>n</mi></msub><mo>−</mo><msub><mi>b</mi><mi>n</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">d=||a_n-b_n||_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，代表两个样本特征的欧氏距离，</li>\n<li>d也可使用cosine距离，d=cos=x*y/|x||y|</li>\n<li>y为两个样本是否匹配的标签，y=1代表两个样本相似或者匹配，y=0则代表不匹配，</li>\n<li>margin为设定的阈值</li>\n<li>这种损失函数可以很好的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。当y=1（即样本相似）时，损失函数只剩下∑d2，即原本相似的样本，如果在特征空间的欧式距离较大，则说明当前的模型不好，因此加大损失。而当y=0时（即样本不相似）时，损失函数为∑max(margin−d,0)2，即当样本不相似时，其特征空间的欧式距离反而小的话（d小，margin-d大），损失值会变大，这也正好符合我们的要求。</li>\n<li>图3表示的就是损失函数值与样本特征的欧式距离之间的关系，其中红色虚线表示的是相似样本的损失值，蓝色实线表示的不相似样本的损失值。</li>\n</ul>\n</li>\n</ul>\n<p>![Siamese Net](Siamese系列/Siamese Net.png)</p>\n<p>![Siamese Net_loss](Siamese系列/Siamese Net_loss.png)</p>\n<p>![Siamese Net_loss1](Siamese系列/Siamese Net_loss1.png)</p>\n<hr>\n<br>\n<h2><span id=\"siamfc\"> SiamFC</span></h2>\n<p><a href=\"https://blog.csdn.net/nightmare_dimple/article/details/74210147\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/nightmare_dimple/article/details/74210147</a></p>\n<ul>\n<li>全卷积孪生网络 fully-convolutional siamese networks for object tracking</li>\n<li>AlexNet</li>\n<li>以往：相关滤波之网络一层作为特征，深度学习之梯度下降，在线学习，存在问题；本法离线学习，tracking时只需进行相似性判断，计算量很小</li>\n<li>细节：在初始离线阶段把深度卷积网络看成一个更通用的<strong>相似性学习</strong>问题，然后在跟踪时对这个问题进行在线的简单估计。训练了一个孪生网络在一个较大的搜索区域搜索样本图片。本文另一个贡献在于，新的孪生网络结构是一个关于搜索区域的<strong>全卷积网络</strong>：密集高效的滑动窗口估计可通过计算两个输入的互相关性并插值得到。</li>\n<li>相似性学习：学习一个函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x,z)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span>来比较样本图像（目标）z和搜索图像（画面）x的相似性</li>\n<li>用深度神经网络模拟<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span>，深度卷积网络中<strong>相似性学习最典型的就是孪生结构</strong>。孪生网络对两个输入z和x进行相同的变换<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>φ</mi></mrow><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">φ</span></span></span></span>，然后将得到的输出送入函数g，最后得到相似性度量函数为：<em>f</em>(<em>z</em>,<em>x</em>)=<em>g</em>(<em>φ</em>(<em>z</em>),<em>φ</em>(<em>x</em>))\n<ul>\n<li>1.函数g是一个简单的距离或相似性度量</li>\n<li>2.φ相当于特征提取器</li>\n</ul>\n</li>\n<li>全卷积网络的优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_1.png\" alt></p>\n<ul>\n<li>搜索图像的确定：跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图</li>\n<li>正负样本的确定：和目标距离不超过阈值</li>\n<li>在经过卷积神经层提取特征后，SiameseFC使用cross-correlation（交叉相关）作为相似度的度量，计算两个feature map各个位置（区域）上的相似度，得到一个score map（或者说heat map）。最后对这个score map进行插值（这里使用的是双三线性插值），获得和原图像一样的空间分辨率，根据该score map，即可定位到跟踪目标在新一帧（检测图像）中的精确位置。</li>\n<li>**训练数据：**从视频的两个帧中提取图像，这两个帧都包含对象并且最多相隔T帧。训练时忽略目标的类别。在不破坏图像的纵横比的情况下对每个图像内的对象的比例进行归一化 。如果得分图中的元素距离中心半径在<img src=\"https://math.jianshu.com/math?formula=R\" alt=\"R\">（根据网络步长<img src=\"https://math.jianshu.com/math?formula=k\" alt=\"k\">决定）以内，就认为是正样本。</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamFC_training_pairs.png\" alt></p>\n<ul>\n<li>\n<p>余弦惩罚：在获得score map之后，SiameseFC会在上面应用一个余弦窗，以对那些不正常的较大位移进行惩罚（余弦窗具有边缘抑制的作用，如果目标是一个正常的位移，那么检测热点应该是在heatmap的中心区域附近，如果检测热点跑到heatmap的边缘，则说明目标发生了瞬时的长位移，这很大可能是由检测错误导致的，因此该检测结果需要被抑制和惩罚）。</p>\n</li>\n<li>\n<p>多尺度检测：通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。</p>\n</li>\n<li>\n<p>优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。</p>\n</li>\n<li>\n<p>本文的相似度函数使用互相关，公式如下<em>f</em>(<em>z</em>,<em>x</em>)=<em>φ</em>(<em>z</em>)∗<em>φ</em>(<em>x</em>)+<em>b</em>1</p>\n<ul>\n<li><em>b</em>1 表示在得分图中每个位置的取值</li>\n<li>上式可将φ(z)看成卷积核，在φ(x)上进行卷积</li>\n</ul>\n</li>\n<li>\n<p>跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图f，将得分最大的位置乘以步长即可得到当前目标的位置</p>\n</li>\n<li>\n<p>phi：五层卷积，提取特征</p>\n</li>\n<li>\n<p>卷积：卷积以实现相似性度量</p>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_3.jpg\" alt></p>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_2.jpg\" alt=\"SiamFC_2\"></p>\n<ul>\n<li>损失函数：每一个候选子窗口，其实相当于一个样本，而它的得分，输出的就是它是正/负样本的概率。使用逻辑回归来表示的话，这就是一个应用逻辑回归的典型二分类问题，对于得分矩阵中的每一个点u有：其中<em>v</em>是实际输出,<em>y</em>是真实标签{+1，-1}</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_loss.png\" alt=\"SiamFC_loss\"></p>\n<ul>\n<li>\n<p>定位目标区域/tracking：相似性矩阵，经双三次插值，变为255²矩阵，定位。</p>\n</li>\n<li>\n<p>目标图像在线不更新，提取高层语义特征</p>\n</li>\n<li>\n<p>5尺度搜索 1.025（-2，-1,0,1,2）。尺度检测是扩大或缩小检测区域，但检测图像都要缩放到255<em>255</em>3，也就是说尺度检测是天然可以并行的，SiamFC通过设置mini-batch的方式实现，一次性完成3或5个尺度样本检测。多尺度检测通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。</p>\n</li>\n<li>\n<p>long term与short term：SiameseFC在预测的时候，不在线更新模板图像。这使得SiameseFC的计算速度很快，但同时也要求SiameseFC中使用的特征需要具有足够的鲁棒性（通常是高层特征，分辨率较低，计算复杂度较大），以便在后续帧中能够应对各种变换。而在另一方面，不在线更新模板图像的策略，可以确保跟踪目标的不变性和纯净性，在long-term跟踪算法上具有天然的优势。</p>\n<p>还有一类visual tracker，在预测时，使用的是在线更新模板图像的策略。这种策略的优点是对特征的鲁棒性要求较低（通常是低层特征，分辨率较高，计算复杂度较小），能适时地学习到目标和背景的变化，但也带来了其他的缺点：在目标跟踪的过程中，如果中间跟丢或跟错了目标（由于遮挡或失败等原因，会导致学习到背景，而不是目标），就无法再恢复到正确的跟踪目标上了；而如果在目标跟踪的过程中，学习到了错误的特征（如来自外界的噪声），则会导致跟踪目标被污染，在后续帧中，跟踪能力降低，甚至逐渐丧失（跟踪目标的累积污染增加）。因此这种更新策略更多地用于short-term跟踪算法上。</p>\n</li>\n<li>\n<p>双三次差值 <a href=\"https://blog.csdn.net/datase/article/details/80576054\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/datase/article/details/80576054</a></p>\n</li>\n</ul>\n<hr>\n<br>\n<h2><span id=\"rpn\"> RPN</span></h2>\n<p>Region Proposal Network 区域推荐网络</p>\n<ul>\n<li>\n<p>本质是 “ 基于滑窗的无类别obejct检测器 ”</p>\n</li>\n<li>\n<p>用于目标检测。把一个任意尺度的图片作为输入，输出一系列的矩形object proposals，每个object proposals都带一个objectness score。分为两个支路，一个用于分类前景和背景，一个用于边界框回归。通俗来讲，就是用RPN来选择感兴趣区域的，即proposal extraction。例如，如果一个区域的p&gt;0.5，则认为这个区域中可能是我们想要的类别中的某一类，具体是哪一类现在还不清楚。到此为止，网络只需要把这些可能含有物体的区域选取出来就可以了，这些被选取出来的区域又叫做ROI （Region of Interests），即感兴趣的区域。当然了，RPN同时也会在feature map上框定这些ROI感兴趣区域的大致位置，即输出Bounding Box。</p>\n</li>\n<li>\n<p>一种更加简单的方法来预测 objects 的边界框，即，学习相对于<strong>参考GT的偏移量</strong></p>\n</li>\n<li>\n<p>anchor的一种理解（anchor的特征图与原始图像的联系）：应该是特征图的某一个像素与对应在原始图像的某一个像素，即<strong>本质上指的是特征图上当前滑窗的中心在原像素空间的映射点称为anchor</strong>，即anchor是在原始图像上的</p>\n</li>\n<li>\n<p>在特征的每个位置，考虑多个可能的候选窗口：窗口数=面积数×比例数，称为anchors。下图中3种面积×3种比例，每个位置9个anchors</p>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5Canchors.jpg\" alt=\"anchors\"></p>\n<ul>\n<li>计算每个像素（256-d）的k个尺度下的值，得到k个anchor，我们给每个anchor分配一个二进制的标签（前景背景），由其与GT重叠度决定。则标记后输出2×k纬度，表示每个位置有2k个cls（classification）分数；同时每个anchor又与GT对应四个偏移量[x, y, w, h]，代表中心点的坐标、框的宽高，则回归组reg（regression）为4k纬度</li>\n<li>anchor会很多，选取部分正、负anchor训练</li>\n</ul>\n<hr>\n<br>\n<h2><span id=\"siamrpn\"> SiamRPN</span></h2>\n<p><a href=\"https://blog.csdn.net/fzp95/article/details/80982201\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fzp95/article/details/80982201</a></p>\n<p><a href=\"https://www.jianshu.com/p/a3786b61031c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a3786b61031c</a></p>\n<p><a href=\"https://blog.csdn.net/leviopku/article/details/81068487\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leviopku/article/details/81068487</a></p>\n<p><a href=\"https://blog.csdn.net/leviopku/article/details/80875368\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leviopku/article/details/80875368</a></p>\n<ul>\n<li>孪生候选区域生成网络 High Performance Visual Tracking with Siamese Region Proposal Network</li>\n<li>Siamese部分基于预训练的AlexNet</li>\n<li>SiamFC缺点：只能得到目标的中心位置，但是得不到目标的尺寸，所以只能采取简单的多尺度加回归，这即增加了计算量，同时也不够精确。</li>\n<li>改进：输出两个分支，分别用于分类和回归（SiamFC没有回归，而是用多尺度测试，增加了计算量且不够精确），帧率160fps（不需要在线微调）</li>\n<li>摘要：这个结构包含用于特征提取的孪生子网络（Siamese subnetwork）和候选区域生成网络（region proposal subnetwork），其中候选区域生成网络包含分类和回归两条支路。在跟踪阶段，作者提出的方法被构造成为单样本检测任务（one-shot detection task）。作者预先计算孪生子网络中的模板支路，也就是第一帧，并且将它构造成一个检测支路中区域提取网络里面的一个卷积层，用于在线跟踪。传统的多尺度测试和在线微调可以被舍弃，这样做也大大提高了速度。</li>\n<li>此方法不更新模型，是离线训练好的基于深度学习跟踪器，在相关特征图谱上提取候选区域，然后作者将模板分支上的目标外观信息编码到RPN特征中来判别前景和背景。在跟踪阶段，作者将此任务视为单目标检测任务（one-shot detection），什么意思呢，就是把第一帧的BB视为检测的样例，在其余帧里面检测与它相似的目标。</li>\n<li>anchor box：具有不同规格（大小，长宽比，本文有一种大小，五种长宽比[0.33,0.5,1,2,3]），锚点由卷积过程中卷积核中心确定，每个锚点对应数个锚点框（不同规格）。则检测问题由“哪里有物体”变为“锚点框是否框住物体，框住多少，离得多远”。</li>\n<li>如下图：RPN网络主要用于生成region proposals，首先生成一堆Anchor box，对其进行裁剪过滤后通过softmax判断anchors属于前景(foreground)或者后景(background)，即是物体or不是物体，所以这是一个二分类；同时，另一分支bounding box regression修正anchor box，形成较精确的proposal</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/RPN.jpg\" alt=\"RPN\"></p>\n<ul>\n<li>分类组：在RPN的分类分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的2k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为2k份，作为2k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为2k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为2的score map，两个维度分别对应anchor中前景（目标）和后景（背景）的分类分数，是关于目标的置信度。</li>\n<li>回归组： 在RPN的回归分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的4k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为4k份，作为4k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为4k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为4的score map，四个维度分别对应anchor的（x,y,w,h），是关于目标的坐标及尺寸。</li>\n<li>RPN的引入，使得Siamese网络自然拥有了多尺度检测的能力（通过anchor机制cover各种size），并且可以准确地回归出目标的位置及大小</li>\n<li>k：anchor box 锚点框数量；\n<ul>\n<li>本文为5，不同长宽比[0.33, 0.5, 1, 2, 3]</li>\n<li>模板帧：因要分为目标、背景两类，故2k</li>\n<li>检测帧：[x, y, w, h]，故4k</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamRPN_net.png\" alt></p>\n<ul>\n<li>不同于SiamFC，可对多个多个anchor box判断。</li>\n<li>RPN部分卷积：3×3进一步集中特征，然后多个/一个1×1提高通道数</li>\n<li>分类组：每个点表示正负得分，softmax分类（anchor box和真实目标重叠且IOU大于阈值）</li>\n<li>回归组：每个点表示anchor和ground truth之间的dx,dy,dw,dh（anchor相比于groundtruth的偏移量），通过smooth L1 loss:</li>\n</ul>\n<p>![smooth loss](Siamese系列\\smooth loss.png)</p>\n<ul>\n<li>tracking as one shot detection：对于一个类别，如果只提供一个或者少量训练样本的情况下，如何检测？解决方法就是：让模型学习，得到一个相似性函数，这样的模型输出的值不是类别，而是两幅图像的相似度。</li>\n<li>始终用第一帧当做模板帧，只需进行detection分支，提速。从分类组的奇数层（目标）中，选取最大的K的建议候选框，<strong>后经距离、余弦窗和尺度变化惩罚因子对proposal进行取舍和重新排序，NMS</strong>得到最佳位置。</li>\n<li>若无回归组，则与FC类似，得分图的叠加。</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN_tracking.png\" alt=\"SiamRPN_tracking\"></p>\n<hr>\n<br>\n<h2><span id=\"dasiamrpn\"> DaSiamRPN</span></h2>\n<p>Distractor-aware Siamese Networks for Visual Object Tracking 添加干扰的</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/42546692\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/42546692</a></p>\n<p><a href=\"https://blog.csdn.net/fzp95/article/details/82380261\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fzp95/article/details/82380261</a></p>\n<ul>\n<li>SiamRPN的缺点：\n<ul>\n<li>响应分数不可靠：跟丢后分类得分仍很高，推测为SiamRPN只能学到（有语义的）物体与非物体的区分，或者理解为区分前景背景，而非学习一个实例级别的表示方法。导致背景有其他物体时易被干扰（csdn提问、feature map）</li>\n<li>跟踪阶段不更新模型，精度换速度</li>\n<li>长时间跟踪中，遮挡、消失效果差</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN_shortcoming2.png\" alt=\"SiamRPN_shortcoming2\"></p>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN_shortcoming1.png\" alt=\"SiamRPN_shortcoming1\"></p>\n<ul>\n<li>总结来说就是样本不均衡：\n<ul>\n<li>正样本种类不够多：添加检测图片数据集，进行数据增益（图片的变换）。增强分辨能力与回归准确性，增强泛化能力</li>\n<li>负样本简单（无语义）、同类：从同类别、不同类别中增加负样本对，使得框选更准，减轻漂移</li>\n<li>这就是说，训练过程中不再让模板 (Template) 和搜索区域 (Search Region) 是相同目标；是让网络学习判别能力，去搜索区域里找模版更相似的物体，而不是一个简单的有语义的物体。</li>\n</ul>\n</li>\n<li>干扰模型，增量学习：17∗17∗5 proposals，选择与模板帧相似度大于某个阈值的错误实例作为干扰项，</li>\n<li>long-term跟踪：丢失时增大搜索区域</li>\n</ul>\n<hr>\n<br>\n<h2><span id=\"siamrpn\"> SiamRPN++</span></h2>\n<p>Evolution of Siamese Visual Tracking with Very Deep Networks</p>\n<p><a href=\"https://blog.csdn.net/baidu_36669549/article/details/85719585\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baidu_36669549/article/details/85719585</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/56254712\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/56254712</a></p>\n<p><strong><a href=\"https://blog.csdn.net/zjc910997316/article/details/90749967?tdsourcetag=s_pctim_aiomsg\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zjc910997316/article/details/90749967?tdsourcetag=s_pctim_aiomsg</a></strong></p>\n<ul>\n<li>\n<p>以往问题：</p>\n<ul>\n<li>浅层网络：Alexnet（无padding）</li>\n<li>精度差</li>\n<li>尝试深层网络ResNet效果不佳（有padding）</li>\n<li>核心原因：绝对平移不变形的破坏</li>\n</ul>\n</li>\n<li>\n<p>孪生的相关操作（A☆B）要求：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(z,x)=g(\\phi(z), \\phi(x))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span>，即f/g应满足以下</li>\n<li>要求1：绝对平移不变性 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">[</mo><mi mathvariant=\"normal\">Δ</mi><msub><mi>τ</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">[</mo><mi mathvariant=\"normal\">Δ</mi><msub><mi>τ</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">f(z, x[\\Delta \\tau_j]) = f(z, x)[\\Delta \\tau_j]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">[</span><span class=\"mord\">Δ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.1132em;\">τ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mopen\">[</span><span class=\"mord\">Δ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.1132em;\">τ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span> 平移移位子窗口操作器，检测帧的移动，结果也应移动。如果在图像中平移一个目标，那么proposal也会跟着平移，这时，同一个函数需要能够在任何位置都预测到这个proposal。</li>\n<li>要求2：基于correlation操作计算相似度的神经网络需要具备对称性。即：将模板图像和检测图像互换，计算出的两者之间的相似度应该是不变的。因为相似度计算本身就是一个对称操作。SiamRPN的监督在于回归的偏移量和分类的分数，而不再是相似度。而对这两个变量的计算都不是对称操作。因此会使神经网络丧失对称性。</li>\n</ul>\n</li>\n<li>\n<p>问题1：平移不变性之padding影响：边缘的patch会由于padding带来黑边，而靠近中心的patch则不会有。所以网络的预测本身是不满足全卷积性质的，也就是在边缘卷出来的和中心卷出来的内容是不一致的。这就可能导致训练过程中，网络倾向于通过padding的pattern来确定目标在哪，即padding少的位置接近中心，更可能是目标。因此如果一个神经网络使用了padding，且在用于训练的图像里，正样本（目标）都位于图像的中心，那么当该神经网络在检测图像上预测目标时，会由于训练样本中目标的分布特性，学习到对图像中心位置的预测偏好。不管目标移动到图像中的哪一处，网络都只会预测中心区域的位置。这也是利用ResNet加深网络后，跟踪性能不升反降的原因。SiamRPN++利用了padding会让网络学习到位置偏好这个特点，用正样本均匀分布在图像中各个位置的数据作为训练集，让网络对各个位置都学习到一定的偏好（相当于没有偏好），从而使网络的跟踪性能不会随着网络的加深而下降（若预测位置一直固定在一个地方，即相当于失去了跟踪能力）。</p>\n</li>\n<li>\n<p>解决1：采样的实现：训练的时候search region会移动，以前是以目标为中心crop 255的图片，现在是以目标周围的某个点为中心，让目标不再是search region的中心。这个只和训练有关，测试还是以上一帧目标位置为中心</p>\n</li>\n</ul>\n<h3><span id=\"深度交叉相关\"> 深度交叉相关</span></h3>\n<ul>\n<li>\n<p>问题2：由于在SiamRPN的回归分支和分类分支上，都对模板图像的feature map进行了channel升维，导致模板图像的feature map的channel维度分别是检测图像的feature map的channel维度的2k倍和4k倍，因此，来自模板图像和检测图像的特征维度不对称（参数量不等），即两组特征并不是从相同的特征提取器中提取出来的，所以若将模板图像和检测图像互换再进行相关操作，必然会输出不同的结果，即失去操作的对称性。这种非对称性会给网络的训练优化带来困难，不利于训练的稳定性和网络的整体性能。</p>\n</li>\n<li>\n<p>解决2：depthwise cross-correlation 深度交叉相关。</p>\n<ul>\n<li>adj：模板图像和检测图像的feature map，在回归分支和分类分支中，都首先分别经过一个卷积神经层（由conv层和bn层构成），得到一样的空间分辨率和channel维度。该卷积神经层不同于SiamRPN中的卷积神经层，其不对feature map进行channel升维，只是对两组feature map都进行了finetune，使其维度对称。</li>\n<li>DW：在经过卷积神经层之后，模板图像和检测图像的feature map进行depthwise的相关操作，即是逐个channel的两者的分量之间进行相关操作，输出和channel数相等数量的score map。</li>\n<li>Head：最后，对于不同任务分支输出的相同分辨率和channel维度的score map，再分别使用不同的1*1卷积进行维度调整，以获得不同任务对应的不同维度的输出（分类任务对应channel维度为2k的输出，回归任务对应channel维度为4k的输出）。</li>\n</ul>\n</li>\n<li>\n<p>对于depthwise cross-correlation输出的和channel数相等个数的score map，各个score map分别代表在不同语义上的响应分布。</p>\n<ul>\n<li>而在进行了1*1卷积后，对于回归分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor各自的(x,y,w,h)；对于分类分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor里面各自的前后景分类分数。</li>\n</ul>\n</li>\n<li>\n<p>第一种交叉相关：SiamFC 模版特征在搜索区域上按照滑窗的方式获取不同位置的响应值，最终获得一个一维的响应映射图。</p>\n<ul>\n<li>第二种提升通道交叉相关：用于SiamRPN中，和Cross Correlation操作不同的是在做correlation操作之前多了两个卷积层，通道个数分别为256和256x2k，其中k表示每一个锚点上面的anchor个数。其中一个用来提升通道数，而另一个则保持不变。之后通过卷积的方式，得到最终的输出。通过控制升维的卷积来实现最终输出特征图的通道数。</li>\n<li>这里的改进主要源自于up channel的方法中，升维卷积参数量极大， 256x(256*2k)x3x3， 光分类分支就有接近6M的参数，回归分支12M。其次升维操作造成了两支参数量的极度不平衡，模版分支是搜索支参数量的 2k/4k 倍，造成了整个网络训练困难的问题。而改为Depthwise版本以后，参数量能够急剧下降；同时整体训练也更为稳定，整体性能也得到了加强。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN++_correlation.png\" alt></p>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN++_RPN.png\" alt=\"SiamRPN++_RPN\"></p>\n","site":{"data":{}},"excerpt":"","more":"<!-- toc -->\n<ul>\n<li><a href=\"#siamese\">Siamese</a></li>\n<li><a href=\"#siamese-network\">Siamese Network</a></li>\n<li><a href=\"#siamfc\">SiamFC</a></li>\n<li><a href=\"#rpn\">RPN</a></li>\n<li><a href=\"#siamrpn\">SiamRPN</a></li>\n<li><a href=\"#dasiamrpn\">DaSiamRPN</a></li>\n<li><a href=\"#siamrpn\">SiamRPN++</a>\n<ul>\n<li><a href=\"#%E6%B7%B1%E5%BA%A6%E4%BA%A4%E5%8F%89%E7%9B%B8%E5%85%B3\">深度交叉相关</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h2 id=\"siamese\"><a class=\"markdownIt-Anchor\" href=\"#siamese\"></a> Siamese</h2>\n<ul>\n<li>Siamese和Chinese有点像。Siam是古时候泰国的称呼，中文译作暹罗。Siamese也就是“暹罗”人或“泰国”人。十九世纪泰国出生了一对连体婴儿，当时的医学技术无法使两人分离出来，于是两人顽强地生活了一生，两人均于63岁离开人间。两人的肝至今仍保存在费城的<a href=\"https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E9%A9%AC%E7%89%B9%E5%8D%9A%E7%89%A9%E9%A6%86%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163\" target=\"_blank\" rel=\"noopener\">马特博物馆</a>内。从此之后“<a href=\"https://link.jianshu.com/?t=https%3A%2F%2Fwww.baidu.com%2Fs%3Fwd%3D%E6%9A%B9%E7%BD%97%E5%8F%8C%E8%83%9E%E8%83%8E%26tn%3D44039180_cpr%26fenlei%3Dmv6quAkxTZn0IZRqIHckPjm4nH00T1dWnAP9uWcvmhcvrADsnvmk0ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EnHRYnHDvn163\" target=\"_blank\" rel=\"noopener\">暹罗双胞胎</a>”（Siamese twins）就成了连体人的代名词</li>\n</ul>\n<p>![Siamese twins](Siamese系列\\Siamese twins.jpg)</p>\n<br>\n<h2 id=\"siamese-network\"><a class=\"markdownIt-Anchor\" href=\"#siamese-network\"></a> Siamese Network</h2>\n<ul>\n<li>判断两个输入相似性，核心思想是，两个子体网络通过权重共享来实现连体，寻找一个映射函数，能够将输入图像转换到一个特征空间，每幅图像对应一个特征向量，通过一些简单的“距离度量”（比如欧式距离）来表示向量之间的差异，最后通过这个距离来拟合输入图像的相似度差异（语义差异）</li>\n<li>对比损失Contrastive Loss：\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mo>=</mo><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><msub><mi>a</mi><mi>n</mi></msub><mo>−</mo><msub><mi>b</mi><mi>n</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">d=||a_n-b_n||_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">∣</span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathdefault\">a</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\">∣</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>，代表两个样本特征的欧氏距离，</li>\n<li>d也可使用cosine距离，d=cos=x*y/|x||y|</li>\n<li>y为两个样本是否匹配的标签，y=1代表两个样本相似或者匹配，y=0则代表不匹配，</li>\n<li>margin为设定的阈值</li>\n<li>这种损失函数可以很好的表达成对样本的匹配程度，也能够很好用于训练提取特征的模型。当y=1（即样本相似）时，损失函数只剩下∑d2，即原本相似的样本，如果在特征空间的欧式距离较大，则说明当前的模型不好，因此加大损失。而当y=0时（即样本不相似）时，损失函数为∑max(margin−d,0)2，即当样本不相似时，其特征空间的欧式距离反而小的话（d小，margin-d大），损失值会变大，这也正好符合我们的要求。</li>\n<li>图3表示的就是损失函数值与样本特征的欧式距离之间的关系，其中红色虚线表示的是相似样本的损失值，蓝色实线表示的不相似样本的损失值。</li>\n</ul>\n</li>\n</ul>\n<p>![Siamese Net](Siamese系列/Siamese Net.png)</p>\n<p>![Siamese Net_loss](Siamese系列/Siamese Net_loss.png)</p>\n<p>![Siamese Net_loss1](Siamese系列/Siamese Net_loss1.png)</p>\n<hr>\n<br>\n<h2 id=\"siamfc\"><a class=\"markdownIt-Anchor\" href=\"#siamfc\"></a> SiamFC</h2>\n<p><a href=\"https://blog.csdn.net/nightmare_dimple/article/details/74210147\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/nightmare_dimple/article/details/74210147</a></p>\n<ul>\n<li>全卷积孪生网络 fully-convolutional siamese networks for object tracking</li>\n<li>AlexNet</li>\n<li>以往：相关滤波之网络一层作为特征，深度学习之梯度下降，在线学习，存在问题；本法离线学习，tracking时只需进行相似性判断，计算量很小</li>\n<li>细节：在初始离线阶段把深度卷积网络看成一个更通用的<strong>相似性学习</strong>问题，然后在跟踪时对这个问题进行在线的简单估计。训练了一个孪生网络在一个较大的搜索区域搜索样本图片。本文另一个贡献在于，新的孪生网络结构是一个关于搜索区域的<strong>全卷积网络</strong>：密集高效的滑动窗口估计可通过计算两个输入的互相关性并插值得到。</li>\n<li>相似性学习：学习一个函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x,z)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span>来比较样本图像（目标）z和搜索图像（画面）x的相似性</li>\n<li>用深度神经网络模拟<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span>，深度卷积网络中<strong>相似性学习最典型的就是孪生结构</strong>。孪生网络对两个输入z和x进行相同的变换<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>φ</mi></mrow><annotation encoding=\"application/x-tex\">\\varphi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\">φ</span></span></span></span>，然后将得到的输出送入函数g，最后得到相似性度量函数为：<em>f</em>(<em>z</em>,<em>x</em>)=<em>g</em>(<em>φ</em>(<em>z</em>),<em>φ</em>(<em>x</em>))\n<ul>\n<li>1.函数g是一个简单的距离或相似性度量</li>\n<li>2.φ相当于特征提取器</li>\n</ul>\n</li>\n<li>全卷积网络的优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_1.png\" alt></p>\n<ul>\n<li>搜索图像的确定：跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图</li>\n<li>正负样本的确定：和目标距离不超过阈值</li>\n<li>在经过卷积神经层提取特征后，SiameseFC使用cross-correlation（交叉相关）作为相似度的度量，计算两个feature map各个位置（区域）上的相似度，得到一个score map（或者说heat map）。最后对这个score map进行插值（这里使用的是双三线性插值），获得和原图像一样的空间分辨率，根据该score map，即可定位到跟踪目标在新一帧（检测图像）中的精确位置。</li>\n<li>**训练数据：**从视频的两个帧中提取图像，这两个帧都包含对象并且最多相隔T帧。训练时忽略目标的类别。在不破坏图像的纵横比的情况下对每个图像内的对象的比例进行归一化 。如果得分图中的元素距离中心半径在<img src=\"https://math.jianshu.com/math?formula=R\" alt=\"R\">（根据网络步长<img src=\"https://math.jianshu.com/math?formula=k\" alt=\"k\">决定）以内，就认为是正样本。</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamFC_training_pairs.png\" alt></p>\n<ul>\n<li>\n<p>余弦惩罚：在获得score map之后，SiameseFC会在上面应用一个余弦窗，以对那些不正常的较大位移进行惩罚（余弦窗具有边缘抑制的作用，如果目标是一个正常的位移，那么检测热点应该是在heatmap的中心区域附近，如果检测热点跑到heatmap的边缘，则说明目标发生了瞬时的长位移，这很大可能是由检测错误导致的，因此该检测结果需要被抑制和惩罚）。</p>\n</li>\n<li>\n<p>多尺度检测：通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。</p>\n</li>\n<li>\n<p>优点是待搜索图像不需要与样本图像具有相同尺寸，可以为网络提供更大的搜索图像作为输入，然后在密集网格上计算所有平移窗口的相似度。</p>\n</li>\n<li>\n<p>本文的相似度函数使用互相关，公式如下<em>f</em>(<em>z</em>,<em>x</em>)=<em>φ</em>(<em>z</em>)∗<em>φ</em>(<em>x</em>)+<em>b</em>1</p>\n<ul>\n<li><em>b</em>1 表示在得分图中每个位置的取值</li>\n<li>上式可将φ(z)看成卷积核，在φ(x)上进行卷积</li>\n</ul>\n</li>\n<li>\n<p>跟踪时以上一帧目标位置为中心的搜索图像来计算响应得分图f，将得分最大的位置乘以步长即可得到当前目标的位置</p>\n</li>\n<li>\n<p>phi：五层卷积，提取特征</p>\n</li>\n<li>\n<p>卷积：卷积以实现相似性度量</p>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_3.jpg\" alt></p>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_2.jpg\" alt=\"SiamFC_2\"></p>\n<ul>\n<li>损失函数：每一个候选子窗口，其实相当于一个样本，而它的得分，输出的就是它是正/负样本的概率。使用逻辑回归来表示的话，这就是一个应用逻辑回归的典型二分类问题，对于得分矩阵中的每一个点u有：其中<em>v</em>是实际输出,<em>y</em>是真实标签{+1，-1}</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamFC_loss.png\" alt=\"SiamFC_loss\"></p>\n<ul>\n<li>\n<p>定位目标区域/tracking：相似性矩阵，经双三次插值，变为255²矩阵，定位。</p>\n</li>\n<li>\n<p>目标图像在线不更新，提取高层语义特征</p>\n</li>\n<li>\n<p>5尺度搜索 1.025（-2，-1,0,1,2）。尺度检测是扩大或缩小检测区域，但检测图像都要缩放到255<em>255</em>3，也就是说尺度检测是天然可以并行的，SiamFC通过设置mini-batch的方式实现，一次性完成3或5个尺度样本检测。多尺度检测通常是将目标先进行不同尺度的采样（如生成图像金字塔），再对不同尺度的图像分别进行检测。在SiameseFC中，对图像先进行不同尺度的采样、再resize到固定的分辨率，可以合并为一个步骤，因此可以并行地生成多张分辨率相同但尺度不同的目标图像（将尺度不同的目标图像resize到同一分辨率即可），集合成一个mini-batch，送进网络进行多尺度检测，从而实现SiameseFC的尺度适应性。</p>\n</li>\n<li>\n<p>long term与short term：SiameseFC在预测的时候，不在线更新模板图像。这使得SiameseFC的计算速度很快，但同时也要求SiameseFC中使用的特征需要具有足够的鲁棒性（通常是高层特征，分辨率较低，计算复杂度较大），以便在后续帧中能够应对各种变换。而在另一方面，不在线更新模板图像的策略，可以确保跟踪目标的不变性和纯净性，在long-term跟踪算法上具有天然的优势。</p>\n<p>还有一类visual tracker，在预测时，使用的是在线更新模板图像的策略。这种策略的优点是对特征的鲁棒性要求较低（通常是低层特征，分辨率较高，计算复杂度较小），能适时地学习到目标和背景的变化，但也带来了其他的缺点：在目标跟踪的过程中，如果中间跟丢或跟错了目标（由于遮挡或失败等原因，会导致学习到背景，而不是目标），就无法再恢复到正确的跟踪目标上了；而如果在目标跟踪的过程中，学习到了错误的特征（如来自外界的噪声），则会导致跟踪目标被污染，在后续帧中，跟踪能力降低，甚至逐渐丧失（跟踪目标的累积污染增加）。因此这种更新策略更多地用于short-term跟踪算法上。</p>\n</li>\n<li>\n<p>双三次差值 <a href=\"https://blog.csdn.net/datase/article/details/80576054\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/datase/article/details/80576054</a></p>\n</li>\n</ul>\n<hr>\n<br>\n<h2 id=\"rpn\"><a class=\"markdownIt-Anchor\" href=\"#rpn\"></a> RPN</h2>\n<p>Region Proposal Network 区域推荐网络</p>\n<ul>\n<li>\n<p>本质是 “ 基于滑窗的无类别obejct检测器 ”</p>\n</li>\n<li>\n<p>用于目标检测。把一个任意尺度的图片作为输入，输出一系列的矩形object proposals，每个object proposals都带一个objectness score。分为两个支路，一个用于分类前景和背景，一个用于边界框回归。通俗来讲，就是用RPN来选择感兴趣区域的，即proposal extraction。例如，如果一个区域的p&gt;0.5，则认为这个区域中可能是我们想要的类别中的某一类，具体是哪一类现在还不清楚。到此为止，网络只需要把这些可能含有物体的区域选取出来就可以了，这些被选取出来的区域又叫做ROI （Region of Interests），即感兴趣的区域。当然了，RPN同时也会在feature map上框定这些ROI感兴趣区域的大致位置，即输出Bounding Box。</p>\n</li>\n<li>\n<p>一种更加简单的方法来预测 objects 的边界框，即，学习相对于<strong>参考GT的偏移量</strong></p>\n</li>\n<li>\n<p>anchor的一种理解（anchor的特征图与原始图像的联系）：应该是特征图的某一个像素与对应在原始图像的某一个像素，即<strong>本质上指的是特征图上当前滑窗的中心在原像素空间的映射点称为anchor</strong>，即anchor是在原始图像上的</p>\n</li>\n<li>\n<p>在特征的每个位置，考虑多个可能的候选窗口：窗口数=面积数×比例数，称为anchors。下图中3种面积×3种比例，每个位置9个anchors</p>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5Canchors.jpg\" alt=\"anchors\"></p>\n<ul>\n<li>计算每个像素（256-d）的k个尺度下的值，得到k个anchor，我们给每个anchor分配一个二进制的标签（前景背景），由其与GT重叠度决定。则标记后输出2×k纬度，表示每个位置有2k个cls（classification）分数；同时每个anchor又与GT对应四个偏移量[x, y, w, h]，代表中心点的坐标、框的宽高，则回归组reg（regression）为4k纬度</li>\n<li>anchor会很多，选取部分正、负anchor训练</li>\n</ul>\n<hr>\n<br>\n<h2 id=\"siamrpn\"><a class=\"markdownIt-Anchor\" href=\"#siamrpn\"></a> SiamRPN</h2>\n<p><a href=\"https://blog.csdn.net/fzp95/article/details/80982201\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fzp95/article/details/80982201</a></p>\n<p><a href=\"https://www.jianshu.com/p/a3786b61031c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/a3786b61031c</a></p>\n<p><a href=\"https://blog.csdn.net/leviopku/article/details/81068487\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leviopku/article/details/81068487</a></p>\n<p><a href=\"https://blog.csdn.net/leviopku/article/details/80875368\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leviopku/article/details/80875368</a></p>\n<ul>\n<li>孪生候选区域生成网络 High Performance Visual Tracking with Siamese Region Proposal Network</li>\n<li>Siamese部分基于预训练的AlexNet</li>\n<li>SiamFC缺点：只能得到目标的中心位置，但是得不到目标的尺寸，所以只能采取简单的多尺度加回归，这即增加了计算量，同时也不够精确。</li>\n<li>改进：输出两个分支，分别用于分类和回归（SiamFC没有回归，而是用多尺度测试，增加了计算量且不够精确），帧率160fps（不需要在线微调）</li>\n<li>摘要：这个结构包含用于特征提取的孪生子网络（Siamese subnetwork）和候选区域生成网络（region proposal subnetwork），其中候选区域生成网络包含分类和回归两条支路。在跟踪阶段，作者提出的方法被构造成为单样本检测任务（one-shot detection task）。作者预先计算孪生子网络中的模板支路，也就是第一帧，并且将它构造成一个检测支路中区域提取网络里面的一个卷积层，用于在线跟踪。传统的多尺度测试和在线微调可以被舍弃，这样做也大大提高了速度。</li>\n<li>此方法不更新模型，是离线训练好的基于深度学习跟踪器，在相关特征图谱上提取候选区域，然后作者将模板分支上的目标外观信息编码到RPN特征中来判别前景和背景。在跟踪阶段，作者将此任务视为单目标检测任务（one-shot detection），什么意思呢，就是把第一帧的BB视为检测的样例，在其余帧里面检测与它相似的目标。</li>\n<li>anchor box：具有不同规格（大小，长宽比，本文有一种大小，五种长宽比[0.33,0.5,1,2,3]），锚点由卷积过程中卷积核中心确定，每个锚点对应数个锚点框（不同规格）。则检测问题由“哪里有物体”变为“锚点框是否框住物体，框住多少，离得多远”。</li>\n<li>如下图：RPN网络主要用于生成region proposals，首先生成一堆Anchor box，对其进行裁剪过滤后通过softmax判断anchors属于前景(foreground)或者后景(background)，即是物体or不是物体，所以这是一个二分类；同时，另一分支bounding box regression修正anchor box，形成较精确的proposal</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/RPN.jpg\" alt=\"RPN\"></p>\n<ul>\n<li>分类组：在RPN的分类分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的2k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为2k份，作为2k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为2k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为2的score map，两个维度分别对应anchor中前景（目标）和后景（背景）的分类分数，是关于目标的置信度。</li>\n<li>回归组： 在RPN的回归分支中，模板图像和检测图像的feature map，都将首先通过一个卷积层，该卷积层主要是对模板图像的feature map进行channel上的升维，令其维度变为检测图像的feature map的维度的4k倍（k为RPN中设定的anchor数）。此后，将模板图像的feature map在channel上按序等分为4k份，作为4k个卷积核，在检测图像的feature map完成卷积操作，得到一个维度为4k的score map。该score map同样在channel上按序等分为k份，得到对应k个anchor的k个维度为4的score map，四个维度分别对应anchor的（x,y,w,h），是关于目标的坐标及尺寸。</li>\n<li>RPN的引入，使得Siamese网络自然拥有了多尺度检测的能力（通过anchor机制cover各种size），并且可以准确地回归出目标的位置及大小</li>\n<li>k：anchor box 锚点框数量；\n<ul>\n<li>本文为5，不同长宽比[0.33, 0.5, 1, 2, 3]</li>\n<li>模板帧：因要分为目标、背景两类，故2k</li>\n<li>检测帧：[x, y, w, h]，故4k</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/SiamRPN_net.png\" alt></p>\n<ul>\n<li>不同于SiamFC，可对多个多个anchor box判断。</li>\n<li>RPN部分卷积：3×3进一步集中特征，然后多个/一个1×1提高通道数</li>\n<li>分类组：每个点表示正负得分，softmax分类（anchor box和真实目标重叠且IOU大于阈值）</li>\n<li>回归组：每个点表示anchor和ground truth之间的dx,dy,dw,dh（anchor相比于groundtruth的偏移量），通过smooth L1 loss:</li>\n</ul>\n<p>![smooth loss](Siamese系列\\smooth loss.png)</p>\n<ul>\n<li>tracking as one shot detection：对于一个类别，如果只提供一个或者少量训练样本的情况下，如何检测？解决方法就是：让模型学习，得到一个相似性函数，这样的模型输出的值不是类别，而是两幅图像的相似度。</li>\n<li>始终用第一帧当做模板帧，只需进行detection分支，提速。从分类组的奇数层（目标）中，选取最大的K的建议候选框，<strong>后经距离、余弦窗和尺度变化惩罚因子对proposal进行取舍和重新排序，NMS</strong>得到最佳位置。</li>\n<li>若无回归组，则与FC类似，得分图的叠加。</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN_tracking.png\" alt=\"SiamRPN_tracking\"></p>\n<hr>\n<br>\n<h2 id=\"dasiamrpn\"><a class=\"markdownIt-Anchor\" href=\"#dasiamrpn\"></a> DaSiamRPN</h2>\n<p>Distractor-aware Siamese Networks for Visual Object Tracking 添加干扰的</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/42546692\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/42546692</a></p>\n<p><a href=\"https://blog.csdn.net/fzp95/article/details/82380261\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fzp95/article/details/82380261</a></p>\n<ul>\n<li>SiamRPN的缺点：\n<ul>\n<li>响应分数不可靠：跟丢后分类得分仍很高，推测为SiamRPN只能学到（有语义的）物体与非物体的区分，或者理解为区分前景背景，而非学习一个实例级别的表示方法。导致背景有其他物体时易被干扰（csdn提问、feature map）</li>\n<li>跟踪阶段不更新模型，精度换速度</li>\n<li>长时间跟踪中，遮挡、消失效果差</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN_shortcoming2.png\" alt=\"SiamRPN_shortcoming2\"></p>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN_shortcoming1.png\" alt=\"SiamRPN_shortcoming1\"></p>\n<ul>\n<li>总结来说就是样本不均衡：\n<ul>\n<li>正样本种类不够多：添加检测图片数据集，进行数据增益（图片的变换）。增强分辨能力与回归准确性，增强泛化能力</li>\n<li>负样本简单（无语义）、同类：从同类别、不同类别中增加负样本对，使得框选更准，减轻漂移</li>\n<li>这就是说，训练过程中不再让模板 (Template) 和搜索区域 (Search Region) 是相同目标；是让网络学习判别能力，去搜索区域里找模版更相似的物体，而不是一个简单的有语义的物体。</li>\n</ul>\n</li>\n<li>干扰模型，增量学习：17∗17∗5 proposals，选择与模板帧相似度大于某个阈值的错误实例作为干扰项，</li>\n<li>long-term跟踪：丢失时增大搜索区域</li>\n</ul>\n<hr>\n<br>\n<h2 id=\"siamrpn-2\"><a class=\"markdownIt-Anchor\" href=\"#siamrpn-2\"></a> SiamRPN++</h2>\n<p>Evolution of Siamese Visual Tracking with Very Deep Networks</p>\n<p><a href=\"https://blog.csdn.net/baidu_36669549/article/details/85719585\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baidu_36669549/article/details/85719585</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/56254712\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/56254712</a></p>\n<p><strong><a href=\"https://blog.csdn.net/zjc910997316/article/details/90749967?tdsourcetag=s_pctim_aiomsg\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zjc910997316/article/details/90749967?tdsourcetag=s_pctim_aiomsg</a></strong></p>\n<ul>\n<li>\n<p>以往问题：</p>\n<ul>\n<li>浅层网络：Alexnet（无padding）</li>\n<li>精度差</li>\n<li>尝试深层网络ResNet效果不佳（有padding）</li>\n<li>核心原因：绝对平移不变形的破坏</li>\n</ul>\n</li>\n<li>\n<p>孪生的相关操作（A☆B）要求：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>g</mi><mo stretchy=\"false\">(</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>ϕ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(z,x)=g(\\phi(z), \\phi(x))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">ϕ</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span>，即f/g应满足以下</li>\n<li>要求1：绝对平移不变性 <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">[</mo><mi mathvariant=\"normal\">Δ</mi><msub><mi>τ</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo separator=\"true\">,</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">[</mo><mi mathvariant=\"normal\">Δ</mi><msub><mi>τ</mi><mi>j</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">f(z, x[\\Delta \\tau_j]) = f(z, x)[\\Delta \\tau_j]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mopen\">[</span><span class=\"mord\">Δ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.1132em;\">τ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span><span class=\"mopen\">[</span><span class=\"mord\">Δ</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.1132em;\">τ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.1132em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05724em;\">j</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span> 平移移位子窗口操作器，检测帧的移动，结果也应移动。如果在图像中平移一个目标，那么proposal也会跟着平移，这时，同一个函数需要能够在任何位置都预测到这个proposal。</li>\n<li>要求2：基于correlation操作计算相似度的神经网络需要具备对称性。即：将模板图像和检测图像互换，计算出的两者之间的相似度应该是不变的。因为相似度计算本身就是一个对称操作。SiamRPN的监督在于回归的偏移量和分类的分数，而不再是相似度。而对这两个变量的计算都不是对称操作。因此会使神经网络丧失对称性。</li>\n</ul>\n</li>\n<li>\n<p>问题1：平移不变性之padding影响：边缘的patch会由于padding带来黑边，而靠近中心的patch则不会有。所以网络的预测本身是不满足全卷积性质的，也就是在边缘卷出来的和中心卷出来的内容是不一致的。这就可能导致训练过程中，网络倾向于通过padding的pattern来确定目标在哪，即padding少的位置接近中心，更可能是目标。因此如果一个神经网络使用了padding，且在用于训练的图像里，正样本（目标）都位于图像的中心，那么当该神经网络在检测图像上预测目标时，会由于训练样本中目标的分布特性，学习到对图像中心位置的预测偏好。不管目标移动到图像中的哪一处，网络都只会预测中心区域的位置。这也是利用ResNet加深网络后，跟踪性能不升反降的原因。SiamRPN++利用了padding会让网络学习到位置偏好这个特点，用正样本均匀分布在图像中各个位置的数据作为训练集，让网络对各个位置都学习到一定的偏好（相当于没有偏好），从而使网络的跟踪性能不会随着网络的加深而下降（若预测位置一直固定在一个地方，即相当于失去了跟踪能力）。</p>\n</li>\n<li>\n<p>解决1：采样的实现：训练的时候search region会移动，以前是以目标为中心crop 255的图片，现在是以目标周围的某个点为中心，让目标不再是search region的中心。这个只和训练有关，测试还是以上一帧目标位置为中心</p>\n</li>\n</ul>\n<h3 id=\"深度交叉相关\"><a class=\"markdownIt-Anchor\" href=\"#深度交叉相关\"></a> 深度交叉相关</h3>\n<ul>\n<li>\n<p>问题2：由于在SiamRPN的回归分支和分类分支上，都对模板图像的feature map进行了channel升维，导致模板图像的feature map的channel维度分别是检测图像的feature map的channel维度的2k倍和4k倍，因此，来自模板图像和检测图像的特征维度不对称（参数量不等），即两组特征并不是从相同的特征提取器中提取出来的，所以若将模板图像和检测图像互换再进行相关操作，必然会输出不同的结果，即失去操作的对称性。这种非对称性会给网络的训练优化带来困难，不利于训练的稳定性和网络的整体性能。</p>\n</li>\n<li>\n<p>解决2：depthwise cross-correlation 深度交叉相关。</p>\n<ul>\n<li>adj：模板图像和检测图像的feature map，在回归分支和分类分支中，都首先分别经过一个卷积神经层（由conv层和bn层构成），得到一样的空间分辨率和channel维度。该卷积神经层不同于SiamRPN中的卷积神经层，其不对feature map进行channel升维，只是对两组feature map都进行了finetune，使其维度对称。</li>\n<li>DW：在经过卷积神经层之后，模板图像和检测图像的feature map进行depthwise的相关操作，即是逐个channel的两者的分量之间进行相关操作，输出和channel数相等数量的score map。</li>\n<li>Head：最后，对于不同任务分支输出的相同分辨率和channel维度的score map，再分别使用不同的1*1卷积进行维度调整，以获得不同任务对应的不同维度的输出（分类任务对应channel维度为2k的输出，回归任务对应channel维度为4k的输出）。</li>\n</ul>\n</li>\n<li>\n<p>对于depthwise cross-correlation输出的和channel数相等个数的score map，各个score map分别代表在不同语义上的响应分布。</p>\n<ul>\n<li>而在进行了1*1卷积后，对于回归分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor各自的(x,y,w,h)；对于分类分支，输出的feature map上，每个feature点都对应其在原图中的感受野内的k个anchor，各个channel值即为这k个anchor里面各自的前后景分类分数。</li>\n</ul>\n</li>\n<li>\n<p>第一种交叉相关：SiamFC 模版特征在搜索区域上按照滑窗的方式获取不同位置的响应值，最终获得一个一维的响应映射图。</p>\n<ul>\n<li>第二种提升通道交叉相关：用于SiamRPN中，和Cross Correlation操作不同的是在做correlation操作之前多了两个卷积层，通道个数分别为256和256x2k，其中k表示每一个锚点上面的anchor个数。其中一个用来提升通道数，而另一个则保持不变。之后通过卷积的方式，得到最终的输出。通过控制升维的卷积来实现最终输出特征图的通道数。</li>\n<li>这里的改进主要源自于up channel的方法中，升维卷积参数量极大， 256x(256*2k)x3x3， 光分类分支就有接近6M的参数，回归分支12M。其次升维操作造成了两支参数量的极度不平衡，模版分支是搜索支参数量的 2k/4k 倍，造成了整个网络训练困难的问题。而改为Depthwise版本以后，参数量能够急剧下降；同时整体训练也更为稳定，整体性能也得到了加强。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN++_correlation.png\" alt></p>\n<p><img src=\"/2020/06/18/Siamese%E7%B3%BB%E5%88%97/Siamese%E7%B3%BB%E5%88%97%5CSiamRPN++_RPN.png\" alt=\"SiamRPN++_RPN\"></p>"},{"title":"英语3：名词从句","mathjax":false,"date":"2020-06-16T13:08:54.000Z","_content":"\n\n\n《刘晓艳语法长难句》第三章笔记\n\n<br/>\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n# 名词（短语）和名词性从句\n\n## 1. 名词（短语）可作成分\n\n1. 主语、宾语、表语、同位语（I enjoy the part, the warm end.）、定语\n\n2. 同位语：前后两部分指同一事物，用逗号或破折号隔开。**（写作可使用）**\n\n\teg：A boy writes the name of Beckham on his face.\n\n\t:arrow_right: A boy, a crazy football fan, writes the name of Beckham, quite a well-known superstar, on his face.\n\n<br/>\n\n## 2. 名词性从句\n\n1. 从句：引导词+分句；名词性从句：从句整体表现为名词属性\n\n2. eg：\n\t1. What I saw repeatedly is so moving and encouraging.\n\t2. I appreciate what his mother said.\n\t3. He is who we should learn from.\n\t4. I enjoy the part that a feather is flying in the sky.\n3. 例子中从句充当主、宾、表、同位语，分别称为主语从句、宾语从句…\n\n<br/>\n\n### 2.1 名词性从句引导词\n\neg：\n\n**I love you** is my fault. :x: 陈述句\n\n**Do you love me** is obvious. :x: 一般疑问句\n\n**Who do you love** is a secret. :x: 特殊疑问句\n\n普通句子不能做另一个句子的成分，要加引导词变为从句。\n\n对于以上的陈述句、一般疑问句、特殊疑问句三种句子，改为从句，有各自引导词：\n\n1. that：陈述句，且在从句中不承担成分，甚至不影响句意时可以省略；\n2. whether/if：一般疑问句，不充当成分，意为是否。\n\t1. whether：可引导所有名词性从句\n\t2. if：仅宾语从句\n3. 特殊疑问句：when、where、why、how、who、whom、what、which、whose，有具体意义，不可省略。\n4. **所有从句中均保持陈述句语序。**\n\n<br/>\n\neg：\n\n1. 我想知道人为什么活在地球上。（宾语从句）\n\n\tI wonder why people live on the earth.\n\n2. 外星人是否存在真的很重要。（主语从句）\n\n\tWeather aliens exist is really vital.\n\n3. 我的想法是，看完本章后，我们去看电影吧。（表语从句）\n\n\tMy idea is that we will go to see a moive after finishing this chapter.\n\n4. 她成功地找到了朋友，这让我很高兴。（主语从句）\n\n\tThat she succeeded in finding a friend **makes** me happy.\n\n\t**从句做主语，动词三单**\n\n5. 他的成功证明了努力决定命运的真理。(同位语从句)\n\n\tHis triumph demonstrated the truth that endeavor decides destiny.\n\n<br/>\n\n## 3. 应用\n\n### 3.1 写作\n\n1. 主语从句 **It … that …**\n\n\t如 That she succeeded in finding a friend **makes** me happy，头重脚轻，改用**it作形式主语**，主语从句放至句尾：It makes me happy that she succeeded in finding a friend.\n\n2. 形式主语除了主语从句，其他特殊形式做主语时，也可用。\n\n\t1. It is adj./n. to do sth. 不定式\n\t2. It v. to do sth.\n\t3. It is adj./n. doing sth. 动名词\n\n3. 同位语从句（用于分析原因）\n\n\t1. 没有什么能掩盖她正在变老这个事实。\n\n\t\tNothing can hide the truth that she is growing old.\n\n\t2. 很多女生都穿上了漂亮的裙子这个事实表明夏天来了。\n\n\t\tThe evidence that many girls have worn attractive skirts manifests that summer is coming.\n\n\t3. 为什么说污染越来越严重了？ ——城市里再也看不到纯净的蓝天，闻不到新鲜的空气这个事实表明污染一天天变得越来越严重。\n\n\t\tThe evidence that blue sky and fresh air fail to available in cities suggests that pollution has become increasingly serious day by day.\n\n\t4. **The evidence/truth that … manifests/indecates/suggests that …**\n\n<br/>\n\n### 3.2 长难句分析\n\n1. 识别主语从句：忽略状语从句（有逗号分隔，好分辨），句首有引导词时，到主语谓语，为主语从句；形式主语时从that到句末为主语从句。\n\n\tHow well the predictions will be validated by later performamce depends upon the amount, reliability and appropriateness of the information used and on the skill and wisdom with which it is interpreted.\n\n\t1. 找主语谓语：depends upon，前主语，后宾语。故how至谓语，都是主语从句;宾语是and连接的并列成分\n\t2. 找并列连词：used后的and即为并列连词。and后的成分是介词+名词短语+定语，and前的内容多了depends，故后内容省略了depends。\n\t3. 译文：这些预言能在多大程度上被以后的行为证实，取决于所使用的信息的数量、可靠性和适合性，并且还取决于解释这些信息的技巧和智慧。\n\n2. 识别宾语从句：实义动词后有引导词的基本都是宾语从句。\n\n3. 识别同位语从句：名词后的引导词（也可能是定语从句）、不及物动词后的引导词（同位语后置）\n\n","source":"_posts/英语3：名词从句.md","raw":"---\ntitle: 英语3：名词从句\nmathjax: false\ndate: 2020-06-16 21:08:54\ntags: 英语\n\n---\n\n\n\n《刘晓艳语法长难句》第三章笔记\n\n<br/>\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n# 名词（短语）和名词性从句\n\n## 1. 名词（短语）可作成分\n\n1. 主语、宾语、表语、同位语（I enjoy the part, the warm end.）、定语\n\n2. 同位语：前后两部分指同一事物，用逗号或破折号隔开。**（写作可使用）**\n\n\teg：A boy writes the name of Beckham on his face.\n\n\t:arrow_right: A boy, a crazy football fan, writes the name of Beckham, quite a well-known superstar, on his face.\n\n<br/>\n\n## 2. 名词性从句\n\n1. 从句：引导词+分句；名词性从句：从句整体表现为名词属性\n\n2. eg：\n\t1. What I saw repeatedly is so moving and encouraging.\n\t2. I appreciate what his mother said.\n\t3. He is who we should learn from.\n\t4. I enjoy the part that a feather is flying in the sky.\n3. 例子中从句充当主、宾、表、同位语，分别称为主语从句、宾语从句…\n\n<br/>\n\n### 2.1 名词性从句引导词\n\neg：\n\n**I love you** is my fault. :x: 陈述句\n\n**Do you love me** is obvious. :x: 一般疑问句\n\n**Who do you love** is a secret. :x: 特殊疑问句\n\n普通句子不能做另一个句子的成分，要加引导词变为从句。\n\n对于以上的陈述句、一般疑问句、特殊疑问句三种句子，改为从句，有各自引导词：\n\n1. that：陈述句，且在从句中不承担成分，甚至不影响句意时可以省略；\n2. whether/if：一般疑问句，不充当成分，意为是否。\n\t1. whether：可引导所有名词性从句\n\t2. if：仅宾语从句\n3. 特殊疑问句：when、where、why、how、who、whom、what、which、whose，有具体意义，不可省略。\n4. **所有从句中均保持陈述句语序。**\n\n<br/>\n\neg：\n\n1. 我想知道人为什么活在地球上。（宾语从句）\n\n\tI wonder why people live on the earth.\n\n2. 外星人是否存在真的很重要。（主语从句）\n\n\tWeather aliens exist is really vital.\n\n3. 我的想法是，看完本章后，我们去看电影吧。（表语从句）\n\n\tMy idea is that we will go to see a moive after finishing this chapter.\n\n4. 她成功地找到了朋友，这让我很高兴。（主语从句）\n\n\tThat she succeeded in finding a friend **makes** me happy.\n\n\t**从句做主语，动词三单**\n\n5. 他的成功证明了努力决定命运的真理。(同位语从句)\n\n\tHis triumph demonstrated the truth that endeavor decides destiny.\n\n<br/>\n\n## 3. 应用\n\n### 3.1 写作\n\n1. 主语从句 **It … that …**\n\n\t如 That she succeeded in finding a friend **makes** me happy，头重脚轻，改用**it作形式主语**，主语从句放至句尾：It makes me happy that she succeeded in finding a friend.\n\n2. 形式主语除了主语从句，其他特殊形式做主语时，也可用。\n\n\t1. It is adj./n. to do sth. 不定式\n\t2. It v. to do sth.\n\t3. It is adj./n. doing sth. 动名词\n\n3. 同位语从句（用于分析原因）\n\n\t1. 没有什么能掩盖她正在变老这个事实。\n\n\t\tNothing can hide the truth that she is growing old.\n\n\t2. 很多女生都穿上了漂亮的裙子这个事实表明夏天来了。\n\n\t\tThe evidence that many girls have worn attractive skirts manifests that summer is coming.\n\n\t3. 为什么说污染越来越严重了？ ——城市里再也看不到纯净的蓝天，闻不到新鲜的空气这个事实表明污染一天天变得越来越严重。\n\n\t\tThe evidence that blue sky and fresh air fail to available in cities suggests that pollution has become increasingly serious day by day.\n\n\t4. **The evidence/truth that … manifests/indecates/suggests that …**\n\n<br/>\n\n### 3.2 长难句分析\n\n1. 识别主语从句：忽略状语从句（有逗号分隔，好分辨），句首有引导词时，到主语谓语，为主语从句；形式主语时从that到句末为主语从句。\n\n\tHow well the predictions will be validated by later performamce depends upon the amount, reliability and appropriateness of the information used and on the skill and wisdom with which it is interpreted.\n\n\t1. 找主语谓语：depends upon，前主语，后宾语。故how至谓语，都是主语从句;宾语是and连接的并列成分\n\t2. 找并列连词：used后的and即为并列连词。and后的成分是介词+名词短语+定语，and前的内容多了depends，故后内容省略了depends。\n\t3. 译文：这些预言能在多大程度上被以后的行为证实，取决于所使用的信息的数量、可靠性和适合性，并且还取决于解释这些信息的技巧和智慧。\n\n2. 识别宾语从句：实义动词后有引导词的基本都是宾语从句。\n\n3. 识别同位语从句：名词后的引导词（也可能是定语从句）、不及物动词后的引导词（同位语后置）\n\n","slug":"英语3：名词从句","published":1,"updated":"2020-06-16T13:12:44.256Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbew6000li0qv9fhp84g2","content":"<p>《刘晓艳语法长难句》第三章笔记</p>\n<br>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#%E5%90%8D%E8%AF%8D%E7%9F%AD%E8%AF%AD%E5%92%8C%E5%90%8D%E8%AF%8D%E6%80%A7%E4%BB%8E%E5%8F%A5\">名词（短语）和名词性从句</a>\n<ul>\n<li><a href=\"#1-%E5%90%8D%E8%AF%8D%E7%9F%AD%E8%AF%AD%E5%8F%AF%E4%BD%9C%E6%88%90%E5%88%86\">1. 名词（短语）可作成分</a></li>\n<li><a href=\"#2-%E5%90%8D%E8%AF%8D%E6%80%A7%E4%BB%8E%E5%8F%A5\">2. 名词性从句</a>\n<ul>\n<li><a href=\"#21-%E5%90%8D%E8%AF%8D%E6%80%A7%E4%BB%8E%E5%8F%A5%E5%BC%95%E5%AF%BC%E8%AF%8D\">2.1 名词性从句引导词</a></li>\n</ul>\n</li>\n<li><a href=\"#3-%E5%BA%94%E7%94%A8\">3. 应用</a>\n<ul>\n<li><a href=\"#31-%E5%86%99%E4%BD%9C\">3.1 写作</a></li>\n<li><a href=\"#32-%E9%95%BF%E9%9A%BE%E5%8F%A5%E5%88%86%E6%9E%90\">3.2 长难句分析</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"名词短语和名词性从句\"> 名词（短语）和名词性从句</span></h1>\n<h2><span id=\"1-名词短语可作成分\"> 1. 名词（短语）可作成分</span></h2>\n<ol>\n<li>\n<p>主语、宾语、表语、同位语（I enjoy the part, the warm end.）、定语</p>\n</li>\n<li>\n<p>同位语：前后两部分指同一事物，用逗号或破折号隔开。<strong>（写作可使用）</strong></p>\n<p>eg：A boy writes the name of Beckham on his face.</p>\n<p>➡️ A boy, a crazy football fan, writes the name of Beckham, quite a well-known superstar, on his face.</p>\n</li>\n</ol>\n<br>\n<h2><span id=\"2-名词性从句\"> 2. 名词性从句</span></h2>\n<ol>\n<li>\n<p>从句：引导词+分句；名词性从句：从句整体表现为名词属性</p>\n</li>\n<li>\n<p>eg：</p>\n<ol>\n<li>What I saw repeatedly is so moving and encouraging.</li>\n<li>I appreciate what his mother said.</li>\n<li>He is who we should learn from.</li>\n<li>I enjoy the part that a feather is flying in the sky.</li>\n</ol>\n</li>\n<li>\n<p>例子中从句充当主、宾、表、同位语，分别称为主语从句、宾语从句…</p>\n</li>\n</ol>\n<br>\n<h3><span id=\"21-名词性从句引导词\"> 2.1 名词性从句引导词</span></h3>\n<p>eg：</p>\n<p><strong>I love you</strong> is my fault. ❌ 陈述句</p>\n<p><strong>Do you love me</strong> is obvious. ❌ 一般疑问句</p>\n<p><strong>Who do you love</strong> is a secret. ❌ 特殊疑问句</p>\n<p>普通句子不能做另一个句子的成分，要加引导词变为从句。</p>\n<p>对于以上的陈述句、一般疑问句、特殊疑问句三种句子，改为从句，有各自引导词：</p>\n<ol>\n<li>that：陈述句，且在从句中不承担成分，甚至不影响句意时可以省略；</li>\n<li>whether/if：一般疑问句，不充当成分，意为是否。\n<ol>\n<li>whether：可引导所有名词性从句</li>\n<li>if：仅宾语从句</li>\n</ol>\n</li>\n<li>特殊疑问句：when、where、why、how、who、whom、what、which、whose，有具体意义，不可省略。</li>\n<li><strong>所有从句中均保持陈述句语序。</strong></li>\n</ol>\n<br>\n<p>eg：</p>\n<ol>\n<li>\n<p>我想知道人为什么活在地球上。（宾语从句）</p>\n<p>I wonder why people live on the earth.</p>\n</li>\n<li>\n<p>外星人是否存在真的很重要。（主语从句）</p>\n<p>Weather aliens exist is really vital.</p>\n</li>\n<li>\n<p>我的想法是，看完本章后，我们去看电影吧。（表语从句）</p>\n<p>My idea is that we will go to see a moive after finishing this chapter.</p>\n</li>\n<li>\n<p>她成功地找到了朋友，这让我很高兴。（主语从句）</p>\n<p>That she succeeded in finding a friend <strong>makes</strong> me happy.</p>\n<p><strong>从句做主语，动词三单</strong></p>\n</li>\n<li>\n<p>他的成功证明了努力决定命运的真理。(同位语从句)</p>\n<p>His triumph demonstrated the truth that endeavor decides destiny.</p>\n</li>\n</ol>\n<br>\n<h2><span id=\"3-应用\"> 3. 应用</span></h2>\n<h3><span id=\"31-写作\"> 3.1 写作</span></h3>\n<ol>\n<li>\n<p>主语从句 <strong>It … that …</strong></p>\n<p>如 That she succeeded in finding a friend <strong>makes</strong> me happy，头重脚轻，改用<strong>it作形式主语</strong>，主语从句放至句尾：It makes me happy that she succeeded in finding a friend.</p>\n</li>\n<li>\n<p>形式主语除了主语从句，其他特殊形式做主语时，也可用。</p>\n<ol>\n<li>It is adj./n. to do sth. 不定式</li>\n<li>It v. to do sth.</li>\n<li>It is adj./n. doing sth. 动名词</li>\n</ol>\n</li>\n<li>\n<p>同位语从句（用于分析原因）</p>\n<ol>\n<li>\n<p>没有什么能掩盖她正在变老这个事实。</p>\n<p>Nothing can hide the truth that she is growing old.</p>\n</li>\n<li>\n<p>很多女生都穿上了漂亮的裙子这个事实表明夏天来了。</p>\n<p>The evidence that many girls have worn attractive skirts manifests that summer is coming.</p>\n</li>\n<li>\n<p>为什么说污染越来越严重了？ ——城市里再也看不到纯净的蓝天，闻不到新鲜的空气这个事实表明污染一天天变得越来越严重。</p>\n<p>The evidence that blue sky and fresh air fail to available in cities suggests that pollution has become increasingly serious day by day.</p>\n</li>\n<li>\n<p><strong>The evidence/truth that … manifests/indecates/suggests that …</strong></p>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h3><span id=\"32-长难句分析\"> 3.2 长难句分析</span></h3>\n<ol>\n<li>\n<p>识别主语从句：忽略状语从句（有逗号分隔，好分辨），句首有引导词时，到主语谓语，为主语从句；形式主语时从that到句末为主语从句。</p>\n<p>How well the predictions will be validated by later performamce depends upon the amount, reliability and appropriateness of the information used and on the skill and wisdom with which it is interpreted.</p>\n<ol>\n<li>找主语谓语：depends upon，前主语，后宾语。故how至谓语，都是主语从句;宾语是and连接的并列成分</li>\n<li>找并列连词：used后的and即为并列连词。and后的成分是介词+名词短语+定语，and前的内容多了depends，故后内容省略了depends。</li>\n<li>译文：这些预言能在多大程度上被以后的行为证实，取决于所使用的信息的数量、可靠性和适合性，并且还取决于解释这些信息的技巧和智慧。</li>\n</ol>\n</li>\n<li>\n<p>识别宾语从句：实义动词后有引导词的基本都是宾语从句。</p>\n</li>\n<li>\n<p>识别同位语从句：名词后的引导词（也可能是定语从句）、不及物动词后的引导词（同位语后置）</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>《刘晓艳语法长难句》第三章笔记</p>\n<br>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#%E5%90%8D%E8%AF%8D%E7%9F%AD%E8%AF%AD%E5%92%8C%E5%90%8D%E8%AF%8D%E6%80%A7%E4%BB%8E%E5%8F%A5\">名词（短语）和名词性从句</a>\n<ul>\n<li><a href=\"#1-%E5%90%8D%E8%AF%8D%E7%9F%AD%E8%AF%AD%E5%8F%AF%E4%BD%9C%E6%88%90%E5%88%86\">1. 名词（短语）可作成分</a></li>\n<li><a href=\"#2-%E5%90%8D%E8%AF%8D%E6%80%A7%E4%BB%8E%E5%8F%A5\">2. 名词性从句</a>\n<ul>\n<li><a href=\"#21-%E5%90%8D%E8%AF%8D%E6%80%A7%E4%BB%8E%E5%8F%A5%E5%BC%95%E5%AF%BC%E8%AF%8D\">2.1 名词性从句引导词</a></li>\n</ul>\n</li>\n<li><a href=\"#3-%E5%BA%94%E7%94%A8\">3. 应用</a>\n<ul>\n<li><a href=\"#31-%E5%86%99%E4%BD%9C\">3.1 写作</a></li>\n<li><a href=\"#32-%E9%95%BF%E9%9A%BE%E5%8F%A5%E5%88%86%E6%9E%90\">3.2 长难句分析</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"名词短语和名词性从句\"><a class=\"markdownIt-Anchor\" href=\"#名词短语和名词性从句\"></a> 名词（短语）和名词性从句</h1>\n<h2 id=\"1-名词短语可作成分\"><a class=\"markdownIt-Anchor\" href=\"#1-名词短语可作成分\"></a> 1. 名词（短语）可作成分</h2>\n<ol>\n<li>\n<p>主语、宾语、表语、同位语（I enjoy the part, the warm end.）、定语</p>\n</li>\n<li>\n<p>同位语：前后两部分指同一事物，用逗号或破折号隔开。<strong>（写作可使用）</strong></p>\n<p>eg：A boy writes the name of Beckham on his face.</p>\n<p>➡️ A boy, a crazy football fan, writes the name of Beckham, quite a well-known superstar, on his face.</p>\n</li>\n</ol>\n<br>\n<h2 id=\"2-名词性从句\"><a class=\"markdownIt-Anchor\" href=\"#2-名词性从句\"></a> 2. 名词性从句</h2>\n<ol>\n<li>\n<p>从句：引导词+分句；名词性从句：从句整体表现为名词属性</p>\n</li>\n<li>\n<p>eg：</p>\n<ol>\n<li>What I saw repeatedly is so moving and encouraging.</li>\n<li>I appreciate what his mother said.</li>\n<li>He is who we should learn from.</li>\n<li>I enjoy the part that a feather is flying in the sky.</li>\n</ol>\n</li>\n<li>\n<p>例子中从句充当主、宾、表、同位语，分别称为主语从句、宾语从句…</p>\n</li>\n</ol>\n<br>\n<h3 id=\"21-名词性从句引导词\"><a class=\"markdownIt-Anchor\" href=\"#21-名词性从句引导词\"></a> 2.1 名词性从句引导词</h3>\n<p>eg：</p>\n<p><strong>I love you</strong> is my fault. ❌ 陈述句</p>\n<p><strong>Do you love me</strong> is obvious. ❌ 一般疑问句</p>\n<p><strong>Who do you love</strong> is a secret. ❌ 特殊疑问句</p>\n<p>普通句子不能做另一个句子的成分，要加引导词变为从句。</p>\n<p>对于以上的陈述句、一般疑问句、特殊疑问句三种句子，改为从句，有各自引导词：</p>\n<ol>\n<li>that：陈述句，且在从句中不承担成分，甚至不影响句意时可以省略；</li>\n<li>whether/if：一般疑问句，不充当成分，意为是否。\n<ol>\n<li>whether：可引导所有名词性从句</li>\n<li>if：仅宾语从句</li>\n</ol>\n</li>\n<li>特殊疑问句：when、where、why、how、who、whom、what、which、whose，有具体意义，不可省略。</li>\n<li><strong>所有从句中均保持陈述句语序。</strong></li>\n</ol>\n<br>\n<p>eg：</p>\n<ol>\n<li>\n<p>我想知道人为什么活在地球上。（宾语从句）</p>\n<p>I wonder why people live on the earth.</p>\n</li>\n<li>\n<p>外星人是否存在真的很重要。（主语从句）</p>\n<p>Weather aliens exist is really vital.</p>\n</li>\n<li>\n<p>我的想法是，看完本章后，我们去看电影吧。（表语从句）</p>\n<p>My idea is that we will go to see a moive after finishing this chapter.</p>\n</li>\n<li>\n<p>她成功地找到了朋友，这让我很高兴。（主语从句）</p>\n<p>That she succeeded in finding a friend <strong>makes</strong> me happy.</p>\n<p><strong>从句做主语，动词三单</strong></p>\n</li>\n<li>\n<p>他的成功证明了努力决定命运的真理。(同位语从句)</p>\n<p>His triumph demonstrated the truth that endeavor decides destiny.</p>\n</li>\n</ol>\n<br>\n<h2 id=\"3-应用\"><a class=\"markdownIt-Anchor\" href=\"#3-应用\"></a> 3. 应用</h2>\n<h3 id=\"31-写作\"><a class=\"markdownIt-Anchor\" href=\"#31-写作\"></a> 3.1 写作</h3>\n<ol>\n<li>\n<p>主语从句 <strong>It … that …</strong></p>\n<p>如 That she succeeded in finding a friend <strong>makes</strong> me happy，头重脚轻，改用<strong>it作形式主语</strong>，主语从句放至句尾：It makes me happy that she succeeded in finding a friend.</p>\n</li>\n<li>\n<p>形式主语除了主语从句，其他特殊形式做主语时，也可用。</p>\n<ol>\n<li>It is adj./n. to do sth. 不定式</li>\n<li>It v. to do sth.</li>\n<li>It is adj./n. doing sth. 动名词</li>\n</ol>\n</li>\n<li>\n<p>同位语从句（用于分析原因）</p>\n<ol>\n<li>\n<p>没有什么能掩盖她正在变老这个事实。</p>\n<p>Nothing can hide the truth that she is growing old.</p>\n</li>\n<li>\n<p>很多女生都穿上了漂亮的裙子这个事实表明夏天来了。</p>\n<p>The evidence that many girls have worn attractive skirts manifests that summer is coming.</p>\n</li>\n<li>\n<p>为什么说污染越来越严重了？ ——城市里再也看不到纯净的蓝天，闻不到新鲜的空气这个事实表明污染一天天变得越来越严重。</p>\n<p>The evidence that blue sky and fresh air fail to available in cities suggests that pollution has become increasingly serious day by day.</p>\n</li>\n<li>\n<p><strong>The evidence/truth that … manifests/indecates/suggests that …</strong></p>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h3 id=\"32-长难句分析\"><a class=\"markdownIt-Anchor\" href=\"#32-长难句分析\"></a> 3.2 长难句分析</h3>\n<ol>\n<li>\n<p>识别主语从句：忽略状语从句（有逗号分隔，好分辨），句首有引导词时，到主语谓语，为主语从句；形式主语时从that到句末为主语从句。</p>\n<p>How well the predictions will be validated by later performamce depends upon the amount, reliability and appropriateness of the information used and on the skill and wisdom with which it is interpreted.</p>\n<ol>\n<li>找主语谓语：depends upon，前主语，后宾语。故how至谓语，都是主语从句;宾语是and连接的并列成分</li>\n<li>找并列连词：used后的and即为并列连词。and后的成分是介词+名词短语+定语，and前的内容多了depends，故后内容省略了depends。</li>\n<li>译文：这些预言能在多大程度上被以后的行为证实，取决于所使用的信息的数量、可靠性和适合性，并且还取决于解释这些信息的技巧和智慧。</li>\n</ol>\n</li>\n<li>\n<p>识别宾语从句：实义动词后有引导词的基本都是宾语从句。</p>\n</li>\n<li>\n<p>识别同位语从句：名词后的引导词（也可能是定语从句）、不及物动词后的引导词（同位语后置）</p>\n</li>\n</ol>"},{"title":"语法4：定语和定语从句","mathjax":false,"date":"2020-07-02T14:58:07.000Z","_content":"\n\n\n\n\n《刘晓艳语法长难句》第四章笔记\n\n<br/>\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n\n\n[toc]\n\n# 定语和定语从句\n\n## 1. 定语\n\n定语就是修饰名词/短语的成分。\n\neg：\n\n​\t它是一只**善良的**夜莺。\n\n​\t**住在年轻人隔壁的**女孩应该很漂亮。\n\n<br/>\n\n## 2. 定语的成分\n\n1. 形容词（短语）作定语\n\n\t1. 那只善良的夜莺最后死了。 \n\n\t\tThat **kind** nightingale died at last.\n\n\t2. 这朵非凡的玫瑰花变成了深红色。 \n\n\t\tThe **extraordinary** rose turns dark red.\n\n2. 形容词化的名词（短语）作定语\n\n\t夜莺的歌声能使这朵玫瑰花开放。 \n\n\t**The nightingale`s** singing can make the rose bloom. \n\n\tThe singing **of the nightingale** can make the rose bloom. （常用）\n\n3. 介词短语作定语\n\n\t1. 窗外的夜莺听到了年轻人的感叹。\n\n\t\tThe nightingale **out of the window** heard the sighs of the young man.\n\n\t2. 我只有和大海的浪花一样白的玫瑰花。\n\n\t\tI only have roses **as white as the foam in the sea**.\n\n4. 分词、不定式（非谓语）作定语\n\n\t1. 唱歌的夜莺最终因爱而死。\n\n\t\tIn the end, the **singing** nightingale died because of love.\n\n\t2. 单纯的夜莺一定是爱上了那个被女孩欺骗的学生。\n\n\t\tThe innocent nightingale must have loved the student **deceived by the girl**.\n\n5. 从句作定语\n\n\t夜莺用生命换来的玫瑰花并没有帮到那个学生。\n\n\tThe rose **Which the nightingale exchanged with her life** failed to help the student.\n\n<br/>\n\n## 3. 定语的位置\n\n不同于汉语的名词前，英语中定语位置“前小后大”。即，定语的位置取决于其长度。另，过去分词作定语，即使一个单词也要置后。\n\neg: 他是一个被抛弃的男人。He is a man abandoned.\n\n<br/>\n\n## 4. 定语从句\n\n1. 构成：先行词（名词（短语）） + 引导词 + 分句\n\n2. 引导词：按照先行词分类\n\n\t1. 人：who, whom, whose \n\t2. 物：that, which, whose\n\t3. 时间：that, which, when\n\t4. 地点：that, which, where\n\t5. 原因：that, which, why. 通常情况下that等同于which\n\n3. 用例：\n\n\t1. He is the man **who** loves me.（who从句充当主语或宾语）\n\t2. He is the man **who/whom** I love.（whom从句中充当宾语）\n\t3. He is the man **whose** father is wealthy.（whose从句中定语）\n\t4. I will never forget the day **when** I met you.(从句不缺成分)\n\t5. I will never forget the day **which/that** we spent.(主语或宾语)\n\t6. You had better have some reason **why** you are late.(从句不缺成分)\n\t7. You had better have some reason **which/that** sounds perfect.（从句缺主语）\n\n4. 可见，引导词也可按其本身词性（从句中担当成分）分类：\n\n\t1. 代词，从句中充当主语、宾语：who, whom, that, which\n\t2. 副词，从句中不充当主干：where, when, why\n\t3. 形容词，从句中充当定语：whose\n\n5. eg：\n\n\t1. 那个老妇人在儿子到达的当天去世了。 \n\n\t\tThe old lady died on that day when her son arrived.\n\n\t2. 女孩还是喜欢王子送给她的珠宝。\n\n\t\tThe girl prefers the jewelry which/that the prince sent to her.\n\n\t3. 把孩子们放到一个他们能够看到不同的自己的地方是很重要的。\n\n\t\tIt`s important to put children into a place where they can see themselves in different circumstances.\n\n<br/>\n\n## 5. 定语从句的特殊用法\n\n1. that引导，若充当宾语，that可省略（呈现出两个名词（短语）直接放在一起）:\n\n\t1. I enjoy the movie Zhao Wei directed.\n\t2. The potential evolution of today`s technology, and its social consequences, is dazzlingly complicated, and it's perhaps best left to science-fiction writers and futurologists to explore **the many possibilities we can envisage**. 现代技术的潜在发展和它产生的社会影响是极其复杂的，所以最好把它留给科幻小说作家和未来学家去发掘我们所能想象到的许许多多的可能性。\n\n2. 区分限定性定语从句和非限定性定语从句\n\n\t1. eg： \n\t\tA nurse is a person who looks after patients.(限定)\n\n\t\tTom`s father, who is over sixty, still works hard.（非限定）\n\n\t\tHe said he had climbed up the top of the Everest, which I suspect very much.（非限定，对整个句子修饰）\n\n\t\t他说他曾爬上珠峰顶，我对十分怀疑。\n\n\t2. 区别：\n\n\t\t1. 限定性定语从句：与先行词关系紧密，删除后影响句意、不用逗号、可用that、引导词作宾语可省略、不可以修饰句子、常译为定语\n\t\t2. 非限定性定语从句：与先行词关系疏松，起补充说明作用、用逗号、**不可用that**、**引导词作宾语不可省略**、可以修饰句子、**常译为两个句子**\n\n3. 介词+关系代词 引导的定语从句\n\n\twhere, when, why在从句中作状语时，可变化为介词+关系代词，非重点，尝试换回寻常副词翻译即可。\n\n4. the same … as 和 the same … that\n\n\teg：\n\n\tDarcy is the same man as I love. 我喜欢的是**像**达西先生**一样**的人。（**主句从句，同类不同物**）\n\n\tDarcy is the same man that I love. 我喜欢的男人**正是**达西先生。（**主句从句，指同一物**）\n\n5. as和which引导的非限定性定语从句\n\n\t1. 相同点：二者都可以引导非限定性定语从句\n\n\t2. 不同点：\n\n\t\t1. as引导的从句，在主句中位置随意；which引导的从句，位于主句后：\n\n\t\t\t**As** we all know, water flows downwards.\n\n\t\t\tWater flows downwards, **which** is known to us all.\n\n\t\t2. as后的动词是be；which后不限制\n\n\t\t\t**As is** known to the US, Mark Twain is a great writer.\n\n\t\t\tImmigrants are quickly fitting into this common culture, **which may** not be altogether elevating but is hardly poisonous. 移民们很快适应了这里的大众文化，它虽然可能不完全引人向上，但至少不会毒害百姓。\n\n6. 定语从句中引导词which和that的区别\n\n\t都可指物，通常可替换。\n\n\twhich：\n\n\t1. 引导非限定性定语从句\n\t2. 放在介词后作宾语（介词+关系代词的引导词 5.3）\n\n\tthat：\n\n\t1. 当先行词是much, little, none, all, few, every(thing), any(thing), no(thing)等时\n\n\t\teg：I did nothing that might hurt you.\n\n\t2. 主句以here, there开头时\n\n\t\teg: Here is the hotel that you`ve been lokking for.\n\n\t3. 当先行词被the only, the same, the very等限定词修饰时\n\n\t\teg: This is the first film that has been shown in our school this term.\n\n\t4. 先行词被any, few, little, no, all, much, some等修饰时\n\n\t\teg: You can take any seat that is free.\n\n\t5. 当先行词被序数词、形容词最高级修饰时\n\n\t6. 当先行词是who, which, what或主句以此开头时\n\n\t\teg: Which is the star that is nearer to the earth?\n\n\t7. 当先行词既有人又有物时\n\n\t\teg: They are talking of the heroines and their deeds that interest them.\n\n<br/>\n\n## 6. 区分定语从句和同位语从句\n\n:one: I had a dream that was definitely sweet.\n\n:two: ​I had a dream that I would become a rich lady someday.\n\n1是定语从句。2是同位语从句。\n\n相同：都是先行词+引导词+分句\n\n不同：1中that在从句中充当成分，而2中不然。\n\n<br>\n\n## 7. 定语从句的至难点\n\nThe words used by the speaker may stir up unfavorable reactions in the listener __ interfere with his comprehension; hence, the transmission-reception system breaks down.\n\nA. who\tB. as\tC. which\tD. what\n\n说话人的语言会激起听者不好的反应，__影响他的判断。\n\n“他的”指说话人，则空格处指“不好的反应”，即先行词是“reaction”，选C。\n\n**定语从句难点：判断先行词。**\n\neg:\n\nFor workers it can mean an end to the security, benefits nad sense of importance **that** came from being a loyal employee. （that指前面并列三者）\n\n对于工人来说，它可能意味着作为一名忠实员工的安全、利益和重要感的结束。\n\nThe Greeks assumed that the structure of language had some connection with the process of thought, **which** took root in Europe long before people realized how diverse languages could be. （which指前面整句）\n\n希腊人认为语言的结构和思维的过程有某种联系，这种观点早在人们认识到语言的多样性之前就在欧洲扎根了。\n\n<br/>\n\n## 8. 定语和定语从句的应用\n\n1. 写作\n\n\t**作文中出现名词（短语）时，都可以尝试加定语。**\n\n\teg：\n\n\t1. 养宠物的好处？\n\n\t\tKeeping pets can reduce loneliness.\n\n\t\t:arrow_down:\n\n\t\tKeeping pets which look so cute and lovely can reduce loneliness of some old citizens and children who stay at home alone.\n\n\t2. 盲目追星的危害？\n\n\t\tPursuing stars blindly will waste time.\n\n\t\t:arrow_down:\n\n\t\tPursuing stars looking so handsome or beautiful blindly will waste time of young people who should spend more time and energy on their studies.\n\n\t3. 描述图画：*文化“火锅”，既美味又营养*\n\n\t\tIn the vivid and simple cartoon, a hot pot which looks not only delicious but also nutrient, cooking while it is smoking, is filled with different cultures including Chinese and western ones such as Buddha, Bi Sheng and Shakespeare.\n\n2. 长难句分析\n\n\t找到定语，分离，翻译\n\n\t1. 如何找定语：先找名词（短语），其后不是动词（词组），就大概率是定语（也可能是状语）\n\t2. 定语翻译：定语较短时，翻译到先行词前面；定语较长时，后置，重复先行词或用相应词代替\n\n\teg:\n\n\t1. Some of the these causes are completely reasonable results of social needs. Others are reasonable consequences of particular advances in science being to some extent self-accelerating.\n\n\t\t定语1：of social needs\n\n\t\t定语2：of particular advances in science being to some extent self-accelerating\n\n\t\t定语2内含小定语2.1：of particular advances\n\n\t\t2.2：in science\n\n\t\t2.3：being to some extent self-accelerating\n\n\t\t**多个定语时，从后向前翻译。**\n\n\t\t其中一些原因完全是社会需要的合理结果。其他则是在某种程度上自我加速的科学上的特殊进步的合理结果。\n\n\t2. In short, a leader of the new school contends, “the scientific revolution, as we call it, was largely the improvement and invention and use of a series of instruments that expanded the reach of science in innumerable directions.”\n\n\t\t定语1：of the new school\n\n\t\t定语2：of a series of instruments that expanded the reach of science in innumerable directions\n\n\t\t2.1：of a series of instruments\n\n\t\t2.2：that expanded the reach of science in innumerable directions\n\n\t\t插入语：as we call it\n\n\t\t简而言之，新学派的一个领袖认为，“我们所说的科学革命很大程度上是**一系列**工具的改善、发明和使用，**而这些工具在无数个方向上扩大了科学所达到的范围**。”\n\n\t\t**（短定语前置，长定语后置同时重复了先行词）**\n\n\t3. After six months of arguing and final 16 hours of hot parliamentary debates, Australia`s Northern Territory became the first legal authority in the world to allow doctors to take the lives of incurably ill patients who wish to die.\n\n\t\t其中的allow … to do …，为固定搭配，分解成分时不要断开。\n\n\t\t经过六个月的争论和最后16个小时激烈的议会争辩，澳大利亚的北领地成为世界上第一个允许医生根据绝症病人个人意愿来结束其生命的合法政府。\n\n\t4. Weather to use tests, other kinds of information, or both in a particular situation depends, therefore, upon the evidence from experience concerning comparative validity and upon such factors as costs and availability.\n\n\t\t其中，and upon的and，并列连词，新开一句，前面的定语到此终止。\n\n\t\t因此，是使用测试或其他种类的信息，还是在一种特殊条件下同时使用两者，这取决于和相对有效性有关的来自经验的证据，也取决于诸如成本和可用性等因素。\n\n## 9. 总结\n\n定语从名词（短语）后开始，一般到主句的谓语前结束。\n\n但是如果主句的谓语在定语前出现，定语通常到句末结束。\n\n大定语中常有很多小定语，每个小定语到下一个名词处结束，翻译时从最后一个小定语向前翻译。\n\n例外一是名词前后的词是固定搭配，则定语应到固定搭配后结束。\n\n例外二是并列连词会隔断定语，定语到连词前结束（若只是连接两个单词，则不隔断）。\n\n\n\n","source":"_posts/英语4：定语和定语从句.md","raw":"---\ntitle: 语法4：定语和定语从句\nmathjax: false\ndate: 2020-07-02 22:58:07\ntags: 英语\n\n---\n\n\n\n\n\n《刘晓艳语法长难句》第四章笔记\n\n<br/>\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n\n\n[toc]\n\n# 定语和定语从句\n\n## 1. 定语\n\n定语就是修饰名词/短语的成分。\n\neg：\n\n​\t它是一只**善良的**夜莺。\n\n​\t**住在年轻人隔壁的**女孩应该很漂亮。\n\n<br/>\n\n## 2. 定语的成分\n\n1. 形容词（短语）作定语\n\n\t1. 那只善良的夜莺最后死了。 \n\n\t\tThat **kind** nightingale died at last.\n\n\t2. 这朵非凡的玫瑰花变成了深红色。 \n\n\t\tThe **extraordinary** rose turns dark red.\n\n2. 形容词化的名词（短语）作定语\n\n\t夜莺的歌声能使这朵玫瑰花开放。 \n\n\t**The nightingale`s** singing can make the rose bloom. \n\n\tThe singing **of the nightingale** can make the rose bloom. （常用）\n\n3. 介词短语作定语\n\n\t1. 窗外的夜莺听到了年轻人的感叹。\n\n\t\tThe nightingale **out of the window** heard the sighs of the young man.\n\n\t2. 我只有和大海的浪花一样白的玫瑰花。\n\n\t\tI only have roses **as white as the foam in the sea**.\n\n4. 分词、不定式（非谓语）作定语\n\n\t1. 唱歌的夜莺最终因爱而死。\n\n\t\tIn the end, the **singing** nightingale died because of love.\n\n\t2. 单纯的夜莺一定是爱上了那个被女孩欺骗的学生。\n\n\t\tThe innocent nightingale must have loved the student **deceived by the girl**.\n\n5. 从句作定语\n\n\t夜莺用生命换来的玫瑰花并没有帮到那个学生。\n\n\tThe rose **Which the nightingale exchanged with her life** failed to help the student.\n\n<br/>\n\n## 3. 定语的位置\n\n不同于汉语的名词前，英语中定语位置“前小后大”。即，定语的位置取决于其长度。另，过去分词作定语，即使一个单词也要置后。\n\neg: 他是一个被抛弃的男人。He is a man abandoned.\n\n<br/>\n\n## 4. 定语从句\n\n1. 构成：先行词（名词（短语）） + 引导词 + 分句\n\n2. 引导词：按照先行词分类\n\n\t1. 人：who, whom, whose \n\t2. 物：that, which, whose\n\t3. 时间：that, which, when\n\t4. 地点：that, which, where\n\t5. 原因：that, which, why. 通常情况下that等同于which\n\n3. 用例：\n\n\t1. He is the man **who** loves me.（who从句充当主语或宾语）\n\t2. He is the man **who/whom** I love.（whom从句中充当宾语）\n\t3. He is the man **whose** father is wealthy.（whose从句中定语）\n\t4. I will never forget the day **when** I met you.(从句不缺成分)\n\t5. I will never forget the day **which/that** we spent.(主语或宾语)\n\t6. You had better have some reason **why** you are late.(从句不缺成分)\n\t7. You had better have some reason **which/that** sounds perfect.（从句缺主语）\n\n4. 可见，引导词也可按其本身词性（从句中担当成分）分类：\n\n\t1. 代词，从句中充当主语、宾语：who, whom, that, which\n\t2. 副词，从句中不充当主干：where, when, why\n\t3. 形容词，从句中充当定语：whose\n\n5. eg：\n\n\t1. 那个老妇人在儿子到达的当天去世了。 \n\n\t\tThe old lady died on that day when her son arrived.\n\n\t2. 女孩还是喜欢王子送给她的珠宝。\n\n\t\tThe girl prefers the jewelry which/that the prince sent to her.\n\n\t3. 把孩子们放到一个他们能够看到不同的自己的地方是很重要的。\n\n\t\tIt`s important to put children into a place where they can see themselves in different circumstances.\n\n<br/>\n\n## 5. 定语从句的特殊用法\n\n1. that引导，若充当宾语，that可省略（呈现出两个名词（短语）直接放在一起）:\n\n\t1. I enjoy the movie Zhao Wei directed.\n\t2. The potential evolution of today`s technology, and its social consequences, is dazzlingly complicated, and it's perhaps best left to science-fiction writers and futurologists to explore **the many possibilities we can envisage**. 现代技术的潜在发展和它产生的社会影响是极其复杂的，所以最好把它留给科幻小说作家和未来学家去发掘我们所能想象到的许许多多的可能性。\n\n2. 区分限定性定语从句和非限定性定语从句\n\n\t1. eg： \n\t\tA nurse is a person who looks after patients.(限定)\n\n\t\tTom`s father, who is over sixty, still works hard.（非限定）\n\n\t\tHe said he had climbed up the top of the Everest, which I suspect very much.（非限定，对整个句子修饰）\n\n\t\t他说他曾爬上珠峰顶，我对十分怀疑。\n\n\t2. 区别：\n\n\t\t1. 限定性定语从句：与先行词关系紧密，删除后影响句意、不用逗号、可用that、引导词作宾语可省略、不可以修饰句子、常译为定语\n\t\t2. 非限定性定语从句：与先行词关系疏松，起补充说明作用、用逗号、**不可用that**、**引导词作宾语不可省略**、可以修饰句子、**常译为两个句子**\n\n3. 介词+关系代词 引导的定语从句\n\n\twhere, when, why在从句中作状语时，可变化为介词+关系代词，非重点，尝试换回寻常副词翻译即可。\n\n4. the same … as 和 the same … that\n\n\teg：\n\n\tDarcy is the same man as I love. 我喜欢的是**像**达西先生**一样**的人。（**主句从句，同类不同物**）\n\n\tDarcy is the same man that I love. 我喜欢的男人**正是**达西先生。（**主句从句，指同一物**）\n\n5. as和which引导的非限定性定语从句\n\n\t1. 相同点：二者都可以引导非限定性定语从句\n\n\t2. 不同点：\n\n\t\t1. as引导的从句，在主句中位置随意；which引导的从句，位于主句后：\n\n\t\t\t**As** we all know, water flows downwards.\n\n\t\t\tWater flows downwards, **which** is known to us all.\n\n\t\t2. as后的动词是be；which后不限制\n\n\t\t\t**As is** known to the US, Mark Twain is a great writer.\n\n\t\t\tImmigrants are quickly fitting into this common culture, **which may** not be altogether elevating but is hardly poisonous. 移民们很快适应了这里的大众文化，它虽然可能不完全引人向上，但至少不会毒害百姓。\n\n6. 定语从句中引导词which和that的区别\n\n\t都可指物，通常可替换。\n\n\twhich：\n\n\t1. 引导非限定性定语从句\n\t2. 放在介词后作宾语（介词+关系代词的引导词 5.3）\n\n\tthat：\n\n\t1. 当先行词是much, little, none, all, few, every(thing), any(thing), no(thing)等时\n\n\t\teg：I did nothing that might hurt you.\n\n\t2. 主句以here, there开头时\n\n\t\teg: Here is the hotel that you`ve been lokking for.\n\n\t3. 当先行词被the only, the same, the very等限定词修饰时\n\n\t\teg: This is the first film that has been shown in our school this term.\n\n\t4. 先行词被any, few, little, no, all, much, some等修饰时\n\n\t\teg: You can take any seat that is free.\n\n\t5. 当先行词被序数词、形容词最高级修饰时\n\n\t6. 当先行词是who, which, what或主句以此开头时\n\n\t\teg: Which is the star that is nearer to the earth?\n\n\t7. 当先行词既有人又有物时\n\n\t\teg: They are talking of the heroines and their deeds that interest them.\n\n<br/>\n\n## 6. 区分定语从句和同位语从句\n\n:one: I had a dream that was definitely sweet.\n\n:two: ​I had a dream that I would become a rich lady someday.\n\n1是定语从句。2是同位语从句。\n\n相同：都是先行词+引导词+分句\n\n不同：1中that在从句中充当成分，而2中不然。\n\n<br>\n\n## 7. 定语从句的至难点\n\nThe words used by the speaker may stir up unfavorable reactions in the listener __ interfere with his comprehension; hence, the transmission-reception system breaks down.\n\nA. who\tB. as\tC. which\tD. what\n\n说话人的语言会激起听者不好的反应，__影响他的判断。\n\n“他的”指说话人，则空格处指“不好的反应”，即先行词是“reaction”，选C。\n\n**定语从句难点：判断先行词。**\n\neg:\n\nFor workers it can mean an end to the security, benefits nad sense of importance **that** came from being a loyal employee. （that指前面并列三者）\n\n对于工人来说，它可能意味着作为一名忠实员工的安全、利益和重要感的结束。\n\nThe Greeks assumed that the structure of language had some connection with the process of thought, **which** took root in Europe long before people realized how diverse languages could be. （which指前面整句）\n\n希腊人认为语言的结构和思维的过程有某种联系，这种观点早在人们认识到语言的多样性之前就在欧洲扎根了。\n\n<br/>\n\n## 8. 定语和定语从句的应用\n\n1. 写作\n\n\t**作文中出现名词（短语）时，都可以尝试加定语。**\n\n\teg：\n\n\t1. 养宠物的好处？\n\n\t\tKeeping pets can reduce loneliness.\n\n\t\t:arrow_down:\n\n\t\tKeeping pets which look so cute and lovely can reduce loneliness of some old citizens and children who stay at home alone.\n\n\t2. 盲目追星的危害？\n\n\t\tPursuing stars blindly will waste time.\n\n\t\t:arrow_down:\n\n\t\tPursuing stars looking so handsome or beautiful blindly will waste time of young people who should spend more time and energy on their studies.\n\n\t3. 描述图画：*文化“火锅”，既美味又营养*\n\n\t\tIn the vivid and simple cartoon, a hot pot which looks not only delicious but also nutrient, cooking while it is smoking, is filled with different cultures including Chinese and western ones such as Buddha, Bi Sheng and Shakespeare.\n\n2. 长难句分析\n\n\t找到定语，分离，翻译\n\n\t1. 如何找定语：先找名词（短语），其后不是动词（词组），就大概率是定语（也可能是状语）\n\t2. 定语翻译：定语较短时，翻译到先行词前面；定语较长时，后置，重复先行词或用相应词代替\n\n\teg:\n\n\t1. Some of the these causes are completely reasonable results of social needs. Others are reasonable consequences of particular advances in science being to some extent self-accelerating.\n\n\t\t定语1：of social needs\n\n\t\t定语2：of particular advances in science being to some extent self-accelerating\n\n\t\t定语2内含小定语2.1：of particular advances\n\n\t\t2.2：in science\n\n\t\t2.3：being to some extent self-accelerating\n\n\t\t**多个定语时，从后向前翻译。**\n\n\t\t其中一些原因完全是社会需要的合理结果。其他则是在某种程度上自我加速的科学上的特殊进步的合理结果。\n\n\t2. In short, a leader of the new school contends, “the scientific revolution, as we call it, was largely the improvement and invention and use of a series of instruments that expanded the reach of science in innumerable directions.”\n\n\t\t定语1：of the new school\n\n\t\t定语2：of a series of instruments that expanded the reach of science in innumerable directions\n\n\t\t2.1：of a series of instruments\n\n\t\t2.2：that expanded the reach of science in innumerable directions\n\n\t\t插入语：as we call it\n\n\t\t简而言之，新学派的一个领袖认为，“我们所说的科学革命很大程度上是**一系列**工具的改善、发明和使用，**而这些工具在无数个方向上扩大了科学所达到的范围**。”\n\n\t\t**（短定语前置，长定语后置同时重复了先行词）**\n\n\t3. After six months of arguing and final 16 hours of hot parliamentary debates, Australia`s Northern Territory became the first legal authority in the world to allow doctors to take the lives of incurably ill patients who wish to die.\n\n\t\t其中的allow … to do …，为固定搭配，分解成分时不要断开。\n\n\t\t经过六个月的争论和最后16个小时激烈的议会争辩，澳大利亚的北领地成为世界上第一个允许医生根据绝症病人个人意愿来结束其生命的合法政府。\n\n\t4. Weather to use tests, other kinds of information, or both in a particular situation depends, therefore, upon the evidence from experience concerning comparative validity and upon such factors as costs and availability.\n\n\t\t其中，and upon的and，并列连词，新开一句，前面的定语到此终止。\n\n\t\t因此，是使用测试或其他种类的信息，还是在一种特殊条件下同时使用两者，这取决于和相对有效性有关的来自经验的证据，也取决于诸如成本和可用性等因素。\n\n## 9. 总结\n\n定语从名词（短语）后开始，一般到主句的谓语前结束。\n\n但是如果主句的谓语在定语前出现，定语通常到句末结束。\n\n大定语中常有很多小定语，每个小定语到下一个名词处结束，翻译时从最后一个小定语向前翻译。\n\n例外一是名词前后的词是固定搭配，则定语应到固定搭配后结束。\n\n例外二是并列连词会隔断定语，定语到连词前结束（若只是连接两个单词，则不隔断）。\n\n\n\n","slug":"英语4：定语和定语从句","published":1,"updated":"2020-07-02T15:06:16.037Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbew8000ni0qv1qvb4gwf","content":"<p>《刘晓艳语法长难句》第四章笔记</p>\n<br>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#%E5%AE%9A%E8%AF%AD%E5%92%8C%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5\">定语和定语从句</a>\n<ul>\n<li><a href=\"#1-%E5%AE%9A%E8%AF%AD\">1. 定语</a></li>\n<li><a href=\"#2-%E5%AE%9A%E8%AF%AD%E7%9A%84%E6%88%90%E5%88%86\">2. 定语的成分</a></li>\n<li><a href=\"#3-%E5%AE%9A%E8%AF%AD%E7%9A%84%E4%BD%8D%E7%BD%AE\">3. 定语的位置</a></li>\n<li><a href=\"#4-%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4. 定语从句</a></li>\n<li><a href=\"#5-%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E7%89%B9%E6%AE%8A%E7%94%A8%E6%B3%95\">5. 定语从句的特殊用法</a></li>\n<li><a href=\"#6-%E5%8C%BA%E5%88%86%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E5%92%8C%E5%90%8C%E4%BD%8D%E8%AF%AD%E4%BB%8E%E5%8F%A5\">6. 区分定语从句和同位语从句</a></li>\n<li><a href=\"#7-%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E8%87%B3%E9%9A%BE%E7%82%B9\">7. 定语从句的至难点</a></li>\n<li><a href=\"#8-%E5%AE%9A%E8%AF%AD%E5%92%8C%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E5%BA%94%E7%94%A8\">8. 定语和定语从句的应用</a></li>\n<li><a href=\"#9-%E6%80%BB%E7%BB%93\">9. 总结</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<p>[toc]</p>\n<h1><span id=\"定语和定语从句\"> 定语和定语从句</span></h1>\n<h2><span id=\"1-定语\"> 1. 定语</span></h2>\n<p>定语就是修饰名词/短语的成分。</p>\n<p>eg：</p>\n<p>​\t它是一只<strong>善良的</strong>夜莺。</p>\n<p>​\t<strong>住在年轻人隔壁的</strong>女孩应该很漂亮。</p>\n<br>\n<h2><span id=\"2-定语的成分\"> 2. 定语的成分</span></h2>\n<ol>\n<li>\n<p>形容词（短语）作定语</p>\n<ol>\n<li>\n<p>那只善良的夜莺最后死了。</p>\n<p>That <strong>kind</strong> nightingale died at last.</p>\n</li>\n<li>\n<p>这朵非凡的玫瑰花变成了深红色。</p>\n<p>The <strong>extraordinary</strong> rose turns dark red.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>形容词化的名词（短语）作定语</p>\n<p>夜莺的歌声能使这朵玫瑰花开放。</p>\n<p><strong>The nightingale`s</strong> singing can make the rose bloom.</p>\n<p>The singing <strong>of the nightingale</strong> can make the rose bloom. （常用）</p>\n</li>\n<li>\n<p>介词短语作定语</p>\n<ol>\n<li>\n<p>窗外的夜莺听到了年轻人的感叹。</p>\n<p>The nightingale <strong>out of the window</strong> heard the sighs of the young man.</p>\n</li>\n<li>\n<p>我只有和大海的浪花一样白的玫瑰花。</p>\n<p>I only have roses <strong>as white as the foam in the sea</strong>.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>分词、不定式（非谓语）作定语</p>\n<ol>\n<li>\n<p>唱歌的夜莺最终因爱而死。</p>\n<p>In the end, the <strong>singing</strong> nightingale died because of love.</p>\n</li>\n<li>\n<p>单纯的夜莺一定是爱上了那个被女孩欺骗的学生。</p>\n<p>The innocent nightingale must have loved the student <strong>deceived by the girl</strong>.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>从句作定语</p>\n<p>夜莺用生命换来的玫瑰花并没有帮到那个学生。</p>\n<p>The rose <strong>Which the nightingale exchanged with her life</strong> failed to help the student.</p>\n</li>\n</ol>\n<br>\n<h2><span id=\"3-定语的位置\"> 3. 定语的位置</span></h2>\n<p>不同于汉语的名词前，英语中定语位置“前小后大”。即，定语的位置取决于其长度。另，过去分词作定语，即使一个单词也要置后。</p>\n<p>eg: 他是一个被抛弃的男人。He is a man abandoned.</p>\n<br>\n<h2><span id=\"4-定语从句\"> 4. 定语从句</span></h2>\n<ol>\n<li>\n<p>构成：先行词（名词（短语）） + 引导词 + 分句</p>\n</li>\n<li>\n<p>引导词：按照先行词分类</p>\n<ol>\n<li>人：who, whom, whose</li>\n<li>物：that, which, whose</li>\n<li>时间：that, which, when</li>\n<li>地点：that, which, where</li>\n<li>原因：that, which, why. 通常情况下that等同于which</li>\n</ol>\n</li>\n<li>\n<p>用例：</p>\n<ol>\n<li>He is the man <strong>who</strong> loves me.（who从句充当主语或宾语）</li>\n<li>He is the man <strong>who/whom</strong> I love.（whom从句中充当宾语）</li>\n<li>He is the man <strong>whose</strong> father is wealthy.（whose从句中定语）</li>\n<li>I will never forget the day <strong>when</strong> I met you.(从句不缺成分)</li>\n<li>I will never forget the day <strong>which/that</strong> we spent.(主语或宾语)</li>\n<li>You had better have some reason <strong>why</strong> you are late.(从句不缺成分)</li>\n<li>You had better have some reason <strong>which/that</strong> sounds perfect.（从句缺主语）</li>\n</ol>\n</li>\n<li>\n<p>可见，引导词也可按其本身词性（从句中担当成分）分类：</p>\n<ol>\n<li>代词，从句中充当主语、宾语：who, whom, that, which</li>\n<li>副词，从句中不充当主干：where, when, why</li>\n<li>形容词，从句中充当定语：whose</li>\n</ol>\n</li>\n<li>\n<p>eg：</p>\n<ol>\n<li>\n<p>那个老妇人在儿子到达的当天去世了。</p>\n<p>The old lady died on that day when her son arrived.</p>\n</li>\n<li>\n<p>女孩还是喜欢王子送给她的珠宝。</p>\n<p>The girl prefers the jewelry which/that the prince sent to her.</p>\n</li>\n<li>\n<p>把孩子们放到一个他们能够看到不同的自己的地方是很重要的。</p>\n<p>It`s important to put children into a place where they can see themselves in different circumstances.</p>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h2><span id=\"5-定语从句的特殊用法\"> 5. 定语从句的特殊用法</span></h2>\n<ol>\n<li>\n<p>that引导，若充当宾语，that可省略（呈现出两个名词（短语）直接放在一起）:</p>\n<ol>\n<li>I enjoy the movie Zhao Wei directed.</li>\n<li>The potential evolution of today`s technology, and its social consequences, is dazzlingly complicated, and it’s perhaps best left to science-fiction writers and futurologists to explore <strong>the many possibilities we can envisage</strong>. 现代技术的潜在发展和它产生的社会影响是极其复杂的，所以最好把它留给科幻小说作家和未来学家去发掘我们所能想象到的许许多多的可能性。</li>\n</ol>\n</li>\n<li>\n<p>区分限定性定语从句和非限定性定语从句</p>\n<ol>\n<li>\n<p>eg：<br>\nA nurse is a person who looks after patients.(限定)</p>\n<p>Tom`s father, who is over sixty, still works hard.（非限定）</p>\n<p>He said he had climbed up the top of the Everest, which I suspect very much.（非限定，对整个句子修饰）</p>\n<p>他说他曾爬上珠峰顶，我对十分怀疑。</p>\n</li>\n<li>\n<p>区别：</p>\n<ol>\n<li>限定性定语从句：与先行词关系紧密，删除后影响句意、不用逗号、可用that、引导词作宾语可省略、不可以修饰句子、常译为定语</li>\n<li>非限定性定语从句：与先行词关系疏松，起补充说明作用、用逗号、<strong>不可用that</strong>、<strong>引导词作宾语不可省略</strong>、可以修饰句子、<strong>常译为两个句子</strong></li>\n</ol>\n</li>\n</ol>\n</li>\n<li>\n<p>介词+关系代词 引导的定语从句</p>\n<p>where, when, why在从句中作状语时，可变化为介词+关系代词，非重点，尝试换回寻常副词翻译即可。</p>\n</li>\n<li>\n<p>the same … as 和 the same … that</p>\n<p>eg：</p>\n<p>Darcy is the same man as I love. 我喜欢的是<strong>像</strong>达西先生<strong>一样</strong>的人。（<strong>主句从句，同类不同物</strong>）</p>\n<p>Darcy is the same man that I love. 我喜欢的男人<strong>正是</strong>达西先生。（<strong>主句从句，指同一物</strong>）</p>\n</li>\n<li>\n<p>as和which引导的非限定性定语从句</p>\n<ol>\n<li>\n<p>相同点：二者都可以引导非限定性定语从句</p>\n</li>\n<li>\n<p>不同点：</p>\n<ol>\n<li>\n<p>as引导的从句，在主句中位置随意；which引导的从句，位于主句后：</p>\n<p><strong>As</strong> we all know, water flows downwards.</p>\n<p>Water flows downwards, <strong>which</strong> is known to us all.</p>\n</li>\n<li>\n<p>as后的动词是be；which后不限制</p>\n<p><strong>As is</strong> known to the US, Mark Twain is a great writer.</p>\n<p>Immigrants are quickly fitting into this common culture, <strong>which may</strong> not be altogether elevating but is hardly poisonous. 移民们很快适应了这里的大众文化，它虽然可能不完全引人向上，但至少不会毒害百姓。</p>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>\n<p>定语从句中引导词which和that的区别</p>\n<p>都可指物，通常可替换。</p>\n<p>which：</p>\n<ol>\n<li>引导非限定性定语从句</li>\n<li>放在介词后作宾语（介词+关系代词的引导词 5.3）</li>\n</ol>\n<p>that：</p>\n<ol>\n<li>\n<p>当先行词是much, little, none, all, few, every(thing), any(thing), no(thing)等时</p>\n<p>eg：I did nothing that might hurt you.</p>\n</li>\n<li>\n<p>主句以here, there开头时</p>\n<p>eg: Here is the hotel that you`ve been lokking for.</p>\n</li>\n<li>\n<p>当先行词被the only, the same, the very等限定词修饰时</p>\n<p>eg: This is the first film that has been shown in our school this term.</p>\n</li>\n<li>\n<p>先行词被any, few, little, no, all, much, some等修饰时</p>\n<p>eg: You can take any seat that is free.</p>\n</li>\n<li>\n<p>当先行词被序数词、形容词最高级修饰时</p>\n</li>\n<li>\n<p>当先行词是who, which, what或主句以此开头时</p>\n<p>eg: Which is the star that is nearer to the earth?</p>\n</li>\n<li>\n<p>当先行词既有人又有物时</p>\n<p>eg: They are talking of the heroines and their deeds that interest them.</p>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h2><span id=\"6-区分定语从句和同位语从句\"> 6. 区分定语从句和同位语从句</span></h2>\n<p>1️⃣ I had a dream that was definitely sweet.</p>\n<p>2️⃣ ​I had a dream that I would become a rich lady someday.</p>\n<p>1是定语从句。2是同位语从句。</p>\n<p>相同：都是先行词+引导词+分句</p>\n<p>不同：1中that在从句中充当成分，而2中不然。</p>\n<br>\n<h2><span id=\"7-定语从句的至难点\"> 7. 定语从句的至难点</span></h2>\n<p>The words used by the speaker may stir up unfavorable reactions in the listener __ interfere with his comprehension; hence, the transmission-reception system breaks down.</p>\n<p>A. who\tB. as\tC. which\tD. what</p>\n<p>说话人的语言会激起听者不好的反应，__影响他的判断。</p>\n<p>“他的”指说话人，则空格处指“不好的反应”，即先行词是“reaction”，选C。</p>\n<p><strong>定语从句难点：判断先行词。</strong></p>\n<p>eg:</p>\n<p>For workers it can mean an end to the security, benefits nad sense of importance <strong>that</strong> came from being a loyal employee. （that指前面并列三者）</p>\n<p>对于工人来说，它可能意味着作为一名忠实员工的安全、利益和重要感的结束。</p>\n<p>The Greeks assumed that the structure of language had some connection with the process of thought, <strong>which</strong> took root in Europe long before people realized how diverse languages could be. （which指前面整句）</p>\n<p>希腊人认为语言的结构和思维的过程有某种联系，这种观点早在人们认识到语言的多样性之前就在欧洲扎根了。</p>\n<br>\n<h2><span id=\"8-定语和定语从句的应用\"> 8. 定语和定语从句的应用</span></h2>\n<ol>\n<li>\n<p>写作</p>\n<p><strong>作文中出现名词（短语）时，都可以尝试加定语。</strong></p>\n<p>eg：</p>\n<ol>\n<li>\n<p>养宠物的好处？</p>\n<p>Keeping pets can reduce loneliness.</p>\n<p>⬇️</p>\n<p>Keeping pets which look so cute and lovely can reduce loneliness of some old citizens and children who stay at home alone.</p>\n</li>\n<li>\n<p>盲目追星的危害？</p>\n<p>Pursuing stars blindly will waste time.</p>\n<p>⬇️</p>\n<p>Pursuing stars looking so handsome or beautiful blindly will waste time of young people who should spend more time and energy on their studies.</p>\n</li>\n<li>\n<p>描述图画：<em>文化“火锅”，既美味又营养</em></p>\n<p>In the vivid and simple cartoon, a hot pot which looks not only delicious but also nutrient, cooking while it is smoking, is filled with different cultures including Chinese and western ones such as Buddha, Bi Sheng and Shakespeare.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>长难句分析</p>\n<p>找到定语，分离，翻译</p>\n<ol>\n<li>如何找定语：先找名词（短语），其后不是动词（词组），就大概率是定语（也可能是状语）</li>\n<li>定语翻译：定语较短时，翻译到先行词前面；定语较长时，后置，重复先行词或用相应词代替</li>\n</ol>\n<p>eg:</p>\n<ol>\n<li>\n<p>Some of the these causes are completely reasonable results of social needs. Others are reasonable consequences of particular advances in science being to some extent self-accelerating.</p>\n<p>定语1：of social needs</p>\n<p>定语2：of particular advances in science being to some extent self-accelerating</p>\n<p>定语2内含小定语2.1：of particular advances</p>\n<p>2.2：in science</p>\n<p>2.3：being to some extent self-accelerating</p>\n<p><strong>多个定语时，从后向前翻译。</strong></p>\n<p>其中一些原因完全是社会需要的合理结果。其他则是在某种程度上自我加速的科学上的特殊进步的合理结果。</p>\n</li>\n<li>\n<p>In short, a leader of the new school contends, “the scientific revolution, as we call it, was largely the improvement and invention and use of a series of instruments that expanded the reach of science in innumerable directions.”</p>\n<p>定语1：of the new school</p>\n<p>定语2：of a series of instruments that expanded the reach of science in innumerable directions</p>\n<p>2.1：of a series of instruments</p>\n<p>2.2：that expanded the reach of science in innumerable directions</p>\n<p>插入语：as we call it</p>\n<p>简而言之，新学派的一个领袖认为，“我们所说的科学革命很大程度上是<strong>一系列</strong>工具的改善、发明和使用，<strong>而这些工具在无数个方向上扩大了科学所达到的范围</strong>。”</p>\n<p><strong>（短定语前置，长定语后置同时重复了先行词）</strong></p>\n</li>\n<li>\n<p>After six months of arguing and final 16 hours of hot parliamentary debates, Australia`s Northern Territory became the first legal authority in the world to allow doctors to take the lives of incurably ill patients who wish to die.</p>\n<p>其中的allow … to do …，为固定搭配，分解成分时不要断开。</p>\n<p>经过六个月的争论和最后16个小时激烈的议会争辩，澳大利亚的北领地成为世界上第一个允许医生根据绝症病人个人意愿来结束其生命的合法政府。</p>\n</li>\n<li>\n<p>Weather to use tests, other kinds of information, or both in a particular situation depends, therefore, upon the evidence from experience concerning comparative validity and upon such factors as costs and availability.</p>\n<p>其中，and upon的and，并列连词，新开一句，前面的定语到此终止。</p>\n<p>因此，是使用测试或其他种类的信息，还是在一种特殊条件下同时使用两者，这取决于和相对有效性有关的来自经验的证据，也取决于诸如成本和可用性等因素。</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"9-总结\"> 9. 总结</span></h2>\n<p>定语从名词（短语）后开始，一般到主句的谓语前结束。</p>\n<p>但是如果主句的谓语在定语前出现，定语通常到句末结束。</p>\n<p>大定语中常有很多小定语，每个小定语到下一个名词处结束，翻译时从最后一个小定语向前翻译。</p>\n<p>例外一是名词前后的词是固定搭配，则定语应到固定搭配后结束。</p>\n<p>例外二是并列连词会隔断定语，定语到连词前结束（若只是连接两个单词，则不隔断）。</p>\n","site":{"data":{}},"excerpt":"<p>《刘晓艳语法长难句》第四章笔记</p>\n<br>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#%E5%AE%9A%E8%AF%AD%E5%92%8C%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5\">定语和定语从句</a>\n<ul>\n<li><a href=\"#1-%E5%AE%9A%E8%AF%AD\">1. 定语</a></li>\n<li><a href=\"#2-%E5%AE%9A%E8%AF%AD%E7%9A%84%E6%88%90%E5%88%86\">2. 定语的成分</a></li>\n<li><a href=\"#3-%E5%AE%9A%E8%AF%AD%E7%9A%84%E4%BD%8D%E7%BD%AE\">3. 定语的位置</a></li>\n<li><a href=\"#4-%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4. 定语从句</a></li>\n<li><a href=\"#5-%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E7%89%B9%E6%AE%8A%E7%94%A8%E6%B3%95\">5. 定语从句的特殊用法</a></li>\n<li><a href=\"#6-%E5%8C%BA%E5%88%86%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E5%92%8C%E5%90%8C%E4%BD%8D%E8%AF%AD%E4%BB%8E%E5%8F%A5\">6. 区分定语从句和同位语从句</a></li>\n<li><a href=\"#7-%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E8%87%B3%E9%9A%BE%E7%82%B9\">7. 定语从句的至难点</a></li>\n<li><a href=\"#8-%E5%AE%9A%E8%AF%AD%E5%92%8C%E5%AE%9A%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E5%BA%94%E7%94%A8\">8. 定语和定语从句的应用</a></li>\n<li><a href=\"#9-%E6%80%BB%E7%BB%93\">9. 总结</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<p>[toc]</p>\n<h1 id=\"定语和定语从句\"><a class=\"markdownIt-Anchor\" href=\"#定语和定语从句\"></a> 定语和定语从句</h1>\n<h2 id=\"1-定语\"><a class=\"markdownIt-Anchor\" href=\"#1-定语\"></a> 1. 定语</h2>\n<p>定语就是修饰名词/短语的成分。</p>\n<p>eg：</p>\n<p>​\t它是一只<strong>善良的</strong>夜莺。</p>\n<p>​\t<strong>住在年轻人隔壁的</strong>女孩应该很漂亮。</p>\n<br>\n<h2 id=\"2-定语的成分\"><a class=\"markdownIt-Anchor\" href=\"#2-定语的成分\"></a> 2. 定语的成分</h2>\n<ol>\n<li>\n<p>形容词（短语）作定语</p>\n<ol>\n<li>\n<p>那只善良的夜莺最后死了。</p>\n<p>That <strong>kind</strong> nightingale died at last.</p>\n</li>\n<li>\n<p>这朵非凡的玫瑰花变成了深红色。</p>\n<p>The <strong>extraordinary</strong> rose turns dark red.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>形容词化的名词（短语）作定语</p>\n<p>夜莺的歌声能使这朵玫瑰花开放。</p>\n<p><strong>The nightingale`s</strong> singing can make the rose bloom.</p>\n<p>The singing <strong>of the nightingale</strong> can make the rose bloom. （常用）</p>\n</li>\n<li>\n<p>介词短语作定语</p>\n<ol>\n<li>\n<p>窗外的夜莺听到了年轻人的感叹。</p>\n<p>The nightingale <strong>out of the window</strong> heard the sighs of the young man.</p>\n</li>\n<li>\n<p>我只有和大海的浪花一样白的玫瑰花。</p>\n<p>I only have roses <strong>as white as the foam in the sea</strong>.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>分词、不定式（非谓语）作定语</p>\n<ol>\n<li>\n<p>唱歌的夜莺最终因爱而死。</p>\n<p>In the end, the <strong>singing</strong> nightingale died because of love.</p>\n</li>\n<li>\n<p>单纯的夜莺一定是爱上了那个被女孩欺骗的学生。</p>\n<p>The innocent nightingale must have loved the student <strong>deceived by the girl</strong>.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>从句作定语</p>\n<p>夜莺用生命换来的玫瑰花并没有帮到那个学生。</p>\n<p>The rose <strong>Which the nightingale exchanged with her life</strong> failed to help the student.</p>\n</li>\n</ol>\n<br>\n<h2 id=\"3-定语的位置\"><a class=\"markdownIt-Anchor\" href=\"#3-定语的位置\"></a> 3. 定语的位置</h2>\n<p>不同于汉语的名词前，英语中定语位置“前小后大”。即，定语的位置取决于其长度。另，过去分词作定语，即使一个单词也要置后。</p>\n<p>eg: 他是一个被抛弃的男人。He is a man abandoned.</p>\n<br>\n<h2 id=\"4-定语从句\"><a class=\"markdownIt-Anchor\" href=\"#4-定语从句\"></a> 4. 定语从句</h2>\n<ol>\n<li>\n<p>构成：先行词（名词（短语）） + 引导词 + 分句</p>\n</li>\n<li>\n<p>引导词：按照先行词分类</p>\n<ol>\n<li>人：who, whom, whose</li>\n<li>物：that, which, whose</li>\n<li>时间：that, which, when</li>\n<li>地点：that, which, where</li>\n<li>原因：that, which, why. 通常情况下that等同于which</li>\n</ol>\n</li>\n<li>\n<p>用例：</p>\n<ol>\n<li>He is the man <strong>who</strong> loves me.（who从句充当主语或宾语）</li>\n<li>He is the man <strong>who/whom</strong> I love.（whom从句中充当宾语）</li>\n<li>He is the man <strong>whose</strong> father is wealthy.（whose从句中定语）</li>\n<li>I will never forget the day <strong>when</strong> I met you.(从句不缺成分)</li>\n<li>I will never forget the day <strong>which/that</strong> we spent.(主语或宾语)</li>\n<li>You had better have some reason <strong>why</strong> you are late.(从句不缺成分)</li>\n<li>You had better have some reason <strong>which/that</strong> sounds perfect.（从句缺主语）</li>\n</ol>\n</li>\n<li>\n<p>可见，引导词也可按其本身词性（从句中担当成分）分类：</p>\n<ol>\n<li>代词，从句中充当主语、宾语：who, whom, that, which</li>\n<li>副词，从句中不充当主干：where, when, why</li>\n<li>形容词，从句中充当定语：whose</li>\n</ol>\n</li>\n<li>\n<p>eg：</p>\n<ol>\n<li>\n<p>那个老妇人在儿子到达的当天去世了。</p>\n<p>The old lady died on that day when her son arrived.</p>\n</li>\n<li>\n<p>女孩还是喜欢王子送给她的珠宝。</p>\n<p>The girl prefers the jewelry which/that the prince sent to her.</p>\n</li>\n<li>\n<p>把孩子们放到一个他们能够看到不同的自己的地方是很重要的。</p>\n<p>It`s important to put children into a place where they can see themselves in different circumstances.</p>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h2 id=\"5-定语从句的特殊用法\"><a class=\"markdownIt-Anchor\" href=\"#5-定语从句的特殊用法\"></a> 5. 定语从句的特殊用法</h2>\n<ol>\n<li>\n<p>that引导，若充当宾语，that可省略（呈现出两个名词（短语）直接放在一起）:</p>\n<ol>\n<li>I enjoy the movie Zhao Wei directed.</li>\n<li>The potential evolution of today`s technology, and its social consequences, is dazzlingly complicated, and it’s perhaps best left to science-fiction writers and futurologists to explore <strong>the many possibilities we can envisage</strong>. 现代技术的潜在发展和它产生的社会影响是极其复杂的，所以最好把它留给科幻小说作家和未来学家去发掘我们所能想象到的许许多多的可能性。</li>\n</ol>\n</li>\n<li>\n<p>区分限定性定语从句和非限定性定语从句</p>\n<ol>\n<li>\n<p>eg：<br>\nA nurse is a person who looks after patients.(限定)</p>\n<p>Tom`s father, who is over sixty, still works hard.（非限定）</p>\n<p>He said he had climbed up the top of the Everest, which I suspect very much.（非限定，对整个句子修饰）</p>\n<p>他说他曾爬上珠峰顶，我对十分怀疑。</p>\n</li>\n<li>\n<p>区别：</p>\n<ol>\n<li>限定性定语从句：与先行词关系紧密，删除后影响句意、不用逗号、可用that、引导词作宾语可省略、不可以修饰句子、常译为定语</li>\n<li>非限定性定语从句：与先行词关系疏松，起补充说明作用、用逗号、<strong>不可用that</strong>、<strong>引导词作宾语不可省略</strong>、可以修饰句子、<strong>常译为两个句子</strong></li>\n</ol>\n</li>\n</ol>\n</li>\n<li>\n<p>介词+关系代词 引导的定语从句</p>\n<p>where, when, why在从句中作状语时，可变化为介词+关系代词，非重点，尝试换回寻常副词翻译即可。</p>\n</li>\n<li>\n<p>the same … as 和 the same … that</p>\n<p>eg：</p>\n<p>Darcy is the same man as I love. 我喜欢的是<strong>像</strong>达西先生<strong>一样</strong>的人。（<strong>主句从句，同类不同物</strong>）</p>\n<p>Darcy is the same man that I love. 我喜欢的男人<strong>正是</strong>达西先生。（<strong>主句从句，指同一物</strong>）</p>\n</li>\n<li>\n<p>as和which引导的非限定性定语从句</p>\n<ol>\n<li>\n<p>相同点：二者都可以引导非限定性定语从句</p>\n</li>\n<li>\n<p>不同点：</p>\n<ol>\n<li>\n<p>as引导的从句，在主句中位置随意；which引导的从句，位于主句后：</p>\n<p><strong>As</strong> we all know, water flows downwards.</p>\n<p>Water flows downwards, <strong>which</strong> is known to us all.</p>\n</li>\n<li>\n<p>as后的动词是be；which后不限制</p>\n<p><strong>As is</strong> known to the US, Mark Twain is a great writer.</p>\n<p>Immigrants are quickly fitting into this common culture, <strong>which may</strong> not be altogether elevating but is hardly poisonous. 移民们很快适应了这里的大众文化，它虽然可能不完全引人向上，但至少不会毒害百姓。</p>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>\n<p>定语从句中引导词which和that的区别</p>\n<p>都可指物，通常可替换。</p>\n<p>which：</p>\n<ol>\n<li>引导非限定性定语从句</li>\n<li>放在介词后作宾语（介词+关系代词的引导词 5.3）</li>\n</ol>\n<p>that：</p>\n<ol>\n<li>\n<p>当先行词是much, little, none, all, few, every(thing), any(thing), no(thing)等时</p>\n<p>eg：I did nothing that might hurt you.</p>\n</li>\n<li>\n<p>主句以here, there开头时</p>\n<p>eg: Here is the hotel that you`ve been lokking for.</p>\n</li>\n<li>\n<p>当先行词被the only, the same, the very等限定词修饰时</p>\n<p>eg: This is the first film that has been shown in our school this term.</p>\n</li>\n<li>\n<p>先行词被any, few, little, no, all, much, some等修饰时</p>\n<p>eg: You can take any seat that is free.</p>\n</li>\n<li>\n<p>当先行词被序数词、形容词最高级修饰时</p>\n</li>\n<li>\n<p>当先行词是who, which, what或主句以此开头时</p>\n<p>eg: Which is the star that is nearer to the earth?</p>\n</li>\n<li>\n<p>当先行词既有人又有物时</p>\n<p>eg: They are talking of the heroines and their deeds that interest them.</p>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h2 id=\"6-区分定语从句和同位语从句\"><a class=\"markdownIt-Anchor\" href=\"#6-区分定语从句和同位语从句\"></a> 6. 区分定语从句和同位语从句</h2>\n<p>1️⃣ I had a dream that was definitely sweet.</p>\n<p>2️⃣ ​I had a dream that I would become a rich lady someday.</p>\n<p>1是定语从句。2是同位语从句。</p>\n<p>相同：都是先行词+引导词+分句</p>\n<p>不同：1中that在从句中充当成分，而2中不然。</p>\n<br>\n<h2 id=\"7-定语从句的至难点\"><a class=\"markdownIt-Anchor\" href=\"#7-定语从句的至难点\"></a> 7. 定语从句的至难点</h2>\n<p>The words used by the speaker may stir up unfavorable reactions in the listener __ interfere with his comprehension; hence, the transmission-reception system breaks down.</p>\n<p>A. who\tB. as\tC. which\tD. what</p>\n<p>说话人的语言会激起听者不好的反应，__影响他的判断。</p>\n<p>“他的”指说话人，则空格处指“不好的反应”，即先行词是“reaction”，选C。</p>\n<p><strong>定语从句难点：判断先行词。</strong></p>\n<p>eg:</p>\n<p>For workers it can mean an end to the security, benefits nad sense of importance <strong>that</strong> came from being a loyal employee. （that指前面并列三者）</p>\n<p>对于工人来说，它可能意味着作为一名忠实员工的安全、利益和重要感的结束。</p>\n<p>The Greeks assumed that the structure of language had some connection with the process of thought, <strong>which</strong> took root in Europe long before people realized how diverse languages could be. （which指前面整句）</p>\n<p>希腊人认为语言的结构和思维的过程有某种联系，这种观点早在人们认识到语言的多样性之前就在欧洲扎根了。</p>\n<br>\n<h2 id=\"8-定语和定语从句的应用\"><a class=\"markdownIt-Anchor\" href=\"#8-定语和定语从句的应用\"></a> 8. 定语和定语从句的应用</h2>\n<ol>\n<li>\n<p>写作</p>\n<p><strong>作文中出现名词（短语）时，都可以尝试加定语。</strong></p>\n<p>eg：</p>\n<ol>\n<li>\n<p>养宠物的好处？</p>\n<p>Keeping pets can reduce loneliness.</p>\n<p>⬇️</p>\n<p>Keeping pets which look so cute and lovely can reduce loneliness of some old citizens and children who stay at home alone.</p>\n</li>\n<li>\n<p>盲目追星的危害？</p>\n<p>Pursuing stars blindly will waste time.</p>\n<p>⬇️</p>\n<p>Pursuing stars looking so handsome or beautiful blindly will waste time of young people who should spend more time and energy on their studies.</p>\n</li>\n<li>\n<p>描述图画：<em>文化“火锅”，既美味又营养</em></p>\n<p>In the vivid and simple cartoon, a hot pot which looks not only delicious but also nutrient, cooking while it is smoking, is filled with different cultures including Chinese and western ones such as Buddha, Bi Sheng and Shakespeare.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>长难句分析</p>\n<p>找到定语，分离，翻译</p>\n<ol>\n<li>如何找定语：先找名词（短语），其后不是动词（词组），就大概率是定语（也可能是状语）</li>\n<li>定语翻译：定语较短时，翻译到先行词前面；定语较长时，后置，重复先行词或用相应词代替</li>\n</ol>\n<p>eg:</p>\n<ol>\n<li>\n<p>Some of the these causes are completely reasonable results of social needs. Others are reasonable consequences of particular advances in science being to some extent self-accelerating.</p>\n<p>定语1：of social needs</p>\n<p>定语2：of particular advances in science being to some extent self-accelerating</p>\n<p>定语2内含小定语2.1：of particular advances</p>\n<p>2.2：in science</p>\n<p>2.3：being to some extent self-accelerating</p>\n<p><strong>多个定语时，从后向前翻译。</strong></p>\n<p>其中一些原因完全是社会需要的合理结果。其他则是在某种程度上自我加速的科学上的特殊进步的合理结果。</p>\n</li>\n<li>\n<p>In short, a leader of the new school contends, “the scientific revolution, as we call it, was largely the improvement and invention and use of a series of instruments that expanded the reach of science in innumerable directions.”</p>\n<p>定语1：of the new school</p>\n<p>定语2：of a series of instruments that expanded the reach of science in innumerable directions</p>\n<p>2.1：of a series of instruments</p>\n<p>2.2：that expanded the reach of science in innumerable directions</p>\n<p>插入语：as we call it</p>\n<p>简而言之，新学派的一个领袖认为，“我们所说的科学革命很大程度上是<strong>一系列</strong>工具的改善、发明和使用，<strong>而这些工具在无数个方向上扩大了科学所达到的范围</strong>。”</p>\n<p><strong>（短定语前置，长定语后置同时重复了先行词）</strong></p>\n</li>\n<li>\n<p>After six months of arguing and final 16 hours of hot parliamentary debates, Australia`s Northern Territory became the first legal authority in the world to allow doctors to take the lives of incurably ill patients who wish to die.</p>\n<p>其中的allow … to do …，为固定搭配，分解成分时不要断开。</p>\n<p>经过六个月的争论和最后16个小时激烈的议会争辩，澳大利亚的北领地成为世界上第一个允许医生根据绝症病人个人意愿来结束其生命的合法政府。</p>\n</li>\n<li>\n<p>Weather to use tests, other kinds of information, or both in a particular situation depends, therefore, upon the evidence from experience concerning comparative validity and upon such factors as costs and availability.</p>\n<p>其中，and upon的and，并列连词，新开一句，前面的定语到此终止。</p>\n<p>因此，是使用测试或其他种类的信息，还是在一种特殊条件下同时使用两者，这取决于和相对有效性有关的来自经验的证据，也取决于诸如成本和可用性等因素。</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"9-总结\"><a class=\"markdownIt-Anchor\" href=\"#9-总结\"></a> 9. 总结</h2>\n<p>定语从名词（短语）后开始，一般到主句的谓语前结束。</p>\n<p>但是如果主句的谓语在定语前出现，定语通常到句末结束。</p>\n<p>大定语中常有很多小定语，每个小定语到下一个名词处结束，翻译时从最后一个小定语向前翻译。</p>\n<p>例外一是名词前后的词是固定搭配，则定语应到固定搭配后结束。</p>\n<p>例外二是并列连词会隔断定语，定语到连词前结束（若只是连接两个单词，则不隔断）。</p>"},{"title":"线性代数空间角度理解","date":"2020-06-06T07:18:58.000Z","mathjax":true,"_content":"\n\n\n> 计算的目的不在于数字本身，而在于洞察其背后的意义。 ——理查德·哈明\n\n[3B1B视频](https://www.bilibili.com/video/BV1ys411472E)\n\n<br/>\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# 向量与基向量\n\n二维空间中，一个向量，例如`[3,4]`，表示$3\\hat{x} + 4\\hat{y}$，$\\hat{x}$表示基向量。即，**一个向量表示对基向量操作的结果。**知道基向量后，通过向量的数字，即可确定向量。 :smile:\n\n同时，数乘向量、向量加法这两个向量最基本的操作，也可由对基向量数乘、相加去理解。\n$$\n\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n&=\n3 *\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+ 4 *\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\\\\\n&=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\\\\n&=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\end{align}\n$$\n\n<br/>\n\n# 空间与线性相关\n\n* 由基向量的各种组合，即可得到各种向量，这些向量的集合可以理解为空间\n* 二维空间内，任意两个不同方向的向量，均可看做基向量，从而得到空间内的所有向量；一旦两个基向量方向相同/相反，即重叠，则其能组合得到的向量集合，将从一个二维平面降维至一条线，可称两条基向量线性相关；一旦两个基向量是零向量，则退化为一点\n* 三维空间中，两条基向量可以确定一个过原点平面，若第三条基向量不在这个平面上，即可平移这个平面得到整个三维空间；但如果基向量3在平面上，则无法组合出新的向量，此时称基向量3与1和2线性相关（可由1和2组合得到）\n* 但一般称坐标轴上的单位向量为基向量\n\n<br/>\n\n# 线性变换\n\n* 对空间（中所有向量）的变换\n* 与函数意义相似，输入向量，进行变换，输出向量\n* 线性：任意直线变换后仍为直线，且原点保持固定 或 保持可加性与成比例\n* 线性变换后的空间，基向量发生了变化，但是**只要知道变化后的基向量，就能完全掌握新的空间**。对于二维空间，有两个基向量，这两个向量4个数字，就能确定新的空间，这就引出了矩阵。\n\n<br/>\n\n# 矩阵\n\n* 将新的基向量写在一起，即可表示进行的线性变化。下面这个矩阵中，$\\hat{x}=[1,3],\\hat{y}=[2,4]$，表示进行线性变换后，两个基向量的变换。\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t1 & 2\\\\\n\t\t3 & 4\n\t\\end{matrix}\n\\right]\n$$\n\n* 又由于一组基向量即可确定一个空间，所以利用这个矩阵，即可求得线性变换后的向量。\n* 如下，乘号左边为线性变换矩阵，右边为原向量，结合矩阵是基向量集合，与向量是对基向量的操作，可以列出下式。\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t1 & 2\\\\\n\t\t3 & 4\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t-1\n\t\\end{matrix}\n\\right]\n=\n2\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t3\n\t\\end{matrix}\n\\right]\n+ -1\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n=\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n$$\n\n\n\n<br/>\n\n# 矩阵乘法与复合线性变换\n\n* 由上可知，矩阵是与线性变换密切相关的。每一个矩阵都可代表一个线性变换。\n* 当出现多次（复合）线性变换时，既可以用一个矩阵直接表示最初到最终的变化结果，也可以用两个矩阵表示对原向量先后进行变换。\n* 此处有一点需强调，若用两个矩阵先后表示，每个矩阵中的基向量，也应表示为对原始基向量的变换。\n* 如何求出复合矩阵？（矩阵乘法如何计算？）我们知道矩阵可理解为一次线性变换；同时矩阵也表示基向量的集合；复合矩阵中是经过两次线性变换后得到的基向量。整合这三个概念，可知：矩阵乘法$ A*B=C $，可以理解为，**对B中每个基向量，进行A的线性变换操作，从而得到C中的每个基向量**。\n\n$$\n\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t1 & 1\\\\\n\t\t0 & 1\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t0 & -1\\\\\n\t\t1 & 0\n\t\\end{matrix}\n\\right]\n\n&=\n\\left[\n\t\\left[\n\t\\begin{matrix}\n\t\t1 & 1\\\\\n\t\t0 & 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\n\\left[\n\t\\begin{matrix}\n\t\t1 & 1\\\\\n\t\t0 & 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t-1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n\\right]\n\\\\\n&=\n\\left[\n\t\\begin{matrix}\n\t\t1 & -1\\\\\n\t\t1 & 0\n\t\\end{matrix}\n\\right]\n\\end{align}\n$$\n\n* 先后顺序：在线性变换的矩阵×向量中，看到矩阵在左，向量在有。这与f(x)类似，映射在x左侧。那么复合矩阵中，也应是*第二步线性变换×第一步线性变换×原向量 = 复合矩阵×原向量*。这给我们的启示是**矩阵乘法中顺序不能随意调换**。\n\n<br/>\n\n# 行列式\n\n* 在线性变换中，空间有时被拉伸，有时被挤压，有时被翻转，行列式就是来衡量变换程度，即一个区域在变换前后的面积之比。当然，对于基向量框选的区域，原始面积当然为1，此时只需求出**变换后的面积**即可，这也正是行列式所代表的意义。\n\n$$\ndet(\n\\left[\n\t\\begin{matrix}\n\t\t3 & 2\\\\\n\t\t0 & 2\n\t\\end{matrix}\n\\right]\n)\n= \n6\n$$\n\n* 行列式>0：将一个区域扩大n倍/缩小至$\\frac{1}{n}$\n* 行列式=0：区域面积变为0，表示空间受到降维，面变为线甚至点。这和线性相关的结果相同，所以，**矩阵行列式=0必然推出矩阵列线性相关**\n* 行列式<0：空间被翻转，绝对值仍表示面积缩放（二维中的自然理解：基向量1向2靠近，空间被压缩，单位面积从1向0靠近；基向量同方向，降维，单位面积为0；基向量1到了2的另一侧，单位面积降至0以下）\n\n<br/>\n\n# 逆矩阵\n\n​    线代可用于求线性方程组的解。对于一个线性方程组（多元一次），可将其改写为$A\\vec{x}=\\vec{v}$形式。则$\\vec{v}$可看作$\\vec{x}$由线性变换A得到，$\\vec{x}$通过对$\\vec{v}$进行相反的线性变换就可求得。\n$$\n\\begin{align}\n2x+5y+3z &= -3\\\\\n4x+0y+8z &= 0\\\\\n1x+3y+0z &= 2\\\\\n\\downarrow \\\\\n\\left[\n\t\\begin{matrix}\n\t\t2 & 5 & 3\\\\\n\t\t4 & 0 & 8\\\\\n\t\t1 & 3 & 0\n\t\\end{matrix}\n\\right]\n\\left[\n\t\\begin{matrix}\n\t\tx\\\\\n\t\ty\\\\\n\t\tz\n\t\\end{matrix}\n\\right]\n&=\n\\left[\n\t\\begin{matrix}\n\t\t-3\\\\\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n\n\\end{align}\n$$\n\n\n>逆矩阵$A^{-1}$：相反的线性变换。$A^{-1}A\\vec{x}=\\vec{x}=A^{-1}\\vec{v}$\n\n此处需先分析原始线性变换A：是否将空间降维，即$det(A)=0?$\n\n* 未降维：此时可以求得逆矩阵$A^{-1}$。\n* 降维：无逆矩阵（无法从底维转高维）。但是解仍然可能存在（如降维至直线，但$\\vec{v}$恰好在这条直线上）\n\n<br/>\n\n# 列空间、秩、零空间\n\n* 列空间：线性变换后，新的空间由矩阵中的每一列共同决定（新的基向量），所以把新的空间称为列空间\n* 秩：列空间的维数（$\\leq原空间维数$）\n* 满秩：秩与原空间维数相同\n* 零向量一定在列空间中\n\t* 满秩变换：仅有零向量能落在原来位置\n\t* 非满秩变换：一系列向量会变为零向量 \n* 零空间：如上的非满秩变换情况中，变换后落在零点的向量的集合，称为零空间或核\n* 当线性方程组的$\\vec{v}$在列空间中时，方程组有解（？）\n* 当线性方程组的$\\vec{v}=[0,0]$时，零空间中的向量是方程组的所有可能解\n\n<br/>\n\n# 非方阵\n\n以上的讨论都是针对方阵，即在相同维数空间中的变换。非方阵表示在不同维度空间中的映射变换。\n\n* 2×3矩阵：3列表示原空间有3个基向量，是三维空间；2行表示新空间中每个基向量用两个数字即可确定，是二维空间；即将3D映射至2D\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t-3 & 2 & 4\\\\\n\t\t0 & 1 & 5\n\t\\end{matrix}\n\\right]\n$$\n\n\n\n* 3*2矩阵：2列表示原空间2个基向量，二维；3行表示新空间三维；即2D映射至3D，但仍为一平面（列空间）\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t-3 & 2\\\\\n\t\t0 & 1\\\\\n\t\t3 & 4\n\t\\end{matrix}\n\\right]\n$$\n\n<br/>\n\n# 点积\n\n​\t对于$\\vec{v}·\\vec{w}$，书中定义是一方向另一方投影的长度×另一方向量长度，正负号表示两向量是否同向（广义）。那么点积是如何与投影建立起联系的？\n\n​    考虑二维降维至一维，且线性变换是二维向量投影至一维的情况：假设$\\hat{u}$是列空间的基向量[1]，显然对于线性变换矩阵$[a, b]$有以下结论：\n$$\na=\\hat{x}在直线投影=u_x\n\\\\\nb=\\hat{y}在直线投影=u_y\n$$\n则变换矩阵为$[u_x, u_y]$，任一向量线性变换后的结果为：\n$$\n[u_x, u_y]\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n$$\n这与点积的计算方法一致：\n$$\n\\left[\n\t\\begin{matrix}\n\tu_x \\\\\n\tu_y\n\t\\end{matrix}\n\\right]\n·\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n$$\n所以可以通过线性变换的角度理解点积，将某一向量看做矩阵进行计算。\n\n<br/>\n\n# 叉积\n\n1. 结果是一个数（2d）/向量（3d），数值上等于两向量围成的平行四边形面积，方向垂直于此平行四边形（右手定则，食指$\\vec{v}$，中指$\\vec{w}$，拇指方向）\n\n2. 值有正负，$\\vec{v}\\times\\vec{w}$时，$\\vec{v}$在$\\vec{w}$右侧时值>0，左侧<0\n\n3. 因为是代表面积，所以可以采用行列式的角度\n\n4. 二维时与线性变换建立联系：二维情况下：输出一个数。原始两个基向量，经线性变换，成为$\\vec{v}$和$\\vec{w}$，此时变换矩阵就是由$[\\vec{v}\\ \\vec{w}]$组成，矩阵的行列式就是带符号的面积，即叉积的值\n\n5. 三维情况下建立联系：接收两个向量，输出一个向量，这与直接延续二维时的思路：接收三个向量，组成矩阵求行列式有所不同。\n\n\t1. 但仍可延续之前想法，建立一个以$\\vec{v}$、$\\vec{w}$ 为已知量、结合某一未知量[x,y,z]的变换过程：行列式的结果是一个数字，相当于一维，这就建立起三维到一维的变换过程\n\n\t\t![](线性代数空间角度理解/1.png)\n\n\t2. 变换矩阵可以变为向量\n\n\t\t![](线性代数空间角度理解/2.png)\n\n\t3. 将变换矩阵/向量命名为$\\vec{p}$\n\n\t\t![](线性代数空间角度理解/3.png)\n\n\t4. 左右拆开，整理，可见$\\vec{p}$ 在计算角度来看就是叉积（右为叉积公式）\n\n\t\t![](线性代数空间角度理解/4.png)\n\n\t\t![](线性代数空间角度理解/5.png)\n\n\t5. 空间角度：上式左侧是点积，即寻找$\\vec{p}$ ，与某一向量的点积，等于这一向量与$\\vec{v}$ $\\vec{w}$ 构成的平行六面体的体积。  \n\n\t\t1. 对于六面体体积，$\\vec{v}$ $\\vec{w}$ 构成底面，[x,y,z]是其斜边，斜边在垂直于底面方向的投影就是高\n\t\t2. 对于左侧点积，点积部分已经说过点积与投影相关。点积=[x,y,z]在$\\vec{p}$ 方向投影长度×$\\vec{p}$ 的长度\n\t\t3. 显然，当$\\vec{p}$ 是垂直于底面，且长度为底面积时等式成立。这也解释了叉积的含义。\n\n<br/>\n\n# 基变换\n\n同一个向量，在不同的基向量下，有不同的表示（标量）\n\n* 在每一种基向量的情况下，基向量都是[1, 0] [0, 1]，只是坐标轴的方向、单位长度不同。默认的标准基向量时，垂直坐标系，两轴单位长度相同；特殊基向量时，坐标系可能不垂直，两轴单位长度也可能不同，但基向量仍为[1,0] [0,1]\n\n* 两种基向量的关系：（向量数字均假设）\n\n\t* 特殊基向量标准下的一个向量\n\t\t$$\n\t\t特殊基向量矩阵\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t1 & 0\\\\\n\t\t\t0 & 1\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t\\times\n\t\t基于特殊基向量的向量（标量）\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t3\\\\\n\t\t\t5\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t$$\n\n\t* 标准基向量标准下的**同样一个向量**\n\t\t$$\n\t\t标准基向量矩阵\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t1 & 0\\\\\n\t\t\t0 & 1\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t\\times\n\t\t基于标准基向量的向量（标量）\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t2\\\\\n\t\t\t6\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t$$\n\n\t* 即，对于同一个向量，特殊标准下，要3个基向量1,5个基向量2；而默认标准下，要2个基向量1,6个基向量2\n\n\t* 此时虽然二者表示的是同一个向量，但因为各自使用不同标准，不能直接划等号；**若要划等号，需要将其中一个的基向量矩阵变换，使用对方的标准来描述自己的基向量（基变换矩阵）。**假设特殊标准中的两个基向量，由默认标准描述是如下，则可划等号\n\t\t$$\n\t\t特殊基向量矩阵\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t1 & 0\\\\\n\t\t\t0 & 1\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t\\rightarrow\n\t\t由默认基向量描述是\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t2 & 1\\\\\n\t\t\t1 & 2\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t$$\n\t\t\n\t\t$$\n\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t2 & 1\\\\\n\t\t\t\t1 & 2\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t\\times\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t3\\\\\n\t\t\t\t5\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t=\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t1 & 0\\\\\n\t\t\t\t0 & 1\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t\\times\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t2\\\\\n\t\t\t\t6\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t=\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t2\\\\\n\t\t\t\t6\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t$$\n\t\t\n\t\t\n\n​\t此时的特殊矩阵仅是改变了描述方法，但实际上的基向量并未改变\n\n* 特殊基向量向常规基向量变换：即以上式21、式22\n\n* 常规基向量向特殊基向量变换：按照如上思路，只要把常规矩阵用特殊标准描述即可，或求逆矩阵\n\n* 常规标准下的线性变换：变换矩阵×向量\n\n* 特殊标准下的线性变换：基变换逆矩阵×变换矩阵×基变换矩阵×向量，表示先将特殊标准的向量转化为常规标准，然后进行线性变换，最后再把基换回去\n\n* $A^{-1}MA$：转移作用\n\n<br/>\n\n# 特征值、特征向量\n\n上文的基变换着眼于视角的变化，这与特征基关系密切\n\n* 在线性变换前后，大部分向量都偏离了原来的直线，仅有一些特殊的直线上的向量，在变换后，仍在此直线上，只是向量长度受到拉伸或压缩，并且一条直线上的所有向量的伸缩程度相同。这些特殊直线上的向量，称为特征向量；一条直线上的伸缩因子，称为特征值。\n\n* 特征值<0：变换使得向量反向，但仍在原直线上即可\n\n* 应用：\n\n\t* 三维空间的旋转，可以看做绕特征向量的旋转，几何角度更直观\n\t* 得益于特征值和特征向量，线性变换能够减少对坐标系的依赖，更多地依靠特征来描述\n\n* 计算：\n\n\t* $A$：变换矩阵\n\t* $\\vec{v}$：特征向量\n\t* $\\lambda$：特征值\n\n\t![](线性代数空间角度理解/7.png)\n\n* 特征基：基向量也是特征向量，这表示在此线性变换中，只是在坐标的两轴方向进行了拉伸，变换矩阵必然是对角矩阵。\n\n* 应用：矩阵连乘。当一个线性变换有多个特征向量，且其能够组合出整个空间时（特征向量可以作为新的基向量），将原变换换基$A^{-1}MA$ ，新的变换矩阵是对角矩阵，可快速进行连乘（对角的高次幂），再将结果换基回来$AMA^{-1}$ ","source":"_posts/线性代数空间角度理解.md","raw":"---\ntitle: 线性代数空间角度理解\ndate: 2020-06-06 15:18:58\nmathjax: true\ntags: 数学\n---\n\n\n\n> 计算的目的不在于数字本身，而在于洞察其背后的意义。 ——理查德·哈明\n\n[3B1B视频](https://www.bilibili.com/video/BV1ys411472E)\n\n<br/>\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# 向量与基向量\n\n二维空间中，一个向量，例如`[3,4]`，表示$3\\hat{x} + 4\\hat{y}$，$\\hat{x}$表示基向量。即，**一个向量表示对基向量操作的结果。**知道基向量后，通过向量的数字，即可确定向量。 :smile:\n\n同时，数乘向量、向量加法这两个向量最基本的操作，也可由对基向量数乘、相加去理解。\n$$\n\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n&=\n3 *\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+ 4 *\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\\\\\n&=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\\\\n&=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\end{align}\n$$\n\n<br/>\n\n# 空间与线性相关\n\n* 由基向量的各种组合，即可得到各种向量，这些向量的集合可以理解为空间\n* 二维空间内，任意两个不同方向的向量，均可看做基向量，从而得到空间内的所有向量；一旦两个基向量方向相同/相反，即重叠，则其能组合得到的向量集合，将从一个二维平面降维至一条线，可称两条基向量线性相关；一旦两个基向量是零向量，则退化为一点\n* 三维空间中，两条基向量可以确定一个过原点平面，若第三条基向量不在这个平面上，即可平移这个平面得到整个三维空间；但如果基向量3在平面上，则无法组合出新的向量，此时称基向量3与1和2线性相关（可由1和2组合得到）\n* 但一般称坐标轴上的单位向量为基向量\n\n<br/>\n\n# 线性变换\n\n* 对空间（中所有向量）的变换\n* 与函数意义相似，输入向量，进行变换，输出向量\n* 线性：任意直线变换后仍为直线，且原点保持固定 或 保持可加性与成比例\n* 线性变换后的空间，基向量发生了变化，但是**只要知道变化后的基向量，就能完全掌握新的空间**。对于二维空间，有两个基向量，这两个向量4个数字，就能确定新的空间，这就引出了矩阵。\n\n<br/>\n\n# 矩阵\n\n* 将新的基向量写在一起，即可表示进行的线性变化。下面这个矩阵中，$\\hat{x}=[1,3],\\hat{y}=[2,4]$，表示进行线性变换后，两个基向量的变换。\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t1 & 2\\\\\n\t\t3 & 4\n\t\\end{matrix}\n\\right]\n$$\n\n* 又由于一组基向量即可确定一个空间，所以利用这个矩阵，即可求得线性变换后的向量。\n* 如下，乘号左边为线性变换矩阵，右边为原向量，结合矩阵是基向量集合，与向量是对基向量的操作，可以列出下式。\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t1 & 2\\\\\n\t\t3 & 4\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t-1\n\t\\end{matrix}\n\\right]\n=\n2\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t3\n\t\\end{matrix}\n\\right]\n+ -1\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n=\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n$$\n\n\n\n<br/>\n\n# 矩阵乘法与复合线性变换\n\n* 由上可知，矩阵是与线性变换密切相关的。每一个矩阵都可代表一个线性变换。\n* 当出现多次（复合）线性变换时，既可以用一个矩阵直接表示最初到最终的变化结果，也可以用两个矩阵表示对原向量先后进行变换。\n* 此处有一点需强调，若用两个矩阵先后表示，每个矩阵中的基向量，也应表示为对原始基向量的变换。\n* 如何求出复合矩阵？（矩阵乘法如何计算？）我们知道矩阵可理解为一次线性变换；同时矩阵也表示基向量的集合；复合矩阵中是经过两次线性变换后得到的基向量。整合这三个概念，可知：矩阵乘法$ A*B=C $，可以理解为，**对B中每个基向量，进行A的线性变换操作，从而得到C中的每个基向量**。\n\n$$\n\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t1 & 1\\\\\n\t\t0 & 1\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t0 & -1\\\\\n\t\t1 & 0\n\t\\end{matrix}\n\\right]\n\n&=\n\\left[\n\t\\left[\n\t\\begin{matrix}\n\t\t1 & 1\\\\\n\t\t0 & 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\n\\left[\n\t\\begin{matrix}\n\t\t1 & 1\\\\\n\t\t0 & 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t-1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n\\right]\n\\\\\n&=\n\\left[\n\t\\begin{matrix}\n\t\t1 & -1\\\\\n\t\t1 & 0\n\t\\end{matrix}\n\\right]\n\\end{align}\n$$\n\n* 先后顺序：在线性变换的矩阵×向量中，看到矩阵在左，向量在有。这与f(x)类似，映射在x左侧。那么复合矩阵中，也应是*第二步线性变换×第一步线性变换×原向量 = 复合矩阵×原向量*。这给我们的启示是**矩阵乘法中顺序不能随意调换**。\n\n<br/>\n\n# 行列式\n\n* 在线性变换中，空间有时被拉伸，有时被挤压，有时被翻转，行列式就是来衡量变换程度，即一个区域在变换前后的面积之比。当然，对于基向量框选的区域，原始面积当然为1，此时只需求出**变换后的面积**即可，这也正是行列式所代表的意义。\n\n$$\ndet(\n\\left[\n\t\\begin{matrix}\n\t\t3 & 2\\\\\n\t\t0 & 2\n\t\\end{matrix}\n\\right]\n)\n= \n6\n$$\n\n* 行列式>0：将一个区域扩大n倍/缩小至$\\frac{1}{n}$\n* 行列式=0：区域面积变为0，表示空间受到降维，面变为线甚至点。这和线性相关的结果相同，所以，**矩阵行列式=0必然推出矩阵列线性相关**\n* 行列式<0：空间被翻转，绝对值仍表示面积缩放（二维中的自然理解：基向量1向2靠近，空间被压缩，单位面积从1向0靠近；基向量同方向，降维，单位面积为0；基向量1到了2的另一侧，单位面积降至0以下）\n\n<br/>\n\n# 逆矩阵\n\n​    线代可用于求线性方程组的解。对于一个线性方程组（多元一次），可将其改写为$A\\vec{x}=\\vec{v}$形式。则$\\vec{v}$可看作$\\vec{x}$由线性变换A得到，$\\vec{x}$通过对$\\vec{v}$进行相反的线性变换就可求得。\n$$\n\\begin{align}\n2x+5y+3z &= -3\\\\\n4x+0y+8z &= 0\\\\\n1x+3y+0z &= 2\\\\\n\\downarrow \\\\\n\\left[\n\t\\begin{matrix}\n\t\t2 & 5 & 3\\\\\n\t\t4 & 0 & 8\\\\\n\t\t1 & 3 & 0\n\t\\end{matrix}\n\\right]\n\\left[\n\t\\begin{matrix}\n\t\tx\\\\\n\t\ty\\\\\n\t\tz\n\t\\end{matrix}\n\\right]\n&=\n\\left[\n\t\\begin{matrix}\n\t\t-3\\\\\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n\n\\end{align}\n$$\n\n\n>逆矩阵$A^{-1}$：相反的线性变换。$A^{-1}A\\vec{x}=\\vec{x}=A^{-1}\\vec{v}$\n\n此处需先分析原始线性变换A：是否将空间降维，即$det(A)=0?$\n\n* 未降维：此时可以求得逆矩阵$A^{-1}$。\n* 降维：无逆矩阵（无法从底维转高维）。但是解仍然可能存在（如降维至直线，但$\\vec{v}$恰好在这条直线上）\n\n<br/>\n\n# 列空间、秩、零空间\n\n* 列空间：线性变换后，新的空间由矩阵中的每一列共同决定（新的基向量），所以把新的空间称为列空间\n* 秩：列空间的维数（$\\leq原空间维数$）\n* 满秩：秩与原空间维数相同\n* 零向量一定在列空间中\n\t* 满秩变换：仅有零向量能落在原来位置\n\t* 非满秩变换：一系列向量会变为零向量 \n* 零空间：如上的非满秩变换情况中，变换后落在零点的向量的集合，称为零空间或核\n* 当线性方程组的$\\vec{v}$在列空间中时，方程组有解（？）\n* 当线性方程组的$\\vec{v}=[0,0]$时，零空间中的向量是方程组的所有可能解\n\n<br/>\n\n# 非方阵\n\n以上的讨论都是针对方阵，即在相同维数空间中的变换。非方阵表示在不同维度空间中的映射变换。\n\n* 2×3矩阵：3列表示原空间有3个基向量，是三维空间；2行表示新空间中每个基向量用两个数字即可确定，是二维空间；即将3D映射至2D\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t-3 & 2 & 4\\\\\n\t\t0 & 1 & 5\n\t\\end{matrix}\n\\right]\n$$\n\n\n\n* 3*2矩阵：2列表示原空间2个基向量，二维；3行表示新空间三维；即2D映射至3D，但仍为一平面（列空间）\n\n$$\n\\left[\n\t\\begin{matrix}\n\t\t-3 & 2\\\\\n\t\t0 & 1\\\\\n\t\t3 & 4\n\t\\end{matrix}\n\\right]\n$$\n\n<br/>\n\n# 点积\n\n​\t对于$\\vec{v}·\\vec{w}$，书中定义是一方向另一方投影的长度×另一方向量长度，正负号表示两向量是否同向（广义）。那么点积是如何与投影建立起联系的？\n\n​    考虑二维降维至一维，且线性变换是二维向量投影至一维的情况：假设$\\hat{u}$是列空间的基向量[1]，显然对于线性变换矩阵$[a, b]$有以下结论：\n$$\na=\\hat{x}在直线投影=u_x\n\\\\\nb=\\hat{y}在直线投影=u_y\n$$\n则变换矩阵为$[u_x, u_y]$，任一向量线性变换后的结果为：\n$$\n[u_x, u_y]\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n$$\n这与点积的计算方法一致：\n$$\n\\left[\n\t\\begin{matrix}\n\tu_x \\\\\n\tu_y\n\t\\end{matrix}\n\\right]\n·\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n$$\n所以可以通过线性变换的角度理解点积，将某一向量看做矩阵进行计算。\n\n<br/>\n\n# 叉积\n\n1. 结果是一个数（2d）/向量（3d），数值上等于两向量围成的平行四边形面积，方向垂直于此平行四边形（右手定则，食指$\\vec{v}$，中指$\\vec{w}$，拇指方向）\n\n2. 值有正负，$\\vec{v}\\times\\vec{w}$时，$\\vec{v}$在$\\vec{w}$右侧时值>0，左侧<0\n\n3. 因为是代表面积，所以可以采用行列式的角度\n\n4. 二维时与线性变换建立联系：二维情况下：输出一个数。原始两个基向量，经线性变换，成为$\\vec{v}$和$\\vec{w}$，此时变换矩阵就是由$[\\vec{v}\\ \\vec{w}]$组成，矩阵的行列式就是带符号的面积，即叉积的值\n\n5. 三维情况下建立联系：接收两个向量，输出一个向量，这与直接延续二维时的思路：接收三个向量，组成矩阵求行列式有所不同。\n\n\t1. 但仍可延续之前想法，建立一个以$\\vec{v}$、$\\vec{w}$ 为已知量、结合某一未知量[x,y,z]的变换过程：行列式的结果是一个数字，相当于一维，这就建立起三维到一维的变换过程\n\n\t\t![](线性代数空间角度理解/1.png)\n\n\t2. 变换矩阵可以变为向量\n\n\t\t![](线性代数空间角度理解/2.png)\n\n\t3. 将变换矩阵/向量命名为$\\vec{p}$\n\n\t\t![](线性代数空间角度理解/3.png)\n\n\t4. 左右拆开，整理，可见$\\vec{p}$ 在计算角度来看就是叉积（右为叉积公式）\n\n\t\t![](线性代数空间角度理解/4.png)\n\n\t\t![](线性代数空间角度理解/5.png)\n\n\t5. 空间角度：上式左侧是点积，即寻找$\\vec{p}$ ，与某一向量的点积，等于这一向量与$\\vec{v}$ $\\vec{w}$ 构成的平行六面体的体积。  \n\n\t\t1. 对于六面体体积，$\\vec{v}$ $\\vec{w}$ 构成底面，[x,y,z]是其斜边，斜边在垂直于底面方向的投影就是高\n\t\t2. 对于左侧点积，点积部分已经说过点积与投影相关。点积=[x,y,z]在$\\vec{p}$ 方向投影长度×$\\vec{p}$ 的长度\n\t\t3. 显然，当$\\vec{p}$ 是垂直于底面，且长度为底面积时等式成立。这也解释了叉积的含义。\n\n<br/>\n\n# 基变换\n\n同一个向量，在不同的基向量下，有不同的表示（标量）\n\n* 在每一种基向量的情况下，基向量都是[1, 0] [0, 1]，只是坐标轴的方向、单位长度不同。默认的标准基向量时，垂直坐标系，两轴单位长度相同；特殊基向量时，坐标系可能不垂直，两轴单位长度也可能不同，但基向量仍为[1,0] [0,1]\n\n* 两种基向量的关系：（向量数字均假设）\n\n\t* 特殊基向量标准下的一个向量\n\t\t$$\n\t\t特殊基向量矩阵\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t1 & 0\\\\\n\t\t\t0 & 1\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t\\times\n\t\t基于特殊基向量的向量（标量）\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t3\\\\\n\t\t\t5\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t$$\n\n\t* 标准基向量标准下的**同样一个向量**\n\t\t$$\n\t\t标准基向量矩阵\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t1 & 0\\\\\n\t\t\t0 & 1\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t\\times\n\t\t基于标准基向量的向量（标量）\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t2\\\\\n\t\t\t6\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t$$\n\n\t* 即，对于同一个向量，特殊标准下，要3个基向量1,5个基向量2；而默认标准下，要2个基向量1,6个基向量2\n\n\t* 此时虽然二者表示的是同一个向量，但因为各自使用不同标准，不能直接划等号；**若要划等号，需要将其中一个的基向量矩阵变换，使用对方的标准来描述自己的基向量（基变换矩阵）。**假设特殊标准中的两个基向量，由默认标准描述是如下，则可划等号\n\t\t$$\n\t\t特殊基向量矩阵\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t1 & 0\\\\\n\t\t\t0 & 1\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t\\rightarrow\n\t\t由默认基向量描述是\n\t\t\\left[\n\t\t\t\\begin{matrix}\n\t\t\t2 & 1\\\\\n\t\t\t1 & 2\n\t\t\t\\end{matrix}\n\t\t\\right]\n\t\t$$\n\t\t\n\t\t$$\n\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t2 & 1\\\\\n\t\t\t\t1 & 2\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t\\times\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t3\\\\\n\t\t\t\t5\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t=\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t1 & 0\\\\\n\t\t\t\t0 & 1\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t\\times\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t2\\\\\n\t\t\t\t6\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t\t=\n\t\t\t\\left[\n\t\t\t\t\\begin{matrix}\n\t\t\t\t2\\\\\n\t\t\t\t6\n\t\t\t\t\\end{matrix}\n\t\t\t\\right]\n\t\t$$\n\t\t\n\t\t\n\n​\t此时的特殊矩阵仅是改变了描述方法，但实际上的基向量并未改变\n\n* 特殊基向量向常规基向量变换：即以上式21、式22\n\n* 常规基向量向特殊基向量变换：按照如上思路，只要把常规矩阵用特殊标准描述即可，或求逆矩阵\n\n* 常规标准下的线性变换：变换矩阵×向量\n\n* 特殊标准下的线性变换：基变换逆矩阵×变换矩阵×基变换矩阵×向量，表示先将特殊标准的向量转化为常规标准，然后进行线性变换，最后再把基换回去\n\n* $A^{-1}MA$：转移作用\n\n<br/>\n\n# 特征值、特征向量\n\n上文的基变换着眼于视角的变化，这与特征基关系密切\n\n* 在线性变换前后，大部分向量都偏离了原来的直线，仅有一些特殊的直线上的向量，在变换后，仍在此直线上，只是向量长度受到拉伸或压缩，并且一条直线上的所有向量的伸缩程度相同。这些特殊直线上的向量，称为特征向量；一条直线上的伸缩因子，称为特征值。\n\n* 特征值<0：变换使得向量反向，但仍在原直线上即可\n\n* 应用：\n\n\t* 三维空间的旋转，可以看做绕特征向量的旋转，几何角度更直观\n\t* 得益于特征值和特征向量，线性变换能够减少对坐标系的依赖，更多地依靠特征来描述\n\n* 计算：\n\n\t* $A$：变换矩阵\n\t* $\\vec{v}$：特征向量\n\t* $\\lambda$：特征值\n\n\t![](线性代数空间角度理解/7.png)\n\n* 特征基：基向量也是特征向量，这表示在此线性变换中，只是在坐标的两轴方向进行了拉伸，变换矩阵必然是对角矩阵。\n\n* 应用：矩阵连乘。当一个线性变换有多个特征向量，且其能够组合出整个空间时（特征向量可以作为新的基向量），将原变换换基$A^{-1}MA$ ，新的变换矩阵是对角矩阵，可快速进行连乘（对角的高次幂），再将结果换基回来$AMA^{-1}$ ","slug":"线性代数空间角度理解","published":1,"updated":"2020-07-14T14:46:19.801Z","_id":"ckc4xbew9000qi0qv3xbude4d","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>计算的目的不在于数字本身，而在于洞察其背后的意义。 ——理查德·哈明</p>\n</blockquote>\n<p><a href=\"https://www.bilibili.com/video/BV1ys411472E\" target=\"_blank\" rel=\"noopener\">3B1B视频</a></p>\n<br>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#%E5%90%91%E9%87%8F%E4%B8%8E%E5%9F%BA%E5%90%91%E9%87%8F\">向量与基向量</a></li>\n<li><a href=\"#%E7%A9%BA%E9%97%B4%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3\">空间与线性相关</a></li>\n<li><a href=\"#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2\">线性变换</a></li>\n<li><a href=\"#%E7%9F%A9%E9%98%B5\">矩阵</a></li>\n<li><a href=\"#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%B8%8E%E5%A4%8D%E5%90%88%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2\">矩阵乘法与复合线性变换</a></li>\n<li><a href=\"#%E8%A1%8C%E5%88%97%E5%BC%8F\">行列式</a></li>\n<li><a href=\"#%E9%80%86%E7%9F%A9%E9%98%B5\">逆矩阵</a></li>\n<li><a href=\"#%E5%88%97%E7%A9%BA%E9%97%B4-%E7%A7%A9-%E9%9B%B6%E7%A9%BA%E9%97%B4\">列空间、秩、零空间</a></li>\n<li><a href=\"#%E9%9D%9E%E6%96%B9%E9%98%B5\">非方阵</a></li>\n<li><a href=\"#%E7%82%B9%E7%A7%AF\">点积</a></li>\n<li><a href=\"#%E5%8F%89%E7%A7%AF\">叉积</a></li>\n<li><a href=\"#%E5%9F%BA%E5%8F%98%E6%8D%A2\">基变换</a></li>\n<li><a href=\"#%E7%89%B9%E5%BE%81%E5%80%BC-%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F\">特征值、特征向量</a></li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"向量与基向量\"> 向量与基向量</span></h1>\n<p>二维空间中，一个向量，例如<code>[3,4]</code>，表示<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>3</mn><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mo>+</mo><mn>4</mn><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">3\\hat{x} + 4\\hat{y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">3</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">4</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span></span></span></span>表示基向量。即，**一个向量表示对基向量操作的结果。**知道基向量后，通过向量的数字，即可确定向量。 😄</p>\n<p>同时，数乘向量、向量加法这两个向量最基本的操作，也可由对基向量数乘、相加去理解。</p>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: No such environment: align at position 7: \\begin{̲a̲l̲i̲g̲n̲}̲\n\\left[\n\t\\begin…\">\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n&amp;=\n3 *\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+ 4 *\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\\\\\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\\\\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\end{align}\n</p>\n<br>\n<h1><span id=\"空间与线性相关\"> 空间与线性相关</span></h1>\n<ul>\n<li>由基向量的各种组合，即可得到各种向量，这些向量的集合可以理解为空间</li>\n<li>二维空间内，任意两个不同方向的向量，均可看做基向量，从而得到空间内的所有向量；一旦两个基向量方向相同/相反，即重叠，则其能组合得到的向量集合，将从一个二维平面降维至一条线，可称两条基向量线性相关；一旦两个基向量是零向量，则退化为一点</li>\n<li>三维空间中，两条基向量可以确定一个过原点平面，若第三条基向量不在这个平面上，即可平移这个平面得到整个三维空间；但如果基向量3在平面上，则无法组合出新的向量，此时称基向量3与1和2线性相关（可由1和2组合得到）</li>\n<li>但一般称坐标轴上的单位向量为基向量</li>\n</ul>\n<br>\n<h1><span id=\"线性变换\"> 线性变换</span></h1>\n<ul>\n<li>对空间（中所有向量）的变换</li>\n<li>与函数意义相似，输入向量，进行变换，输出向量</li>\n<li>线性：任意直线变换后仍为直线，且原点保持固定 或 保持可加性与成比例</li>\n<li>线性变换后的空间，基向量发生了变化，但是<strong>只要知道变化后的基向量，就能完全掌握新的空间</strong>。对于二维空间，有两个基向量，这两个向量4个数字，就能确定新的空间，这就引出了矩阵。</li>\n</ul>\n<br>\n<h1><span id=\"矩阵\"> 矩阵</span></h1>\n<ul>\n<li>将新的基向量写在一起，即可表示进行的线性变化。下面这个矩阵中，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">]</mo><mo separator=\"true\">,</mo><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><mn>2</mn><mo separator=\"true\">,</mo><mn>4</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{x}=[1,3],\\hat{y}=[2,4]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">]</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">4</span><span class=\"mclose\">]</span></span></span></span>，表示进行线性变换后，两个基向量的变换。</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 2\\\\\n\t\t3 &amp; 4\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></p>\n<ul>\n<li>又由于一组基向量即可确定一个空间，所以利用这个矩阵，即可求得线性变换后的向量。</li>\n<li>如下，乘号左边为线性变换矩阵，右边为原向量，结合矩阵是基向量集合，与向量是对基向量的操作，可以列出下式。</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>∗</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mn>2</mn><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>+</mo><mo>−</mo><mn>1</mn><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 2\\\\\n\t\t3 &amp; 4\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t-1\n\t\\end{matrix}\n\\right]\n=\n2\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t3\n\t\\end{matrix}\n\\right]\n+ -1\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n=\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord\">−</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></p>\n<br>\n<h1><span id=\"矩阵乘法与复合线性变换\"> 矩阵乘法与复合线性变换</span></h1>\n<ul>\n<li>由上可知，矩阵是与线性变换密切相关的。每一个矩阵都可代表一个线性变换。</li>\n<li>当出现多次（复合）线性变换时，既可以用一个矩阵直接表示最初到最终的变化结果，也可以用两个矩阵表示对原向量先后进行变换。</li>\n<li>此处有一点需强调，若用两个矩阵先后表示，每个矩阵中的基向量，也应表示为对原始基向量的变换。</li>\n<li>如何求出复合矩阵？（矩阵乘法如何计算？）我们知道矩阵可理解为一次线性变换；同时矩阵也表示基向量的集合；复合矩阵中是经过两次线性变换后得到的基向量。整合这三个概念，可知：矩阵乘法$ A*B=C $，可以理解为，<strong>对B中每个基向量，进行A的线性变换操作，从而得到C中的每个基向量</strong>。</li>\n</ul>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: No such environment: align at position 7: \\begin{̲a̲l̲i̲g̲n̲}̲\n\\left[\n\t\\begin…\">\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 1\\\\\n\t\t0 &amp; 1\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t0 &amp; -1\\\\\n\t\t1 &amp; 0\n\t\\end{matrix}\n\\right]\n\n&amp;=\n\\left[\n\t\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 1\\\\\n\t\t0 &amp; 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\n\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 1\\\\\n\t\t0 &amp; 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t-1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n\\right]\n\\\\\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t1 &amp; -1\\\\\n\t\t1 &amp; 0\n\t\\end{matrix}\n\\right]\n\\end{align}\n</p>\n<ul>\n<li>先后顺序：在线性变换的矩阵×向量中，看到矩阵在左，向量在有。这与f(x)类似，映射在x左侧。那么复合矩阵中，也应是<em>第二步线性变换×第一步线性变换×原向量 = 复合矩阵×原向量</em>。这给我们的启示是<strong>矩阵乘法中顺序不能随意调换</strong>。</li>\n</ul>\n<br>\n<h1><span id=\"行列式\"> 行列式</span></h1>\n<ul>\n<li>在线性变换中，空间有时被拉伸，有时被挤压，有时被翻转，行列式就是来衡量变换程度，即一个区域在变换前后的面积之比。当然，对于基向量框选的区域，原始面积当然为1，此时只需求出<strong>变换后的面积</strong>即可，这也正是行列式所代表的意义。</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo stretchy=\"false\">)</mo><mo>=</mo><mn>6</mn></mrow><annotation encoding=\"application/x-tex\">det(\n\\left[\n\t\\begin{matrix}\n\t\t3 &amp; 2\\\\\n\t\t0 &amp; 2\n\t\\end{matrix}\n\\right]\n)\n= \n6\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">t</span><span class=\"mopen\">(</span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">6</span></span></span></span></span></p>\n<ul>\n<li>行列式&gt;0：将一个区域扩大n倍/缩小至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></li>\n<li>行列式=0：区域面积变为0，表示空间受到降维，面变为线甚至点。这和线性相关的结果相同，所以，<strong>矩阵行列式=0必然推出矩阵列线性相关</strong></li>\n<li>行列式&lt;0：空间被翻转，绝对值仍表示面积缩放（二维中的自然理解：基向量1向2靠近，空间被压缩，单位面积从1向0靠近；基向量同方向，降维，单位面积为0；基向量1到了2的另一侧，单位面积降至0以下）</li>\n</ul>\n<br>\n<h1><span id=\"逆矩阵\"> 逆矩阵</span></h1>\n<p>​    线代可用于求线性方程组的解。对于一个线性方程组（多元一次），可将其改写为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover><mo>=</mo><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">A\\vec{x}=\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>形式。则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>可看作<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>由线性变换A得到，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>通过对<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>进行相反的线性变换就可求得。</p>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: No such environment: align at position 7: \\begin{̲a̲l̲i̲g̲n̲}̲\n2x+5y+3z &amp;= -3…\">\\begin{align}\n2x+5y+3z &amp;= -3\\\\\n4x+0y+8z &amp;= 0\\\\\n1x+3y+0z &amp;= 2\\\\\n\\downarrow \\\\\n\\left[\n\t\\begin{matrix}\n\t\t2 &amp; 5 &amp; 3\\\\\n\t\t4 &amp; 0 &amp; 8\\\\\n\t\t1 &amp; 3 &amp; 0\n\t\\end{matrix}\n\\right]\n\\left[\n\t\\begin{matrix}\n\t\tx\\\\\n\t\ty\\\\\n\t\tz\n\t\\end{matrix}\n\\right]\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t-3\\\\\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n\n\\end{align}\n</p>\n<blockquote>\n<p>逆矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">A^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span>：相反的线性变换。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>A</mi><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover><mo>=</mo><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover><mo>=</mo><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">A^{-1}A\\vec{x}=\\vec{x}=A^{-1}\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\">A</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span></p>\n</blockquote>\n<p>此处需先分析原始线性变换A：是否将空间降维，即<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn><mo stretchy=\"false\">?</mo></mrow><annotation encoding=\"application/x-tex\">det(A)=0?</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">t</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">?</span></span></span></span></p>\n<ul>\n<li>未降维：此时可以求得逆矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">A^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span>。</li>\n<li>降维：无逆矩阵（无法从底维转高维）。但是解仍然可能存在（如降维至直线，但<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>恰好在这条直线上）</li>\n</ul>\n<br>\n<h1><span id=\"列空间-秩-零空间\"> 列空间、秩、零空间</span></h1>\n<ul>\n<li>列空间：线性变换后，新的空间由矩阵中的每一列共同决定（新的基向量），所以把新的空间称为列空间</li>\n<li>秩：列空间的维数（<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>≤</mo><mi mathvariant=\"normal\">原</mi><mi mathvariant=\"normal\">空</mi><mi mathvariant=\"normal\">间</mi><mi mathvariant=\"normal\">维</mi><mi mathvariant=\"normal\">数</mi></mrow><annotation encoding=\"application/x-tex\">\\leq原空间维数</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7719400000000001em;vertical-align:-0.13597em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">原</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">维</span><span class=\"mord cjk_fallback\">数</span></span></span></span>）</li>\n<li>满秩：秩与原空间维数相同</li>\n<li>零向量一定在列空间中\n<ul>\n<li>满秩变换：仅有零向量能落在原来位置</li>\n<li>非满秩变换：一系列向量会变为零向量</li>\n</ul>\n</li>\n<li>零空间：如上的非满秩变换情况中，变换后落在零点的向量的集合，称为零空间或核</li>\n<li>当线性方程组的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>在列空间中时，方程组有解（？）</li>\n<li>当线性方程组的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\vec{v}=[0,0]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">]</span></span></span></span>时，零空间中的向量是方程组的所有可能解</li>\n</ul>\n<br>\n<h1><span id=\"非方阵\"> 非方阵</span></h1>\n<p>以上的讨论都是针对方阵，即在相同维数空间中的变换。非方阵表示在不同维度空间中的映射变换。</p>\n<ul>\n<li>2×3矩阵：3列表示原空间有3个基向量，是三维空间；2行表示新空间中每个基向量用两个数字即可确定，是二维空间；即将3D映射至2D</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>5</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t-3 &amp; 2 &amp; 4\\\\\n\t\t0 &amp; 1 &amp; 5\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">3</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></p>\n<ul>\n<li>3*2矩阵：2列表示原空间2个基向量，二维；3行表示新空间三维；即2D映射至3D，但仍为一平面（列空间）</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t-3 &amp; 2\\\\\n\t\t0 &amp; 1\\\\\n\t\t3 &amp; 4\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:3.60004em;vertical-align:-1.55002em;\"></span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05em;\"><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">3</span></span></span><span style=\"top:-3.0099999999999993em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span><span style=\"top:-1.8099999999999994em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5500000000000007em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05em;\"><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-3.0099999999999993em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-1.8099999999999994em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5500000000000007em;\"><span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<br>\n<h1><span id=\"点积\"> 点积</span></h1>\n<p>​\t对于<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mo separator=\"true\">⋅</mo><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}·\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，书中定义是一方向另一方投影的长度×另一方向量长度，正负号表示两向量是否同向（广义）。那么点积是如何与投影建立起联系的？</p>\n<p>​    考虑二维降维至一维，且线性变换是二维向量投影至一维的情况：假设<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>u</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{u}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span></span></span></span>是列空间的基向量[1]，显然对于线性变换矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[a, b]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">a</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">]</span></span></span></span>有以下结论：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>=</mo><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mi mathvariant=\"normal\">在</mi><mi mathvariant=\"normal\">直</mi><mi mathvariant=\"normal\">线</mi><mi mathvariant=\"normal\">投</mi><mi mathvariant=\"normal\">影</mi><mo>=</mo><msub><mi>u</mi><mi>x</mi></msub><mspace linebreak=\"newline\"></mspace><mi>b</mi><mo>=</mo><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi mathvariant=\"normal\">在</mi><mi mathvariant=\"normal\">直</mi><mi mathvariant=\"normal\">线</mi><mi mathvariant=\"normal\">投</mi><mi mathvariant=\"normal\">影</mi><mo>=</mo><msub><mi>u</mi><mi>y</mi></msub></mrow><annotation encoding=\"application/x-tex\">a=\\hat{x}在直线投影=u_x\n\\\\\nb=\\hat{y}在直线投影=u_y\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">直</span><span class=\"mord cjk_fallback\">线</span><span class=\"mord cjk_fallback\">投</span><span class=\"mord cjk_fallback\">影</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">直</span><span class=\"mord cjk_fallback\">线</span><span class=\"mord cjk_fallback\">投</span><span class=\"mord cjk_fallback\">影</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>则变换矩阵为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>u</mi><mi>x</mi></msub><mo separator=\"true\">,</mo><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[u_x, u_y]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>，任一向量线性变换后的结果为：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>u</mi><mi>x</mi></msub><mo separator=\"true\">,</mo><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>x</mi></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>y</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mi>x</mi></msub><msub><mi>u</mi><mi>x</mi></msub><mo>+</mo><msub><mi>v</mi><mi>y</mi></msub><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[u_x, u_y]\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>这与点积的计算方法一致：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>u</mi><mi>x</mi></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>u</mi><mi>y</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo separator=\"true\">⋅</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>x</mi></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>y</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mi>x</mi></msub><msub><mi>u</mi><mi>x</mi></msub><mo>+</mo><msub><mi>v</mi><mi>y</mi></msub><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\tu_x \\\\\n\tu_y\n\t\\end{matrix}\n\\right]\n·\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>所以可以通过线性变换的角度理解点积，将某一向量看做矩阵进行计算。</p>\n<br>\n<h1><span id=\"叉积\"> 叉积</span></h1>\n<ol>\n<li>\n<p>结果是一个数（2d）/向量（3d），数值上等于两向量围成的平行四边形面积，方向垂直于此平行四边形（右手定则，食指<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，中指<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，拇指方向）</p>\n</li>\n<li>\n<p>值有正负，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mo>×</mo><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}\\times\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.79733em;vertical-align:-0.08333em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>时，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>右侧时值&gt;0，左侧&lt;0</p>\n</li>\n<li>\n<p>因为是代表面积，所以可以采用行列式的角度</p>\n</li>\n<li>\n<p>二维时与线性变换建立联系：二维情况下：输出一个数。原始两个基向量，经线性变换，成为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，此时变换矩阵就是由<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mtext> </mtext><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[\\vec{v}\\ \\vec{w}]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>组成，矩阵的行列式就是带符号的面积，即叉积的值</p>\n</li>\n<li>\n<p>三维情况下建立联系：接收两个向量，输出一个向量，这与直接延续二维时的思路：接收三个向量，组成矩阵求行列式有所不同。</p>\n<ol>\n<li>\n<p>但仍可延续之前想法，建立一个以<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>、<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> 为已知量、结合某一未知量[x,y,z]的变换过程：行列式的结果是一个数字，相当于一维，这就建立起三维到一维的变换过程</p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/1.png\" alt></p>\n</li>\n<li>\n<p>变换矩阵可以变为向量</p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/2.png\" alt></p>\n</li>\n<li>\n<p>将变换矩阵/向量命名为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span></p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/3.png\" alt></p>\n</li>\n<li>\n<p>左右拆开，整理，可见<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 在计算角度来看就是叉积（右为叉积公式）</p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/4.png\" alt></p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/5.png\" alt></p>\n</li>\n<li>\n<p>空间角度：上式左侧是点积，即寻找<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> ，与某一向量的点积，等于这一向量与<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> 构成的平行六面体的体积。</p>\n<ol>\n<li>对于六面体体积，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> 构成底面，[x,y,z]是其斜边，斜边在垂直于底面方向的投影就是高</li>\n<li>对于左侧点积，点积部分已经说过点积与投影相关。点积=[x,y,z]在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 方向投影长度×<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 的长度</li>\n<li>显然，当<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 是垂直于底面，且长度为底面积时等式成立。这也解释了叉积的含义。</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h1><span id=\"基变换\"> 基变换</span></h1>\n<p>同一个向量，在不同的基向量下，有不同的表示（标量）</p>\n<ul>\n<li>\n<p>在每一种基向量的情况下，基向量都是[1, 0] [0, 1]，只是坐标轴的方向、单位长度不同。默认的标准基向量时，垂直坐标系，两轴单位长度相同；特殊基向量时，坐标系可能不垂直，两轴单位长度也可能不同，但基向量仍为[1,0] [0,1]</p>\n</li>\n<li>\n<p>两种基向量的关系：（向量数字均假设）</p>\n<ul>\n<li>\n<p>特殊基向量标准下的一个向量</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n基于特殊基向量的向量（标量）<br>\n\\left[<br>\n\\begin{matrix}<br>\n3\\<br>\n5<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n基于标准基向量的向量（标量）<br>\n\\left[<br>\n\\begin{matrix}<br>\n2\\<br>\n6<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n</li>\n<li>\n<p>此时虽然二者表示的是同一个向量，但因为各自使用不同标准，不能直接划等号；**若要划等号，需要将其中一个的基向量矩阵变换，使用对方的标准来描述自己的基向量（基变换矩阵）。**假设特殊标准中的两个基向量，由默认标准描述是如下，则可划等号</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\rightarrow<br>\n由默认基向量描述是<br>\n\\left[<br>\n\\begin{matrix}<br>\n2 &amp; 1\\<br>\n1 &amp; 2<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">  \t\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n2 &amp; 1\\<br>\n1 &amp; 2<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n\\left[<br>\n\\begin{matrix}<br>\n3\\<br>\n5<br>\n\\end{matrix}<br>\n\\right]<br>\n=<br>\n\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n\\left[<br>\n\\begin{matrix}<br>\n2\\<br>\n6<br>\n\\end{matrix}<br>\n\\right]<br>\n=<br>\n\\left[<br>\n\\begin{matrix}<br>\n2\\<br>\n6<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">  \t\n  \t\n\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n</li>\n</ul>\n</li>\n<li>\n<p>特殊基向量向常规基向量变换：即以上式21、式22</p>\n</li>\n<li>\n<p>常规基向量向特殊基向量变换：按照如上思路，只要把常规矩阵用特殊标准描述即可，或求逆矩阵</p>\n</li>\n<li>\n<p>常规标准下的线性变换：变换矩阵×向量</p>\n</li>\n<li>\n<p>特殊标准下的线性变换：基变换逆矩阵×变换矩阵×基变换矩阵×向量，表示先将特殊标准的向量转化为常规标准，然后进行线性变换，最后再把基换回去</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>M</mi><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A^{-1}MA</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault\">A</span></span></span></span>：转移作用</p>\n</li>\n</ul>\n<br>\n<h1><span id=\"特征值-特征向量\"> 特征值、特征向量</span></h1>\n<p>上文的基变换着眼于视角的变化，这与特征基关系密切</p>\n<ul>\n<li>\n<p>在线性变换前后，大部分向量都偏离了原来的直线，仅有一些特殊的直线上的向量，在变换后，仍在此直线上，只是向量长度受到拉伸或压缩，并且一条直线上的所有向量的伸缩程度相同。这些特殊直线上的向量，称为特征向量；一条直线上的伸缩因子，称为特征值。</p>\n</li>\n<li>\n<p>特征值&lt;0：变换使得向量反向，但仍在原直线上即可</p>\n</li>\n<li>\n<p>应用：</p>\n<ul>\n<li>三维空间的旋转，可以看做绕特征向量的旋转，几何角度更直观</li>\n<li>得益于特征值和特征向量，线性变换能够减少对坐标系的依赖，更多地依靠特征来描述</li>\n</ul>\n</li>\n<li>\n<p>计算：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>：变换矩阵</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>：特征向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">λ</span></span></span></span>：特征值</li>\n</ul>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/7.png\" alt></p>\n</li>\n<li>\n<p>特征基：基向量也是特征向量，这表示在此线性变换中，只是在坐标的两轴方向进行了拉伸，变换矩阵必然是对角矩阵。</p>\n</li>\n<li>\n<p>应用：矩阵连乘。当一个线性变换有多个特征向量，且其能够组合出整个空间时（特征向量可以作为新的基向量），将原变换换基<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>M</mi><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A^{-1}MA</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault\">A</span></span></span></span> ，新的变换矩阵是对角矩阵，可快速进行连乘（对角的高次幂），再将结果换基回来<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mi>M</mi><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">AMA^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<blockquote>\n<p>计算的目的不在于数字本身，而在于洞察其背后的意义。 ——理查德·哈明</p>\n</blockquote>\n<p><a href=\"https://www.bilibili.com/video/BV1ys411472E\" target=\"_blank\" rel=\"noopener\">3B1B视频</a></p>\n<br>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#%E5%90%91%E9%87%8F%E4%B8%8E%E5%9F%BA%E5%90%91%E9%87%8F\">向量与基向量</a></li>\n<li><a href=\"#%E7%A9%BA%E9%97%B4%E4%B8%8E%E7%BA%BF%E6%80%A7%E7%9B%B8%E5%85%B3\">空间与线性相关</a></li>\n<li><a href=\"#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2\">线性变换</a></li>\n<li><a href=\"#%E7%9F%A9%E9%98%B5\">矩阵</a></li>\n<li><a href=\"#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%B8%8E%E5%A4%8D%E5%90%88%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2\">矩阵乘法与复合线性变换</a></li>\n<li><a href=\"#%E8%A1%8C%E5%88%97%E5%BC%8F\">行列式</a></li>\n<li><a href=\"#%E9%80%86%E7%9F%A9%E9%98%B5\">逆矩阵</a></li>\n<li><a href=\"#%E5%88%97%E7%A9%BA%E9%97%B4-%E7%A7%A9-%E9%9B%B6%E7%A9%BA%E9%97%B4\">列空间、秩、零空间</a></li>\n<li><a href=\"#%E9%9D%9E%E6%96%B9%E9%98%B5\">非方阵</a></li>\n<li><a href=\"#%E7%82%B9%E7%A7%AF\">点积</a></li>\n<li><a href=\"#%E5%8F%89%E7%A7%AF\">叉积</a></li>\n<li><a href=\"#%E5%9F%BA%E5%8F%98%E6%8D%A2\">基变换</a></li>\n<li><a href=\"#%E7%89%B9%E5%BE%81%E5%80%BC-%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F\">特征值、特征向量</a></li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"向量与基向量\"><a class=\"markdownIt-Anchor\" href=\"#向量与基向量\"></a> 向量与基向量</h1>\n<p>二维空间中，一个向量，例如<code>[3,4]</code>，表示<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mn>3</mn><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mo>+</mo><mn>4</mn><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">3\\hat{x} + 4\\hat{y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord\">3</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">4</span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span>，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span></span></span></span>表示基向量。即，**一个向量表示对基向量操作的结果。**知道基向量后，通过向量的数字，即可确定向量。 😄</p>\n<p>同时，数乘向量、向量加法这两个向量最基本的操作，也可由对基向量数乘、相加去理解。</p>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: No such environment: align at position 7: \\begin{̲a̲l̲i̲g̲n̲}̲\n\\left[\n\t\\begin…\">\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n&amp;=\n3 *\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+ 4 *\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\\\\\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n+\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\\\\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t3\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n\\end{align}\n</p>\n<br>\n<h1 id=\"空间与线性相关\"><a class=\"markdownIt-Anchor\" href=\"#空间与线性相关\"></a> 空间与线性相关</h1>\n<ul>\n<li>由基向量的各种组合，即可得到各种向量，这些向量的集合可以理解为空间</li>\n<li>二维空间内，任意两个不同方向的向量，均可看做基向量，从而得到空间内的所有向量；一旦两个基向量方向相同/相反，即重叠，则其能组合得到的向量集合，将从一个二维平面降维至一条线，可称两条基向量线性相关；一旦两个基向量是零向量，则退化为一点</li>\n<li>三维空间中，两条基向量可以确定一个过原点平面，若第三条基向量不在这个平面上，即可平移这个平面得到整个三维空间；但如果基向量3在平面上，则无法组合出新的向量，此时称基向量3与1和2线性相关（可由1和2组合得到）</li>\n<li>但一般称坐标轴上的单位向量为基向量</li>\n</ul>\n<br>\n<h1 id=\"线性变换\"><a class=\"markdownIt-Anchor\" href=\"#线性变换\"></a> 线性变换</h1>\n<ul>\n<li>对空间（中所有向量）的变换</li>\n<li>与函数意义相似，输入向量，进行变换，输出向量</li>\n<li>线性：任意直线变换后仍为直线，且原点保持固定 或 保持可加性与成比例</li>\n<li>线性变换后的空间，基向量发生了变化，但是<strong>只要知道变化后的基向量，就能完全掌握新的空间</strong>。对于二维空间，有两个基向量，这两个向量4个数字，就能确定新的空间，这就引出了矩阵。</li>\n</ul>\n<br>\n<h1 id=\"矩阵\"><a class=\"markdownIt-Anchor\" href=\"#矩阵\"></a> 矩阵</h1>\n<ul>\n<li>将新的基向量写在一起，即可表示进行的线性变化。下面这个矩阵中，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>3</mn><mo stretchy=\"false\">]</mo><mo separator=\"true\">,</mo><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><mn>2</mn><mo separator=\"true\">,</mo><mn>4</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{x}=[1,3],\\hat{y}=[2,4]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">3</span><span class=\"mclose\">]</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">4</span><span class=\"mclose\">]</span></span></span></span>，表示进行线性变换后，两个基向量的变换。</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 2\\\\\n\t\t3 &amp; 4\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></p>\n<ul>\n<li>又由于一组基向量即可确定一个空间，所以利用这个矩阵，即可求得线性变换后的向量。</li>\n<li>如下，乘号左边为线性变换矩阵，右边为原向量，结合矩阵是基向量集合，与向量是对基向量的操作，可以列出下式。</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>∗</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mn>2</mn><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>+</mo><mo>−</mo><mn>1</mn><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 2\\\\\n\t\t3 &amp; 4\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t-1\n\t\\end{matrix}\n\\right]\n=\n2\n\\left[\n\t\\begin{matrix}\n\t\t1\\\\\n\t\t3\n\t\\end{matrix}\n\\right]\n+ -1\n\\left[\n\t\\begin{matrix}\n\t\t2\\\\\n\t\t4\n\t\\end{matrix}\n\\right]\n=\n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord\">−</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></p>\n<br>\n<h1 id=\"矩阵乘法与复合线性变换\"><a class=\"markdownIt-Anchor\" href=\"#矩阵乘法与复合线性变换\"></a> 矩阵乘法与复合线性变换</h1>\n<ul>\n<li>由上可知，矩阵是与线性变换密切相关的。每一个矩阵都可代表一个线性变换。</li>\n<li>当出现多次（复合）线性变换时，既可以用一个矩阵直接表示最初到最终的变化结果，也可以用两个矩阵表示对原向量先后进行变换。</li>\n<li>此处有一点需强调，若用两个矩阵先后表示，每个矩阵中的基向量，也应表示为对原始基向量的变换。</li>\n<li>如何求出复合矩阵？（矩阵乘法如何计算？）我们知道矩阵可理解为一次线性变换；同时矩阵也表示基向量的集合；复合矩阵中是经过两次线性变换后得到的基向量。整合这三个概念，可知：矩阵乘法$ A*B=C $，可以理解为，<strong>对B中每个基向量，进行A的线性变换操作，从而得到C中的每个基向量</strong>。</li>\n</ul>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: No such environment: align at position 7: \\begin{̲a̲l̲i̲g̲n̲}̲\n\\left[\n\t\\begin…\">\\begin{align}\n\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 1\\\\\n\t\t0 &amp; 1\n\t\\end{matrix}\n\\right]\n*\n\\left[\n\t\\begin{matrix}\n\t\t0 &amp; -1\\\\\n\t\t1 &amp; 0\n\t\\end{matrix}\n\\right]\n\n&amp;=\n\\left[\n\t\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 1\\\\\n\t\t0 &amp; 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t0\\\\\n\t\t1\n\t\\end{matrix}\n\\right]\n\n\\left[\n\t\\begin{matrix}\n\t\t1 &amp; 1\\\\\n\t\t0 &amp; 1\n\t\\end{matrix}\n\\right]\n* \n\\left[\n\t\\begin{matrix}\n\t\t-1\\\\\n\t\t0\n\t\\end{matrix}\n\\right]\n\\right]\n\\\\\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t1 &amp; -1\\\\\n\t\t1 &amp; 0\n\t\\end{matrix}\n\\right]\n\\end{align}\n</p>\n<ul>\n<li>先后顺序：在线性变换的矩阵×向量中，看到矩阵在左，向量在有。这与f(x)类似，映射在x左侧。那么复合矩阵中，也应是<em>第二步线性变换×第一步线性变换×原向量 = 复合矩阵×原向量</em>。这给我们的启示是<strong>矩阵乘法中顺序不能随意调换</strong>。</li>\n</ul>\n<br>\n<h1 id=\"行列式\"><a class=\"markdownIt-Anchor\" href=\"#行列式\"></a> 行列式</h1>\n<ul>\n<li>在线性变换中，空间有时被拉伸，有时被挤压，有时被翻转，行列式就是来衡量变换程度，即一个区域在变换前后的面积之比。当然，对于基向量框选的区域，原始面积当然为1，此时只需求出<strong>变换后的面积</strong>即可，这也正是行列式所代表的意义。</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo stretchy=\"false\">)</mo><mo>=</mo><mn>6</mn></mrow><annotation encoding=\"application/x-tex\">det(\n\\left[\n\t\\begin{matrix}\n\t\t3 &amp; 2\\\\\n\t\t0 &amp; 2\n\t\\end{matrix}\n\\right]\n)\n= \n6\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">t</span><span class=\"mopen\">(</span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">6</span></span></span></span></span></p>\n<ul>\n<li>行列式&gt;0：将一个区域扩大n倍/缩小至<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{1}{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.190108em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></li>\n<li>行列式=0：区域面积变为0，表示空间受到降维，面变为线甚至点。这和线性相关的结果相同，所以，<strong>矩阵行列式=0必然推出矩阵列线性相关</strong></li>\n<li>行列式&lt;0：空间被翻转，绝对值仍表示面积缩放（二维中的自然理解：基向量1向2靠近，空间被压缩，单位面积从1向0靠近；基向量同方向，降维，单位面积为0；基向量1到了2的另一侧，单位面积降至0以下）</li>\n</ul>\n<br>\n<h1 id=\"逆矩阵\"><a class=\"markdownIt-Anchor\" href=\"#逆矩阵\"></a> 逆矩阵</h1>\n<p>​    线代可用于求线性方程组的解。对于一个线性方程组（多元一次），可将其改写为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover><mo>=</mo><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">A\\vec{x}=\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>形式。则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>可看作<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>由线性变换A得到，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>通过对<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>进行相反的线性变换就可求得。</p>\n<p class=\"katex-block katex-error\" title=\"ParseError: KaTeX parse error: No such environment: align at position 7: \\begin{̲a̲l̲i̲g̲n̲}̲\n2x+5y+3z &amp;= -3…\">\\begin{align}\n2x+5y+3z &amp;= -3\\\\\n4x+0y+8z &amp;= 0\\\\\n1x+3y+0z &amp;= 2\\\\\n\\downarrow \\\\\n\\left[\n\t\\begin{matrix}\n\t\t2 &amp; 5 &amp; 3\\\\\n\t\t4 &amp; 0 &amp; 8\\\\\n\t\t1 &amp; 3 &amp; 0\n\t\\end{matrix}\n\\right]\n\\left[\n\t\\begin{matrix}\n\t\tx\\\\\n\t\ty\\\\\n\t\tz\n\t\\end{matrix}\n\\right]\n&amp;=\n\\left[\n\t\\begin{matrix}\n\t\t-3\\\\\n\t\t0\\\\\n\t\t2\n\t\\end{matrix}\n\\right]\n\n\\end{align}\n</p>\n<blockquote>\n<p>逆矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">A^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span>：相反的线性变换。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>A</mi><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover><mo>=</mo><mover accent=\"true\"><mi>x</mi><mo>⃗</mo></mover><mo>=</mo><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">A^{-1}A\\vec{x}=\\vec{x}=A^{-1}\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\">A</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span></p>\n</blockquote>\n<p>此处需先分析原始线性变换A：是否将空间降维，即<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0</mn><mo stretchy=\"false\">?</mo></mrow><annotation encoding=\"application/x-tex\">det(A)=0?</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">t</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">?</span></span></span></span></p>\n<ul>\n<li>未降维：此时可以求得逆矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">A^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span>。</li>\n<li>降维：无逆矩阵（无法从底维转高维）。但是解仍然可能存在（如降维至直线，但<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>恰好在这条直线上）</li>\n</ul>\n<br>\n<h1 id=\"列空间-秩-零空间\"><a class=\"markdownIt-Anchor\" href=\"#列空间-秩-零空间\"></a> 列空间、秩、零空间</h1>\n<ul>\n<li>列空间：线性变换后，新的空间由矩阵中的每一列共同决定（新的基向量），所以把新的空间称为列空间</li>\n<li>秩：列空间的维数（<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo>≤</mo><mi mathvariant=\"normal\">原</mi><mi mathvariant=\"normal\">空</mi><mi mathvariant=\"normal\">间</mi><mi mathvariant=\"normal\">维</mi><mi mathvariant=\"normal\">数</mi></mrow><annotation encoding=\"application/x-tex\">\\leq原空间维数</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7719400000000001em;vertical-align:-0.13597em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0em;vertical-align:0em;\"></span><span class=\"mord cjk_fallback\">原</span><span class=\"mord cjk_fallback\">空</span><span class=\"mord cjk_fallback\">间</span><span class=\"mord cjk_fallback\">维</span><span class=\"mord cjk_fallback\">数</span></span></span></span>）</li>\n<li>满秩：秩与原空间维数相同</li>\n<li>零向量一定在列空间中\n<ul>\n<li>满秩变换：仅有零向量能落在原来位置</li>\n<li>非满秩变换：一系列向量会变为零向量</li>\n</ul>\n</li>\n<li>零空间：如上的非满秩变换情况中，变换后落在零点的向量的集合，称为零空间或核</li>\n<li>当线性方程组的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>在列空间中时，方程组有解（？）</li>\n<li>当线性方程组的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mo>=</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>0</mn><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\vec{v}=[0,0]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">]</span></span></span></span>时，零空间中的向量是方程组的所有可能解</li>\n</ul>\n<br>\n<h1 id=\"非方阵\"><a class=\"markdownIt-Anchor\" href=\"#非方阵\"></a> 非方阵</h1>\n<p>以上的讨论都是针对方阵，即在相同维数空间中的变换。非方阵表示在不同维度空间中的映射变换。</p>\n<ul>\n<li>2×3矩阵：3列表示原空间有3个基向量，是三维空间；2行表示新空间中每个基向量用两个数字即可确定，是二维空间；即将3D映射至2D</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>5</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t-3 &amp; 2 &amp; 4\\\\\n\t\t0 &amp; 1 &amp; 5\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">3</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">5</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span></span></span></span></span></p>\n<ul>\n<li>3*2矩阵：2列表示原空间2个基向量，二维；3行表示新空间三维；即2D映射至3D，但仍为一平面（列空间）</li>\n</ul>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mrow><mo>−</mo><mn>3</mn></mrow></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>2</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>1</mn></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><mn>4</mn></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\t\t-3 &amp; 2\\\\\n\t\t0 &amp; 1\\\\\n\t\t3 &amp; 4\n\t\\end{matrix}\n\\right]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:3.60004em;vertical-align:-1.55002em;\"></span><span class=\"minner\"><span class=\"mopen\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎣</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎡</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05em;\"><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord\">3</span></span></span><span style=\"top:-3.0099999999999993em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">0</span></span></span><span style=\"top:-1.8099999999999994em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">3</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5500000000000007em;\"><span></span></span></span></span></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"arraycolsep\" style=\"width:0.5em;\"></span><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05em;\"><span style=\"top:-4.21em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-3.0099999999999993em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span><span style=\"top:-1.8099999999999994em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.5500000000000007em;\"><span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"delimsizing mult\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:2.05002em;\"><span style=\"top:-2.2500000000000004em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎦</span></span></span><span style=\"top:-4.05002em;\"><span class=\"pstrut\" style=\"height:3.1550000000000002em;\"></span><span class=\"delimsizinginner delim-size4\"><span>⎤</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.55002em;\"><span></span></span></span></span></span></span></span></span></span></span></span></p>\n<br>\n<h1 id=\"点积\"><a class=\"markdownIt-Anchor\" href=\"#点积\"></a> 点积</h1>\n<p>​\t对于<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mo separator=\"true\">⋅</mo><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}·\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，书中定义是一方向另一方投影的长度×另一方向量长度，正负号表示两向量是否同向（广义）。那么点积是如何与投影建立起联系的？</p>\n<p>​    考虑二维降维至一维，且线性变换是二维向量投影至一维的情况：假设<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>u</mi><mo>^</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\hat{u}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span></span></span></span>是列空间的基向量[1]，显然对于线性变换矩阵<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mi>a</mi><mo separator=\"true\">,</mo><mi>b</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[a, b]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">a</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">]</span></span></span></span>有以下结论：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>a</mi><mo>=</mo><mover accent=\"true\"><mi>x</mi><mo>^</mo></mover><mi mathvariant=\"normal\">在</mi><mi mathvariant=\"normal\">直</mi><mi mathvariant=\"normal\">线</mi><mi mathvariant=\"normal\">投</mi><mi mathvariant=\"normal\">影</mi><mo>=</mo><msub><mi>u</mi><mi>x</mi></msub><mspace linebreak=\"newline\"></mspace><mi>b</mi><mo>=</mo><mover accent=\"true\"><mi>y</mi><mo>^</mo></mover><mi mathvariant=\"normal\">在</mi><mi mathvariant=\"normal\">直</mi><mi mathvariant=\"normal\">线</mi><mi mathvariant=\"normal\">投</mi><mi mathvariant=\"normal\">影</mi><mo>=</mo><msub><mi>u</mi><mi>y</mi></msub></mrow><annotation encoding=\"application/x-tex\">a=\\hat{x}在直线投影=u_x\n\\\\\nb=\\hat{y}在直线投影=u_y\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">a</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.22222em;\">^</span></span></span></span></span></span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">直</span><span class=\"mord cjk_fallback\">线</span><span class=\"mord cjk_fallback\">投</span><span class=\"mord cjk_fallback\">影</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span class=\"mspace newline\"></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.69444em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.19444em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span><span class=\"mord cjk_fallback\">在</span><span class=\"mord cjk_fallback\">直</span><span class=\"mord cjk_fallback\">线</span><span class=\"mord cjk_fallback\">投</span><span class=\"mord cjk_fallback\">影</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.716668em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<p>则变换矩阵为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>u</mi><mi>x</mi></msub><mo separator=\"true\">,</mo><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[u_x, u_y]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>，任一向量线性变换后的结果为：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><msub><mi>u</mi><mi>x</mi></msub><mo separator=\"true\">,</mo><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>x</mi></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>y</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mi>x</mi></msub><msub><mi>u</mi><mi>x</mi></msub><mo>+</mo><msub><mi>v</mi><mi>y</mi></msub><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[u_x, u_y]\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>这与点积的计算方法一致：</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>u</mi><mi>x</mi></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>u</mi><mi>y</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo separator=\"true\">⋅</mo><mrow><mo fence=\"true\">[</mo><mtable rowspacing=\"0.15999999999999992em\" columnspacing=\"1em\"><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>x</mi></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel=\"0\" displaystyle=\"false\"><msub><mi>v</mi><mi>y</mi></msub></mstyle></mtd></mtr></mtable><mo fence=\"true\">]</mo></mrow><mo>=</mo><mo stretchy=\"false\">[</mo><msub><mi>v</mi><mi>x</mi></msub><msub><mi>u</mi><mi>x</mi></msub><mo>+</mo><msub><mi>v</mi><mi>y</mi></msub><msub><mi>u</mi><mi>y</mi></msub><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">\\left[\n\t\\begin{matrix}\n\tu_x \\\\\n\tu_y\n\t\\end{matrix}\n\\right]\n·\n\\left[\n\t\\begin{matrix}\n\tv_x \\\\\n\tv_y\n\t\\end{matrix}\n\\right]\n=\n[v_x u_x + v_y u_y]\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.40003em;vertical-align:-0.95003em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">[</span></span><span class=\"mord\"><span class=\"mtable\"><span class=\"col-align-c\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.45em;\"><span style=\"top:-3.61em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.4099999999999997em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9500000000000004em;\"><span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size3\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">x</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\">u</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span></span></p>\n<p>所以可以通过线性变换的角度理解点积，将某一向量看做矩阵进行计算。</p>\n<br>\n<h1 id=\"叉积\"><a class=\"markdownIt-Anchor\" href=\"#叉积\"></a> 叉积</h1>\n<ol>\n<li>\n<p>结果是一个数（2d）/向量（3d），数值上等于两向量围成的平行四边形面积，方向垂直于此平行四边形（右手定则，食指<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，中指<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，拇指方向）</p>\n</li>\n<li>\n<p>值有正负，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mo>×</mo><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}\\times\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.79733em;vertical-align:-0.08333em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>时，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>右侧时值&gt;0，左侧&lt;0</p>\n</li>\n<li>\n<p>因为是代表面积，所以可以采用行列式的角度</p>\n</li>\n<li>\n<p>二维时与线性变换建立联系：二维情况下：输出一个数。原始两个基向量，经线性变换，成为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>和<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>，此时变换矩阵就是由<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mo stretchy=\"false\">[</mo><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover><mtext> </mtext><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[\\vec{v}\\ \\vec{w}]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mspace\"> </span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span><span class=\"mclose\">]</span></span></span></span>组成，矩阵的行列式就是带符号的面积，即叉积的值</p>\n</li>\n<li>\n<p>三维情况下建立联系：接收两个向量，输出一个向量，这与直接延续二维时的思路：接收三个向量，组成矩阵求行列式有所不同。</p>\n<ol>\n<li>\n<p>但仍可延续之前想法，建立一个以<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>、<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> 为已知量、结合某一未知量[x,y,z]的变换过程：行列式的结果是一个数字，相当于一维，这就建立起三维到一维的变换过程</p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/1.png\" alt></p>\n</li>\n<li>\n<p>变换矩阵可以变为向量</p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/2.png\" alt></p>\n</li>\n<li>\n<p>将变换矩阵/向量命名为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span></p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/3.png\" alt></p>\n</li>\n<li>\n<p>左右拆开，整理，可见<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 在计算角度来看就是叉积（右为叉积公式）</p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/4.png\" alt></p>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/5.png\" alt></p>\n</li>\n<li>\n<p>空间角度：上式左侧是点积，即寻找<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> ，与某一向量的点积，等于这一向量与<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> 构成的平行六面体的体积。</p>\n<ol>\n<li>对于六面体体积，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> <span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>w</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span> 构成底面，[x,y,z]是其斜边，斜边在垂直于底面方向的投影就是高</li>\n<li>对于左侧点积，点积部分已经说过点积与投影相关。点积=[x,y,z]在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 方向投影长度×<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 的长度</li>\n<li>显然，当<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>p</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{p}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9084399999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">p</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.15216em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.19444em;\"><span></span></span></span></span></span></span></span></span> 是垂直于底面，且长度为底面积时等式成立。这也解释了叉积的含义。</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h1 id=\"基变换\"><a class=\"markdownIt-Anchor\" href=\"#基变换\"></a> 基变换</h1>\n<p>同一个向量，在不同的基向量下，有不同的表示（标量）</p>\n<ul>\n<li>\n<p>在每一种基向量的情况下，基向量都是[1, 0] [0, 1]，只是坐标轴的方向、单位长度不同。默认的标准基向量时，垂直坐标系，两轴单位长度相同；特殊基向量时，坐标系可能不垂直，两轴单位长度也可能不同，但基向量仍为[1,0] [0,1]</p>\n</li>\n<li>\n<p>两种基向量的关系：（向量数字均假设）</p>\n<ul>\n<li>\n<p>特殊基向量标准下的一个向量</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n基于特殊基向量的向量（标量）<br>\n\\left[<br>\n\\begin{matrix}<br>\n3\\<br>\n5<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n基于标准基向量的向量（标量）<br>\n\\left[<br>\n\\begin{matrix}<br>\n2\\<br>\n6<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n</li>\n<li>\n<p>此时虽然二者表示的是同一个向量，但因为各自使用不同标准，不能直接划等号；**若要划等号，需要将其中一个的基向量矩阵变换，使用对方的标准来描述自己的基向量（基变换矩阵）。**假设特殊标准中的两个基向量，由默认标准描述是如下，则可划等号</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\rightarrow<br>\n由默认基向量描述是<br>\n\\left[<br>\n\\begin{matrix}<br>\n2 &amp; 1\\<br>\n1 &amp; 2<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">  \t\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n<p>\\left[<br>\n\\begin{matrix}<br>\n2 &amp; 1\\<br>\n1 &amp; 2<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n\\left[<br>\n\\begin{matrix}<br>\n3\\<br>\n5<br>\n\\end{matrix}<br>\n\\right]<br>\n=<br>\n\\left[<br>\n\\begin{matrix}<br>\n1 &amp; 0\\<br>\n0 &amp; 1<br>\n\\end{matrix}<br>\n\\right]<br>\n\\times<br>\n\\left[<br>\n\\begin{matrix}<br>\n2\\<br>\n6<br>\n\\end{matrix}<br>\n\\right]<br>\n=<br>\n\\left[<br>\n\\begin{matrix}<br>\n2\\<br>\n6<br>\n\\end{matrix}<br>\n\\right]</p>\n<p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow></mrow><annotation encoding=\"application/x-tex\">  \t\n  \t\n\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></p>\n</li>\n</ul>\n</li>\n<li>\n<p>特殊基向量向常规基向量变换：即以上式21、式22</p>\n</li>\n<li>\n<p>常规基向量向特殊基向量变换：按照如上思路，只要把常规矩阵用特殊标准描述即可，或求逆矩阵</p>\n</li>\n<li>\n<p>常规标准下的线性变换：变换矩阵×向量</p>\n</li>\n<li>\n<p>特殊标准下的线性变换：基变换逆矩阵×变换矩阵×基变换矩阵×向量，表示先将特殊标准的向量转化为常规标准，然后进行线性变换，最后再把基换回去</p>\n</li>\n<li>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>M</mi><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A^{-1}MA</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault\">A</span></span></span></span>：转移作用</p>\n</li>\n</ul>\n<br>\n<h1 id=\"特征值-特征向量\"><a class=\"markdownIt-Anchor\" href=\"#特征值-特征向量\"></a> 特征值、特征向量</h1>\n<p>上文的基变换着眼于视角的变化，这与特征基关系密切</p>\n<ul>\n<li>\n<p>在线性变换前后，大部分向量都偏离了原来的直线，仅有一些特殊的直线上的向量，在变换后，仍在此直线上，只是向量长度受到拉伸或压缩，并且一条直线上的所有向量的伸缩程度相同。这些特殊直线上的向量，称为特征向量；一条直线上的伸缩因子，称为特征值。</p>\n</li>\n<li>\n<p>特征值&lt;0：变换使得向量反向，但仍在原直线上即可</p>\n</li>\n<li>\n<p>应用：</p>\n<ul>\n<li>三维空间的旋转，可以看做绕特征向量的旋转，几何角度更直观</li>\n<li>得益于特征值和特征向量，线性变换能够减少对坐标系的依赖，更多地依靠特征来描述</li>\n</ul>\n</li>\n<li>\n<p>计算：</p>\n<ul>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span></span></span></span>：变换矩阵</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mi>v</mi><mo>⃗</mo></mover></mrow><annotation encoding=\"application/x-tex\">\\vec{v}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.714em;vertical-align:0em;\"></span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.714em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">v</span></span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.20772em;\"><span class=\"overlay\" style=\"height:0.714em;width:0.471em;\"><svg width=\"0.471em\" height=\"0.714em\" style=\"width:0.471em\" viewbox=\"0 0 471 714\" preserveaspectratio=\"xMinYMin\"><path d=\"M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5\n3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11\n10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63\n-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1\n-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59\nH213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359\nc-16-25.333-24-45-24-59z\"/></svg></span></span></span></span></span></span></span></span></span></span>：特征向量</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">λ</span></span></span></span>：特征值</li>\n</ul>\n<p><img src=\"/2020/06/06/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%A9%BA%E9%97%B4%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3/7.png\" alt></p>\n</li>\n<li>\n<p>特征基：基向量也是特征向量，这表示在此线性变换中，只是在坐标的两轴方向进行了拉伸，变换矩阵必然是对角矩阵。</p>\n</li>\n<li>\n<p>应用：矩阵连乘。当一个线性变换有多个特征向量，且其能够组合出整个空间时（特征向量可以作为新的基向量），将原变换换基<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>M</mi><mi>A</mi></mrow><annotation encoding=\"application/x-tex\">A^{-1}MA</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault\">A</span></span></span></span> ，新的变换矩阵是对角矩阵，可快速进行连乘（对角的高次幂），再将结果换基回来<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>A</mi><mi>M</mi><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">AMA^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141079999999999em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></p>\n</li>\n</ul>"},{"title":"英语2：并列句","mathjax":false,"date":"2020-06-09T12:52:30.000Z","_content":"\n\n\n《刘晓艳语法长难句》第二章笔记\n\n<br/>\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# 并列句\n\n**由并列连词连接的两个或多个句子。**\n\neg：I love you, you love the dog. :x:\n\n不能由逗号连接两个句子，可改为：\n\n1. I love you but you love the dog.（并列连词）\n2. Although I love you, you love the dog.（从句）\n\n<br/>\n\n## 1. 并列连词与逻辑关系词\n\n### 1.1 并列连词\n\n1. 平行：and, not only… but also…, both … and …, either … or …, neither … nor …\n2. 转折：but, while, yet, whereas\n3. 选择：or, whether … or …\n4. 因果：for, so\n5. 递进：then\n\n<br/>\n\n### 1.2 同义的逻辑关系词（副词与介词短语）\n\n1. 平行：similarly, equally, likewise, at the same time, in the meanwhile \n2. 转折：however, nevertheless, nonetheless, conversely, contrarily, unexpectedly, unfortunately, on the contrary, in contrast\n3. 选择：alternatively\n4. 因果：therefore, thus, consequently, as a result, as a consequence\n5. 递进：besides, additionally, subsequently, in addition\n\n<br/>\n\n### 1.3 三者区别\n\n1. 连词时，逗号可加可不加\n2. 副词与介词短语时，要把逗号变句号，或加连词and（**即副词和介词短语不承担连接句子的功能**）\n\t1. I love you. However you love the dog.\n\t2. I love you, and however you love the dog.\n3. 使用副词与介词短语更出彩。\n\n<br/>\n\n## 2. 应用\n\n### 2.1 写作\n\n以常用于原因分析的not only … but also …为例\n\n1. Pets not **only can** bite others especially our neighbors or strangers **but also** usually make our living environment rather nasty.\n2. Respecting parents **not only keeps** a Chinese traditional virtue **but also proves** the duty of their offspring.（系动词替换）\n\n<br/>\n\n### 2.2 长难句分析（并列句省略）\n\n1. 并列句对称原则：\n\n\t1. 并列连词前后的词性、单复数、时态、语态保持一致；\n\n\t\tHe went shopping, bought some gifts and visited his friend.\n\n\t2. 连接三个及以上词时，前面用逗号，最后用and；\n\n\t3. 结构一致\n\n\t\tOn that day, a friend got married, then I realized the fleeting time.（主谓 主谓宾）\n\n2. 并列句的省略现象：因为要保持对称，同时避免重复，所以会省略部分内容\n\n\t1. 主谓一致可省略：He is not only a nice teacher but a friend to his students.（后句省略he is）\n\t2. 省略be动词：Disease A can be replaced, B controlled, and C removed. 三句主语不同但是谓语动词都是be，可省略\n\t3. 省略主语：He is rich, but leads a modest life.\n\t4. 省略重复部分：Do you remember all those years when scientists argued that smoking would kill us **but** the doubters insisted that we did not konw for sure?（but连接两个由that引导的从句，后句know的宾语是smoking would kill us，省略）\n\n3. 省略现象的查找判断\n\n\t1. 省略位于连词之后\n\t2. 后句有，前句也有\n\t3. 前句有，后句无，即为省略内容\n\n4. eg: Under modern conditions, this requires varying measures of centralized control and hence the help of specialized scientists such as economists and operational research experts.\n\n\t1. 找动词：requires\n\t2. 从而确定主谓：这项事情 需要 多种措施\n\t3. 找连词：and\n\t4. 连词后句：名词+定语 the help of … experts\n\t5. 所以前句也应是名词+定语：varying measures of centralized control\n\t6. 可见，后句省略了主谓：this requires\n\t7. 翻译：目前，这需要中央控制的各种措施，所以这也需要诸如经济学家和运筹学家等专业科学家的帮助。\n\n5. 书中仍有很多例子。\n\n","source":"_posts/英语2：并列句.md","raw":"---\ntitle: 英语2：并列句\nmathjax: false\ndate: 2020-06-09 20:52:30\ntags: 英语\n---\n\n\n\n《刘晓艳语法长难句》第二章笔记\n\n<br/>\n\n<!--more-->\n\n<!-- toc -->\n\n<br/>\n\n# 并列句\n\n**由并列连词连接的两个或多个句子。**\n\neg：I love you, you love the dog. :x:\n\n不能由逗号连接两个句子，可改为：\n\n1. I love you but you love the dog.（并列连词）\n2. Although I love you, you love the dog.（从句）\n\n<br/>\n\n## 1. 并列连词与逻辑关系词\n\n### 1.1 并列连词\n\n1. 平行：and, not only… but also…, both … and …, either … or …, neither … nor …\n2. 转折：but, while, yet, whereas\n3. 选择：or, whether … or …\n4. 因果：for, so\n5. 递进：then\n\n<br/>\n\n### 1.2 同义的逻辑关系词（副词与介词短语）\n\n1. 平行：similarly, equally, likewise, at the same time, in the meanwhile \n2. 转折：however, nevertheless, nonetheless, conversely, contrarily, unexpectedly, unfortunately, on the contrary, in contrast\n3. 选择：alternatively\n4. 因果：therefore, thus, consequently, as a result, as a consequence\n5. 递进：besides, additionally, subsequently, in addition\n\n<br/>\n\n### 1.3 三者区别\n\n1. 连词时，逗号可加可不加\n2. 副词与介词短语时，要把逗号变句号，或加连词and（**即副词和介词短语不承担连接句子的功能**）\n\t1. I love you. However you love the dog.\n\t2. I love you, and however you love the dog.\n3. 使用副词与介词短语更出彩。\n\n<br/>\n\n## 2. 应用\n\n### 2.1 写作\n\n以常用于原因分析的not only … but also …为例\n\n1. Pets not **only can** bite others especially our neighbors or strangers **but also** usually make our living environment rather nasty.\n2. Respecting parents **not only keeps** a Chinese traditional virtue **but also proves** the duty of their offspring.（系动词替换）\n\n<br/>\n\n### 2.2 长难句分析（并列句省略）\n\n1. 并列句对称原则：\n\n\t1. 并列连词前后的词性、单复数、时态、语态保持一致；\n\n\t\tHe went shopping, bought some gifts and visited his friend.\n\n\t2. 连接三个及以上词时，前面用逗号，最后用and；\n\n\t3. 结构一致\n\n\t\tOn that day, a friend got married, then I realized the fleeting time.（主谓 主谓宾）\n\n2. 并列句的省略现象：因为要保持对称，同时避免重复，所以会省略部分内容\n\n\t1. 主谓一致可省略：He is not only a nice teacher but a friend to his students.（后句省略he is）\n\t2. 省略be动词：Disease A can be replaced, B controlled, and C removed. 三句主语不同但是谓语动词都是be，可省略\n\t3. 省略主语：He is rich, but leads a modest life.\n\t4. 省略重复部分：Do you remember all those years when scientists argued that smoking would kill us **but** the doubters insisted that we did not konw for sure?（but连接两个由that引导的从句，后句know的宾语是smoking would kill us，省略）\n\n3. 省略现象的查找判断\n\n\t1. 省略位于连词之后\n\t2. 后句有，前句也有\n\t3. 前句有，后句无，即为省略内容\n\n4. eg: Under modern conditions, this requires varying measures of centralized control and hence the help of specialized scientists such as economists and operational research experts.\n\n\t1. 找动词：requires\n\t2. 从而确定主谓：这项事情 需要 多种措施\n\t3. 找连词：and\n\t4. 连词后句：名词+定语 the help of … experts\n\t5. 所以前句也应是名词+定语：varying measures of centralized control\n\t6. 可见，后句省略了主谓：this requires\n\t7. 翻译：目前，这需要中央控制的各种措施，所以这也需要诸如经济学家和运筹学家等专业科学家的帮助。\n\n5. 书中仍有很多例子。\n\n","slug":"英语2：并列句","published":1,"updated":"2020-06-16T13:12:58.441Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbewb000si0qv0kk23fte","content":"<p>《刘晓艳语法长难句》第二章笔记</p>\n<br>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#%E5%B9%B6%E5%88%97%E5%8F%A5\">并列句</a>\n<ul>\n<li><a href=\"#1-%E5%B9%B6%E5%88%97%E8%BF%9E%E8%AF%8D%E4%B8%8E%E9%80%BB%E8%BE%91%E5%85%B3%E7%B3%BB%E8%AF%8D\">1. 并列连词与逻辑关系词</a>\n<ul>\n<li><a href=\"#11-%E5%B9%B6%E5%88%97%E8%BF%9E%E8%AF%8D\">1.1 并列连词</a></li>\n<li><a href=\"#12-%E5%90%8C%E4%B9%89%E7%9A%84%E9%80%BB%E8%BE%91%E5%85%B3%E7%B3%BB%E8%AF%8D%E5%89%AF%E8%AF%8D%E4%B8%8E%E4%BB%8B%E8%AF%8D%E7%9F%AD%E8%AF%AD\">1.2 同义的逻辑关系词（副词与介词短语）</a></li>\n<li><a href=\"#13-%E4%B8%89%E8%80%85%E5%8C%BA%E5%88%AB\">1.3 三者区别</a></li>\n</ul>\n</li>\n<li><a href=\"#2-%E5%BA%94%E7%94%A8\">2. 应用</a>\n<ul>\n<li><a href=\"#21-%E5%86%99%E4%BD%9C\">2.1 写作</a></li>\n<li><a href=\"#22-%E9%95%BF%E9%9A%BE%E5%8F%A5%E5%88%86%E6%9E%90%E5%B9%B6%E5%88%97%E5%8F%A5%E7%9C%81%E7%95%A5\">2.2 长难句分析（并列句省略）</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"并列句\"> 并列句</span></h1>\n<p><strong>由并列连词连接的两个或多个句子。</strong></p>\n<p>eg：I love you, you love the dog. ❌</p>\n<p>不能由逗号连接两个句子，可改为：</p>\n<ol>\n<li>I love you but you love the dog.（并列连词）</li>\n<li>Although I love you, you love the dog.（从句）</li>\n</ol>\n<br>\n<h2><span id=\"1-并列连词与逻辑关系词\"> 1. 并列连词与逻辑关系词</span></h2>\n<h3><span id=\"11-并列连词\"> 1.1 并列连词</span></h3>\n<ol>\n<li>平行：and, not only… but also…, both … and …, either … or …, neither … nor …</li>\n<li>转折：but, while, yet, whereas</li>\n<li>选择：or, whether … or …</li>\n<li>因果：for, so</li>\n<li>递进：then</li>\n</ol>\n<br>\n<h3><span id=\"12-同义的逻辑关系词副词与介词短语\"> 1.2 同义的逻辑关系词（副词与介词短语）</span></h3>\n<ol>\n<li>平行：similarly, equally, likewise, at the same time, in the meanwhile</li>\n<li>转折：however, nevertheless, nonetheless, conversely, contrarily, unexpectedly, unfortunately, on the contrary, in contrast</li>\n<li>选择：alternatively</li>\n<li>因果：therefore, thus, consequently, as a result, as a consequence</li>\n<li>递进：besides, additionally, subsequently, in addition</li>\n</ol>\n<br>\n<h3><span id=\"13-三者区别\"> 1.3 三者区别</span></h3>\n<ol>\n<li>连词时，逗号可加可不加</li>\n<li>副词与介词短语时，要把逗号变句号，或加连词and（<strong>即副词和介词短语不承担连接句子的功能</strong>）\n<ol>\n<li>I love you. However you love the dog.</li>\n<li>I love you, and however you love the dog.</li>\n</ol>\n</li>\n<li>使用副词与介词短语更出彩。</li>\n</ol>\n<br>\n<h2><span id=\"2-应用\"> 2. 应用</span></h2>\n<h3><span id=\"21-写作\"> 2.1 写作</span></h3>\n<p>以常用于原因分析的not only … but also …为例</p>\n<ol>\n<li>Pets not <strong>only can</strong> bite others especially our neighbors or strangers <strong>but also</strong> usually make our living environment rather nasty.</li>\n<li>Respecting parents <strong>not only keeps</strong> a Chinese traditional virtue <strong>but also proves</strong> the duty of their offspring.（系动词替换）</li>\n</ol>\n<br>\n<h3><span id=\"22-长难句分析并列句省略\"> 2.2 长难句分析（并列句省略）</span></h3>\n<ol>\n<li>\n<p>并列句对称原则：</p>\n<ol>\n<li>\n<p>并列连词前后的词性、单复数、时态、语态保持一致；</p>\n<p>He went shopping, bought some gifts and visited his friend.</p>\n</li>\n<li>\n<p>连接三个及以上词时，前面用逗号，最后用and；</p>\n</li>\n<li>\n<p>结构一致</p>\n<p>On that day, a friend got married, then I realized the fleeting time.（主谓 主谓宾）</p>\n</li>\n</ol>\n</li>\n<li>\n<p>并列句的省略现象：因为要保持对称，同时避免重复，所以会省略部分内容</p>\n<ol>\n<li>主谓一致可省略：He is not only a nice teacher but a friend to his students.（后句省略he is）</li>\n<li>省略be动词：Disease A can be replaced, B controlled, and C removed. 三句主语不同但是谓语动词都是be，可省略</li>\n<li>省略主语：He is rich, but leads a modest life.</li>\n<li>省略重复部分：Do you remember all those years when scientists argued that smoking would kill us <strong>but</strong> the doubters insisted that we did not konw for sure?（but连接两个由that引导的从句，后句know的宾语是smoking would kill us，省略）</li>\n</ol>\n</li>\n<li>\n<p>省略现象的查找判断</p>\n<ol>\n<li>省略位于连词之后</li>\n<li>后句有，前句也有</li>\n<li>前句有，后句无，即为省略内容</li>\n</ol>\n</li>\n<li>\n<p>eg: Under modern conditions, this requires varying measures of centralized control and hence the help of specialized scientists such as economists and operational research experts.</p>\n<ol>\n<li>找动词：requires</li>\n<li>从而确定主谓：这项事情 需要 多种措施</li>\n<li>找连词：and</li>\n<li>连词后句：名词+定语 the help of … experts</li>\n<li>所以前句也应是名词+定语：varying measures of centralized control</li>\n<li>可见，后句省略了主谓：this requires</li>\n<li>翻译：目前，这需要中央控制的各种措施，所以这也需要诸如经济学家和运筹学家等专业科学家的帮助。</li>\n</ol>\n</li>\n<li>\n<p>书中仍有很多例子。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>《刘晓艳语法长难句》第二章笔记</p>\n<br>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#%E5%B9%B6%E5%88%97%E5%8F%A5\">并列句</a>\n<ul>\n<li><a href=\"#1-%E5%B9%B6%E5%88%97%E8%BF%9E%E8%AF%8D%E4%B8%8E%E9%80%BB%E8%BE%91%E5%85%B3%E7%B3%BB%E8%AF%8D\">1. 并列连词与逻辑关系词</a>\n<ul>\n<li><a href=\"#11-%E5%B9%B6%E5%88%97%E8%BF%9E%E8%AF%8D\">1.1 并列连词</a></li>\n<li><a href=\"#12-%E5%90%8C%E4%B9%89%E7%9A%84%E9%80%BB%E8%BE%91%E5%85%B3%E7%B3%BB%E8%AF%8D%E5%89%AF%E8%AF%8D%E4%B8%8E%E4%BB%8B%E8%AF%8D%E7%9F%AD%E8%AF%AD\">1.2 同义的逻辑关系词（副词与介词短语）</a></li>\n<li><a href=\"#13-%E4%B8%89%E8%80%85%E5%8C%BA%E5%88%AB\">1.3 三者区别</a></li>\n</ul>\n</li>\n<li><a href=\"#2-%E5%BA%94%E7%94%A8\">2. 应用</a>\n<ul>\n<li><a href=\"#21-%E5%86%99%E4%BD%9C\">2.1 写作</a></li>\n<li><a href=\"#22-%E9%95%BF%E9%9A%BE%E5%8F%A5%E5%88%86%E6%9E%90%E5%B9%B6%E5%88%97%E5%8F%A5%E7%9C%81%E7%95%A5\">2.2 长难句分析（并列句省略）</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"并列句\"><a class=\"markdownIt-Anchor\" href=\"#并列句\"></a> 并列句</h1>\n<p><strong>由并列连词连接的两个或多个句子。</strong></p>\n<p>eg：I love you, you love the dog. ❌</p>\n<p>不能由逗号连接两个句子，可改为：</p>\n<ol>\n<li>I love you but you love the dog.（并列连词）</li>\n<li>Although I love you, you love the dog.（从句）</li>\n</ol>\n<br>\n<h2 id=\"1-并列连词与逻辑关系词\"><a class=\"markdownIt-Anchor\" href=\"#1-并列连词与逻辑关系词\"></a> 1. 并列连词与逻辑关系词</h2>\n<h3 id=\"11-并列连词\"><a class=\"markdownIt-Anchor\" href=\"#11-并列连词\"></a> 1.1 并列连词</h3>\n<ol>\n<li>平行：and, not only… but also…, both … and …, either … or …, neither … nor …</li>\n<li>转折：but, while, yet, whereas</li>\n<li>选择：or, whether … or …</li>\n<li>因果：for, so</li>\n<li>递进：then</li>\n</ol>\n<br>\n<h3 id=\"12-同义的逻辑关系词副词与介词短语\"><a class=\"markdownIt-Anchor\" href=\"#12-同义的逻辑关系词副词与介词短语\"></a> 1.2 同义的逻辑关系词（副词与介词短语）</h3>\n<ol>\n<li>平行：similarly, equally, likewise, at the same time, in the meanwhile</li>\n<li>转折：however, nevertheless, nonetheless, conversely, contrarily, unexpectedly, unfortunately, on the contrary, in contrast</li>\n<li>选择：alternatively</li>\n<li>因果：therefore, thus, consequently, as a result, as a consequence</li>\n<li>递进：besides, additionally, subsequently, in addition</li>\n</ol>\n<br>\n<h3 id=\"13-三者区别\"><a class=\"markdownIt-Anchor\" href=\"#13-三者区别\"></a> 1.3 三者区别</h3>\n<ol>\n<li>连词时，逗号可加可不加</li>\n<li>副词与介词短语时，要把逗号变句号，或加连词and（<strong>即副词和介词短语不承担连接句子的功能</strong>）\n<ol>\n<li>I love you. However you love the dog.</li>\n<li>I love you, and however you love the dog.</li>\n</ol>\n</li>\n<li>使用副词与介词短语更出彩。</li>\n</ol>\n<br>\n<h2 id=\"2-应用\"><a class=\"markdownIt-Anchor\" href=\"#2-应用\"></a> 2. 应用</h2>\n<h3 id=\"21-写作\"><a class=\"markdownIt-Anchor\" href=\"#21-写作\"></a> 2.1 写作</h3>\n<p>以常用于原因分析的not only … but also …为例</p>\n<ol>\n<li>Pets not <strong>only can</strong> bite others especially our neighbors or strangers <strong>but also</strong> usually make our living environment rather nasty.</li>\n<li>Respecting parents <strong>not only keeps</strong> a Chinese traditional virtue <strong>but also proves</strong> the duty of their offspring.（系动词替换）</li>\n</ol>\n<br>\n<h3 id=\"22-长难句分析并列句省略\"><a class=\"markdownIt-Anchor\" href=\"#22-长难句分析并列句省略\"></a> 2.2 长难句分析（并列句省略）</h3>\n<ol>\n<li>\n<p>并列句对称原则：</p>\n<ol>\n<li>\n<p>并列连词前后的词性、单复数、时态、语态保持一致；</p>\n<p>He went shopping, bought some gifts and visited his friend.</p>\n</li>\n<li>\n<p>连接三个及以上词时，前面用逗号，最后用and；</p>\n</li>\n<li>\n<p>结构一致</p>\n<p>On that day, a friend got married, then I realized the fleeting time.（主谓 主谓宾）</p>\n</li>\n</ol>\n</li>\n<li>\n<p>并列句的省略现象：因为要保持对称，同时避免重复，所以会省略部分内容</p>\n<ol>\n<li>主谓一致可省略：He is not only a nice teacher but a friend to his students.（后句省略he is）</li>\n<li>省略be动词：Disease A can be replaced, B controlled, and C removed. 三句主语不同但是谓语动词都是be，可省略</li>\n<li>省略主语：He is rich, but leads a modest life.</li>\n<li>省略重复部分：Do you remember all those years when scientists argued that smoking would kill us <strong>but</strong> the doubters insisted that we did not konw for sure?（but连接两个由that引导的从句，后句know的宾语是smoking would kill us，省略）</li>\n</ol>\n</li>\n<li>\n<p>省略现象的查找判断</p>\n<ol>\n<li>省略位于连词之后</li>\n<li>后句有，前句也有</li>\n<li>前句有，后句无，即为省略内容</li>\n</ol>\n</li>\n<li>\n<p>eg: Under modern conditions, this requires varying measures of centralized control and hence the help of specialized scientists such as economists and operational research experts.</p>\n<ol>\n<li>找动词：requires</li>\n<li>从而确定主谓：这项事情 需要 多种措施</li>\n<li>找连词：and</li>\n<li>连词后句：名词+定语 the help of … experts</li>\n<li>所以前句也应是名词+定语：varying measures of centralized control</li>\n<li>可见，后句省略了主谓：this requires</li>\n<li>翻译：目前，这需要中央控制的各种措施，所以这也需要诸如经济学家和运筹学家等专业科学家的帮助。</li>\n</ol>\n</li>\n<li>\n<p>书中仍有很多例子。</p>\n</li>\n</ol>"},{"title":"重置博客","date":"2020-02-27T03:41:54.000Z","_content":"\n\n\n更换硬盘后原有hexo本地文件丢失，重置博客后的小结。\n\n<!--more-->\n\n\n\n[参考博客](https://blog.csdn.net/ZWX2445205419/article/details/66970640?utm_source=blogxgwz5)\n\n1. 文中存在问题：`clone`后`init`，会报错非空文件夹不能执行，可`init`后将`clone`到的文件存入\n2. github仓库应配置两个branch：master用于存放blog页面内容；hexo分支用于存放hexo（本地）内容\n3. `hexo d`后会自动部署到master分支；hexo分支需手动`git add . -f`、 `git commit`、 `git push origin hexo`~~、`git push origin_coding hexo`。因为有两个remote，一个github、一个coding，所以push要在origin和origin_coding各做一次。~~\n\t1. `.git/config`中，`[remote \"origin\"]`添加以下两句，即可一次 push，两个上传\n\t\t1. `pushurl = git@github.com:gaylong9/gaylong9.github.io.git`\n\t\t2. `pushurl = git@e.coding.net:gaylong9/gaylong9.git`\n4. 后续换机、或异地管理，只需clone仓库即可\n5. 文中提到异地管理时，需将`.deploy_git`删除，否则部署时会将博客部署到master分支，因为此次只是重建，并未涉及到博客复原（异地管理），故未尝试，存疑（两个分支不就是为了部署到master，备份到hexo吗）\n6. 图片问题：要使用`npm install https://github.com/CodeFalling/hexo-asset-image --save`命令安装hexo-asset-image插件，否则版本号不对，图片显示有些问题 [参考博客](https://blog.csdn.net/Strong997/article/details/97767929)\n7. 换行：`<br/>`\n8. 目录：安装`hexo-toc`，在`_config.yaml`中添加`toc: maxDepth: 5`，文章中添加 `<!-- t_o_c -->` ，没有下划线，**注意空格**","source":"_posts/重置博客.md","raw":"---\ntitle: 重置博客\ndate: 2020-02-27 11:41:54\ntags: 杂项\n---\n\n\n\n更换硬盘后原有hexo本地文件丢失，重置博客后的小结。\n\n<!--more-->\n\n\n\n[参考博客](https://blog.csdn.net/ZWX2445205419/article/details/66970640?utm_source=blogxgwz5)\n\n1. 文中存在问题：`clone`后`init`，会报错非空文件夹不能执行，可`init`后将`clone`到的文件存入\n2. github仓库应配置两个branch：master用于存放blog页面内容；hexo分支用于存放hexo（本地）内容\n3. `hexo d`后会自动部署到master分支；hexo分支需手动`git add . -f`、 `git commit`、 `git push origin hexo`~~、`git push origin_coding hexo`。因为有两个remote，一个github、一个coding，所以push要在origin和origin_coding各做一次。~~\n\t1. `.git/config`中，`[remote \"origin\"]`添加以下两句，即可一次 push，两个上传\n\t\t1. `pushurl = git@github.com:gaylong9/gaylong9.github.io.git`\n\t\t2. `pushurl = git@e.coding.net:gaylong9/gaylong9.git`\n4. 后续换机、或异地管理，只需clone仓库即可\n5. 文中提到异地管理时，需将`.deploy_git`删除，否则部署时会将博客部署到master分支，因为此次只是重建，并未涉及到博客复原（异地管理），故未尝试，存疑（两个分支不就是为了部署到master，备份到hexo吗）\n6. 图片问题：要使用`npm install https://github.com/CodeFalling/hexo-asset-image --save`命令安装hexo-asset-image插件，否则版本号不对，图片显示有些问题 [参考博客](https://blog.csdn.net/Strong997/article/details/97767929)\n7. 换行：`<br/>`\n8. 目录：安装`hexo-toc`，在`_config.yaml`中添加`toc: maxDepth: 5`，文章中添加 `<!-- t_o_c -->` ，没有下划线，**注意空格**","slug":"重置博客","published":1,"updated":"2020-05-30T12:22:42.439Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbewc000ui0qvgbz64dzn","content":"<p>更换硬盘后原有hexo本地文件丢失，重置博客后的小结。</p>\n<a id=\"more\"></a>\n<p><a href=\"https://blog.csdn.net/ZWX2445205419/article/details/66970640?utm_source=blogxgwz5\" target=\"_blank\" rel=\"noopener\">参考博客</a></p>\n<ol>\n<li>文中存在问题：<code>clone</code>后<code>init</code>，会报错非空文件夹不能执行，可<code>init</code>后将<code>clone</code>到的文件存入</li>\n<li>github仓库应配置两个branch：master用于存放blog页面内容；hexo分支用于存放hexo（本地）内容</li>\n<li><code>hexo d</code>后会自动部署到master分支；hexo分支需手动<code>git add . -f</code>、 <code>git commit</code>、 <code>git push origin hexo</code><s>、<code>git push origin_coding hexo</code>。因为有两个remote，一个github、一个coding，所以push要在origin和origin_coding各做一次。</s>\n<ol>\n<li><code>.git/config</code>中，<code>[remote &quot;origin&quot;]</code>添加以下两句，即可一次 push，两个上传\n<ol>\n<li><code>pushurl = git@github.com:gaylong9/gaylong9.github.io.git</code></li>\n<li><code>pushurl = git@e.coding.net:gaylong9/gaylong9.git</code></li>\n</ol>\n</li>\n</ol>\n</li>\n<li>后续换机、或异地管理，只需clone仓库即可</li>\n<li>文中提到异地管理时，需将<code>.deploy_git</code>删除，否则部署时会将博客部署到master分支，因为此次只是重建，并未涉及到博客复原（异地管理），故未尝试，存疑（两个分支不就是为了部署到master，备份到hexo吗）</li>\n<li>图片问题：要使用<code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code>命令安装hexo-asset-image插件，否则版本号不对，图片显示有些问题 <a href=\"https://blog.csdn.net/Strong997/article/details/97767929\" target=\"_blank\" rel=\"noopener\">参考博客</a></li>\n<li>换行：<code>&lt;br/&gt;</code></li>\n<li>目录：安装<code>hexo-toc</code>，在<code>_config.yaml</code>中添加<code>toc: maxDepth: 5</code>，文章中添加 <code>&lt;!-- t_o_c --&gt;</code> ，没有下划线，<strong>注意空格</strong></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>更换硬盘后原有hexo本地文件丢失，重置博客后的小结。</p>","more":"<p><a href=\"https://blog.csdn.net/ZWX2445205419/article/details/66970640?utm_source=blogxgwz5\" target=\"_blank\" rel=\"noopener\">参考博客</a></p>\n<ol>\n<li>文中存在问题：<code>clone</code>后<code>init</code>，会报错非空文件夹不能执行，可<code>init</code>后将<code>clone</code>到的文件存入</li>\n<li>github仓库应配置两个branch：master用于存放blog页面内容；hexo分支用于存放hexo（本地）内容</li>\n<li><code>hexo d</code>后会自动部署到master分支；hexo分支需手动<code>git add . -f</code>、 <code>git commit</code>、 <code>git push origin hexo</code><s>、<code>git push origin_coding hexo</code>。因为有两个remote，一个github、一个coding，所以push要在origin和origin_coding各做一次。</s>\n<ol>\n<li><code>.git/config</code>中，<code>[remote &quot;origin&quot;]</code>添加以下两句，即可一次 push，两个上传\n<ol>\n<li><code>pushurl = git@github.com:gaylong9/gaylong9.github.io.git</code></li>\n<li><code>pushurl = git@e.coding.net:gaylong9/gaylong9.git</code></li>\n</ol>\n</li>\n</ol>\n</li>\n<li>后续换机、或异地管理，只需clone仓库即可</li>\n<li>文中提到异地管理时，需将<code>.deploy_git</code>删除，否则部署时会将博客部署到master分支，因为此次只是重建，并未涉及到博客复原（异地管理），故未尝试，存疑（两个分支不就是为了部署到master，备份到hexo吗）</li>\n<li>图片问题：要使用<code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code>命令安装hexo-asset-image插件，否则版本号不对，图片显示有些问题 <a href=\"https://blog.csdn.net/Strong997/article/details/97767929\" target=\"_blank\" rel=\"noopener\">参考博客</a></li>\n<li>换行：<code>&lt;br/&gt;</code></li>\n<li>目录：安装<code>hexo-toc</code>，在<code>_config.yaml</code>中添加<code>toc: maxDepth: 5</code>，文章中添加 <code>&lt;!-- t_o_c --&gt;</code> ，没有下划线，<strong>注意空格</strong></li>\n</ol>"},{"title":"英语1：简单句","date":"2020-05-21T15:05:44.000Z","_content":"\n\n\n《刘晓艳语法长难句》第一章笔记\n\n<!--more-->\n\n<br/>\n\n<!-- toc -->\n\n<br/>\n\n[toc]\n\n<br/>\n\n# 1. 英语句子特点\n\n1. 有主谓\n\n2. 主语是谓语的发出者\n\n3. 宾语是谓语的承受者\n\n4. 一个句子只能有一个主语、一个谓语，否则需要连词\n\n5. :exclamation: 写作避免出现主语、谓语、宾语不匹配的情况\n\n6. eg：我的英语说得很好\n\n\t:o: I speak English well.\n\n\t:x: My English speaks well. \n\n<br/>\n\n---\n\n<br/>\n\n# 2. 基本结构\n\n1. 主谓\n2. 主谓宾\n3. 主谓表\n4. 主谓双宾\n5. 主谓宾宾补\n\n## 2.1 主谓\n\n一个主语、一个**带有时态的**谓语构成\n\n## 2.2 主谓宾 & 主谓表\n\n1. 主谓宾的谓语是**实义动词/行为动词**，能够表达实际动作\n\n2. 主谓表的谓语是**系动词/连系动词**，分为六类：\n\n\t1. 状态：be\n\t2. 感官：look, sound, taste, smell, feel + adj.\n\t3. 变化：get, become, turn, grow, fall\n\t4. 保持：keep, stay, remain, stand\n\t5. 表象：seem, appear\n\t6. 终止：prove\n\n3. 部分系动词也可作实义动词\n\n\teg：grow\n\n\tI grew up in this town. 实义动词\n\n\tThe coat grew dirty. 系动词\n\n## 2.3 主谓双宾\n\n主语+谓语+间接宾语+直接宾语，两个宾语的区分影响不大\n\n1. 常用双宾语动词：buy, pass, lend, give, tell, teach, show, bring, send, etc.\n2. eg: He brought **me a gift**.\n\n## 2.4 主谓宾宾补\n\n宾语+补语 → 复合宾语\n\n1. 宾语补足语：补充说明宾语特点、身份、让宾语完成动作\n2. 宾补常见类型：\n\t1. You should keep room **clean**. 形容词\n\t2. We made him **our leader**. 名词\n\t3. He told me **not to play in the street**. 不定式\n\t4. I like to watch boys **playing football**. 现在分词\n\t5. Yesterday I had a picture **taken with a cat**. 过去分词\n3. ~~双宾和宾宾补，区分不清又有什么关系呢~~\n\n<br/>\n\n---\n\n<br/>\n\n# 3. 句子成分\n\n句子的组成成分，由词或词组构成；从而词性会决定其所担任的成分 ~~（但是怎么可能能把词性也背下来呢，单词都背不会呢）~~\n\n1. 主语\n2. 谓语\n3. 宾语\n4. 表语\n5. 定语\n6. 状语\n7. 补足语\n8. 同位语\n\n## 3.1 谓语\n\n具有时态的实义动词（词组）或系动词。\n\n1. 成分：谓语只能是动词（词组），一般的动词（词组）也只能做谓语\n\n2. 谓语要做其他成分时，要变成非谓语结构（非动词结构）：\n\n\t1. 动词-ing，表示主动或进行\n\t2. 动词-ed，表示被动或完成\n\t3. to-动词，表示目的或将来\n\n3. 非谓语结构可做任何成分：\n\n\t1. 主语：-ing，或to do；to do（动词不定式）时常用it做主语，to do后置\n\t2. 表语：His job is **to look after** the baby.\n\t3. 宾语：He enjoys **staying with** his family.\n\t4. 定语：He found a good place **to live in**.\n\t5. 状语：He work hard **to get** money.\n\t6. 同位语：His habit, eating snack before sleeping, has not been changed.\n\n4. 多个动词时，**只能有一个做谓语**，其余要用非谓语结构：\n\n\tHe **pushed** the door, **walking** into the room and **seeing** a girl **sitting** on the bed.\n\n## 3.2 主语\n\n1. 成分：从句、代词、名词、非谓语\n\n2. 主语不能缺失；祈使句中为加强语气而省略，但不能说没有\n\n\t1. 下雨了 :arrow_right: It is raining.\n\t2. 有很多人喜欢我 :arrow_right: There are loads of individuals **having** affection for me.\n\t3. **多用高级词汇**\n\t4. 以There be句型为代表，容易出现多个谓语的错误，注意要用非谓语结构\n\n3. 减少以人称代词做主语；变主动为被动：\n\n\t1. 必须指出语法在考试中还是很重要的 :arrow_right: Grammar must be pointed out to be quite crucial in the examination.\n\t2. 我们不应该盲目追星 :arrow_right: Superstart should never be pursued blindly. \n\t3. 孝敬父母很重要 :arrow_right: Respecting parents is argued to be of great importance by a sea of private individuals.\n\n4. think :arrow_right: argue, contend, assume, presume, insist, maintain, assert, claim, be of the option that, have been convinced that, cling to the perspective that\n\n5. important :arrow_right: be of great importance, vital, significant, essential, indispensable, play a key role in sth.\n\n6. 实在难以解决时，使用人称代词做主语\n\n7. 被动语态：\n\n\t1. 语态：主语谓语之间的关系是主动还是被动；主语无法发出动作，就使用被动语态\n\n\t2. 与时态是独立的两个概念，所以被动语态也有时态\n\n\t| 时态         | 结构                 |\n\t| ------------ | -------------------- |\n\t| 原型（基础） | be done              |\n\t| 一般现在时   | am/is/are done       |\n\t| 一般过去时   | was/were done        |\n\t| 一般将来时   | will be done         |\n\t| 现在进行时   | am/is/are being done |\n\t| 过去进行时   | was/were being done  |\n\t| 现在完成时   | have/has been done   |\n\t| 过去完成时   | had been done        |\n\t| 情态动词     | 情态动词 be done     |\n\t\n\t3. 部分动词无被动：\n\n\t  1. have、own、possess等意为“拥有”的词\n\t  2. 系动词\n\t  3. happen、break out等意为“发生”或“爆发”的词\n\t  4. 不及物动词（主谓） eg：The sun rose.\n\n## 3.3 宾语\n\n1. 成分：代词、名词、非谓语、从句\n\n## 3.4 表语\n\n1. 成分：代词、名词、非谓语、形容词、介词短语\n\n<br/>\n\n---\n\n<br/>\n\n# 4. 动词时态\n\n1. 不同时间内所发生的动作（主谓宾）或存在的状态（主系表）\n\n2. 时态的判断，要**通过谓语判断**；时间短语或副词性标志词仅仅能够描述该动作发生的具体时间\n\n\teg：I always swam at the weekend. 我以前周末经常游泳。\n\n3. 时态种类：\n\n\t| 时态     | 一般     | 进行           | 完成            | 完成进行              |\n\t| -------- | -------- | -------------- | --------------- | --------------------- |\n\t| 现在     | do       | be doing       | have done       | have been doing       |\n\t| 过去     | did      | was doing      | had done        | had been doing        |\n\t| 将来     | will do  | will be doing  | will have done  | will have been doing  |\n\t| 过去将来 | would do | would be doing | would have done | would have been doing |\n\n4. 助动词：帮助谓语构成肯定句、否定句和疑问句的时态\n\n5. 有be：否定句be not；疑问句be提前\n\n6. 有动词：疑问句用助动词的不同时态形式\n\n## 4.1 一般现在时\n\n1. 定义：现阶段经常发生的事；客观真理及自然现象；人/物永久状态\n2. 助动词：do/does\n3. 肯定句：\n\t1. He **loves** me.\n\t2. I **am** a student.\n4. 否定句：do/does not；be not\n  5. He **does not like** his work.\n  6. He **is not** a child anymore.\n7. 疑问句：do/does/be提前、\n  8. **Do** you like dogs？\n  9. **Are** they friends？\n\n10. 常见标志词：频度、频率副词；其他具体时间段（in the morning、on Sundays）\n\n## 4.2 一般将来时\n\n1. 将来某时间发生的动作/存在的状态\n2. 助动词：will（所有人称）、shall（第一人称）\n3. 肯定句：\n\t1. I **will bring** him a present.\n\t2. I **will be** a teacher soon.\n\n4. 否定句：\n\t1. He **won`t fulfill** his promise.\n\t2. He **will not be** there next day.\n5. 疑问句：\n\t1. **Will you travel** to Beijing?\n\t2. **Will you be** a nurse?\n6. 标志词：将来时间、soon、in 段时间\n7. 其他结构：be going to, be about to do, be to do\n\n## 4.3 现在进行时\n\n1. **仅表示动作**正在发生，不表示状态\n2. 助动词：be\n3. 肯定句：\n\t1. We **are having** classes.\n4. 否定句：\n\t1. We **are not having** classes.\n5. 疑问句：\n\t1. **Are you having** classes?\n6. 标志词：right now, at present, at this time, these days, look, listen\n\n## 4.4 一般过去时\n\n1. 过去某段时间的动作/状态\n2. 助动词：did\n3. 肯定句：\n\t1. I **saw** him in the library yesterday.\n\t2. I **was** late for school yesterday.\n4. 否定句：\n\t1. I **didn`t** live there before.\n\t2. He **was not** a student long ago.\n5. 疑问句：\n\t1. **Did** you study English at 10?\n\t2. **Were** they in the park just now?\n6. 标志词：ago、last、just now、once upon a time\n\n## 4.5 现在完成时\n\n1. 动作持续到现在才完成，强调已经或曾经；但也可能延续下去\n\n2. 助动词：have has\n\n3. 肯定句：过去分词\n\n\t1. He **has already obtained** a scholarship.\n\t2. I **have been** in the city for more than 5 years.\n\n4. 否定句：have not/haven`t + done/been\n\n5. 疑问句：\n\n\t1. **Have** you **found** the missing child?\n\t2. **Have** you ever **been** to the UK?\n\n6. 标志词：already, ever, never, just, yet, still, since + 段时间（since引导时间状语从句用一般过去时，主句现在完成时）\n\n7. 瞬时动词可以完成时，但是不能接时间段，除非转换为延续性动词：\n\n\t![搜狗截图20200316222055](英语1：简单句/搜狗截图20200316222055.png)\n\n8. 与一般过去时区别：\n\n\t1. 一般过去时强调以前做过，与现在无关\n\t2. 现在完成时强调持续到现在/已完成/可能继续持续\n\n## 4.6 不常见时态：\n\n不常用不常见，但可能出现的难点时态\n\n1. 过去进行时：过去某个时间点正在发生的动作：\n\n\tI **was watching** TV at 9 last night.\n\n2. 过去将来时：过去视角将要发生的动作：\n\n\tShe promised that she **would come** to China some day.\n\n3. 过去完成时：过去某一时间之前就已完成：\n\n\tMy father **had slept** before I came back home.\n\n4. 现在完成进行时：过去持续到现在，并可能一直持续下去，译为一直做：\n\n\tI **have been doing** the experience these days.\n\n5. 过去完成进行时：过去时间段持续进行：\n\n\tI **had been writing** this paper those days.\n\n6. 将来完成时：将来某段时间内将要完成的动作：\n\n\tI **will have finished** my paper by the end of this semester.\n\n7. 将来进行时：将来时间点正在进行：\n\n\tI **will be meeting** him this time tomorrow.\n\n8. 过去将来进行时：过去角度，将来时刻正在进行：\n\n\tLi told me that he **would be living** in China some day.\n\n9. 过去将来完成时：过去角度，某一时间前将完成：\n\n\tDavid told me that he **would have finished** homework by 9.\n\n10. 将来完成进行时：在将来某时间段内持续进行：\n\n\tHe **will have been living** here for 5 years by the end of this month.\n\n11. 过去将来完成进行时：从过去某一时间，持续到过去将来某一时间：\n\n\tHe said that he **would have been living** here for 10 years by the end of last year.\n\n12. 时态区分不出也无关紧要，从动词的意义和过去式、过去分词也能猜出几分\n\n<br/>\n\n---\n\n<br/>\n\n# 5. 动词分类\n\n## 5.1 实义动词\n\n1. 就是表示具体动作的词\n2. 分类：及物动词、不及物动词\n\t1. 及物动词Vt.：+ 宾语\n\t2. 不及物动词Vi.：+ 介词 + 宾语\n\t3. V.表示均可\n\n## 5.2 连系动词\n\n即系动词，前面总结过\n\n## 5.3 情态动词\n\n1. 含义：本身有一定词义，表示说话人态度\n2. 用法：不单独出现，+实义动词/系动词\n3. 分类\n\t1. can、could 能、会、请求 = be capable of、be competent in\n\t2. may、might 许可，可能性 = be likely to\n\t3. must必须、have to不得不 = be bound to、be bound for\n\t4. should、ought to 应该 = be supposed to、be obliged to\n\t5. would 将会，想要 = intend to\n\t6. dare 敢\n4. 情态动词的完成时表示推测：\n\t1. must have done：一定做过\n\t2. needn`t have done：没必要，但做了\n\t3. could have done：本能做，但没做，遗憾\n\t4. should have done：本应做\n\n## 5.4 助动词\n\n1. 含义：帮助谓语动词一起构成否定、疑问、时态、语态的词\n2. 分类\n\t1. be：进行时，被动语态\n\t2. do：现在时、过去式、否定、疑问，强调，倒装\n\t3. have：完成时\n\t4. will：将来时\n\t5. 每个助动词均可倒装（助动词提前，从句提前前）：Only after things disappear will we cherish them. 人们只有失去才懂得珍惜。\n\n<br/>\n\n---\n\n<br/>\n\n# 6. 写作\n\n1. 难词替换成会的词，正确最重要\n2. 写不来的长难句用简单句表示\n\n<br/>\n\n---\n\n<br/>\n\n# 7. 长难句分析\n\n步骤：\n\n1. 找动词/词组，以有无连接词判断并确定主句的谓语（从句也有谓语）\n2. 解释谓语\n3. 翻译主干\n\n\n\neg： \n\n​\tThe coming of age of the postwar baby boom and an entry of women into the male-dominated job market have limited the opportunities of teenagers who are already questioning the heavy personal sacrifices involved in climbing Japan`s rigid social ladder to good schools and jobs.\n\n1. 谓语：have limited\n2. 解释：限制\n3. 主干——主语：and连接的两个并列成分，宾语：opportunities机会\n4. 战后生育潮的到来，和女性进入由男性主导的职场，都限制了…的机会。\n\n\n\n","source":"_posts/英语1：简单句.md","raw":"---\ntitle: 英语1：简单句\ndate: 2020-05-21 23:05:44\ntags: 英语\n---\n\n\n\n《刘晓艳语法长难句》第一章笔记\n\n<!--more-->\n\n<br/>\n\n<!-- toc -->\n\n<br/>\n\n[toc]\n\n<br/>\n\n# 1. 英语句子特点\n\n1. 有主谓\n\n2. 主语是谓语的发出者\n\n3. 宾语是谓语的承受者\n\n4. 一个句子只能有一个主语、一个谓语，否则需要连词\n\n5. :exclamation: 写作避免出现主语、谓语、宾语不匹配的情况\n\n6. eg：我的英语说得很好\n\n\t:o: I speak English well.\n\n\t:x: My English speaks well. \n\n<br/>\n\n---\n\n<br/>\n\n# 2. 基本结构\n\n1. 主谓\n2. 主谓宾\n3. 主谓表\n4. 主谓双宾\n5. 主谓宾宾补\n\n## 2.1 主谓\n\n一个主语、一个**带有时态的**谓语构成\n\n## 2.2 主谓宾 & 主谓表\n\n1. 主谓宾的谓语是**实义动词/行为动词**，能够表达实际动作\n\n2. 主谓表的谓语是**系动词/连系动词**，分为六类：\n\n\t1. 状态：be\n\t2. 感官：look, sound, taste, smell, feel + adj.\n\t3. 变化：get, become, turn, grow, fall\n\t4. 保持：keep, stay, remain, stand\n\t5. 表象：seem, appear\n\t6. 终止：prove\n\n3. 部分系动词也可作实义动词\n\n\teg：grow\n\n\tI grew up in this town. 实义动词\n\n\tThe coat grew dirty. 系动词\n\n## 2.3 主谓双宾\n\n主语+谓语+间接宾语+直接宾语，两个宾语的区分影响不大\n\n1. 常用双宾语动词：buy, pass, lend, give, tell, teach, show, bring, send, etc.\n2. eg: He brought **me a gift**.\n\n## 2.4 主谓宾宾补\n\n宾语+补语 → 复合宾语\n\n1. 宾语补足语：补充说明宾语特点、身份、让宾语完成动作\n2. 宾补常见类型：\n\t1. You should keep room **clean**. 形容词\n\t2. We made him **our leader**. 名词\n\t3. He told me **not to play in the street**. 不定式\n\t4. I like to watch boys **playing football**. 现在分词\n\t5. Yesterday I had a picture **taken with a cat**. 过去分词\n3. ~~双宾和宾宾补，区分不清又有什么关系呢~~\n\n<br/>\n\n---\n\n<br/>\n\n# 3. 句子成分\n\n句子的组成成分，由词或词组构成；从而词性会决定其所担任的成分 ~~（但是怎么可能能把词性也背下来呢，单词都背不会呢）~~\n\n1. 主语\n2. 谓语\n3. 宾语\n4. 表语\n5. 定语\n6. 状语\n7. 补足语\n8. 同位语\n\n## 3.1 谓语\n\n具有时态的实义动词（词组）或系动词。\n\n1. 成分：谓语只能是动词（词组），一般的动词（词组）也只能做谓语\n\n2. 谓语要做其他成分时，要变成非谓语结构（非动词结构）：\n\n\t1. 动词-ing，表示主动或进行\n\t2. 动词-ed，表示被动或完成\n\t3. to-动词，表示目的或将来\n\n3. 非谓语结构可做任何成分：\n\n\t1. 主语：-ing，或to do；to do（动词不定式）时常用it做主语，to do后置\n\t2. 表语：His job is **to look after** the baby.\n\t3. 宾语：He enjoys **staying with** his family.\n\t4. 定语：He found a good place **to live in**.\n\t5. 状语：He work hard **to get** money.\n\t6. 同位语：His habit, eating snack before sleeping, has not been changed.\n\n4. 多个动词时，**只能有一个做谓语**，其余要用非谓语结构：\n\n\tHe **pushed** the door, **walking** into the room and **seeing** a girl **sitting** on the bed.\n\n## 3.2 主语\n\n1. 成分：从句、代词、名词、非谓语\n\n2. 主语不能缺失；祈使句中为加强语气而省略，但不能说没有\n\n\t1. 下雨了 :arrow_right: It is raining.\n\t2. 有很多人喜欢我 :arrow_right: There are loads of individuals **having** affection for me.\n\t3. **多用高级词汇**\n\t4. 以There be句型为代表，容易出现多个谓语的错误，注意要用非谓语结构\n\n3. 减少以人称代词做主语；变主动为被动：\n\n\t1. 必须指出语法在考试中还是很重要的 :arrow_right: Grammar must be pointed out to be quite crucial in the examination.\n\t2. 我们不应该盲目追星 :arrow_right: Superstart should never be pursued blindly. \n\t3. 孝敬父母很重要 :arrow_right: Respecting parents is argued to be of great importance by a sea of private individuals.\n\n4. think :arrow_right: argue, contend, assume, presume, insist, maintain, assert, claim, be of the option that, have been convinced that, cling to the perspective that\n\n5. important :arrow_right: be of great importance, vital, significant, essential, indispensable, play a key role in sth.\n\n6. 实在难以解决时，使用人称代词做主语\n\n7. 被动语态：\n\n\t1. 语态：主语谓语之间的关系是主动还是被动；主语无法发出动作，就使用被动语态\n\n\t2. 与时态是独立的两个概念，所以被动语态也有时态\n\n\t| 时态         | 结构                 |\n\t| ------------ | -------------------- |\n\t| 原型（基础） | be done              |\n\t| 一般现在时   | am/is/are done       |\n\t| 一般过去时   | was/were done        |\n\t| 一般将来时   | will be done         |\n\t| 现在进行时   | am/is/are being done |\n\t| 过去进行时   | was/were being done  |\n\t| 现在完成时   | have/has been done   |\n\t| 过去完成时   | had been done        |\n\t| 情态动词     | 情态动词 be done     |\n\t\n\t3. 部分动词无被动：\n\n\t  1. have、own、possess等意为“拥有”的词\n\t  2. 系动词\n\t  3. happen、break out等意为“发生”或“爆发”的词\n\t  4. 不及物动词（主谓） eg：The sun rose.\n\n## 3.3 宾语\n\n1. 成分：代词、名词、非谓语、从句\n\n## 3.4 表语\n\n1. 成分：代词、名词、非谓语、形容词、介词短语\n\n<br/>\n\n---\n\n<br/>\n\n# 4. 动词时态\n\n1. 不同时间内所发生的动作（主谓宾）或存在的状态（主系表）\n\n2. 时态的判断，要**通过谓语判断**；时间短语或副词性标志词仅仅能够描述该动作发生的具体时间\n\n\teg：I always swam at the weekend. 我以前周末经常游泳。\n\n3. 时态种类：\n\n\t| 时态     | 一般     | 进行           | 完成            | 完成进行              |\n\t| -------- | -------- | -------------- | --------------- | --------------------- |\n\t| 现在     | do       | be doing       | have done       | have been doing       |\n\t| 过去     | did      | was doing      | had done        | had been doing        |\n\t| 将来     | will do  | will be doing  | will have done  | will have been doing  |\n\t| 过去将来 | would do | would be doing | would have done | would have been doing |\n\n4. 助动词：帮助谓语构成肯定句、否定句和疑问句的时态\n\n5. 有be：否定句be not；疑问句be提前\n\n6. 有动词：疑问句用助动词的不同时态形式\n\n## 4.1 一般现在时\n\n1. 定义：现阶段经常发生的事；客观真理及自然现象；人/物永久状态\n2. 助动词：do/does\n3. 肯定句：\n\t1. He **loves** me.\n\t2. I **am** a student.\n4. 否定句：do/does not；be not\n  5. He **does not like** his work.\n  6. He **is not** a child anymore.\n7. 疑问句：do/does/be提前、\n  8. **Do** you like dogs？\n  9. **Are** they friends？\n\n10. 常见标志词：频度、频率副词；其他具体时间段（in the morning、on Sundays）\n\n## 4.2 一般将来时\n\n1. 将来某时间发生的动作/存在的状态\n2. 助动词：will（所有人称）、shall（第一人称）\n3. 肯定句：\n\t1. I **will bring** him a present.\n\t2. I **will be** a teacher soon.\n\n4. 否定句：\n\t1. He **won`t fulfill** his promise.\n\t2. He **will not be** there next day.\n5. 疑问句：\n\t1. **Will you travel** to Beijing?\n\t2. **Will you be** a nurse?\n6. 标志词：将来时间、soon、in 段时间\n7. 其他结构：be going to, be about to do, be to do\n\n## 4.3 现在进行时\n\n1. **仅表示动作**正在发生，不表示状态\n2. 助动词：be\n3. 肯定句：\n\t1. We **are having** classes.\n4. 否定句：\n\t1. We **are not having** classes.\n5. 疑问句：\n\t1. **Are you having** classes?\n6. 标志词：right now, at present, at this time, these days, look, listen\n\n## 4.4 一般过去时\n\n1. 过去某段时间的动作/状态\n2. 助动词：did\n3. 肯定句：\n\t1. I **saw** him in the library yesterday.\n\t2. I **was** late for school yesterday.\n4. 否定句：\n\t1. I **didn`t** live there before.\n\t2. He **was not** a student long ago.\n5. 疑问句：\n\t1. **Did** you study English at 10?\n\t2. **Were** they in the park just now?\n6. 标志词：ago、last、just now、once upon a time\n\n## 4.5 现在完成时\n\n1. 动作持续到现在才完成，强调已经或曾经；但也可能延续下去\n\n2. 助动词：have has\n\n3. 肯定句：过去分词\n\n\t1. He **has already obtained** a scholarship.\n\t2. I **have been** in the city for more than 5 years.\n\n4. 否定句：have not/haven`t + done/been\n\n5. 疑问句：\n\n\t1. **Have** you **found** the missing child?\n\t2. **Have** you ever **been** to the UK?\n\n6. 标志词：already, ever, never, just, yet, still, since + 段时间（since引导时间状语从句用一般过去时，主句现在完成时）\n\n7. 瞬时动词可以完成时，但是不能接时间段，除非转换为延续性动词：\n\n\t![搜狗截图20200316222055](英语1：简单句/搜狗截图20200316222055.png)\n\n8. 与一般过去时区别：\n\n\t1. 一般过去时强调以前做过，与现在无关\n\t2. 现在完成时强调持续到现在/已完成/可能继续持续\n\n## 4.6 不常见时态：\n\n不常用不常见，但可能出现的难点时态\n\n1. 过去进行时：过去某个时间点正在发生的动作：\n\n\tI **was watching** TV at 9 last night.\n\n2. 过去将来时：过去视角将要发生的动作：\n\n\tShe promised that she **would come** to China some day.\n\n3. 过去完成时：过去某一时间之前就已完成：\n\n\tMy father **had slept** before I came back home.\n\n4. 现在完成进行时：过去持续到现在，并可能一直持续下去，译为一直做：\n\n\tI **have been doing** the experience these days.\n\n5. 过去完成进行时：过去时间段持续进行：\n\n\tI **had been writing** this paper those days.\n\n6. 将来完成时：将来某段时间内将要完成的动作：\n\n\tI **will have finished** my paper by the end of this semester.\n\n7. 将来进行时：将来时间点正在进行：\n\n\tI **will be meeting** him this time tomorrow.\n\n8. 过去将来进行时：过去角度，将来时刻正在进行：\n\n\tLi told me that he **would be living** in China some day.\n\n9. 过去将来完成时：过去角度，某一时间前将完成：\n\n\tDavid told me that he **would have finished** homework by 9.\n\n10. 将来完成进行时：在将来某时间段内持续进行：\n\n\tHe **will have been living** here for 5 years by the end of this month.\n\n11. 过去将来完成进行时：从过去某一时间，持续到过去将来某一时间：\n\n\tHe said that he **would have been living** here for 10 years by the end of last year.\n\n12. 时态区分不出也无关紧要，从动词的意义和过去式、过去分词也能猜出几分\n\n<br/>\n\n---\n\n<br/>\n\n# 5. 动词分类\n\n## 5.1 实义动词\n\n1. 就是表示具体动作的词\n2. 分类：及物动词、不及物动词\n\t1. 及物动词Vt.：+ 宾语\n\t2. 不及物动词Vi.：+ 介词 + 宾语\n\t3. V.表示均可\n\n## 5.2 连系动词\n\n即系动词，前面总结过\n\n## 5.3 情态动词\n\n1. 含义：本身有一定词义，表示说话人态度\n2. 用法：不单独出现，+实义动词/系动词\n3. 分类\n\t1. can、could 能、会、请求 = be capable of、be competent in\n\t2. may、might 许可，可能性 = be likely to\n\t3. must必须、have to不得不 = be bound to、be bound for\n\t4. should、ought to 应该 = be supposed to、be obliged to\n\t5. would 将会，想要 = intend to\n\t6. dare 敢\n4. 情态动词的完成时表示推测：\n\t1. must have done：一定做过\n\t2. needn`t have done：没必要，但做了\n\t3. could have done：本能做，但没做，遗憾\n\t4. should have done：本应做\n\n## 5.4 助动词\n\n1. 含义：帮助谓语动词一起构成否定、疑问、时态、语态的词\n2. 分类\n\t1. be：进行时，被动语态\n\t2. do：现在时、过去式、否定、疑问，强调，倒装\n\t3. have：完成时\n\t4. will：将来时\n\t5. 每个助动词均可倒装（助动词提前，从句提前前）：Only after things disappear will we cherish them. 人们只有失去才懂得珍惜。\n\n<br/>\n\n---\n\n<br/>\n\n# 6. 写作\n\n1. 难词替换成会的词，正确最重要\n2. 写不来的长难句用简单句表示\n\n<br/>\n\n---\n\n<br/>\n\n# 7. 长难句分析\n\n步骤：\n\n1. 找动词/词组，以有无连接词判断并确定主句的谓语（从句也有谓语）\n2. 解释谓语\n3. 翻译主干\n\n\n\neg： \n\n​\tThe coming of age of the postwar baby boom and an entry of women into the male-dominated job market have limited the opportunities of teenagers who are already questioning the heavy personal sacrifices involved in climbing Japan`s rigid social ladder to good schools and jobs.\n\n1. 谓语：have limited\n2. 解释：限制\n3. 主干——主语：and连接的两个并列成分，宾语：opportunities机会\n4. 战后生育潮的到来，和女性进入由男性主导的职场，都限制了…的机会。\n\n\n\n","slug":"英语1：简单句","published":1,"updated":"2020-06-16T13:13:11.229Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckc4xbewe000xi0qvcamcf5z5","content":"<p>《刘晓艳语法长难句》第一章笔记</p>\n<a id=\"more\"></a>\n<br>\n<!-- toc -->\n<ul>\n<li><a href=\"#1-%E8%8B%B1%E8%AF%AD%E5%8F%A5%E5%AD%90%E7%89%B9%E7%82%B9\">1. 英语句子特点</a></li>\n<li><a href=\"#2-%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84\">2. 基本结构</a>\n<ul>\n<li><a href=\"#21-%E4%B8%BB%E8%B0%93\">2.1 主谓</a></li>\n<li><a href=\"#22-%E4%B8%BB%E8%B0%93%E5%AE%BE-%E4%B8%BB%E8%B0%93%E8%A1%A8\">2.2 主谓宾 &amp; 主谓表</a></li>\n<li><a href=\"#23-%E4%B8%BB%E8%B0%93%E5%8F%8C%E5%AE%BE\">2.3 主谓双宾</a></li>\n<li><a href=\"#24-%E4%B8%BB%E8%B0%93%E5%AE%BE%E5%AE%BE%E8%A1%A5\">2.4 主谓宾宾补</a></li>\n</ul>\n</li>\n<li><a href=\"#3-%E5%8F%A5%E5%AD%90%E6%88%90%E5%88%86\">3. 句子成分</a>\n<ul>\n<li><a href=\"#31-%E8%B0%93%E8%AF%AD\">3.1 谓语</a></li>\n<li><a href=\"#32-%E4%B8%BB%E8%AF%AD\">3.2 主语</a></li>\n<li><a href=\"#33-%E5%AE%BE%E8%AF%AD\">3.3 宾语</a></li>\n<li><a href=\"#34-%E8%A1%A8%E8%AF%AD\">3.4 表语</a></li>\n</ul>\n</li>\n<li><a href=\"#4-%E5%8A%A8%E8%AF%8D%E6%97%B6%E6%80%81\">4. 动词时态</a>\n<ul>\n<li><a href=\"#41-%E4%B8%80%E8%88%AC%E7%8E%B0%E5%9C%A8%E6%97%B6\">4.1 一般现在时</a></li>\n<li><a href=\"#42-%E4%B8%80%E8%88%AC%E5%B0%86%E6%9D%A5%E6%97%B6\">4.2 一般将来时</a></li>\n<li><a href=\"#43-%E7%8E%B0%E5%9C%A8%E8%BF%9B%E8%A1%8C%E6%97%B6\">4.3 现在进行时</a></li>\n<li><a href=\"#44-%E4%B8%80%E8%88%AC%E8%BF%87%E5%8E%BB%E6%97%B6\">4.4 一般过去时</a></li>\n<li><a href=\"#45-%E7%8E%B0%E5%9C%A8%E5%AE%8C%E6%88%90%E6%97%B6\">4.5 现在完成时</a></li>\n<li><a href=\"#46-%E4%B8%8D%E5%B8%B8%E8%A7%81%E6%97%B6%E6%80%81\">4.6 不常见时态：</a></li>\n</ul>\n</li>\n<li><a href=\"#5-%E5%8A%A8%E8%AF%8D%E5%88%86%E7%B1%BB\">5. 动词分类</a>\n<ul>\n<li><a href=\"#51-%E5%AE%9E%E4%B9%89%E5%8A%A8%E8%AF%8D\">5.1 实义动词</a></li>\n<li><a href=\"#52-%E8%BF%9E%E7%B3%BB%E5%8A%A8%E8%AF%8D\">5.2 连系动词</a></li>\n<li><a href=\"#53-%E6%83%85%E6%80%81%E5%8A%A8%E8%AF%8D\">5.3 情态动词</a></li>\n<li><a href=\"#54-%E5%8A%A9%E5%8A%A8%E8%AF%8D\">5.4 助动词</a></li>\n</ul>\n</li>\n<li><a href=\"#6-%E5%86%99%E4%BD%9C\">6. 写作</a></li>\n<li><a href=\"#7-%E9%95%BF%E9%9A%BE%E5%8F%A5%E5%88%86%E6%9E%90\">7. 长难句分析</a></li>\n</ul>\n<!-- tocstop -->\n<br>\n<p>[toc]</p>\n<br>\n<h1><span id=\"1-英语句子特点\"> 1. 英语句子特点</span></h1>\n<ol>\n<li>\n<p>有主谓</p>\n</li>\n<li>\n<p>主语是谓语的发出者</p>\n</li>\n<li>\n<p>宾语是谓语的承受者</p>\n</li>\n<li>\n<p>一个句子只能有一个主语、一个谓语，否则需要连词</p>\n</li>\n<li>\n<p>❗️ 写作避免出现主语、谓语、宾语不匹配的情况</p>\n</li>\n<li>\n<p>eg：我的英语说得很好</p>\n<p>⭕️ I speak English well.</p>\n<p>❌ My English speaks well.</p>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1><span id=\"2-基本结构\"> 2. 基本结构</span></h1>\n<ol>\n<li>主谓</li>\n<li>主谓宾</li>\n<li>主谓表</li>\n<li>主谓双宾</li>\n<li>主谓宾宾补</li>\n</ol>\n<h2><span id=\"21-主谓\"> 2.1 主谓</span></h2>\n<p>一个主语、一个<strong>带有时态的</strong>谓语构成</p>\n<h2><span id=\"22-主谓宾-amp-主谓表\"> 2.2 主谓宾 &amp; 主谓表</span></h2>\n<ol>\n<li>\n<p>主谓宾的谓语是<strong>实义动词/行为动词</strong>，能够表达实际动作</p>\n</li>\n<li>\n<p>主谓表的谓语是<strong>系动词/连系动词</strong>，分为六类：</p>\n<ol>\n<li>状态：be</li>\n<li>感官：look, sound, taste, smell, feel + adj.</li>\n<li>变化：get, become, turn, grow, fall</li>\n<li>保持：keep, stay, remain, stand</li>\n<li>表象：seem, appear</li>\n<li>终止：prove</li>\n</ol>\n</li>\n<li>\n<p>部分系动词也可作实义动词</p>\n<p>eg：grow</p>\n<p>I grew up in this town. 实义动词</p>\n<p>The coat grew dirty. 系动词</p>\n</li>\n</ol>\n<h2><span id=\"23-主谓双宾\"> 2.3 主谓双宾</span></h2>\n<p>主语+谓语+间接宾语+直接宾语，两个宾语的区分影响不大</p>\n<ol>\n<li>常用双宾语动词：buy, pass, lend, give, tell, teach, show, bring, send, etc.</li>\n<li>eg: He brought <strong>me a gift</strong>.</li>\n</ol>\n<h2><span id=\"24-主谓宾宾补\"> 2.4 主谓宾宾补</span></h2>\n<p>宾语+补语 → 复合宾语</p>\n<ol>\n<li>宾语补足语：补充说明宾语特点、身份、让宾语完成动作</li>\n<li>宾补常见类型：\n<ol>\n<li>You should keep room <strong>clean</strong>. 形容词</li>\n<li>We made him <strong>our leader</strong>. 名词</li>\n<li>He told me <strong>not to play in the street</strong>. 不定式</li>\n<li>I like to watch boys <strong>playing football</strong>. 现在分词</li>\n<li>Yesterday I had a picture <strong>taken with a cat</strong>. 过去分词</li>\n</ol>\n</li>\n<li><s>双宾和宾宾补，区分不清又有什么关系呢</s></li>\n</ol>\n<br>\n<hr>\n<br>\n<h1><span id=\"3-句子成分\"> 3. 句子成分</span></h1>\n<p>句子的组成成分，由词或词组构成；从而词性会决定其所担任的成分 <s>（但是怎么可能能把词性也背下来呢，单词都背不会呢）</s></p>\n<ol>\n<li>主语</li>\n<li>谓语</li>\n<li>宾语</li>\n<li>表语</li>\n<li>定语</li>\n<li>状语</li>\n<li>补足语</li>\n<li>同位语</li>\n</ol>\n<h2><span id=\"31-谓语\"> 3.1 谓语</span></h2>\n<p>具有时态的实义动词（词组）或系动词。</p>\n<ol>\n<li>\n<p>成分：谓语只能是动词（词组），一般的动词（词组）也只能做谓语</p>\n</li>\n<li>\n<p>谓语要做其他成分时，要变成非谓语结构（非动词结构）：</p>\n<ol>\n<li>动词-ing，表示主动或进行</li>\n<li>动词-ed，表示被动或完成</li>\n<li>to-动词，表示目的或将来</li>\n</ol>\n</li>\n<li>\n<p>非谓语结构可做任何成分：</p>\n<ol>\n<li>主语：-ing，或to do；to do（动词不定式）时常用it做主语，to do后置</li>\n<li>表语：His job is <strong>to look after</strong> the baby.</li>\n<li>宾语：He enjoys <strong>staying with</strong> his family.</li>\n<li>定语：He found a good place <strong>to live in</strong>.</li>\n<li>状语：He work hard <strong>to get</strong> money.</li>\n<li>同位语：His habit, eating snack before sleeping, has not been changed.</li>\n</ol>\n</li>\n<li>\n<p>多个动词时，<strong>只能有一个做谓语</strong>，其余要用非谓语结构：</p>\n<p>He <strong>pushed</strong> the door, <strong>walking</strong> into the room and <strong>seeing</strong> a girl <strong>sitting</strong> on the bed.</p>\n</li>\n</ol>\n<h2><span id=\"32-主语\"> 3.2 主语</span></h2>\n<ol>\n<li>\n<p>成分：从句、代词、名词、非谓语</p>\n</li>\n<li>\n<p>主语不能缺失；祈使句中为加强语气而省略，但不能说没有</p>\n<ol>\n<li>下雨了 ➡️ It is raining.</li>\n<li>有很多人喜欢我 ➡️ There are loads of individuals <strong>having</strong> affection for me.</li>\n<li><strong>多用高级词汇</strong></li>\n<li>以There be句型为代表，容易出现多个谓语的错误，注意要用非谓语结构</li>\n</ol>\n</li>\n<li>\n<p>减少以人称代词做主语；变主动为被动：</p>\n<ol>\n<li>必须指出语法在考试中还是很重要的 ➡️ Grammar must be pointed out to be quite crucial in the examination.</li>\n<li>我们不应该盲目追星 ➡️ Superstart should never be pursued blindly.</li>\n<li>孝敬父母很重要 ➡️ Respecting parents is argued to be of great importance by a sea of private individuals.</li>\n</ol>\n</li>\n<li>\n<p>think ➡️ argue, contend, assume, presume, insist, maintain, assert, claim, be of the option that, have been convinced that, cling to the perspective that</p>\n</li>\n<li>\n<p>important ➡️ be of great importance, vital, significant, essential, indispensable, play a key role in sth.</p>\n</li>\n<li>\n<p>实在难以解决时，使用人称代词做主语</p>\n</li>\n<li>\n<p>被动语态：</p>\n<ol>\n<li>\n<p>语态：主语谓语之间的关系是主动还是被动；主语无法发出动作，就使用被动语态</p>\n</li>\n<li>\n<p>与时态是独立的两个概念，所以被动语态也有时态</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>时态</th>\n<th>结构</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>原型（基础）</td>\n<td>be done</td>\n</tr>\n<tr>\n<td>一般现在时</td>\n<td>am/is/are done</td>\n</tr>\n<tr>\n<td>一般过去时</td>\n<td>was/were done</td>\n</tr>\n<tr>\n<td>一般将来时</td>\n<td>will be done</td>\n</tr>\n<tr>\n<td>现在进行时</td>\n<td>am/is/are being done</td>\n</tr>\n<tr>\n<td>过去进行时</td>\n<td>was/were being done</td>\n</tr>\n<tr>\n<td>现在完成时</td>\n<td>have/has been done</td>\n</tr>\n<tr>\n<td>过去完成时</td>\n<td>had been done</td>\n</tr>\n<tr>\n<td>情态动词</td>\n<td>情态动词 be done</td>\n</tr>\n</tbody>\n</table>\n<ol start=\"3\">\n<li>\n<p>部分动词无被动：</p>\n</li>\n<li>\n<p>have、own、possess等意为“拥有”的词</p>\n</li>\n<li>\n<p>系动词</p>\n</li>\n<li>\n<p>happen、break out等意为“发生”或“爆发”的词</p>\n</li>\n<li>\n<p>不及物动词（主谓） eg：The sun rose.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"33-宾语\"> 3.3 宾语</span></h2>\n<ol>\n<li>成分：代词、名词、非谓语、从句</li>\n</ol>\n<h2><span id=\"34-表语\"> 3.4 表语</span></h2>\n<ol>\n<li>成分：代词、名词、非谓语、形容词、介词短语</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1><span id=\"4-动词时态\"> 4. 动词时态</span></h1>\n<ol>\n<li>\n<p>不同时间内所发生的动作（主谓宾）或存在的状态（主系表）</p>\n</li>\n<li>\n<p>时态的判断，要<strong>通过谓语判断</strong>；时间短语或副词性标志词仅仅能够描述该动作发生的具体时间</p>\n<p>eg：I always swam at the weekend. 我以前周末经常游泳。</p>\n</li>\n<li>\n<p>时态种类：</p>\n<table>\n<thead>\n<tr>\n<th>时态</th>\n<th>一般</th>\n<th>进行</th>\n<th>完成</th>\n<th>完成进行</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>现在</td>\n<td>do</td>\n<td>be doing</td>\n<td>have done</td>\n<td>have been doing</td>\n</tr>\n<tr>\n<td>过去</td>\n<td>did</td>\n<td>was doing</td>\n<td>had done</td>\n<td>had been doing</td>\n</tr>\n<tr>\n<td>将来</td>\n<td>will do</td>\n<td>will be doing</td>\n<td>will have done</td>\n<td>will have been doing</td>\n</tr>\n<tr>\n<td>过去将来</td>\n<td>would do</td>\n<td>would be doing</td>\n<td>would have done</td>\n<td>would have been doing</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>\n<p>助动词：帮助谓语构成肯定句、否定句和疑问句的时态</p>\n</li>\n<li>\n<p>有be：否定句be not；疑问句be提前</p>\n</li>\n<li>\n<p>有动词：疑问句用助动词的不同时态形式</p>\n</li>\n</ol>\n<h2><span id=\"41-一般现在时\"> 4.1 一般现在时</span></h2>\n<ol>\n<li>\n<p>定义：现阶段经常发生的事；客观真理及自然现象；人/物永久状态</p>\n</li>\n<li>\n<p>助动词：do/does</p>\n</li>\n<li>\n<p>肯定句：</p>\n<ol>\n<li>He <strong>loves</strong> me.</li>\n<li>I <strong>am</strong> a student.</li>\n</ol>\n</li>\n<li>\n<p>否定句：do/does not；be not</p>\n</li>\n<li>\n<p>He <strong>does not like</strong> his work.</p>\n</li>\n<li>\n<p>He <strong>is not</strong> a child anymore.</p>\n</li>\n<li>\n<p>疑问句：do/does/be提前、</p>\n</li>\n<li>\n<p><strong>Do</strong> you like dogs？</p>\n</li>\n<li>\n<p><strong>Are</strong> they friends？</p>\n</li>\n<li>\n<p>常见标志词：频度、频率副词；其他具体时间段（in the morning、on Sundays）</p>\n</li>\n</ol>\n<h2><span id=\"42-一般将来时\"> 4.2 一般将来时</span></h2>\n<ol>\n<li>\n<p>将来某时间发生的动作/存在的状态</p>\n</li>\n<li>\n<p>助动词：will（所有人称）、shall（第一人称）</p>\n</li>\n<li>\n<p>肯定句：</p>\n<ol>\n<li>I <strong>will bring</strong> him a present.</li>\n<li>I <strong>will be</strong> a teacher soon.</li>\n</ol>\n</li>\n<li>\n<p>否定句：</p>\n<ol>\n<li>He <strong>won`t fulfill</strong> his promise.</li>\n<li>He <strong>will not be</strong> there next day.</li>\n</ol>\n</li>\n<li>\n<p>疑问句：</p>\n<ol>\n<li><strong>Will you travel</strong> to Beijing?</li>\n<li><strong>Will you be</strong> a nurse?</li>\n</ol>\n</li>\n<li>\n<p>标志词：将来时间、soon、in 段时间</p>\n</li>\n<li>\n<p>其他结构：be going to, be about to do, be to do</p>\n</li>\n</ol>\n<h2><span id=\"43-现在进行时\"> 4.3 现在进行时</span></h2>\n<ol>\n<li><strong>仅表示动作</strong>正在发生，不表示状态</li>\n<li>助动词：be</li>\n<li>肯定句：\n<ol>\n<li>We <strong>are having</strong> classes.</li>\n</ol>\n</li>\n<li>否定句：\n<ol>\n<li>We <strong>are not having</strong> classes.</li>\n</ol>\n</li>\n<li>疑问句：\n<ol>\n<li><strong>Are you having</strong> classes?</li>\n</ol>\n</li>\n<li>标志词：right now, at present, at this time, these days, look, listen</li>\n</ol>\n<h2><span id=\"44-一般过去时\"> 4.4 一般过去时</span></h2>\n<ol>\n<li>过去某段时间的动作/状态</li>\n<li>助动词：did</li>\n<li>肯定句：\n<ol>\n<li>I <strong>saw</strong> him in the library yesterday.</li>\n<li>I <strong>was</strong> late for school yesterday.</li>\n</ol>\n</li>\n<li>否定句：\n<ol>\n<li>I <strong>didn`t</strong> live there before.</li>\n<li>He <strong>was not</strong> a student long ago.</li>\n</ol>\n</li>\n<li>疑问句：\n<ol>\n<li><strong>Did</strong> you study English at 10?</li>\n<li><strong>Were</strong> they in the park just now?</li>\n</ol>\n</li>\n<li>标志词：ago、last、just now、once upon a time</li>\n</ol>\n<h2><span id=\"45-现在完成时\"> 4.5 现在完成时</span></h2>\n<ol>\n<li>\n<p>动作持续到现在才完成，强调已经或曾经；但也可能延续下去</p>\n</li>\n<li>\n<p>助动词：have has</p>\n</li>\n<li>\n<p>肯定句：过去分词</p>\n<ol>\n<li>He <strong>has already obtained</strong> a scholarship.</li>\n<li>I <strong>have been</strong> in the city for more than 5 years.</li>\n</ol>\n</li>\n<li>\n<p>否定句：have not/haven`t + done/been</p>\n</li>\n<li>\n<p>疑问句：</p>\n<ol>\n<li><strong>Have</strong> you <strong>found</strong> the missing child?</li>\n<li><strong>Have</strong> you ever <strong>been</strong> to the UK?</li>\n</ol>\n</li>\n<li>\n<p>标志词：already, ever, never, just, yet, still, since + 段时间（since引导时间状语从句用一般过去时，主句现在完成时）</p>\n</li>\n<li>\n<p>瞬时动词可以完成时，但是不能接时间段，除非转换为延续性动词：</p>\n<p><img src=\"/2020/05/21/%E8%8B%B1%E8%AF%AD1%EF%BC%9A%E7%AE%80%E5%8D%95%E5%8F%A5/%E6%90%9C%E7%8B%97%E6%88%AA%E5%9B%BE20200316222055.png\" alt=\"搜狗截图20200316222055\"></p>\n</li>\n<li>\n<p>与一般过去时区别：</p>\n<ol>\n<li>一般过去时强调以前做过，与现在无关</li>\n<li>现在完成时强调持续到现在/已完成/可能继续持续</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"46-不常见时态\"> 4.6 不常见时态：</span></h2>\n<p>不常用不常见，但可能出现的难点时态</p>\n<ol>\n<li>\n<p>过去进行时：过去某个时间点正在发生的动作：</p>\n<p>I <strong>was watching</strong> TV at 9 last night.</p>\n</li>\n<li>\n<p>过去将来时：过去视角将要发生的动作：</p>\n<p>She promised that she <strong>would come</strong> to China some day.</p>\n</li>\n<li>\n<p>过去完成时：过去某一时间之前就已完成：</p>\n<p>My father <strong>had slept</strong> before I came back home.</p>\n</li>\n<li>\n<p>现在完成进行时：过去持续到现在，并可能一直持续下去，译为一直做：</p>\n<p>I <strong>have been doing</strong> the experience these days.</p>\n</li>\n<li>\n<p>过去完成进行时：过去时间段持续进行：</p>\n<p>I <strong>had been writing</strong> this paper those days.</p>\n</li>\n<li>\n<p>将来完成时：将来某段时间内将要完成的动作：</p>\n<p>I <strong>will have finished</strong> my paper by the end of this semester.</p>\n</li>\n<li>\n<p>将来进行时：将来时间点正在进行：</p>\n<p>I <strong>will be meeting</strong> him this time tomorrow.</p>\n</li>\n<li>\n<p>过去将来进行时：过去角度，将来时刻正在进行：</p>\n<p>Li told me that he <strong>would be living</strong> in China some day.</p>\n</li>\n<li>\n<p>过去将来完成时：过去角度，某一时间前将完成：</p>\n<p>David told me that he <strong>would have finished</strong> homework by 9.</p>\n</li>\n<li>\n<p>将来完成进行时：在将来某时间段内持续进行：</p>\n<p>He <strong>will have been living</strong> here for 5 years by the end of this month.</p>\n</li>\n<li>\n<p>过去将来完成进行时：从过去某一时间，持续到过去将来某一时间：</p>\n<p>He said that he <strong>would have been living</strong> here for 10 years by the end of last year.</p>\n</li>\n<li>\n<p>时态区分不出也无关紧要，从动词的意义和过去式、过去分词也能猜出几分</p>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1><span id=\"5-动词分类\"> 5. 动词分类</span></h1>\n<h2><span id=\"51-实义动词\"> 5.1 实义动词</span></h2>\n<ol>\n<li>就是表示具体动作的词</li>\n<li>分类：及物动词、不及物动词\n<ol>\n<li>及物动词Vt.：+ 宾语</li>\n<li>不及物动词Vi.：+ 介词 + 宾语</li>\n<li>V.表示均可</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"52-连系动词\"> 5.2 连系动词</span></h2>\n<p>即系动词，前面总结过</p>\n<h2><span id=\"53-情态动词\"> 5.3 情态动词</span></h2>\n<ol>\n<li>含义：本身有一定词义，表示说话人态度</li>\n<li>用法：不单独出现，+实义动词/系动词</li>\n<li>分类\n<ol>\n<li>can、could 能、会、请求 = be capable of、be competent in</li>\n<li>may、might 许可，可能性 = be likely to</li>\n<li>must必须、have to不得不 = be bound to、be bound for</li>\n<li>should、ought to 应该 = be supposed to、be obliged to</li>\n<li>would 将会，想要 = intend to</li>\n<li>dare 敢</li>\n</ol>\n</li>\n<li>情态动词的完成时表示推测：\n<ol>\n<li>must have done：一定做过</li>\n<li>needn`t have done：没必要，但做了</li>\n<li>could have done：本能做，但没做，遗憾</li>\n<li>should have done：本应做</li>\n</ol>\n</li>\n</ol>\n<h2><span id=\"54-助动词\"> 5.4 助动词</span></h2>\n<ol>\n<li>含义：帮助谓语动词一起构成否定、疑问、时态、语态的词</li>\n<li>分类\n<ol>\n<li>be：进行时，被动语态</li>\n<li>do：现在时、过去式、否定、疑问，强调，倒装</li>\n<li>have：完成时</li>\n<li>will：将来时</li>\n<li>每个助动词均可倒装（助动词提前，从句提前前）：Only after things disappear will we cherish them. 人们只有失去才懂得珍惜。</li>\n</ol>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1><span id=\"6-写作\"> 6. 写作</span></h1>\n<ol>\n<li>难词替换成会的词，正确最重要</li>\n<li>写不来的长难句用简单句表示</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1><span id=\"7-长难句分析\"> 7. 长难句分析</span></h1>\n<p>步骤：</p>\n<ol>\n<li>找动词/词组，以有无连接词判断并确定主句的谓语（从句也有谓语）</li>\n<li>解释谓语</li>\n<li>翻译主干</li>\n</ol>\n<p>eg：</p>\n<p>​\tThe coming of age of the postwar baby boom and an entry of women into the male-dominated job market have limited the opportunities of teenagers who are already questioning the heavy personal sacrifices involved in climbing Japan`s rigid social ladder to good schools and jobs.</p>\n<ol>\n<li>谓语：have limited</li>\n<li>解释：限制</li>\n<li>主干——主语：and连接的两个并列成分，宾语：opportunities机会</li>\n<li>战后生育潮的到来，和女性进入由男性主导的职场，都限制了…的机会。</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>《刘晓艳语法长难句》第一章笔记</p>","more":"<br>\n<!-- toc -->\n<ul>\n<li><a href=\"#1-%E8%8B%B1%E8%AF%AD%E5%8F%A5%E5%AD%90%E7%89%B9%E7%82%B9\">1. 英语句子特点</a></li>\n<li><a href=\"#2-%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84\">2. 基本结构</a>\n<ul>\n<li><a href=\"#21-%E4%B8%BB%E8%B0%93\">2.1 主谓</a></li>\n<li><a href=\"#22-%E4%B8%BB%E8%B0%93%E5%AE%BE-%E4%B8%BB%E8%B0%93%E8%A1%A8\">2.2 主谓宾 &amp; 主谓表</a></li>\n<li><a href=\"#23-%E4%B8%BB%E8%B0%93%E5%8F%8C%E5%AE%BE\">2.3 主谓双宾</a></li>\n<li><a href=\"#24-%E4%B8%BB%E8%B0%93%E5%AE%BE%E5%AE%BE%E8%A1%A5\">2.4 主谓宾宾补</a></li>\n</ul>\n</li>\n<li><a href=\"#3-%E5%8F%A5%E5%AD%90%E6%88%90%E5%88%86\">3. 句子成分</a>\n<ul>\n<li><a href=\"#31-%E8%B0%93%E8%AF%AD\">3.1 谓语</a></li>\n<li><a href=\"#32-%E4%B8%BB%E8%AF%AD\">3.2 主语</a></li>\n<li><a href=\"#33-%E5%AE%BE%E8%AF%AD\">3.3 宾语</a></li>\n<li><a href=\"#34-%E8%A1%A8%E8%AF%AD\">3.4 表语</a></li>\n</ul>\n</li>\n<li><a href=\"#4-%E5%8A%A8%E8%AF%8D%E6%97%B6%E6%80%81\">4. 动词时态</a>\n<ul>\n<li><a href=\"#41-%E4%B8%80%E8%88%AC%E7%8E%B0%E5%9C%A8%E6%97%B6\">4.1 一般现在时</a></li>\n<li><a href=\"#42-%E4%B8%80%E8%88%AC%E5%B0%86%E6%9D%A5%E6%97%B6\">4.2 一般将来时</a></li>\n<li><a href=\"#43-%E7%8E%B0%E5%9C%A8%E8%BF%9B%E8%A1%8C%E6%97%B6\">4.3 现在进行时</a></li>\n<li><a href=\"#44-%E4%B8%80%E8%88%AC%E8%BF%87%E5%8E%BB%E6%97%B6\">4.4 一般过去时</a></li>\n<li><a href=\"#45-%E7%8E%B0%E5%9C%A8%E5%AE%8C%E6%88%90%E6%97%B6\">4.5 现在完成时</a></li>\n<li><a href=\"#46-%E4%B8%8D%E5%B8%B8%E8%A7%81%E6%97%B6%E6%80%81\">4.6 不常见时态：</a></li>\n</ul>\n</li>\n<li><a href=\"#5-%E5%8A%A8%E8%AF%8D%E5%88%86%E7%B1%BB\">5. 动词分类</a>\n<ul>\n<li><a href=\"#51-%E5%AE%9E%E4%B9%89%E5%8A%A8%E8%AF%8D\">5.1 实义动词</a></li>\n<li><a href=\"#52-%E8%BF%9E%E7%B3%BB%E5%8A%A8%E8%AF%8D\">5.2 连系动词</a></li>\n<li><a href=\"#53-%E6%83%85%E6%80%81%E5%8A%A8%E8%AF%8D\">5.3 情态动词</a></li>\n<li><a href=\"#54-%E5%8A%A9%E5%8A%A8%E8%AF%8D\">5.4 助动词</a></li>\n</ul>\n</li>\n<li><a href=\"#6-%E5%86%99%E4%BD%9C\">6. 写作</a></li>\n<li><a href=\"#7-%E9%95%BF%E9%9A%BE%E5%8F%A5%E5%88%86%E6%9E%90\">7. 长难句分析</a></li>\n</ul>\n<!-- tocstop -->\n<br>\n<p>[toc]</p>\n<br>\n<h1 id=\"1-英语句子特点\"><a class=\"markdownIt-Anchor\" href=\"#1-英语句子特点\"></a> 1. 英语句子特点</h1>\n<ol>\n<li>\n<p>有主谓</p>\n</li>\n<li>\n<p>主语是谓语的发出者</p>\n</li>\n<li>\n<p>宾语是谓语的承受者</p>\n</li>\n<li>\n<p>一个句子只能有一个主语、一个谓语，否则需要连词</p>\n</li>\n<li>\n<p>❗️ 写作避免出现主语、谓语、宾语不匹配的情况</p>\n</li>\n<li>\n<p>eg：我的英语说得很好</p>\n<p>⭕️ I speak English well.</p>\n<p>❌ My English speaks well.</p>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1 id=\"2-基本结构\"><a class=\"markdownIt-Anchor\" href=\"#2-基本结构\"></a> 2. 基本结构</h1>\n<ol>\n<li>主谓</li>\n<li>主谓宾</li>\n<li>主谓表</li>\n<li>主谓双宾</li>\n<li>主谓宾宾补</li>\n</ol>\n<h2 id=\"21-主谓\"><a class=\"markdownIt-Anchor\" href=\"#21-主谓\"></a> 2.1 主谓</h2>\n<p>一个主语、一个<strong>带有时态的</strong>谓语构成</p>\n<h2 id=\"22-主谓宾-主谓表\"><a class=\"markdownIt-Anchor\" href=\"#22-主谓宾-主谓表\"></a> 2.2 主谓宾 &amp; 主谓表</h2>\n<ol>\n<li>\n<p>主谓宾的谓语是<strong>实义动词/行为动词</strong>，能够表达实际动作</p>\n</li>\n<li>\n<p>主谓表的谓语是<strong>系动词/连系动词</strong>，分为六类：</p>\n<ol>\n<li>状态：be</li>\n<li>感官：look, sound, taste, smell, feel + adj.</li>\n<li>变化：get, become, turn, grow, fall</li>\n<li>保持：keep, stay, remain, stand</li>\n<li>表象：seem, appear</li>\n<li>终止：prove</li>\n</ol>\n</li>\n<li>\n<p>部分系动词也可作实义动词</p>\n<p>eg：grow</p>\n<p>I grew up in this town. 实义动词</p>\n<p>The coat grew dirty. 系动词</p>\n</li>\n</ol>\n<h2 id=\"23-主谓双宾\"><a class=\"markdownIt-Anchor\" href=\"#23-主谓双宾\"></a> 2.3 主谓双宾</h2>\n<p>主语+谓语+间接宾语+直接宾语，两个宾语的区分影响不大</p>\n<ol>\n<li>常用双宾语动词：buy, pass, lend, give, tell, teach, show, bring, send, etc.</li>\n<li>eg: He brought <strong>me a gift</strong>.</li>\n</ol>\n<h2 id=\"24-主谓宾宾补\"><a class=\"markdownIt-Anchor\" href=\"#24-主谓宾宾补\"></a> 2.4 主谓宾宾补</h2>\n<p>宾语+补语 → 复合宾语</p>\n<ol>\n<li>宾语补足语：补充说明宾语特点、身份、让宾语完成动作</li>\n<li>宾补常见类型：\n<ol>\n<li>You should keep room <strong>clean</strong>. 形容词</li>\n<li>We made him <strong>our leader</strong>. 名词</li>\n<li>He told me <strong>not to play in the street</strong>. 不定式</li>\n<li>I like to watch boys <strong>playing football</strong>. 现在分词</li>\n<li>Yesterday I had a picture <strong>taken with a cat</strong>. 过去分词</li>\n</ol>\n</li>\n<li><s>双宾和宾宾补，区分不清又有什么关系呢</s></li>\n</ol>\n<br>\n<hr>\n<br>\n<h1 id=\"3-句子成分\"><a class=\"markdownIt-Anchor\" href=\"#3-句子成分\"></a> 3. 句子成分</h1>\n<p>句子的组成成分，由词或词组构成；从而词性会决定其所担任的成分 <s>（但是怎么可能能把词性也背下来呢，单词都背不会呢）</s></p>\n<ol>\n<li>主语</li>\n<li>谓语</li>\n<li>宾语</li>\n<li>表语</li>\n<li>定语</li>\n<li>状语</li>\n<li>补足语</li>\n<li>同位语</li>\n</ol>\n<h2 id=\"31-谓语\"><a class=\"markdownIt-Anchor\" href=\"#31-谓语\"></a> 3.1 谓语</h2>\n<p>具有时态的实义动词（词组）或系动词。</p>\n<ol>\n<li>\n<p>成分：谓语只能是动词（词组），一般的动词（词组）也只能做谓语</p>\n</li>\n<li>\n<p>谓语要做其他成分时，要变成非谓语结构（非动词结构）：</p>\n<ol>\n<li>动词-ing，表示主动或进行</li>\n<li>动词-ed，表示被动或完成</li>\n<li>to-动词，表示目的或将来</li>\n</ol>\n</li>\n<li>\n<p>非谓语结构可做任何成分：</p>\n<ol>\n<li>主语：-ing，或to do；to do（动词不定式）时常用it做主语，to do后置</li>\n<li>表语：His job is <strong>to look after</strong> the baby.</li>\n<li>宾语：He enjoys <strong>staying with</strong> his family.</li>\n<li>定语：He found a good place <strong>to live in</strong>.</li>\n<li>状语：He work hard <strong>to get</strong> money.</li>\n<li>同位语：His habit, eating snack before sleeping, has not been changed.</li>\n</ol>\n</li>\n<li>\n<p>多个动词时，<strong>只能有一个做谓语</strong>，其余要用非谓语结构：</p>\n<p>He <strong>pushed</strong> the door, <strong>walking</strong> into the room and <strong>seeing</strong> a girl <strong>sitting</strong> on the bed.</p>\n</li>\n</ol>\n<h2 id=\"32-主语\"><a class=\"markdownIt-Anchor\" href=\"#32-主语\"></a> 3.2 主语</h2>\n<ol>\n<li>\n<p>成分：从句、代词、名词、非谓语</p>\n</li>\n<li>\n<p>主语不能缺失；祈使句中为加强语气而省略，但不能说没有</p>\n<ol>\n<li>下雨了 ➡️ It is raining.</li>\n<li>有很多人喜欢我 ➡️ There are loads of individuals <strong>having</strong> affection for me.</li>\n<li><strong>多用高级词汇</strong></li>\n<li>以There be句型为代表，容易出现多个谓语的错误，注意要用非谓语结构</li>\n</ol>\n</li>\n<li>\n<p>减少以人称代词做主语；变主动为被动：</p>\n<ol>\n<li>必须指出语法在考试中还是很重要的 ➡️ Grammar must be pointed out to be quite crucial in the examination.</li>\n<li>我们不应该盲目追星 ➡️ Superstart should never be pursued blindly.</li>\n<li>孝敬父母很重要 ➡️ Respecting parents is argued to be of great importance by a sea of private individuals.</li>\n</ol>\n</li>\n<li>\n<p>think ➡️ argue, contend, assume, presume, insist, maintain, assert, claim, be of the option that, have been convinced that, cling to the perspective that</p>\n</li>\n<li>\n<p>important ➡️ be of great importance, vital, significant, essential, indispensable, play a key role in sth.</p>\n</li>\n<li>\n<p>实在难以解决时，使用人称代词做主语</p>\n</li>\n<li>\n<p>被动语态：</p>\n<ol>\n<li>\n<p>语态：主语谓语之间的关系是主动还是被动；主语无法发出动作，就使用被动语态</p>\n</li>\n<li>\n<p>与时态是独立的两个概念，所以被动语态也有时态</p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>时态</th>\n<th>结构</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>原型（基础）</td>\n<td>be done</td>\n</tr>\n<tr>\n<td>一般现在时</td>\n<td>am/is/are done</td>\n</tr>\n<tr>\n<td>一般过去时</td>\n<td>was/were done</td>\n</tr>\n<tr>\n<td>一般将来时</td>\n<td>will be done</td>\n</tr>\n<tr>\n<td>现在进行时</td>\n<td>am/is/are being done</td>\n</tr>\n<tr>\n<td>过去进行时</td>\n<td>was/were being done</td>\n</tr>\n<tr>\n<td>现在完成时</td>\n<td>have/has been done</td>\n</tr>\n<tr>\n<td>过去完成时</td>\n<td>had been done</td>\n</tr>\n<tr>\n<td>情态动词</td>\n<td>情态动词 be done</td>\n</tr>\n</tbody>\n</table>\n<ol start=\"3\">\n<li>\n<p>部分动词无被动：</p>\n</li>\n<li>\n<p>have、own、possess等意为“拥有”的词</p>\n</li>\n<li>\n<p>系动词</p>\n</li>\n<li>\n<p>happen、break out等意为“发生”或“爆发”的词</p>\n</li>\n<li>\n<p>不及物动词（主谓） eg：The sun rose.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"33-宾语\"><a class=\"markdownIt-Anchor\" href=\"#33-宾语\"></a> 3.3 宾语</h2>\n<ol>\n<li>成分：代词、名词、非谓语、从句</li>\n</ol>\n<h2 id=\"34-表语\"><a class=\"markdownIt-Anchor\" href=\"#34-表语\"></a> 3.4 表语</h2>\n<ol>\n<li>成分：代词、名词、非谓语、形容词、介词短语</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1 id=\"4-动词时态\"><a class=\"markdownIt-Anchor\" href=\"#4-动词时态\"></a> 4. 动词时态</h1>\n<ol>\n<li>\n<p>不同时间内所发生的动作（主谓宾）或存在的状态（主系表）</p>\n</li>\n<li>\n<p>时态的判断，要<strong>通过谓语判断</strong>；时间短语或副词性标志词仅仅能够描述该动作发生的具体时间</p>\n<p>eg：I always swam at the weekend. 我以前周末经常游泳。</p>\n</li>\n<li>\n<p>时态种类：</p>\n<table>\n<thead>\n<tr>\n<th>时态</th>\n<th>一般</th>\n<th>进行</th>\n<th>完成</th>\n<th>完成进行</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>现在</td>\n<td>do</td>\n<td>be doing</td>\n<td>have done</td>\n<td>have been doing</td>\n</tr>\n<tr>\n<td>过去</td>\n<td>did</td>\n<td>was doing</td>\n<td>had done</td>\n<td>had been doing</td>\n</tr>\n<tr>\n<td>将来</td>\n<td>will do</td>\n<td>will be doing</td>\n<td>will have done</td>\n<td>will have been doing</td>\n</tr>\n<tr>\n<td>过去将来</td>\n<td>would do</td>\n<td>would be doing</td>\n<td>would have done</td>\n<td>would have been doing</td>\n</tr>\n</tbody>\n</table>\n</li>\n<li>\n<p>助动词：帮助谓语构成肯定句、否定句和疑问句的时态</p>\n</li>\n<li>\n<p>有be：否定句be not；疑问句be提前</p>\n</li>\n<li>\n<p>有动词：疑问句用助动词的不同时态形式</p>\n</li>\n</ol>\n<h2 id=\"41-一般现在时\"><a class=\"markdownIt-Anchor\" href=\"#41-一般现在时\"></a> 4.1 一般现在时</h2>\n<ol>\n<li>\n<p>定义：现阶段经常发生的事；客观真理及自然现象；人/物永久状态</p>\n</li>\n<li>\n<p>助动词：do/does</p>\n</li>\n<li>\n<p>肯定句：</p>\n<ol>\n<li>He <strong>loves</strong> me.</li>\n<li>I <strong>am</strong> a student.</li>\n</ol>\n</li>\n<li>\n<p>否定句：do/does not；be not</p>\n</li>\n<li>\n<p>He <strong>does not like</strong> his work.</p>\n</li>\n<li>\n<p>He <strong>is not</strong> a child anymore.</p>\n</li>\n<li>\n<p>疑问句：do/does/be提前、</p>\n</li>\n<li>\n<p><strong>Do</strong> you like dogs？</p>\n</li>\n<li>\n<p><strong>Are</strong> they friends？</p>\n</li>\n<li>\n<p>常见标志词：频度、频率副词；其他具体时间段（in the morning、on Sundays）</p>\n</li>\n</ol>\n<h2 id=\"42-一般将来时\"><a class=\"markdownIt-Anchor\" href=\"#42-一般将来时\"></a> 4.2 一般将来时</h2>\n<ol>\n<li>\n<p>将来某时间发生的动作/存在的状态</p>\n</li>\n<li>\n<p>助动词：will（所有人称）、shall（第一人称）</p>\n</li>\n<li>\n<p>肯定句：</p>\n<ol>\n<li>I <strong>will bring</strong> him a present.</li>\n<li>I <strong>will be</strong> a teacher soon.</li>\n</ol>\n</li>\n<li>\n<p>否定句：</p>\n<ol>\n<li>He <strong>won`t fulfill</strong> his promise.</li>\n<li>He <strong>will not be</strong> there next day.</li>\n</ol>\n</li>\n<li>\n<p>疑问句：</p>\n<ol>\n<li><strong>Will you travel</strong> to Beijing?</li>\n<li><strong>Will you be</strong> a nurse?</li>\n</ol>\n</li>\n<li>\n<p>标志词：将来时间、soon、in 段时间</p>\n</li>\n<li>\n<p>其他结构：be going to, be about to do, be to do</p>\n</li>\n</ol>\n<h2 id=\"43-现在进行时\"><a class=\"markdownIt-Anchor\" href=\"#43-现在进行时\"></a> 4.3 现在进行时</h2>\n<ol>\n<li><strong>仅表示动作</strong>正在发生，不表示状态</li>\n<li>助动词：be</li>\n<li>肯定句：\n<ol>\n<li>We <strong>are having</strong> classes.</li>\n</ol>\n</li>\n<li>否定句：\n<ol>\n<li>We <strong>are not having</strong> classes.</li>\n</ol>\n</li>\n<li>疑问句：\n<ol>\n<li><strong>Are you having</strong> classes?</li>\n</ol>\n</li>\n<li>标志词：right now, at present, at this time, these days, look, listen</li>\n</ol>\n<h2 id=\"44-一般过去时\"><a class=\"markdownIt-Anchor\" href=\"#44-一般过去时\"></a> 4.4 一般过去时</h2>\n<ol>\n<li>过去某段时间的动作/状态</li>\n<li>助动词：did</li>\n<li>肯定句：\n<ol>\n<li>I <strong>saw</strong> him in the library yesterday.</li>\n<li>I <strong>was</strong> late for school yesterday.</li>\n</ol>\n</li>\n<li>否定句：\n<ol>\n<li>I <strong>didn`t</strong> live there before.</li>\n<li>He <strong>was not</strong> a student long ago.</li>\n</ol>\n</li>\n<li>疑问句：\n<ol>\n<li><strong>Did</strong> you study English at 10?</li>\n<li><strong>Were</strong> they in the park just now?</li>\n</ol>\n</li>\n<li>标志词：ago、last、just now、once upon a time</li>\n</ol>\n<h2 id=\"45-现在完成时\"><a class=\"markdownIt-Anchor\" href=\"#45-现在完成时\"></a> 4.5 现在完成时</h2>\n<ol>\n<li>\n<p>动作持续到现在才完成，强调已经或曾经；但也可能延续下去</p>\n</li>\n<li>\n<p>助动词：have has</p>\n</li>\n<li>\n<p>肯定句：过去分词</p>\n<ol>\n<li>He <strong>has already obtained</strong> a scholarship.</li>\n<li>I <strong>have been</strong> in the city for more than 5 years.</li>\n</ol>\n</li>\n<li>\n<p>否定句：have not/haven`t + done/been</p>\n</li>\n<li>\n<p>疑问句：</p>\n<ol>\n<li><strong>Have</strong> you <strong>found</strong> the missing child?</li>\n<li><strong>Have</strong> you ever <strong>been</strong> to the UK?</li>\n</ol>\n</li>\n<li>\n<p>标志词：already, ever, never, just, yet, still, since + 段时间（since引导时间状语从句用一般过去时，主句现在完成时）</p>\n</li>\n<li>\n<p>瞬时动词可以完成时，但是不能接时间段，除非转换为延续性动词：</p>\n<p><img src=\"/2020/05/21/%E8%8B%B1%E8%AF%AD1%EF%BC%9A%E7%AE%80%E5%8D%95%E5%8F%A5/%E6%90%9C%E7%8B%97%E6%88%AA%E5%9B%BE20200316222055.png\" alt=\"搜狗截图20200316222055\"></p>\n</li>\n<li>\n<p>与一般过去时区别：</p>\n<ol>\n<li>一般过去时强调以前做过，与现在无关</li>\n<li>现在完成时强调持续到现在/已完成/可能继续持续</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"46-不常见时态\"><a class=\"markdownIt-Anchor\" href=\"#46-不常见时态\"></a> 4.6 不常见时态：</h2>\n<p>不常用不常见，但可能出现的难点时态</p>\n<ol>\n<li>\n<p>过去进行时：过去某个时间点正在发生的动作：</p>\n<p>I <strong>was watching</strong> TV at 9 last night.</p>\n</li>\n<li>\n<p>过去将来时：过去视角将要发生的动作：</p>\n<p>She promised that she <strong>would come</strong> to China some day.</p>\n</li>\n<li>\n<p>过去完成时：过去某一时间之前就已完成：</p>\n<p>My father <strong>had slept</strong> before I came back home.</p>\n</li>\n<li>\n<p>现在完成进行时：过去持续到现在，并可能一直持续下去，译为一直做：</p>\n<p>I <strong>have been doing</strong> the experience these days.</p>\n</li>\n<li>\n<p>过去完成进行时：过去时间段持续进行：</p>\n<p>I <strong>had been writing</strong> this paper those days.</p>\n</li>\n<li>\n<p>将来完成时：将来某段时间内将要完成的动作：</p>\n<p>I <strong>will have finished</strong> my paper by the end of this semester.</p>\n</li>\n<li>\n<p>将来进行时：将来时间点正在进行：</p>\n<p>I <strong>will be meeting</strong> him this time tomorrow.</p>\n</li>\n<li>\n<p>过去将来进行时：过去角度，将来时刻正在进行：</p>\n<p>Li told me that he <strong>would be living</strong> in China some day.</p>\n</li>\n<li>\n<p>过去将来完成时：过去角度，某一时间前将完成：</p>\n<p>David told me that he <strong>would have finished</strong> homework by 9.</p>\n</li>\n<li>\n<p>将来完成进行时：在将来某时间段内持续进行：</p>\n<p>He <strong>will have been living</strong> here for 5 years by the end of this month.</p>\n</li>\n<li>\n<p>过去将来完成进行时：从过去某一时间，持续到过去将来某一时间：</p>\n<p>He said that he <strong>would have been living</strong> here for 10 years by the end of last year.</p>\n</li>\n<li>\n<p>时态区分不出也无关紧要，从动词的意义和过去式、过去分词也能猜出几分</p>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1 id=\"5-动词分类\"><a class=\"markdownIt-Anchor\" href=\"#5-动词分类\"></a> 5. 动词分类</h1>\n<h2 id=\"51-实义动词\"><a class=\"markdownIt-Anchor\" href=\"#51-实义动词\"></a> 5.1 实义动词</h2>\n<ol>\n<li>就是表示具体动作的词</li>\n<li>分类：及物动词、不及物动词\n<ol>\n<li>及物动词Vt.：+ 宾语</li>\n<li>不及物动词Vi.：+ 介词 + 宾语</li>\n<li>V.表示均可</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"52-连系动词\"><a class=\"markdownIt-Anchor\" href=\"#52-连系动词\"></a> 5.2 连系动词</h2>\n<p>即系动词，前面总结过</p>\n<h2 id=\"53-情态动词\"><a class=\"markdownIt-Anchor\" href=\"#53-情态动词\"></a> 5.3 情态动词</h2>\n<ol>\n<li>含义：本身有一定词义，表示说话人态度</li>\n<li>用法：不单独出现，+实义动词/系动词</li>\n<li>分类\n<ol>\n<li>can、could 能、会、请求 = be capable of、be competent in</li>\n<li>may、might 许可，可能性 = be likely to</li>\n<li>must必须、have to不得不 = be bound to、be bound for</li>\n<li>should、ought to 应该 = be supposed to、be obliged to</li>\n<li>would 将会，想要 = intend to</li>\n<li>dare 敢</li>\n</ol>\n</li>\n<li>情态动词的完成时表示推测：\n<ol>\n<li>must have done：一定做过</li>\n<li>needn`t have done：没必要，但做了</li>\n<li>could have done：本能做，但没做，遗憾</li>\n<li>should have done：本应做</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"54-助动词\"><a class=\"markdownIt-Anchor\" href=\"#54-助动词\"></a> 5.4 助动词</h2>\n<ol>\n<li>含义：帮助谓语动词一起构成否定、疑问、时态、语态的词</li>\n<li>分类\n<ol>\n<li>be：进行时，被动语态</li>\n<li>do：现在时、过去式、否定、疑问，强调，倒装</li>\n<li>have：完成时</li>\n<li>will：将来时</li>\n<li>每个助动词均可倒装（助动词提前，从句提前前）：Only after things disappear will we cherish them. 人们只有失去才懂得珍惜。</li>\n</ol>\n</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1 id=\"6-写作\"><a class=\"markdownIt-Anchor\" href=\"#6-写作\"></a> 6. 写作</h1>\n<ol>\n<li>难词替换成会的词，正确最重要</li>\n<li>写不来的长难句用简单句表示</li>\n</ol>\n<br>\n<hr>\n<br>\n<h1 id=\"7-长难句分析\"><a class=\"markdownIt-Anchor\" href=\"#7-长难句分析\"></a> 7. 长难句分析</h1>\n<p>步骤：</p>\n<ol>\n<li>找动词/词组，以有无连接词判断并确定主句的谓语（从句也有谓语）</li>\n<li>解释谓语</li>\n<li>翻译主干</li>\n</ol>\n<p>eg：</p>\n<p>​\tThe coming of age of the postwar baby boom and an entry of women into the male-dominated job market have limited the opportunities of teenagers who are already questioning the heavy personal sacrifices involved in climbing Japan`s rigid social ladder to good schools and jobs.</p>\n<ol>\n<li>谓语：have limited</li>\n<li>解释：限制</li>\n<li>主干——主语：and连接的两个并列成分，宾语：opportunities机会</li>\n<li>战后生育潮的到来，和女性进入由男性主导的职场，都限制了…的机会。</li>\n</ol>"},{"title":"英语5：状语和状语从句","mathjax":true,"date":"2020-07-11T13:34:43.000Z","_content":"\n\n\n《刘晓艳语法长难句》第五章笔记\n\n<br/>\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n\n\n# 状语和状语从句\n\n## 1. 引语：形容词和副词\n\neg：\n\nHe smiles **sweetly**. 副词sweetly修饰动词smiles。\n\nHe smiles especially sweetly. 副词especially修饰副词sweetly。\n\nHe looks pretty sweet. 副词pretty修饰形容词sweet。\n\nLuckily， he passed the examination. 副词Luckily修饰整个句子。\n\n**副词在句中做且只能做状语。**\n\n<br/>\n\n## 2. 状语\n\n句中，用来修饰实义动词、形容词、副词或整个句子的成分。\n\n### 2.1 成分\n\n1. 副词：She smiles **sweetly**.\n2. 副词短语：I tried **again and again**.\n3. 介词短语：He runs fast **like a crazy dog**.\n4. 分词、不定式：He leaves, **crying**.\n5. 从句：I will return the book **as soon as I have read it**.\n\n### 2.2 位置\n\n灵活，可句中，但句首句末情况较多。另，句首时逗号隔开。\n\n1. In ChongQing, I am now working.\n2. I am now working in ChongQing.\n3. I am now in ChongQing working.\n\n<br/>\n\n## 3. 状语从句\n\n### 3.1 构成\n\n状语从句可在主句前，也可主句后：\n\n引导词+状语从句+“，”+主句（句首状语从句，必须加逗号）\n\n或 主句+引导词+状语从句（句末状语从句，逗号可加可不加）\n\n### 3.2 引导词\n\n按照引导词本身意思，状语从句分为九类9：时间、地点、原因、目的、结果、条件、让步、方式、比较。\n\n### 3.3 时态\n\n1. 主句过去，从句相应地也使用过去：\n\n\tBefore I went home, my mother had slept. 两个动作都发生在过去，所以使用过去时。且主句的动作发生在从句之前，因此主句用过去完成时。\n\n2. 主句表示将来时，主句一般将来时，从句一般现在时，用“现在”表示“将来”：\n\n\tI will treat you if I manage to pass the examination of postgraduates.\n\n3. 主句将来完成时，从句使用现在完成时：\n\n\tAs soon as I have finished this work, I will have gone home. 如果我早完成工作的话，我现在已经到家了。\n\n<br/>\n\n## 4. 九种状语从句\n\n### 4.1 时间状语从句\n\n#### 4.1.1 引导词\n\n1. 普通引导词：when, as（正当/随着）, while, once（一旦）, as soon as（一…就…）, before, after, since, not … until, until/till（直到）\n2. 名词短语：the moment（一…就）, every time（每当）, the day（那一天）, the instant（当…时）\n3. 副词：immediately, directly, no sooner … than, hardly … when, scarcely … when（都译为一…就）\n\n#### 4.1.2 when，as，while的区别\n\n1. when引导的从句的谓语可以是延续性动词，也可以是短暂性动词：\n\n\tWhen I lived in the countryside, I used to live a tough life.\n\n\tWhen the teacher came in, we stop talking.\n\n2. while引导的从句的谓语必须是延续性动词，多用于进行时态：\n\n\tWhile my mother was reading the newspaper, I was wathching TV.\n\n3. as引导的从句的谓语是延续性动词，表示“一边一边”，一般用于主从句动作同时发生；也可表示“随着”：\n\n\tWe always sing as we walk.（一边一边）\n\n\tAs families moved away from their stable community, the informal flow of information is cut off.（随着）\n\n#### 4.1.3 no sooner… than 和 hardly… when\n\n1. 含义：一…就…\n\n2. 时态：主句过去完成时，从句一般过去时：\n\n\tI had no sooner begun to take a shower, the water was unavaiable. 我一开始洗澡，水就停了。\n\n\tThey hardly had arrived at the bus stop when the bus started to leave. 他们一赶到车站，车就开走了。\n\n3. 高级用法：二者引导时间状语从句时可以使用倒装句式：\n\n\tNo sooner had I begun to take a shower, the water was unvailable.\n\n\tHardly had they arrived at the bus stop when the bus started to leave.\n\n#### 4.1.4 when引导时间状语从句的特殊用法\n\nWhen引导时间状语从句，如果主、从句主语一致，且从句谓语有be动词，则从句的主语和be动词可以省略：\n\nWhen I was a little girl, I loved Jeff so much.\n\nWhen a little girl, I loved Jeff so much.\n\n#### 4.1.5 区分until 和 not… until\n\n1. I will wait here until you come.\n2. I will not leave until you come.\n\nnot… until 并无否定的意思。\n\n主句谓语是短暂性动词，用not… until；\n\n是延续性动词，用until。\n\neg：I did not realize the greatness of mothers until I had my own daughter.\n\n<br/>\n\n### 4.2 地点状语从句\n\n1. 常用引导词where。\n\n2. 不常用引导词：wherever, anywhere, everywhere等。\n\n3. where引导的地点状语从句与定语从句的区别和转换：\n\t1. 区别：地点状语从句和定语从句的引导词都有where，所以容易混淆。两种从句翻译方法一致，但语义不同。区分时判断where是否指代前面的先行词：若果指代先行词，是定语从句；否则是状语从句。\n\n\t\tI find my phone where I had lost it. 状语从句，where是从属连词，where修饰谓语，没有表示地点的先行词。\n\n\t\tThis is the house where I lived two years ago. where引导定语从句，修饰先行词，where是关系副词，在从句中代替先行词作地点状语。\n\n\t2. 转换：状语从句前加“in/at the place”，就成了定语从句\n\n\t\tWe will start where we left off.\n\n\t\tWe will start at the point where we left off.\n\n4. eg:\n\n\tEverywhere I see rural laborers in the city, it will remind me of my old father. 每当看到城市里的农民工，我就会想起我的老父亲。\n\n\tWherever you go, whatever you do, I am just here waiting for you.\n\n<br/>\n\n### 4.3 原因状语从句\n\n1. 常用引导词：because、since、as、for\n2. 介词短语+名词，不+从句：because of, due to, owing to（句首）, thanks to, for the sake of, as a result of\n\n<br/>\n\n### 4.4 目的状语从句\n\n1. 常用引导词：so that, in order that\n2. 表示目的的不定式：to, in order to, so as to + v.\n\n<br/>\n\n### 4.5 结果状语从句\n\n1. 常用引导词：so that, so … that, such … that\n2. 区别：\n\t1. so that：既可目的状语从句，也可结果状语从句\n\t2. so… that：\n\t\t1. 中间放形容词/副词，如此以致于\n\t\t2. so much/many/few/litte + n. + that 如此多的东西，以致于\n\t\t3. so + adj. + a/an + n. + that 如此好的老师，以致于\n\t3. such… that:\n\t\t1. such a/an adj. n. that 这个东西太，以致于\n\t\t2. such adj. ns that 这些东西太，以致于\n\n\n\n<br/>\n\n### 4.6 条件状语从句\n\n1. 引导词：if, unless(if not), as/so long as（只要）, only if（只要）, providing（假如）, supposing（假如）, in case that（以防）, on condition that（如果）\n2. eg：I will never give up so long as there is a ghost of hope.\n\n<br/>\n\n### 4.7 让步状语从句\n\n1. 引导词：though、although、even if、even though\n\n2. 特殊引导词：as, while, no matter…, in spite of the fact that(虽然), whatever, whoever…\n\n3. 写作常用，一个陈述观点、表示事实、表示原因的句中，避免语气的绝对，加入让步状语。\n\n\t污染很严重。 Pollution becomes increasingly serious although a sea of adults fail to realize it.\n\n<br/>\n\n### 4.8 方式状语从句\n\n1. as, as if, as though 好像\n2. the way 方式\n3. by, though, in … way, in … manner \n4. eg：\n\t1. She talks with me as she were my mother.\n\t2. Always do to the others as you would be done by.\n\n<br/>\n\n### 4.9 比较状语从句\n\n1. as, than, the more… the more…, more than, more… than…, not so much … as…（没有）\n\n2. eg: \n\n\t1. she is not so energetic as she used to be.\n\t2. The harder one works, the luckier he will feel.\n\n3. as… as…：类似so that，有形容词副词的地方都可以使用\n\n\tEnglish proves as essential as air and water, which plays a key role in our daily life.\n\n4. more than：\n\n\t1. +名词，不仅仅是\n\t2. +形容词，非常\n\t3. +数词，超过\n\t4. +动词，不仅仅是\n\n5. not so much as 甚至不 He cannot so much as sing a song.\n\n6. not so much A as B 与其说A，不如B He is not so much a teacher as a poet.\n\n7. more A than B，与其说A，不如说B\n\n<br/>\n\n## 5. 分词作状语\n\n\n\n","source":"_posts/英语5：状语和状语从句.md","raw":"---\ntitle: 英语5：状语和状语从句\nmathjax: true\ndate: 2020-07-11 21:34:43\ntags: 英语\n---\n\n\n\n《刘晓艳语法长难句》第五章笔记\n\n<br/>\n\n<!-- more -->\n\n<!-- toc -->\n\n<br/>\n\n\n\n# 状语和状语从句\n\n## 1. 引语：形容词和副词\n\neg：\n\nHe smiles **sweetly**. 副词sweetly修饰动词smiles。\n\nHe smiles especially sweetly. 副词especially修饰副词sweetly。\n\nHe looks pretty sweet. 副词pretty修饰形容词sweet。\n\nLuckily， he passed the examination. 副词Luckily修饰整个句子。\n\n**副词在句中做且只能做状语。**\n\n<br/>\n\n## 2. 状语\n\n句中，用来修饰实义动词、形容词、副词或整个句子的成分。\n\n### 2.1 成分\n\n1. 副词：She smiles **sweetly**.\n2. 副词短语：I tried **again and again**.\n3. 介词短语：He runs fast **like a crazy dog**.\n4. 分词、不定式：He leaves, **crying**.\n5. 从句：I will return the book **as soon as I have read it**.\n\n### 2.2 位置\n\n灵活，可句中，但句首句末情况较多。另，句首时逗号隔开。\n\n1. In ChongQing, I am now working.\n2. I am now working in ChongQing.\n3. I am now in ChongQing working.\n\n<br/>\n\n## 3. 状语从句\n\n### 3.1 构成\n\n状语从句可在主句前，也可主句后：\n\n引导词+状语从句+“，”+主句（句首状语从句，必须加逗号）\n\n或 主句+引导词+状语从句（句末状语从句，逗号可加可不加）\n\n### 3.2 引导词\n\n按照引导词本身意思，状语从句分为九类9：时间、地点、原因、目的、结果、条件、让步、方式、比较。\n\n### 3.3 时态\n\n1. 主句过去，从句相应地也使用过去：\n\n\tBefore I went home, my mother had slept. 两个动作都发生在过去，所以使用过去时。且主句的动作发生在从句之前，因此主句用过去完成时。\n\n2. 主句表示将来时，主句一般将来时，从句一般现在时，用“现在”表示“将来”：\n\n\tI will treat you if I manage to pass the examination of postgraduates.\n\n3. 主句将来完成时，从句使用现在完成时：\n\n\tAs soon as I have finished this work, I will have gone home. 如果我早完成工作的话，我现在已经到家了。\n\n<br/>\n\n## 4. 九种状语从句\n\n### 4.1 时间状语从句\n\n#### 4.1.1 引导词\n\n1. 普通引导词：when, as（正当/随着）, while, once（一旦）, as soon as（一…就…）, before, after, since, not … until, until/till（直到）\n2. 名词短语：the moment（一…就）, every time（每当）, the day（那一天）, the instant（当…时）\n3. 副词：immediately, directly, no sooner … than, hardly … when, scarcely … when（都译为一…就）\n\n#### 4.1.2 when，as，while的区别\n\n1. when引导的从句的谓语可以是延续性动词，也可以是短暂性动词：\n\n\tWhen I lived in the countryside, I used to live a tough life.\n\n\tWhen the teacher came in, we stop talking.\n\n2. while引导的从句的谓语必须是延续性动词，多用于进行时态：\n\n\tWhile my mother was reading the newspaper, I was wathching TV.\n\n3. as引导的从句的谓语是延续性动词，表示“一边一边”，一般用于主从句动作同时发生；也可表示“随着”：\n\n\tWe always sing as we walk.（一边一边）\n\n\tAs families moved away from their stable community, the informal flow of information is cut off.（随着）\n\n#### 4.1.3 no sooner… than 和 hardly… when\n\n1. 含义：一…就…\n\n2. 时态：主句过去完成时，从句一般过去时：\n\n\tI had no sooner begun to take a shower, the water was unavaiable. 我一开始洗澡，水就停了。\n\n\tThey hardly had arrived at the bus stop when the bus started to leave. 他们一赶到车站，车就开走了。\n\n3. 高级用法：二者引导时间状语从句时可以使用倒装句式：\n\n\tNo sooner had I begun to take a shower, the water was unvailable.\n\n\tHardly had they arrived at the bus stop when the bus started to leave.\n\n#### 4.1.4 when引导时间状语从句的特殊用法\n\nWhen引导时间状语从句，如果主、从句主语一致，且从句谓语有be动词，则从句的主语和be动词可以省略：\n\nWhen I was a little girl, I loved Jeff so much.\n\nWhen a little girl, I loved Jeff so much.\n\n#### 4.1.5 区分until 和 not… until\n\n1. I will wait here until you come.\n2. I will not leave until you come.\n\nnot… until 并无否定的意思。\n\n主句谓语是短暂性动词，用not… until；\n\n是延续性动词，用until。\n\neg：I did not realize the greatness of mothers until I had my own daughter.\n\n<br/>\n\n### 4.2 地点状语从句\n\n1. 常用引导词where。\n\n2. 不常用引导词：wherever, anywhere, everywhere等。\n\n3. where引导的地点状语从句与定语从句的区别和转换：\n\t1. 区别：地点状语从句和定语从句的引导词都有where，所以容易混淆。两种从句翻译方法一致，但语义不同。区分时判断where是否指代前面的先行词：若果指代先行词，是定语从句；否则是状语从句。\n\n\t\tI find my phone where I had lost it. 状语从句，where是从属连词，where修饰谓语，没有表示地点的先行词。\n\n\t\tThis is the house where I lived two years ago. where引导定语从句，修饰先行词，where是关系副词，在从句中代替先行词作地点状语。\n\n\t2. 转换：状语从句前加“in/at the place”，就成了定语从句\n\n\t\tWe will start where we left off.\n\n\t\tWe will start at the point where we left off.\n\n4. eg:\n\n\tEverywhere I see rural laborers in the city, it will remind me of my old father. 每当看到城市里的农民工，我就会想起我的老父亲。\n\n\tWherever you go, whatever you do, I am just here waiting for you.\n\n<br/>\n\n### 4.3 原因状语从句\n\n1. 常用引导词：because、since、as、for\n2. 介词短语+名词，不+从句：because of, due to, owing to（句首）, thanks to, for the sake of, as a result of\n\n<br/>\n\n### 4.4 目的状语从句\n\n1. 常用引导词：so that, in order that\n2. 表示目的的不定式：to, in order to, so as to + v.\n\n<br/>\n\n### 4.5 结果状语从句\n\n1. 常用引导词：so that, so … that, such … that\n2. 区别：\n\t1. so that：既可目的状语从句，也可结果状语从句\n\t2. so… that：\n\t\t1. 中间放形容词/副词，如此以致于\n\t\t2. so much/many/few/litte + n. + that 如此多的东西，以致于\n\t\t3. so + adj. + a/an + n. + that 如此好的老师，以致于\n\t3. such… that:\n\t\t1. such a/an adj. n. that 这个东西太，以致于\n\t\t2. such adj. ns that 这些东西太，以致于\n\n\n\n<br/>\n\n### 4.6 条件状语从句\n\n1. 引导词：if, unless(if not), as/so long as（只要）, only if（只要）, providing（假如）, supposing（假如）, in case that（以防）, on condition that（如果）\n2. eg：I will never give up so long as there is a ghost of hope.\n\n<br/>\n\n### 4.7 让步状语从句\n\n1. 引导词：though、although、even if、even though\n\n2. 特殊引导词：as, while, no matter…, in spite of the fact that(虽然), whatever, whoever…\n\n3. 写作常用，一个陈述观点、表示事实、表示原因的句中，避免语气的绝对，加入让步状语。\n\n\t污染很严重。 Pollution becomes increasingly serious although a sea of adults fail to realize it.\n\n<br/>\n\n### 4.8 方式状语从句\n\n1. as, as if, as though 好像\n2. the way 方式\n3. by, though, in … way, in … manner \n4. eg：\n\t1. She talks with me as she were my mother.\n\t2. Always do to the others as you would be done by.\n\n<br/>\n\n### 4.9 比较状语从句\n\n1. as, than, the more… the more…, more than, more… than…, not so much … as…（没有）\n\n2. eg: \n\n\t1. she is not so energetic as she used to be.\n\t2. The harder one works, the luckier he will feel.\n\n3. as… as…：类似so that，有形容词副词的地方都可以使用\n\n\tEnglish proves as essential as air and water, which plays a key role in our daily life.\n\n4. more than：\n\n\t1. +名词，不仅仅是\n\t2. +形容词，非常\n\t3. +数词，超过\n\t4. +动词，不仅仅是\n\n5. not so much as 甚至不 He cannot so much as sing a song.\n\n6. not so much A as B 与其说A，不如B He is not so much a teacher as a poet.\n\n7. more A than B，与其说A，不如说B\n\n<br/>\n\n## 5. 分词作状语\n\n\n\n","slug":"英语5：状语和状语从句","published":1,"updated":"2020-07-28T14:39:47.081Z","_id":"ckcm1vrbp00001kqvdqwc5zox","comments":1,"layout":"post","photos":[],"link":"","content":"<p>《刘晓艳语法长难句》第五章笔记</p>\n<br>\n<a id=\"more\"></a>\n<!-- toc -->\n<ul>\n<li><a href=\"#%E7%8A%B6%E8%AF%AD%E5%92%8C%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">状语和状语从句</a>\n<ul>\n<li><a href=\"#1-%E5%BC%95%E8%AF%AD%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%92%8C%E5%89%AF%E8%AF%8D\">1. 引语：形容词和副词</a></li>\n<li><a href=\"#2-%E7%8A%B6%E8%AF%AD\">2. 状语</a>\n<ul>\n<li><a href=\"#21-%E6%88%90%E5%88%86\">2.1 成分</a></li>\n<li><a href=\"#22-%E4%BD%8D%E7%BD%AE\">2.2 位置</a></li>\n</ul>\n</li>\n<li><a href=\"#3-%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">3. 状语从句</a>\n<ul>\n<li><a href=\"#31-%E6%9E%84%E6%88%90\">3.1 构成</a></li>\n<li><a href=\"#32-%E5%BC%95%E5%AF%BC%E8%AF%8D\">3.2 引导词</a></li>\n<li><a href=\"#33-%E6%97%B6%E6%80%81\">3.3 时态</a></li>\n</ul>\n</li>\n<li><a href=\"#4-%E4%B9%9D%E7%A7%8D%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4. 九种状语从句</a>\n<ul>\n<li><a href=\"#41-%E6%97%B6%E9%97%B4%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.1 时间状语从句</a>\n<ul>\n<li><a href=\"#411-%E5%BC%95%E5%AF%BC%E8%AF%8D\">4.1.1 引导词</a></li>\n<li><a href=\"#412-whenaswhile%E7%9A%84%E5%8C%BA%E5%88%AB\">4.1.2 when，as，while的区别</a></li>\n<li><a href=\"#413-no-sooner-than-%E5%92%8C-hardly-when\">4.1.3 no sooner… than 和 hardly… when</a></li>\n<li><a href=\"#414-when%E5%BC%95%E5%AF%BC%E6%97%B6%E9%97%B4%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E7%89%B9%E6%AE%8A%E7%94%A8%E6%B3%95\">4.1.4 when引导时间状语从句的特殊用法</a></li>\n<li><a href=\"#415-%E5%8C%BA%E5%88%86until-%E5%92%8C-not-until\">4.1.5 区分until 和 not… until</a></li>\n</ul>\n</li>\n<li><a href=\"#42-%E5%9C%B0%E7%82%B9%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.2 地点状语从句</a></li>\n<li><a href=\"#43-%E5%8E%9F%E5%9B%A0%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.3 原因状语从句</a></li>\n<li><a href=\"#44-%E7%9B%AE%E7%9A%84%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.4 目的状语从句</a></li>\n<li><a href=\"#45-%E7%BB%93%E6%9E%9C%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.5 结果状语从句</a></li>\n<li><a href=\"#46-%E6%9D%A1%E4%BB%B6%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.6 条件状语从句</a></li>\n<li><a href=\"#47-%E8%AE%A9%E6%AD%A5%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.7 让步状语从句</a></li>\n<li><a href=\"#48-%E6%96%B9%E5%BC%8F%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.8 方式状语从句</a></li>\n<li><a href=\"#49-%E6%AF%94%E8%BE%83%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.9 比较状语从句</a></li>\n</ul>\n</li>\n<li><a href=\"#5-%E5%88%86%E8%AF%8D%E4%BD%9C%E7%8A%B6%E8%AF%AD\">5. 分词作状语</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1><span id=\"状语和状语从句\"> 状语和状语从句</span></h1>\n<h2><span id=\"1-引语形容词和副词\"> 1. 引语：形容词和副词</span></h2>\n<p>eg：</p>\n<p>He smiles <strong>sweetly</strong>. 副词sweetly修饰动词smiles。</p>\n<p>He smiles especially sweetly. 副词especially修饰副词sweetly。</p>\n<p>He looks pretty sweet. 副词pretty修饰形容词sweet。</p>\n<p>Luckily， he passed the examination. 副词Luckily修饰整个句子。</p>\n<p><strong>副词在句中做且只能做状语。</strong></p>\n<br>\n<h2><span id=\"2-状语\"> 2. 状语</span></h2>\n<p>句中，用来修饰实义动词、形容词、副词或整个句子的成分。</p>\n<h3><span id=\"21-成分\"> 2.1 成分</span></h3>\n<ol>\n<li>副词：She smiles <strong>sweetly</strong>.</li>\n<li>副词短语：I tried <strong>again and again</strong>.</li>\n<li>介词短语：He runs fast <strong>like a crazy dog</strong>.</li>\n<li>分词、不定式：He leaves, <strong>crying</strong>.</li>\n<li>从句：I will return the book <strong>as soon as I have read it</strong>.</li>\n</ol>\n<h3><span id=\"22-位置\"> 2.2 位置</span></h3>\n<p>灵活，可句中，但句首句末情况较多。另，句首时逗号隔开。</p>\n<ol>\n<li>In ChongQing, I am now working.</li>\n<li>I am now working in ChongQing.</li>\n<li>I am now in ChongQing working.</li>\n</ol>\n<br>\n<h2><span id=\"3-状语从句\"> 3. 状语从句</span></h2>\n<h3><span id=\"31-构成\"> 3.1 构成</span></h3>\n<p>状语从句可在主句前，也可主句后：</p>\n<p>引导词+状语从句+“，”+主句（句首状语从句，必须加逗号）</p>\n<p>或 主句+引导词+状语从句（句末状语从句，逗号可加可不加）</p>\n<h3><span id=\"32-引导词\"> 3.2 引导词</span></h3>\n<p>按照引导词本身意思，状语从句分为九类9：时间、地点、原因、目的、结果、条件、让步、方式、比较。</p>\n<h3><span id=\"33-时态\"> 3.3 时态</span></h3>\n<ol>\n<li>\n<p>主句过去，从句相应地也使用过去：</p>\n<p>Before I went home, my mother had slept. 两个动作都发生在过去，所以使用过去时。且主句的动作发生在从句之前，因此主句用过去完成时。</p>\n</li>\n<li>\n<p>主句表示将来时，主句一般将来时，从句一般现在时，用“现在”表示“将来”：</p>\n<p>I will treat you if I manage to pass the examination of postgraduates.</p>\n</li>\n<li>\n<p>主句将来完成时，从句使用现在完成时：</p>\n<p>As soon as I have finished this work, I will have gone home. 如果我早完成工作的话，我现在已经到家了。</p>\n</li>\n</ol>\n<br>\n<h2><span id=\"4-九种状语从句\"> 4. 九种状语从句</span></h2>\n<h3><span id=\"41-时间状语从句\"> 4.1 时间状语从句</span></h3>\n<h4><span id=\"411-引导词\"> 4.1.1 引导词</span></h4>\n<ol>\n<li>普通引导词：when, as（正当/随着）, while, once（一旦）, as soon as（一…就…）, before, after, since, not … until, until/till（直到）</li>\n<li>名词短语：the moment（一…就）, every time（每当）, the day（那一天）, the instant（当…时）</li>\n<li>副词：immediately, directly, no sooner … than, hardly … when, scarcely … when（都译为一…就）</li>\n</ol>\n<h4><span id=\"412-whenaswhile的区别\"> 4.1.2 when，as，while的区别</span></h4>\n<ol>\n<li>\n<p>when引导的从句的谓语可以是延续性动词，也可以是短暂性动词：</p>\n<p>When I lived in the countryside, I used to live a tough life.</p>\n<p>When the teacher came in, we stop talking.</p>\n</li>\n<li>\n<p>while引导的从句的谓语必须是延续性动词，多用于进行时态：</p>\n<p>While my mother was reading the newspaper, I was wathching TV.</p>\n</li>\n<li>\n<p>as引导的从句的谓语是延续性动词，表示“一边一边”，一般用于主从句动作同时发生；也可表示“随着”：</p>\n<p>We always sing as we walk.（一边一边）</p>\n<p>As families moved away from their stable community, the informal flow of information is cut off.（随着）</p>\n</li>\n</ol>\n<h4><span id=\"413-no-sooner-than-和-hardly-when\"> 4.1.3 no sooner… than 和 hardly… when</span></h4>\n<ol>\n<li>\n<p>含义：一…就…</p>\n</li>\n<li>\n<p>时态：主句过去完成时，从句一般过去时：</p>\n<p>I had no sooner begun to take a shower, the water was unavaiable. 我一开始洗澡，水就停了。</p>\n<p>They hardly had arrived at the bus stop when the bus started to leave. 他们一赶到车站，车就开走了。</p>\n</li>\n<li>\n<p>高级用法：二者引导时间状语从句时可以使用倒装句式：</p>\n<p>No sooner had I begun to take a shower, the water was unvailable.</p>\n<p>Hardly had they arrived at the bus stop when the bus started to leave.</p>\n</li>\n</ol>\n<h4><span id=\"414-when引导时间状语从句的特殊用法\"> 4.1.4 when引导时间状语从句的特殊用法</span></h4>\n<p>When引导时间状语从句，如果主、从句主语一致，且从句谓语有be动词，则从句的主语和be动词可以省略：</p>\n<p>When I was a little girl, I loved Jeff so much.</p>\n<p>When a little girl, I loved Jeff so much.</p>\n<h4><span id=\"415-区分until-和-not-until\"> 4.1.5 区分until 和 not… until</span></h4>\n<ol>\n<li>I will wait here until you come.</li>\n<li>I will not leave until you come.</li>\n</ol>\n<p>not… until 并无否定的意思。</p>\n<p>主句谓语是短暂性动词，用not… until；</p>\n<p>是延续性动词，用until。</p>\n<p>eg：I did not realize the greatness of mothers until I had my own daughter.</p>\n<br>\n<h3><span id=\"42-地点状语从句\"> 4.2 地点状语从句</span></h3>\n<ol>\n<li>\n<p>常用引导词where。</p>\n</li>\n<li>\n<p>不常用引导词：wherever, anywhere, everywhere等。</p>\n</li>\n<li>\n<p>where引导的地点状语从句与定语从句的区别和转换：</p>\n<ol>\n<li>\n<p>区别：地点状语从句和定语从句的引导词都有where，所以容易混淆。两种从句翻译方法一致，但语义不同。区分时判断where是否指代前面的先行词：若果指代先行词，是定语从句；否则是状语从句。</p>\n<p>I find my phone where I had lost it. 状语从句，where是从属连词，where修饰谓语，没有表示地点的先行词。</p>\n<p>This is the house where I lived two years ago. where引导定语从句，修饰先行词，where是关系副词，在从句中代替先行词作地点状语。</p>\n</li>\n<li>\n<p>转换：状语从句前加“in/at the place”，就成了定语从句</p>\n<p>We will start where we left off.</p>\n<p>We will start at the point where we left off.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>eg:</p>\n<p>Everywhere I see rural laborers in the city, it will remind me of my old father. 每当看到城市里的农民工，我就会想起我的老父亲。</p>\n<p>Wherever you go, whatever you do, I am just here waiting for you.</p>\n</li>\n</ol>\n<br>\n<h3><span id=\"43-原因状语从句\"> 4.3 原因状语从句</span></h3>\n<ol>\n<li>常用引导词：because、since、as、for</li>\n<li>介词短语+名词，不+从句：because of, due to, owing to（句首）, thanks to, for the sake of, as a result of</li>\n</ol>\n<br>\n<h3><span id=\"44-目的状语从句\"> 4.4 目的状语从句</span></h3>\n<ol>\n<li>常用引导词：so that, in order that</li>\n<li>表示目的的不定式：to, in order to, so as to + v.</li>\n</ol>\n<br>\n<h3><span id=\"45-结果状语从句\"> 4.5 结果状语从句</span></h3>\n<ol>\n<li>常用引导词：so that, so … that, such … that</li>\n<li>区别：\n<ol>\n<li>so that：既可目的状语从句，也可结果状语从句</li>\n<li>so… that：\n<ol>\n<li>中间放形容词/副词，如此以致于</li>\n<li>so much/many/few/litte + n. + that 如此多的东西，以致于</li>\n<li>so + adj. + a/an + n. + that 如此好的老师，以致于</li>\n</ol>\n</li>\n<li>such… that:\n<ol>\n<li>such a/an adj. n. that 这个东西太，以致于</li>\n<li>such adj. ns that 这些东西太，以致于</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h3><span id=\"46-条件状语从句\"> 4.6 条件状语从句</span></h3>\n<ol>\n<li>引导词：if, unless(if not), as/so long as（只要）, only if（只要）, providing（假如）, supposing（假如）, in case that（以防）, on condition that（如果）</li>\n<li>eg：I will never give up so long as there is a ghost of hope.</li>\n</ol>\n<br>\n<h3><span id=\"47-让步状语从句\"> 4.7 让步状语从句</span></h3>\n<ol>\n<li>\n<p>引导词：though、although、even if、even though</p>\n</li>\n<li>\n<p>特殊引导词：as, while, no matter…, in spite of the fact that(虽然), whatever, whoever…</p>\n</li>\n<li>\n<p>写作常用，一个陈述观点、表示事实、表示原因的句中，避免语气的绝对，加入让步状语。</p>\n<p>污染很严重。 Pollution becomes increasingly serious although a sea of adults fail to realize it.</p>\n</li>\n</ol>\n<br>\n<h3><span id=\"48-方式状语从句\"> 4.8 方式状语从句</span></h3>\n<ol>\n<li>as, as if, as though 好像</li>\n<li>the way 方式</li>\n<li>by, though, in … way, in … manner</li>\n<li>eg：\n<ol>\n<li>She talks with me as she were my mother.</li>\n<li>Always do to the others as you would be done by.</li>\n</ol>\n</li>\n</ol>\n<br>\n<h3><span id=\"49-比较状语从句\"> 4.9 比较状语从句</span></h3>\n<ol>\n<li>\n<p>as, than, the more… the more…, more than, more… than…, not so much … as…（没有）</p>\n</li>\n<li>\n<p>eg:</p>\n<ol>\n<li>she is not so energetic as she used to be.</li>\n<li>The harder one works, the luckier he will feel.</li>\n</ol>\n</li>\n<li>\n<p>as… as…：类似so that，有形容词副词的地方都可以使用</p>\n<p>English proves as essential as air and water, which plays a key role in our daily life.</p>\n</li>\n<li>\n<p>more than：</p>\n<ol>\n<li>+名词，不仅仅是</li>\n<li>+形容词，非常</li>\n<li>+数词，超过</li>\n<li>+动词，不仅仅是</li>\n</ol>\n</li>\n<li>\n<p>not so much as 甚至不 He cannot so much as sing a song.</p>\n</li>\n<li>\n<p>not so much A as B 与其说A，不如B He is not so much a teacher as a poet.</p>\n</li>\n<li>\n<p>more A than B，与其说A，不如说B</p>\n</li>\n</ol>\n<br>\n<h2><span id=\"5-分词作状语\"> 5. 分词作状语</span></h2>\n","site":{"data":{}},"excerpt":"<p>《刘晓艳语法长难句》第五章笔记</p>\n<br>","more":"<!-- toc -->\n<ul>\n<li><a href=\"#%E7%8A%B6%E8%AF%AD%E5%92%8C%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">状语和状语从句</a>\n<ul>\n<li><a href=\"#1-%E5%BC%95%E8%AF%AD%E5%BD%A2%E5%AE%B9%E8%AF%8D%E5%92%8C%E5%89%AF%E8%AF%8D\">1. 引语：形容词和副词</a></li>\n<li><a href=\"#2-%E7%8A%B6%E8%AF%AD\">2. 状语</a>\n<ul>\n<li><a href=\"#21-%E6%88%90%E5%88%86\">2.1 成分</a></li>\n<li><a href=\"#22-%E4%BD%8D%E7%BD%AE\">2.2 位置</a></li>\n</ul>\n</li>\n<li><a href=\"#3-%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">3. 状语从句</a>\n<ul>\n<li><a href=\"#31-%E6%9E%84%E6%88%90\">3.1 构成</a></li>\n<li><a href=\"#32-%E5%BC%95%E5%AF%BC%E8%AF%8D\">3.2 引导词</a></li>\n<li><a href=\"#33-%E6%97%B6%E6%80%81\">3.3 时态</a></li>\n</ul>\n</li>\n<li><a href=\"#4-%E4%B9%9D%E7%A7%8D%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4. 九种状语从句</a>\n<ul>\n<li><a href=\"#41-%E6%97%B6%E9%97%B4%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.1 时间状语从句</a>\n<ul>\n<li><a href=\"#411-%E5%BC%95%E5%AF%BC%E8%AF%8D\">4.1.1 引导词</a></li>\n<li><a href=\"#412-whenaswhile%E7%9A%84%E5%8C%BA%E5%88%AB\">4.1.2 when，as，while的区别</a></li>\n<li><a href=\"#413-no-sooner-than-%E5%92%8C-hardly-when\">4.1.3 no sooner… than 和 hardly… when</a></li>\n<li><a href=\"#414-when%E5%BC%95%E5%AF%BC%E6%97%B6%E9%97%B4%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5%E7%9A%84%E7%89%B9%E6%AE%8A%E7%94%A8%E6%B3%95\">4.1.4 when引导时间状语从句的特殊用法</a></li>\n<li><a href=\"#415-%E5%8C%BA%E5%88%86until-%E5%92%8C-not-until\">4.1.5 区分until 和 not… until</a></li>\n</ul>\n</li>\n<li><a href=\"#42-%E5%9C%B0%E7%82%B9%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.2 地点状语从句</a></li>\n<li><a href=\"#43-%E5%8E%9F%E5%9B%A0%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.3 原因状语从句</a></li>\n<li><a href=\"#44-%E7%9B%AE%E7%9A%84%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.4 目的状语从句</a></li>\n<li><a href=\"#45-%E7%BB%93%E6%9E%9C%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.5 结果状语从句</a></li>\n<li><a href=\"#46-%E6%9D%A1%E4%BB%B6%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.6 条件状语从句</a></li>\n<li><a href=\"#47-%E8%AE%A9%E6%AD%A5%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.7 让步状语从句</a></li>\n<li><a href=\"#48-%E6%96%B9%E5%BC%8F%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.8 方式状语从句</a></li>\n<li><a href=\"#49-%E6%AF%94%E8%BE%83%E7%8A%B6%E8%AF%AD%E4%BB%8E%E5%8F%A5\">4.9 比较状语从句</a></li>\n</ul>\n</li>\n<li><a href=\"#5-%E5%88%86%E8%AF%8D%E4%BD%9C%E7%8A%B6%E8%AF%AD\">5. 分词作状语</a></li>\n</ul>\n</li>\n</ul>\n<!-- tocstop -->\n<br>\n<h1 id=\"状语和状语从句\"><a class=\"markdownIt-Anchor\" href=\"#状语和状语从句\"></a> 状语和状语从句</h1>\n<h2 id=\"1-引语形容词和副词\"><a class=\"markdownIt-Anchor\" href=\"#1-引语形容词和副词\"></a> 1. 引语：形容词和副词</h2>\n<p>eg：</p>\n<p>He smiles <strong>sweetly</strong>. 副词sweetly修饰动词smiles。</p>\n<p>He smiles especially sweetly. 副词especially修饰副词sweetly。</p>\n<p>He looks pretty sweet. 副词pretty修饰形容词sweet。</p>\n<p>Luckily， he passed the examination. 副词Luckily修饰整个句子。</p>\n<p><strong>副词在句中做且只能做状语。</strong></p>\n<br>\n<h2 id=\"2-状语\"><a class=\"markdownIt-Anchor\" href=\"#2-状语\"></a> 2. 状语</h2>\n<p>句中，用来修饰实义动词、形容词、副词或整个句子的成分。</p>\n<h3 id=\"21-成分\"><a class=\"markdownIt-Anchor\" href=\"#21-成分\"></a> 2.1 成分</h3>\n<ol>\n<li>副词：She smiles <strong>sweetly</strong>.</li>\n<li>副词短语：I tried <strong>again and again</strong>.</li>\n<li>介词短语：He runs fast <strong>like a crazy dog</strong>.</li>\n<li>分词、不定式：He leaves, <strong>crying</strong>.</li>\n<li>从句：I will return the book <strong>as soon as I have read it</strong>.</li>\n</ol>\n<h3 id=\"22-位置\"><a class=\"markdownIt-Anchor\" href=\"#22-位置\"></a> 2.2 位置</h3>\n<p>灵活，可句中，但句首句末情况较多。另，句首时逗号隔开。</p>\n<ol>\n<li>In ChongQing, I am now working.</li>\n<li>I am now working in ChongQing.</li>\n<li>I am now in ChongQing working.</li>\n</ol>\n<br>\n<h2 id=\"3-状语从句\"><a class=\"markdownIt-Anchor\" href=\"#3-状语从句\"></a> 3. 状语从句</h2>\n<h3 id=\"31-构成\"><a class=\"markdownIt-Anchor\" href=\"#31-构成\"></a> 3.1 构成</h3>\n<p>状语从句可在主句前，也可主句后：</p>\n<p>引导词+状语从句+“，”+主句（句首状语从句，必须加逗号）</p>\n<p>或 主句+引导词+状语从句（句末状语从句，逗号可加可不加）</p>\n<h3 id=\"32-引导词\"><a class=\"markdownIt-Anchor\" href=\"#32-引导词\"></a> 3.2 引导词</h3>\n<p>按照引导词本身意思，状语从句分为九类9：时间、地点、原因、目的、结果、条件、让步、方式、比较。</p>\n<h3 id=\"33-时态\"><a class=\"markdownIt-Anchor\" href=\"#33-时态\"></a> 3.3 时态</h3>\n<ol>\n<li>\n<p>主句过去，从句相应地也使用过去：</p>\n<p>Before I went home, my mother had slept. 两个动作都发生在过去，所以使用过去时。且主句的动作发生在从句之前，因此主句用过去完成时。</p>\n</li>\n<li>\n<p>主句表示将来时，主句一般将来时，从句一般现在时，用“现在”表示“将来”：</p>\n<p>I will treat you if I manage to pass the examination of postgraduates.</p>\n</li>\n<li>\n<p>主句将来完成时，从句使用现在完成时：</p>\n<p>As soon as I have finished this work, I will have gone home. 如果我早完成工作的话，我现在已经到家了。</p>\n</li>\n</ol>\n<br>\n<h2 id=\"4-九种状语从句\"><a class=\"markdownIt-Anchor\" href=\"#4-九种状语从句\"></a> 4. 九种状语从句</h2>\n<h3 id=\"41-时间状语从句\"><a class=\"markdownIt-Anchor\" href=\"#41-时间状语从句\"></a> 4.1 时间状语从句</h3>\n<h4 id=\"411-引导词\"><a class=\"markdownIt-Anchor\" href=\"#411-引导词\"></a> 4.1.1 引导词</h4>\n<ol>\n<li>普通引导词：when, as（正当/随着）, while, once（一旦）, as soon as（一…就…）, before, after, since, not … until, until/till（直到）</li>\n<li>名词短语：the moment（一…就）, every time（每当）, the day（那一天）, the instant（当…时）</li>\n<li>副词：immediately, directly, no sooner … than, hardly … when, scarcely … when（都译为一…就）</li>\n</ol>\n<h4 id=\"412-whenaswhile的区别\"><a class=\"markdownIt-Anchor\" href=\"#412-whenaswhile的区别\"></a> 4.1.2 when，as，while的区别</h4>\n<ol>\n<li>\n<p>when引导的从句的谓语可以是延续性动词，也可以是短暂性动词：</p>\n<p>When I lived in the countryside, I used to live a tough life.</p>\n<p>When the teacher came in, we stop talking.</p>\n</li>\n<li>\n<p>while引导的从句的谓语必须是延续性动词，多用于进行时态：</p>\n<p>While my mother was reading the newspaper, I was wathching TV.</p>\n</li>\n<li>\n<p>as引导的从句的谓语是延续性动词，表示“一边一边”，一般用于主从句动作同时发生；也可表示“随着”：</p>\n<p>We always sing as we walk.（一边一边）</p>\n<p>As families moved away from their stable community, the informal flow of information is cut off.（随着）</p>\n</li>\n</ol>\n<h4 id=\"413-no-sooner-than-和-hardly-when\"><a class=\"markdownIt-Anchor\" href=\"#413-no-sooner-than-和-hardly-when\"></a> 4.1.3 no sooner… than 和 hardly… when</h4>\n<ol>\n<li>\n<p>含义：一…就…</p>\n</li>\n<li>\n<p>时态：主句过去完成时，从句一般过去时：</p>\n<p>I had no sooner begun to take a shower, the water was unavaiable. 我一开始洗澡，水就停了。</p>\n<p>They hardly had arrived at the bus stop when the bus started to leave. 他们一赶到车站，车就开走了。</p>\n</li>\n<li>\n<p>高级用法：二者引导时间状语从句时可以使用倒装句式：</p>\n<p>No sooner had I begun to take a shower, the water was unvailable.</p>\n<p>Hardly had they arrived at the bus stop when the bus started to leave.</p>\n</li>\n</ol>\n<h4 id=\"414-when引导时间状语从句的特殊用法\"><a class=\"markdownIt-Anchor\" href=\"#414-when引导时间状语从句的特殊用法\"></a> 4.1.4 when引导时间状语从句的特殊用法</h4>\n<p>When引导时间状语从句，如果主、从句主语一致，且从句谓语有be动词，则从句的主语和be动词可以省略：</p>\n<p>When I was a little girl, I loved Jeff so much.</p>\n<p>When a little girl, I loved Jeff so much.</p>\n<h4 id=\"415-区分until-和-not-until\"><a class=\"markdownIt-Anchor\" href=\"#415-区分until-和-not-until\"></a> 4.1.5 区分until 和 not… until</h4>\n<ol>\n<li>I will wait here until you come.</li>\n<li>I will not leave until you come.</li>\n</ol>\n<p>not… until 并无否定的意思。</p>\n<p>主句谓语是短暂性动词，用not… until；</p>\n<p>是延续性动词，用until。</p>\n<p>eg：I did not realize the greatness of mothers until I had my own daughter.</p>\n<br>\n<h3 id=\"42-地点状语从句\"><a class=\"markdownIt-Anchor\" href=\"#42-地点状语从句\"></a> 4.2 地点状语从句</h3>\n<ol>\n<li>\n<p>常用引导词where。</p>\n</li>\n<li>\n<p>不常用引导词：wherever, anywhere, everywhere等。</p>\n</li>\n<li>\n<p>where引导的地点状语从句与定语从句的区别和转换：</p>\n<ol>\n<li>\n<p>区别：地点状语从句和定语从句的引导词都有where，所以容易混淆。两种从句翻译方法一致，但语义不同。区分时判断where是否指代前面的先行词：若果指代先行词，是定语从句；否则是状语从句。</p>\n<p>I find my phone where I had lost it. 状语从句，where是从属连词，where修饰谓语，没有表示地点的先行词。</p>\n<p>This is the house where I lived two years ago. where引导定语从句，修饰先行词，where是关系副词，在从句中代替先行词作地点状语。</p>\n</li>\n<li>\n<p>转换：状语从句前加“in/at the place”，就成了定语从句</p>\n<p>We will start where we left off.</p>\n<p>We will start at the point where we left off.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>eg:</p>\n<p>Everywhere I see rural laborers in the city, it will remind me of my old father. 每当看到城市里的农民工，我就会想起我的老父亲。</p>\n<p>Wherever you go, whatever you do, I am just here waiting for you.</p>\n</li>\n</ol>\n<br>\n<h3 id=\"43-原因状语从句\"><a class=\"markdownIt-Anchor\" href=\"#43-原因状语从句\"></a> 4.3 原因状语从句</h3>\n<ol>\n<li>常用引导词：because、since、as、for</li>\n<li>介词短语+名词，不+从句：because of, due to, owing to（句首）, thanks to, for the sake of, as a result of</li>\n</ol>\n<br>\n<h3 id=\"44-目的状语从句\"><a class=\"markdownIt-Anchor\" href=\"#44-目的状语从句\"></a> 4.4 目的状语从句</h3>\n<ol>\n<li>常用引导词：so that, in order that</li>\n<li>表示目的的不定式：to, in order to, so as to + v.</li>\n</ol>\n<br>\n<h3 id=\"45-结果状语从句\"><a class=\"markdownIt-Anchor\" href=\"#45-结果状语从句\"></a> 4.5 结果状语从句</h3>\n<ol>\n<li>常用引导词：so that, so … that, such … that</li>\n<li>区别：\n<ol>\n<li>so that：既可目的状语从句，也可结果状语从句</li>\n<li>so… that：\n<ol>\n<li>中间放形容词/副词，如此以致于</li>\n<li>so much/many/few/litte + n. + that 如此多的东西，以致于</li>\n<li>so + adj. + a/an + n. + that 如此好的老师，以致于</li>\n</ol>\n</li>\n<li>such… that:\n<ol>\n<li>such a/an adj. n. that 这个东西太，以致于</li>\n<li>such adj. ns that 这些东西太，以致于</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<br>\n<h3 id=\"46-条件状语从句\"><a class=\"markdownIt-Anchor\" href=\"#46-条件状语从句\"></a> 4.6 条件状语从句</h3>\n<ol>\n<li>引导词：if, unless(if not), as/so long as（只要）, only if（只要）, providing（假如）, supposing（假如）, in case that（以防）, on condition that（如果）</li>\n<li>eg：I will never give up so long as there is a ghost of hope.</li>\n</ol>\n<br>\n<h3 id=\"47-让步状语从句\"><a class=\"markdownIt-Anchor\" href=\"#47-让步状语从句\"></a> 4.7 让步状语从句</h3>\n<ol>\n<li>\n<p>引导词：though、although、even if、even though</p>\n</li>\n<li>\n<p>特殊引导词：as, while, no matter…, in spite of the fact that(虽然), whatever, whoever…</p>\n</li>\n<li>\n<p>写作常用，一个陈述观点、表示事实、表示原因的句中，避免语气的绝对，加入让步状语。</p>\n<p>污染很严重。 Pollution becomes increasingly serious although a sea of adults fail to realize it.</p>\n</li>\n</ol>\n<br>\n<h3 id=\"48-方式状语从句\"><a class=\"markdownIt-Anchor\" href=\"#48-方式状语从句\"></a> 4.8 方式状语从句</h3>\n<ol>\n<li>as, as if, as though 好像</li>\n<li>the way 方式</li>\n<li>by, though, in … way, in … manner</li>\n<li>eg：\n<ol>\n<li>She talks with me as she were my mother.</li>\n<li>Always do to the others as you would be done by.</li>\n</ol>\n</li>\n</ol>\n<br>\n<h3 id=\"49-比较状语从句\"><a class=\"markdownIt-Anchor\" href=\"#49-比较状语从句\"></a> 4.9 比较状语从句</h3>\n<ol>\n<li>\n<p>as, than, the more… the more…, more than, more… than…, not so much … as…（没有）</p>\n</li>\n<li>\n<p>eg:</p>\n<ol>\n<li>she is not so energetic as she used to be.</li>\n<li>The harder one works, the luckier he will feel.</li>\n</ol>\n</li>\n<li>\n<p>as… as…：类似so that，有形容词副词的地方都可以使用</p>\n<p>English proves as essential as air and water, which plays a key role in our daily life.</p>\n</li>\n<li>\n<p>more than：</p>\n<ol>\n<li>+名词，不仅仅是</li>\n<li>+形容词，非常</li>\n<li>+数词，超过</li>\n<li>+动词，不仅仅是</li>\n</ol>\n</li>\n<li>\n<p>not so much as 甚至不 He cannot so much as sing a song.</p>\n</li>\n<li>\n<p>not so much A as B 与其说A，不如B He is not so much a teacher as a poet.</p>\n</li>\n<li>\n<p>more A than B，与其说A，不如说B</p>\n</li>\n</ol>\n<br>\n<h2 id=\"5-分词作状语\"><a class=\"markdownIt-Anchor\" href=\"#5-分词作状语\"></a> 5. 分词作状语</h2>"}],"PostAsset":[{"_id":"source/_posts/AdaBound/AdaBound_figure5.png","slug":"AdaBound_figure5.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/SGD+Nesterov.png","slug":"SGD+Nesterov.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/MDNet/MDNet_struct.png","slug":"MDNet_struct.png","post":"ckc4xbevl0006i0qvaw2scw4e","modified":0,"renderable":0},{"_id":"source/_posts/MDNet/MDnet_algorithm.png","slug":"MDnet_algorithm.png","post":"ckc4xbevl0006i0qvaw2scw4e","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure3.1.png","slug":"AdaBound_figure3.1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure6.png","slug":"AdaBound_figure6.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/1times1conv.png","slug":"1times1conv.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/NMS_multi1.png","slug":"NMS_multi1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/NMS_multi3.png","slug":"NMS_multi3.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/NMS_multi4.png","slug":"NMS_multi4.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_net_left.png","slug":"SiamRPN++_net_left.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/线性代数空间角度理解/4.png","slug":"4.png","post":"ckc4xbew9000qi0qv3xbude4d","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure3.2.png","slug":"AdaBound_figure3.2.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/1062917-20161117212457248-1468090428.png","slug":"1062917-20161117212457248-1468090428.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/optimizations on saddle point.gif","slug":"optimizations on saddle point.gif","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/sgd_problem.png","slug":"sgd_problem.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/RT-MDNet/inst_loss.png","slug":"inst_loss.png","post":"ckc4xbevy000gi0qv5bgl288s","modified":0,"renderable":0},{"_id":"source/_posts/RT-MDNet/Adaptive RoIAlign.png","slug":"Adaptive RoIAlign.png","post":"ckc4xbevy000gi0qv5bgl288s","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/1times1conv-1583335627710.png","slug":"1times1conv-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/other_test-1583335627710.png","slug":"other_test-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/Android总结1/zelda.png","slug":"zelda.png","post":"ckc4xbevh0004i0qv1xegcufu","modified":0,"renderable":0},{"_id":"source/_posts/RSA/c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png","slug":"c62d183717d174ae73fe66980c67833b_wallhaven-gjvg6l.png","post":"ckc4xbevp000bi0qvc3fvf3l8","modified":0,"renderable":0},{"_id":"source/_posts/英语1：简单句/搜狗截图20200316222055.png","slug":"搜狗截图20200316222055.png","post":"ckc4xbewe000xi0qvcamcf5z5","modified":0,"renderable":0},{"_id":"source/_posts/MD5/FFGGHHII.png","slug":"FFGGHHII.png","post":"ckc4xbevj0005i0qv8bew6d48","modified":0,"renderable":0},{"_id":"source/_posts/MD5/FGHI.png","slug":"FGHI.png","post":"ckc4xbevj0005i0qv8bew6d48","modified":0,"renderable":0},{"_id":"source/_posts/MD5/MD5.png","slug":"MD5.png","post":"ckc4xbevj0005i0qv8bew6d48","modified":0,"renderable":0},{"_id":"source/_posts/MDNet/MDNet_neg_mining.png","slug":"MDNet_neg_mining.png","post":"ckc4xbevl0006i0qvaw2scw4e","modified":0,"renderable":0},{"_id":"source/_posts/RT-MDNet/ROIAlign.png","slug":"ROIAlign.png","post":"ckc4xbevy000gi0qv5bgl288s","modified":0,"renderable":0},{"_id":"source/_posts/RT-MDNet/ROIPooling.png","slug":"ROIPooling.png","post":"ckc4xbevy000gi0qv5bgl288s","modified":0,"renderable":0},{"_id":"source/_posts/线性代数空间角度理解/1.png","slug":"1.png","post":"ckc4xbew9000qi0qv3xbude4d","modified":0,"renderable":0},{"_id":"source/_posts/线性代数空间角度理解/2.png","slug":"2.png","post":"ckc4xbew9000qi0qv3xbude4d","modified":0,"renderable":0},{"_id":"source/_posts/线性代数空间角度理解/3.png","slug":"3.png","post":"ckc4xbew9000qi0qv3xbude4d","modified":0,"renderable":0},{"_id":"source/_posts/线性代数空间角度理解/5.png","slug":"5.png","post":"ckc4xbew9000qi0qv3xbude4d","modified":0,"renderable":0},{"_id":"source/_posts/线性代数空间角度理解/7.png","slug":"7.png","post":"ckc4xbew9000qi0qv3xbude4d","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/other_test.png","slug":"other_test.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/CBC.jpg","slug":"CBC.jpg","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/CFB.jpg","slug":"CFB.jpg","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/DES.png","slug":"DES.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/ECB.jpg","slug":"ECB.jpg","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/IP&IP-1.png","slug":"IP&IP-1.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/OFB.jpg","slug":"OFB.jpg","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/P.png","slug":"P.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/S.png","slug":"S.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/e_bit-selection.png","slug":"e_bit-selection.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/f(R,K).png","slug":"f(R,K).png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/image-20200512205728831.png","slug":"image-20200512205728831.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/pc_1.png","slug":"pc_1.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/DES和分组密码工作模式/pc_2.png","slug":"pc_2.png","post":"ckc4xbev30000i0qvh8et3qd0","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/padding_test.png","slug":"padding_test.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_algorithm1.png","slug":"AdaBound_algorithm1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_algorithm2.png","slug":"AdaBound_algorithm2.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_clip.png","slug":"AdaBound_clip.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_corollary4.1.png","slug":"AdaBound_corollary4.1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure1.png","slug":"AdaBound_figure1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure2.png","slug":"AdaBound_figure2.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure4.1.png","slug":"AdaBound_figure4.1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure4.2.png","slug":"AdaBound_figure4.2.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure7.1.png","slug":"AdaBound_figure7.1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_figure7.2.png","slug":"AdaBound_figure7.2.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_table1.png","slug":"AdaBound_table1.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_table2.png","slug":"AdaBound_table2.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/AdaBound/AdaBound_theorem4.png","slug":"AdaBound_theorem4.png","post":"ckc4xbevb0002i0qvfygubo7z","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/NMS_multi2.png","slug":"NMS_multi2.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/AdaBound_clip.png","slug":"AdaBound_clip.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/AdaBound_figure1.png","slug":"AdaBound_figure1.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/SGDM.jpg","slug":"SGDM.jpg","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/bn_backward.jpg","slug":"bn_backward.jpg","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/bn_forward.png","slug":"bn_forward.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/elu.png","slug":"elu.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/leaky relu.png","slug":"leaky relu.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/loss-learing rate.png","slug":"loss-learing rate.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/optimizations on loss surface contours.gif","slug":"optimizations on loss surface contours.gif","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/relu.png","slug":"relu.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/sgd_problem1.png","slug":"sgd_problem1.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/sgd_problem2.png","slug":"sgd_problem2.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/sigmoid.png","slug":"sigmoid.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/tanh.png","slug":"tanh.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/CS231n笔记/主流.png","slug":"主流.png","post":"ckc4xbevn0009i0qveu53hnp5","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/NMS_single.png","slug":"NMS_single.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/CIR-1583335627710.png","slug":"CIR-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/CIR-D-1583335627710.png","slug":"CIR-D-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/CIR-D.png","slug":"CIR-D.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/CIR-D_2-1583335627710.png","slug":"CIR-D_2-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/CIR-D_2.png","slug":"CIR-D_2.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/CIR.png","slug":"CIR.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/SINT-1583335627709.png","slug":"SINT-1583335627709.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/SINT.png","slug":"SINT.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/SiamFC_1-1583335627710.png","slug":"SiamFC_1-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/SiamFC_1.png","slug":"SiamFC_1.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/SiamRPN_net-1583335627710.png","slug":"SiamRPN_net-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/SiamRPN_net.png","slug":"SiamRPN_net.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/analysis-1583335627710.png","slug":"analysis-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/analysis.png","slug":"analysis.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/loss_feature_with_str-1583335627710.png","slug":"loss_feature_with_str-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/loss_feature_with_str.png","slug":"loss_feature_with_str.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/motivation-1583335627710.png","slug":"motivation-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/motivation.png","slug":"motivation.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/padding_test-1583335627710.png","slug":"padding_test-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/simple_siam-1583335627709.png","slug":"simple_siam-1583335627709.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/simple_siam.png","slug":"simple_siam.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/with_padding-1583335627710.png","slug":"with_padding-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/with_padding.png","slug":"with_padding.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/without_padding-1583335627710.png","slug":"without_padding-1583335627710.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/SiamDW/without_padding.png","slug":"without_padding.png","post":"ckc4xbevv000ei0qv8f3s0nn7","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/Bicubic interpolation1.PNG","slug":"Bicubic interpolation1.PNG","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/Bicubic interpolation2.png","slug":"Bicubic interpolation2.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/DaSiamRPN_data.png","slug":"DaSiamRPN_data.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/RPN.jpg","slug":"RPN.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamFC_1.png","slug":"SiamFC_1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamFC_2.jpg","slug":"SiamFC_2.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamFC_3.jpg","slug":"SiamFC_3.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamFC_loss.png","slug":"SiamFC_loss.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamFC_net_layer.png","slug":"SiamFC_net_layer.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamFC_training_pairs.png","slug":"SiamFC_training_pairs.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_RPN.png","slug":"SiamRPN++_RPN.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_correlate_heatmap.png","slug":"SiamRPN++_correlate_heatmap.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_correlation.png","slug":"SiamRPN++_correlation.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_heatmap.png","slug":"SiamRPN++_heatmap.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_net.png","slug":"SiamRPN++_net.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN++_translation.png","slug":"SiamRPN++_translation.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN_net.png","slug":"SiamRPN_net.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN_prosal_select.png","slug":"SiamRPN_prosal_select.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN_shortcoming1.png","slug":"SiamRPN_shortcoming1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN_shortcoming2.png","slug":"SiamRPN_shortcoming2.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/SiamRPN_tracking.png","slug":"SiamRPN_tracking.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/Siamese Net.png","slug":"Siamese Net.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/Siamese Net_loss.png","slug":"Siamese Net_loss.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/Siamese Net_loss1.png","slug":"Siamese Net_loss1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/Siamese twins.jpg","slug":"Siamese twins.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/anchors.jpg","slug":"anchors.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/nonlocal_block_struct.jpg","slug":"nonlocal_block_struct.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/nonlocal_eq1.png","slug":"nonlocal_eq1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/nonlocal_eq2.png","slug":"nonlocal_eq2.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/nonlocal_eq3.png","slug":"nonlocal_eq3.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/rpn1.png","slug":"rpn1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/rpn_regression.png","slug":"rpn_regression.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/rpn_regression1.png","slug":"rpn_regression1.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/smooth loss.png","slug":"smooth loss.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/smoothL1.jpg","slug":"smoothL1.jpg","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0},{"_id":"source/_posts/Siamese系列/差值3.png","slug":"差值3.png","post":"ckc4xbew3000ji0qv4m0rbgd8","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"ckc4xbevj0005i0qv8bew6d48","tag_id":"ckc4xbevf0003i0qvdmc35q8m","_id":"ckc4xbevn0008i0qvddpzayze"},{"post_id":"ckc4xbev30000i0qvh8et3qd0","tag_id":"ckc4xbevf0003i0qvdmc35q8m","_id":"ckc4xbevp000ai0qvf2ky665d"},{"post_id":"ckc4xbevn0009i0qveu53hnp5","tag_id":"ckc4xbevl0007i0qv25oi6zhx","_id":"ckc4xbevu000di0qvbjkra3nz"},{"post_id":"ckc4xbevb0002i0qvfygubo7z","tag_id":"ckc4xbevl0007i0qv25oi6zhx","_id":"ckc4xbevx000fi0qv9ph0cr5v"},{"post_id":"ckc4xbevp000bi0qvc3fvf3l8","tag_id":"ckc4xbevf0003i0qvdmc35q8m","_id":"ckc4xbew1000ii0qvcr3x4ec6"},{"post_id":"ckc4xbevv000ei0qv8f3s0nn7","tag_id":"ckc4xbevl0007i0qv25oi6zhx","_id":"ckc4xbew5000ki0qv4v2n8qp8"},{"post_id":"ckc4xbevh0004i0qv1xegcufu","tag_id":"ckc4xbevq000ci0qv6s6f83vv","_id":"ckc4xbew7000mi0qv3doo2qdb"},{"post_id":"ckc4xbevy000gi0qv5bgl288s","tag_id":"ckc4xbevl0007i0qv25oi6zhx","_id":"ckc4xbew9000pi0qv9d1bgwtu"},{"post_id":"ckc4xbew3000ji0qv4m0rbgd8","tag_id":"ckc4xbevl0007i0qv25oi6zhx","_id":"ckc4xbewb000ri0qv0ctb2syo"},{"post_id":"ckc4xbevl0006i0qvaw2scw4e","tag_id":"ckc4xbevl0007i0qv25oi6zhx","_id":"ckc4xbewc000ti0qvci0p78v1"},{"post_id":"ckc4xbewb000si0qv0kk23fte","tag_id":"ckc4xbew9000oi0qv0toqdzty","_id":"ckc4xbewe000wi0qv1cv2dkww"},{"post_id":"ckc4xbew6000li0qv9fhp84g2","tag_id":"ckc4xbew9000oi0qv0toqdzty","_id":"ckc4xbewf000yi0qv8ew8acaj"},{"post_id":"ckc4xbewe000xi0qvcamcf5z5","tag_id":"ckc4xbew9000oi0qv0toqdzty","_id":"ckc4xbewf0010i0qvf8cl2sg3"},{"post_id":"ckc4xbew8000ni0qv1qvb4gwf","tag_id":"ckc4xbew9000oi0qv0toqdzty","_id":"ckc4xbewf0011i0qvgivk4rcu"},{"post_id":"ckc4xbew9000qi0qv3xbude4d","tag_id":"ckc4xbewf000zi0qv80sya67h","_id":"ckc4xbewf0013i0qvem36ab0d"},{"post_id":"ckc4xbewc000ui0qvgbz64dzn","tag_id":"ckc4xbewf0012i0qv1g6078ik","_id":"ckc4xbewg0014i0qvhd0r9nc8"},{"post_id":"ckcm1vrbp00001kqvdqwc5zox","tag_id":"ckc4xbew9000oi0qv0toqdzty","_id":"ckcm1vrbv00011kqvelpfgw67"}],"Tag":[{"name":"信息安全","_id":"ckc4xbevf0003i0qvdmc35q8m"},{"name":"AI","_id":"ckc4xbevl0007i0qv25oi6zhx"},{"name":"Android","_id":"ckc4xbevq000ci0qv6s6f83vv"},{"name":"英语","_id":"ckc4xbew9000oi0qv0toqdzty"},{"name":"数学","_id":"ckc4xbewf000zi0qv80sya67h"},{"name":"杂项","_id":"ckc4xbewf0012i0qv1g6078ik"}]}}